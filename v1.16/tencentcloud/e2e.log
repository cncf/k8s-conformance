I0303 12:03:23.265814      23 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-187709168
I0303 12:03:23.265933      23 e2e.go:92] Starting e2e run "6aeb7322-f5a9-4ed7-a887-33f1e4217edf" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1583237001 - Will randomize all specs
Will run 276 of 4732 specs

Mar  3 12:03:23.277: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 12:03:23.280: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar  3 12:03:23.297: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar  3 12:03:23.333: INFO: 9 / 9 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar  3 12:03:23.333: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Mar  3 12:03:23.333: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar  3 12:03:23.342: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'ip-masq-agent' (0 seconds elapsed)
Mar  3 12:03:23.342: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'tke-bridge-agent' (0 seconds elapsed)
Mar  3 12:03:23.342: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'tke-cni-agent' (0 seconds elapsed)
Mar  3 12:03:23.342: INFO: e2e test version: v1.16.3
Mar  3 12:03:23.344: INFO: kube-apiserver version: v1.16.3-tke.2
Mar  3 12:03:23.344: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 12:03:23.351: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:03:23.351: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
Mar  3 12:03:23.409: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Mar  3 12:03:23.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 create -f - --namespace=kubectl-9573'
Mar  3 12:03:24.236: INFO: stderr: ""
Mar  3 12:03:24.236: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  3 12:03:25.241: INFO: Selector matched 1 pods for map[app:redis]
Mar  3 12:03:25.241: INFO: Found 0 / 1
Mar  3 12:03:26.241: INFO: Selector matched 1 pods for map[app:redis]
Mar  3 12:03:26.242: INFO: Found 0 / 1
Mar  3 12:03:27.242: INFO: Selector matched 1 pods for map[app:redis]
Mar  3 12:03:27.242: INFO: Found 0 / 1
Mar  3 12:03:28.241: INFO: Selector matched 1 pods for map[app:redis]
Mar  3 12:03:28.241: INFO: Found 0 / 1
Mar  3 12:03:29.244: INFO: Selector matched 1 pods for map[app:redis]
Mar  3 12:03:29.244: INFO: Found 0 / 1
Mar  3 12:03:30.242: INFO: Selector matched 1 pods for map[app:redis]
Mar  3 12:03:30.242: INFO: Found 0 / 1
Mar  3 12:03:31.242: INFO: Selector matched 1 pods for map[app:redis]
Mar  3 12:03:31.242: INFO: Found 1 / 1
Mar  3 12:03:31.242: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Mar  3 12:03:31.247: INFO: Selector matched 1 pods for map[app:redis]
Mar  3 12:03:31.247: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  3 12:03:31.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 patch pod redis-master-mr7c6 --namespace=kubectl-9573 -p {"metadata":{"annotations":{"x":"y"}}}'
Mar  3 12:03:31.339: INFO: stderr: ""
Mar  3 12:03:31.339: INFO: stdout: "pod/redis-master-mr7c6 patched\n"
STEP: checking annotations
Mar  3 12:03:31.344: INFO: Selector matched 1 pods for map[app:redis]
Mar  3 12:03:31.344: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:03:31.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9573" for this suite.
Mar  3 12:03:59.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:03:59.645: INFO: namespace kubectl-9573 deletion completed in 28.296524905s

• [SLOW TEST:36.294 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:03:59.645: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Mar  3 12:04:00.087: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Mar  3 12:04:02.147: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833840, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833840, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833840, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833840, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-66795bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  3 12:04:04.156: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833840, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833840, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833840, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833840, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-66795bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  3 12:04:06.155: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833840, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833840, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833840, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833840, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-66795bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  3 12:04:08.153: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833840, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833840, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833840, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833840, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-66795bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  3 12:04:11.168: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 12:04:11.173: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:04:12.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-3693" for this suite.
Mar  3 12:04:18.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:04:18.273: INFO: namespace crd-webhook-3693 deletion completed in 6.211355067s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:18.662 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:04:18.308: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 12:04:18.377: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-d3886933-8bb4-40ee-a277-5b0c8f0e0472" in namespace "security-context-test-747" to be "success or failure"
Mar  3 12:04:18.381: INFO: Pod "alpine-nnp-false-d3886933-8bb4-40ee-a277-5b0c8f0e0472": Phase="Pending", Reason="", readiness=false. Elapsed: 3.732774ms
Mar  3 12:04:20.385: INFO: Pod "alpine-nnp-false-d3886933-8bb4-40ee-a277-5b0c8f0e0472": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008352704s
Mar  3 12:04:22.390: INFO: Pod "alpine-nnp-false-d3886933-8bb4-40ee-a277-5b0c8f0e0472": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013502859s
Mar  3 12:04:24.395: INFO: Pod "alpine-nnp-false-d3886933-8bb4-40ee-a277-5b0c8f0e0472": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018559424s
Mar  3 12:04:24.395: INFO: Pod "alpine-nnp-false-d3886933-8bb4-40ee-a277-5b0c8f0e0472" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:04:24.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-747" for this suite.
Mar  3 12:04:30.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:04:30.724: INFO: namespace security-context-test-747 deletion completed in 6.306982379s

• [SLOW TEST:12.416 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:04:30.724: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar  3 12:04:34.859: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:04:34.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9255" for this suite.
Mar  3 12:04:40.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:04:41.174: INFO: namespace container-runtime-9255 deletion completed in 6.221082735s

• [SLOW TEST:10.450 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:04:41.174: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 12:04:41.258: INFO: Create a RollingUpdate DaemonSet
Mar  3 12:04:41.265: INFO: Check that daemon pods launch on every node of the cluster
Mar  3 12:04:41.277: INFO: Number of nodes with available pods: 0
Mar  3 12:04:41.277: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:04:42.288: INFO: Number of nodes with available pods: 0
Mar  3 12:04:42.288: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:04:43.289: INFO: Number of nodes with available pods: 0
Mar  3 12:04:43.289: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:04:44.290: INFO: Number of nodes with available pods: 0
Mar  3 12:04:44.290: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:04:45.290: INFO: Number of nodes with available pods: 0
Mar  3 12:04:45.290: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:04:46.287: INFO: Number of nodes with available pods: 0
Mar  3 12:04:46.287: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:04:47.290: INFO: Number of nodes with available pods: 0
Mar  3 12:04:47.290: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:04:48.293: INFO: Number of nodes with available pods: 0
Mar  3 12:04:48.293: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:04:49.289: INFO: Number of nodes with available pods: 0
Mar  3 12:04:49.289: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:04:50.289: INFO: Number of nodes with available pods: 0
Mar  3 12:04:50.289: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:04:51.293: INFO: Number of nodes with available pods: 0
Mar  3 12:04:51.293: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:04:52.295: INFO: Number of nodes with available pods: 0
Mar  3 12:04:52.295: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:04:53.302: INFO: Number of nodes with available pods: 0
Mar  3 12:04:53.302: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:04:54.288: INFO: Number of nodes with available pods: 2
Mar  3 12:04:54.288: INFO: Number of running nodes: 2, number of available pods: 2
Mar  3 12:04:54.288: INFO: Update the DaemonSet to trigger a rollout
Mar  3 12:04:54.309: INFO: Updating DaemonSet daemon-set
Mar  3 12:05:05.330: INFO: Roll back the DaemonSet before rollout is complete
Mar  3 12:05:05.350: INFO: Updating DaemonSet daemon-set
Mar  3 12:05:05.350: INFO: Make sure DaemonSet rollback is complete
Mar  3 12:05:05.355: INFO: Wrong image for pod: daemon-set-g9nl6. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Mar  3 12:05:05.355: INFO: Pod daemon-set-g9nl6 is not available
Mar  3 12:05:06.366: INFO: Wrong image for pod: daemon-set-g9nl6. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Mar  3 12:05:06.366: INFO: Pod daemon-set-g9nl6 is not available
Mar  3 12:05:07.365: INFO: Pod daemon-set-bbnp7 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2092, will wait for the garbage collector to delete the pods
Mar  3 12:05:07.472: INFO: Deleting DaemonSet.extensions daemon-set took: 33.093997ms
Mar  3 12:05:07.972: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.204502ms
Mar  3 12:05:09.977: INFO: Number of nodes with available pods: 0
Mar  3 12:05:09.977: INFO: Number of running nodes: 0, number of available pods: 0
Mar  3 12:05:09.984: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2092/daemonsets","resourceVersion":"1243241185"},"items":null}

Mar  3 12:05:09.988: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2092/pods","resourceVersion":"1243241185"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:05:10.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2092" for this suite.
Mar  3 12:05:16.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:05:16.336: INFO: namespace daemonsets-2092 deletion completed in 6.321679423s

• [SLOW TEST:35.162 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:05:16.337: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Mar  3 12:05:19.452: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:05:20.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1752" for this suite.
Mar  3 12:05:48.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:05:48.730: INFO: namespace replicaset-1752 deletion completed in 28.248636437s

• [SLOW TEST:32.393 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:05:48.730: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-91aff1c3-bd18-404a-986c-20911cb599c8
STEP: Creating a pod to test consume configMaps
Mar  3 12:05:48.811: INFO: Waiting up to 5m0s for pod "pod-configmaps-900fe3f5-8d05-4a77-9289-d9c661966cc4" in namespace "configmap-3461" to be "success or failure"
Mar  3 12:05:48.815: INFO: Pod "pod-configmaps-900fe3f5-8d05-4a77-9289-d9c661966cc4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.897702ms
Mar  3 12:05:50.820: INFO: Pod "pod-configmaps-900fe3f5-8d05-4a77-9289-d9c661966cc4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008842812s
Mar  3 12:05:52.825: INFO: Pod "pod-configmaps-900fe3f5-8d05-4a77-9289-d9c661966cc4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014053179s
STEP: Saw pod success
Mar  3 12:05:52.825: INFO: Pod "pod-configmaps-900fe3f5-8d05-4a77-9289-d9c661966cc4" satisfied condition "success or failure"
Mar  3 12:05:52.829: INFO: Trying to get logs from node 10.0.2.119 pod pod-configmaps-900fe3f5-8d05-4a77-9289-d9c661966cc4 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  3 12:05:52.865: INFO: Waiting for pod pod-configmaps-900fe3f5-8d05-4a77-9289-d9c661966cc4 to disappear
Mar  3 12:05:52.869: INFO: Pod pod-configmaps-900fe3f5-8d05-4a77-9289-d9c661966cc4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:05:52.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3461" for this suite.
Mar  3 12:05:58.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:05:59.081: INFO: namespace configmap-3461 deletion completed in 6.207050886s

• [SLOW TEST:10.350 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:05:59.081: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-2395819c-8b60-4a03-a965-0beef651733c
STEP: Creating a pod to test consume configMaps
Mar  3 12:05:59.217: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-457a84b1-5dbf-419f-bc3d-e8df0201afa5" in namespace "projected-4915" to be "success or failure"
Mar  3 12:05:59.244: INFO: Pod "pod-projected-configmaps-457a84b1-5dbf-419f-bc3d-e8df0201afa5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.296905ms
Mar  3 12:06:01.249: INFO: Pod "pod-projected-configmaps-457a84b1-5dbf-419f-bc3d-e8df0201afa5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031379814s
STEP: Saw pod success
Mar  3 12:06:01.249: INFO: Pod "pod-projected-configmaps-457a84b1-5dbf-419f-bc3d-e8df0201afa5" satisfied condition "success or failure"
Mar  3 12:06:01.343: INFO: Trying to get logs from node 10.0.2.119 pod pod-projected-configmaps-457a84b1-5dbf-419f-bc3d-e8df0201afa5 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  3 12:06:01.373: INFO: Waiting for pod pod-projected-configmaps-457a84b1-5dbf-419f-bc3d-e8df0201afa5 to disappear
Mar  3 12:06:01.377: INFO: Pod pod-projected-configmaps-457a84b1-5dbf-419f-bc3d-e8df0201afa5 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:06:01.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4915" for this suite.
Mar  3 12:06:07.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:06:07.611: INFO: namespace projected-4915 deletion completed in 6.226005911s

• [SLOW TEST:8.530 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:06:07.611: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  3 12:06:08.108: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  3 12:06:10.151: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833968, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833968, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833968, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833968, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7f4f78fb6b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  3 12:06:12.156: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833968, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833968, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833968, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833968, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7f4f78fb6b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  3 12:06:14.156: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833968, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833968, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833968, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718833968, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7f4f78fb6b\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  3 12:06:17.205: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 12:06:17.212: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Registering the custom resource webhook via the AdmissionRegistration API
Mar  3 12:06:17.947: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:06:18.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9925" for this suite.
Mar  3 12:06:24.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:06:24.990: INFO: namespace webhook-9925 deletion completed in 6.198016219s
STEP: Destroying namespace "webhook-9925-markers" for this suite.
Mar  3 12:06:31.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:06:31.300: INFO: namespace webhook-9925-markers deletion completed in 6.309841265s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:23.728 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:06:31.340: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:06:47.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9334" for this suite.
Mar  3 12:06:53.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:06:53.699: INFO: namespace resourcequota-9334 deletion completed in 6.219790642s

• [SLOW TEST:22.359 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:06:53.699: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Mar  3 12:06:53.771: INFO: Waiting up to 5m0s for pod "client-containers-d4cb5455-c2e2-4055-96ab-9343e3ecc6e6" in namespace "containers-54" to be "success or failure"
Mar  3 12:06:53.775: INFO: Pod "client-containers-d4cb5455-c2e2-4055-96ab-9343e3ecc6e6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.119564ms
Mar  3 12:06:55.839: INFO: Pod "client-containers-d4cb5455-c2e2-4055-96ab-9343e3ecc6e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.068432267s
STEP: Saw pod success
Mar  3 12:06:55.839: INFO: Pod "client-containers-d4cb5455-c2e2-4055-96ab-9343e3ecc6e6" satisfied condition "success or failure"
Mar  3 12:06:55.844: INFO: Trying to get logs from node 10.0.2.74 pod client-containers-d4cb5455-c2e2-4055-96ab-9343e3ecc6e6 container test-container: <nil>
STEP: delete the pod
Mar  3 12:06:55.875: INFO: Waiting for pod client-containers-d4cb5455-c2e2-4055-96ab-9343e3ecc6e6 to disappear
Mar  3 12:06:55.879: INFO: Pod client-containers-d4cb5455-c2e2-4055-96ab-9343e3ecc6e6 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:06:55.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-54" for this suite.
Mar  3 12:07:01.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:07:02.162: INFO: namespace containers-54 deletion completed in 6.278293537s

• [SLOW TEST:8.463 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:07:02.163: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Mar  3 12:07:02.226: INFO: Waiting up to 1m0s for all nodes to be ready
Mar  3 12:08:02.245: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 12:08:02.249: INFO: Starting informer...
STEP: Starting pod...
Mar  3 12:08:02.476: INFO: Pod is running on 10.0.2.74. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Mar  3 12:08:02.496: INFO: Pod wasn't evicted. Proceeding
Mar  3 12:08:02.496: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Mar  3 12:09:17.519: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:09:17.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-8478" for this suite.
Mar  3 12:09:45.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:09:45.728: INFO: namespace taint-single-pod-8478 deletion completed in 28.203244343s

• [SLOW TEST:163.565 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:09:45.728: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Mar  3 12:09:45.812: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Mar  3 12:09:59.973: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 12:10:03.682: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:10:18.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8161" for this suite.
Mar  3 12:10:24.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:10:24.406: INFO: namespace crd-publish-openapi-8161 deletion completed in 6.202479788s

• [SLOW TEST:38.678 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:10:24.407: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar  3 12:10:31.043: INFO: Successfully updated pod "pod-update-82e7161e-6a2d-4357-aba8-d83c143c10c3"
STEP: verifying the updated pod is in kubernetes
Mar  3 12:10:31.053: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:10:31.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9500" for this suite.
Mar  3 12:10:43.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:10:43.323: INFO: namespace pods-9500 deletion completed in 12.263876737s

• [SLOW TEST:18.916 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:10:43.323: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6414
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Mar  3 12:10:43.398: INFO: Found 0 stateful pods, waiting for 3
Mar  3 12:10:53.404: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  3 12:10:53.404: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  3 12:10:53.404: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar  3 12:10:53.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=statefulset-6414 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  3 12:10:53.631: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  3 12:10:53.631: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  3 12:10:53.631: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Mar  3 12:11:03.682: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Mar  3 12:11:13.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=statefulset-6414 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  3 12:11:13.944: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar  3 12:11:13.944: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  3 12:11:13.944: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  3 12:11:23.982: INFO: Waiting for StatefulSet statefulset-6414/ss2 to complete update
Mar  3 12:11:23.982: INFO: Waiting for Pod statefulset-6414/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Mar  3 12:11:23.982: INFO: Waiting for Pod statefulset-6414/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Mar  3 12:11:33.999: INFO: Waiting for StatefulSet statefulset-6414/ss2 to complete update
Mar  3 12:11:33.999: INFO: Waiting for Pod statefulset-6414/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Mar  3 12:11:33.999: INFO: Waiting for Pod statefulset-6414/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Mar  3 12:11:44.091: INFO: Waiting for StatefulSet statefulset-6414/ss2 to complete update
Mar  3 12:11:44.091: INFO: Waiting for Pod statefulset-6414/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Mar  3 12:11:53.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=statefulset-6414 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  3 12:11:54.196: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  3 12:11:54.196: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  3 12:11:54.196: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  3 12:12:04.248: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Mar  3 12:12:14.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=statefulset-6414 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  3 12:12:14.483: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar  3 12:12:14.483: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  3 12:12:14.483: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  3 12:12:24.511: INFO: Waiting for StatefulSet statefulset-6414/ss2 to complete update
Mar  3 12:12:24.511: INFO: Waiting for Pod statefulset-6414/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Mar  3 12:12:24.511: INFO: Waiting for Pod statefulset-6414/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Mar  3 12:12:24.511: INFO: Waiting for Pod statefulset-6414/ss2-2 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Mar  3 12:12:34.522: INFO: Waiting for StatefulSet statefulset-6414/ss2 to complete update
Mar  3 12:12:34.522: INFO: Waiting for Pod statefulset-6414/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Mar  3 12:12:34.522: INFO: Waiting for Pod statefulset-6414/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Mar  3 12:12:44.521: INFO: Deleting all statefulset in ns statefulset-6414
Mar  3 12:12:44.526: INFO: Scaling statefulset ss2 to 0
Mar  3 12:13:24.548: INFO: Waiting for statefulset status.replicas updated to 0
Mar  3 12:13:24.552: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:13:24.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6414" for this suite.
Mar  3 12:13:32.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:13:32.811: INFO: namespace statefulset-6414 deletion completed in 8.227064965s

• [SLOW TEST:169.488 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:13:32.811: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-285adbde-096d-486d-b5ce-ff66beba5703
STEP: Creating a pod to test consume configMaps
Mar  3 12:13:32.876: INFO: Waiting up to 5m0s for pod "pod-configmaps-de60d317-8213-4557-9519-c8dd6be76443" in namespace "configmap-2875" to be "success or failure"
Mar  3 12:13:32.880: INFO: Pod "pod-configmaps-de60d317-8213-4557-9519-c8dd6be76443": Phase="Pending", Reason="", readiness=false. Elapsed: 3.939459ms
Mar  3 12:13:34.918: INFO: Pod "pod-configmaps-de60d317-8213-4557-9519-c8dd6be76443": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042036767s
STEP: Saw pod success
Mar  3 12:13:34.918: INFO: Pod "pod-configmaps-de60d317-8213-4557-9519-c8dd6be76443" satisfied condition "success or failure"
Mar  3 12:13:34.923: INFO: Trying to get logs from node 10.0.2.119 pod pod-configmaps-de60d317-8213-4557-9519-c8dd6be76443 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  3 12:13:34.955: INFO: Waiting for pod pod-configmaps-de60d317-8213-4557-9519-c8dd6be76443 to disappear
Mar  3 12:13:34.959: INFO: Pod pod-configmaps-de60d317-8213-4557-9519-c8dd6be76443 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:13:34.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2875" for this suite.
Mar  3 12:13:40.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:13:41.165: INFO: namespace configmap-2875 deletion completed in 6.20146721s

• [SLOW TEST:8.355 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:13:41.166: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  3 12:13:41.228: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b53f2b82-10df-4989-bed4-81af4b6f7d79" in namespace "projected-6236" to be "success or failure"
Mar  3 12:13:41.233: INFO: Pod "downwardapi-volume-b53f2b82-10df-4989-bed4-81af4b6f7d79": Phase="Pending", Reason="", readiness=false. Elapsed: 4.872449ms
Mar  3 12:13:43.239: INFO: Pod "downwardapi-volume-b53f2b82-10df-4989-bed4-81af4b6f7d79": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01046605s
STEP: Saw pod success
Mar  3 12:13:43.239: INFO: Pod "downwardapi-volume-b53f2b82-10df-4989-bed4-81af4b6f7d79" satisfied condition "success or failure"
Mar  3 12:13:43.244: INFO: Trying to get logs from node 10.0.2.119 pod downwardapi-volume-b53f2b82-10df-4989-bed4-81af4b6f7d79 container client-container: <nil>
STEP: delete the pod
Mar  3 12:13:43.279: INFO: Waiting for pod downwardapi-volume-b53f2b82-10df-4989-bed4-81af4b6f7d79 to disappear
Mar  3 12:13:43.282: INFO: Pod downwardapi-volume-b53f2b82-10df-4989-bed4-81af4b6f7d79 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:13:43.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6236" for this suite.
Mar  3 12:13:49.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:13:49.546: INFO: namespace projected-6236 deletion completed in 6.254478365s

• [SLOW TEST:8.381 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:13:49.546: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  3 12:13:49.967: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  3 12:13:52.999: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
Mar  3 12:13:53.041: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource definition that should be denied by the webhook
Mar  3 12:13:53.152: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:13:53.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4707" for this suite.
Mar  3 12:13:59.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:13:59.454: INFO: namespace webhook-4707 deletion completed in 6.275549752s
STEP: Destroying namespace "webhook-4707-markers" for this suite.
Mar  3 12:14:05.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:14:05.679: INFO: namespace webhook-4707-markers deletion completed in 6.224833821s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.165 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:14:05.712: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Mar  3 12:14:05.815: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-610 /api/v1/namespaces/watch-610/configmaps/e2e-watch-test-label-changed 4f0160ea-cf02-4656-92fc-7194dd73e206 1243348586 0 2020-03-03 12:14:05 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  3 12:14:05.815: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-610 /api/v1/namespaces/watch-610/configmaps/e2e-watch-test-label-changed 4f0160ea-cf02-4656-92fc-7194dd73e206 1243348590 0 2020-03-03 12:14:05 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar  3 12:14:05.815: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-610 /api/v1/namespaces/watch-610/configmaps/e2e-watch-test-label-changed 4f0160ea-cf02-4656-92fc-7194dd73e206 1243348594 0 2020-03-03 12:14:05 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Mar  3 12:14:15.866: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-610 /api/v1/namespaces/watch-610/configmaps/e2e-watch-test-label-changed 4f0160ea-cf02-4656-92fc-7194dd73e206 1243350573 0 2020-03-03 12:14:05 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  3 12:14:15.866: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-610 /api/v1/namespaces/watch-610/configmaps/e2e-watch-test-label-changed 4f0160ea-cf02-4656-92fc-7194dd73e206 1243350576 0 2020-03-03 12:14:05 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar  3 12:14:15.866: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-610 /api/v1/namespaces/watch-610/configmaps/e2e-watch-test-label-changed 4f0160ea-cf02-4656-92fc-7194dd73e206 1243350581 0 2020-03-03 12:14:05 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:14:15.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-610" for this suite.
Mar  3 12:14:21.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:14:22.090: INFO: namespace watch-610 deletion completed in 6.218467237s

• [SLOW TEST:16.378 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:14:22.090: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Mar  3 12:14:22.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 create -f - --namespace=kubectl-7274'
Mar  3 12:14:22.753: INFO: stderr: ""
Mar  3 12:14:22.753: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  3 12:14:22.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7274'
Mar  3 12:14:22.837: INFO: stderr: ""
Mar  3 12:14:22.837: INFO: stdout: "update-demo-nautilus-lwm88 update-demo-nautilus-vrjv2 "
Mar  3 12:14:22.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-lwm88 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7274'
Mar  3 12:14:22.924: INFO: stderr: ""
Mar  3 12:14:22.924: INFO: stdout: ""
Mar  3 12:14:22.924: INFO: update-demo-nautilus-lwm88 is created but not running
Mar  3 12:14:27.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7274'
Mar  3 12:14:28.012: INFO: stderr: ""
Mar  3 12:14:28.012: INFO: stdout: "update-demo-nautilus-lwm88 update-demo-nautilus-vrjv2 "
Mar  3 12:14:28.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-lwm88 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7274'
Mar  3 12:14:28.107: INFO: stderr: ""
Mar  3 12:14:28.107: INFO: stdout: "true"
Mar  3 12:14:28.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-lwm88 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7274'
Mar  3 12:14:28.189: INFO: stderr: ""
Mar  3 12:14:28.189: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  3 12:14:28.189: INFO: validating pod update-demo-nautilus-lwm88
Mar  3 12:14:28.197: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  3 12:14:28.197: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  3 12:14:28.197: INFO: update-demo-nautilus-lwm88 is verified up and running
Mar  3 12:14:28.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-vrjv2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7274'
Mar  3 12:14:28.278: INFO: stderr: ""
Mar  3 12:14:28.278: INFO: stdout: "true"
Mar  3 12:14:28.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-vrjv2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7274'
Mar  3 12:14:28.356: INFO: stderr: ""
Mar  3 12:14:28.356: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  3 12:14:28.356: INFO: validating pod update-demo-nautilus-vrjv2
Mar  3 12:14:28.363: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  3 12:14:28.363: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  3 12:14:28.363: INFO: update-demo-nautilus-vrjv2 is verified up and running
STEP: using delete to clean up resources
Mar  3 12:14:28.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 delete --grace-period=0 --force -f - --namespace=kubectl-7274'
Mar  3 12:14:28.454: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  3 12:14:28.454: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar  3 12:14:28.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7274'
Mar  3 12:14:28.541: INFO: stderr: "No resources found in kubectl-7274 namespace.\n"
Mar  3 12:14:28.541: INFO: stdout: ""
Mar  3 12:14:28.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods -l name=update-demo --namespace=kubectl-7274 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  3 12:14:28.638: INFO: stderr: ""
Mar  3 12:14:28.638: INFO: stdout: "update-demo-nautilus-lwm88\nupdate-demo-nautilus-vrjv2\n"
Mar  3 12:14:29.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7274'
Mar  3 12:14:29.248: INFO: stderr: "No resources found in kubectl-7274 namespace.\n"
Mar  3 12:14:29.248: INFO: stdout: ""
Mar  3 12:14:29.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods -l name=update-demo --namespace=kubectl-7274 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  3 12:14:29.344: INFO: stderr: ""
Mar  3 12:14:29.344: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:14:29.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7274" for this suite.
Mar  3 12:14:41.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:14:41.563: INFO: namespace kubectl-7274 deletion completed in 12.212172939s

• [SLOW TEST:19.473 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:14:41.563: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  3 12:14:42.146: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  3 12:14:45.180: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Mar  3 12:14:49.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 attach --namespace=webhook-9590 to-be-attached-pod -i -c=container1'
Mar  3 12:14:49.324: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:14:49.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9590" for this suite.
Mar  3 12:15:01.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:15:01.709: INFO: namespace webhook-9590 deletion completed in 12.369436176s
STEP: Destroying namespace "webhook-9590-markers" for this suite.
Mar  3 12:15:07.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:15:07.923: INFO: namespace webhook-9590-markers deletion completed in 6.21314294s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:26.391 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:15:07.954: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:15:11.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-410" for this suite.
Mar  3 12:15:39.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:15:39.318: INFO: namespace replication-controller-410 deletion completed in 28.210190014s

• [SLOW TEST:31.365 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:15:39.318: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  3 12:15:39.381: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a4b52544-2964-4373-b407-55a300ba1942" in namespace "downward-api-6078" to be "success or failure"
Mar  3 12:15:39.386: INFO: Pod "downwardapi-volume-a4b52544-2964-4373-b407-55a300ba1942": Phase="Pending", Reason="", readiness=false. Elapsed: 4.160014ms
Mar  3 12:15:41.390: INFO: Pod "downwardapi-volume-a4b52544-2964-4373-b407-55a300ba1942": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008901884s
STEP: Saw pod success
Mar  3 12:15:41.390: INFO: Pod "downwardapi-volume-a4b52544-2964-4373-b407-55a300ba1942" satisfied condition "success or failure"
Mar  3 12:15:41.394: INFO: Trying to get logs from node 10.0.2.119 pod downwardapi-volume-a4b52544-2964-4373-b407-55a300ba1942 container client-container: <nil>
STEP: delete the pod
Mar  3 12:15:41.423: INFO: Waiting for pod downwardapi-volume-a4b52544-2964-4373-b407-55a300ba1942 to disappear
Mar  3 12:15:41.433: INFO: Pod downwardapi-volume-a4b52544-2964-4373-b407-55a300ba1942 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:15:41.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6078" for this suite.
Mar  3 12:15:47.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:15:47.726: INFO: namespace downward-api-6078 deletion completed in 6.288405905s

• [SLOW TEST:8.408 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:15:47.726: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:16:00.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3063" for this suite.
Mar  3 12:16:06.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:16:07.101: INFO: namespace resourcequota-3063 deletion completed in 6.195441494s

• [SLOW TEST:19.375 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:16:07.101: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar  3 12:16:07.199: INFO: Waiting up to 5m0s for pod "pod-193268bf-8ddb-416d-8f54-83c138ab3a92" in namespace "emptydir-6096" to be "success or failure"
Mar  3 12:16:07.207: INFO: Pod "pod-193268bf-8ddb-416d-8f54-83c138ab3a92": Phase="Pending", Reason="", readiness=false. Elapsed: 7.494921ms
Mar  3 12:16:09.214: INFO: Pod "pod-193268bf-8ddb-416d-8f54-83c138ab3a92": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014565255s
Mar  3 12:16:11.219: INFO: Pod "pod-193268bf-8ddb-416d-8f54-83c138ab3a92": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019500701s
STEP: Saw pod success
Mar  3 12:16:11.219: INFO: Pod "pod-193268bf-8ddb-416d-8f54-83c138ab3a92" satisfied condition "success or failure"
Mar  3 12:16:11.226: INFO: Trying to get logs from node 10.0.2.74 pod pod-193268bf-8ddb-416d-8f54-83c138ab3a92 container test-container: <nil>
STEP: delete the pod
Mar  3 12:16:11.260: INFO: Waiting for pod pod-193268bf-8ddb-416d-8f54-83c138ab3a92 to disappear
Mar  3 12:16:11.265: INFO: Pod pod-193268bf-8ddb-416d-8f54-83c138ab3a92 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:16:11.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6096" for this suite.
Mar  3 12:16:17.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:16:17.539: INFO: namespace emptydir-6096 deletion completed in 6.269465254s

• [SLOW TEST:10.438 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:16:17.539: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Mar  3 12:16:17.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 cluster-info'
Mar  3 12:16:17.678: INFO: stderr: ""
Mar  3 12:16:17.678: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.27.252.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.27.252.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns-tcp/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:16:17.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6368" for this suite.
Mar  3 12:16:23.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:16:23.909: INFO: namespace kubectl-6368 deletion completed in 6.221703658s

• [SLOW TEST:6.370 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:16:23.909: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar  3 12:16:30.100: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8646 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  3 12:16:30.100: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 12:16:30.213: INFO: Exec stderr: ""
Mar  3 12:16:30.213: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8646 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  3 12:16:30.213: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 12:16:30.315: INFO: Exec stderr: ""
Mar  3 12:16:30.315: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8646 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  3 12:16:30.315: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 12:16:30.423: INFO: Exec stderr: ""
Mar  3 12:16:30.423: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8646 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  3 12:16:30.423: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 12:16:30.535: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar  3 12:16:30.535: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8646 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  3 12:16:30.535: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 12:16:30.638: INFO: Exec stderr: ""
Mar  3 12:16:30.638: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8646 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  3 12:16:30.638: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 12:16:30.745: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar  3 12:16:30.745: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8646 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  3 12:16:30.745: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 12:16:30.855: INFO: Exec stderr: ""
Mar  3 12:16:30.855: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8646 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  3 12:16:30.855: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 12:16:30.963: INFO: Exec stderr: ""
Mar  3 12:16:30.963: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8646 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  3 12:16:30.963: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 12:16:31.073: INFO: Exec stderr: ""
Mar  3 12:16:31.073: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8646 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  3 12:16:31.073: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 12:16:31.212: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:16:31.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-8646" for this suite.
Mar  3 12:17:17.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:17:17.446: INFO: namespace e2e-kubelet-etc-hosts-8646 deletion completed in 46.22775851s

• [SLOW TEST:53.536 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:17:17.446: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar  3 12:17:17.514: INFO: Waiting up to 5m0s for pod "pod-771d94a0-104c-4c15-84ee-4a87e8b63a86" in namespace "emptydir-7554" to be "success or failure"
Mar  3 12:17:17.518: INFO: Pod "pod-771d94a0-104c-4c15-84ee-4a87e8b63a86": Phase="Pending", Reason="", readiness=false. Elapsed: 3.841809ms
Mar  3 12:17:19.525: INFO: Pod "pod-771d94a0-104c-4c15-84ee-4a87e8b63a86": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010507291s
STEP: Saw pod success
Mar  3 12:17:19.525: INFO: Pod "pod-771d94a0-104c-4c15-84ee-4a87e8b63a86" satisfied condition "success or failure"
Mar  3 12:17:19.531: INFO: Trying to get logs from node 10.0.2.119 pod pod-771d94a0-104c-4c15-84ee-4a87e8b63a86 container test-container: <nil>
STEP: delete the pod
Mar  3 12:17:19.565: INFO: Waiting for pod pod-771d94a0-104c-4c15-84ee-4a87e8b63a86 to disappear
Mar  3 12:17:19.573: INFO: Pod pod-771d94a0-104c-4c15-84ee-4a87e8b63a86 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:17:19.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7554" for this suite.
Mar  3 12:17:25.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:17:25.768: INFO: namespace emptydir-7554 deletion completed in 6.190835623s

• [SLOW TEST:8.322 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:17:25.768: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-e1413f0c-dafe-44a3-9f7a-61c93c3dcd52
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:17:27.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5310" for this suite.
Mar  3 12:17:49.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:17:50.247: INFO: namespace configmap-5310 deletion completed in 22.296116162s

• [SLOW TEST:24.478 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:17:50.247: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-60a4bcf8-cb12-44eb-a859-57ece51bc78a
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:17:50.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2829" for this suite.
Mar  3 12:17:56.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:17:56.554: INFO: namespace configmap-2829 deletion completed in 6.247880467s

• [SLOW TEST:6.307 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:17:56.554: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Mar  3 12:17:57.158: INFO: created pod pod-service-account-defaultsa
Mar  3 12:17:57.158: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar  3 12:17:57.165: INFO: created pod pod-service-account-mountsa
Mar  3 12:17:57.165: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar  3 12:17:57.174: INFO: created pod pod-service-account-nomountsa
Mar  3 12:17:57.174: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar  3 12:17:57.180: INFO: created pod pod-service-account-defaultsa-mountspec
Mar  3 12:17:57.180: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar  3 12:17:57.190: INFO: created pod pod-service-account-mountsa-mountspec
Mar  3 12:17:57.190: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar  3 12:17:57.199: INFO: created pod pod-service-account-nomountsa-mountspec
Mar  3 12:17:57.199: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar  3 12:17:57.209: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar  3 12:17:57.209: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar  3 12:17:57.216: INFO: created pod pod-service-account-mountsa-nomountspec
Mar  3 12:17:57.216: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar  3 12:17:57.225: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar  3 12:17:57.225: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:17:57.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8540" for this suite.
Mar  3 12:18:03.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:18:03.459: INFO: namespace svcaccounts-8540 deletion completed in 6.223860453s

• [SLOW TEST:6.905 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:18:03.459: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-947
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Mar  3 12:18:03.546: INFO: Found 0 stateful pods, waiting for 3
Mar  3 12:18:13.552: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  3 12:18:13.552: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  3 12:18:13.552: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Mar  3 12:18:13.591: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Mar  3 12:18:23.669: INFO: Updating stateful set ss2
Mar  3 12:18:23.680: INFO: Waiting for Pod statefulset-947/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Mar  3 12:18:33.742: INFO: Found 2 stateful pods, waiting for 3
Mar  3 12:18:43.751: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  3 12:18:43.751: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  3 12:18:43.751: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Mar  3 12:18:43.782: INFO: Updating stateful set ss2
Mar  3 12:18:43.793: INFO: Waiting for Pod statefulset-947/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Mar  3 12:18:53.825: INFO: Updating stateful set ss2
Mar  3 12:18:53.839: INFO: Waiting for StatefulSet statefulset-947/ss2 to complete update
Mar  3 12:18:53.839: INFO: Waiting for Pod statefulset-947/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Mar  3 12:19:03.851: INFO: Deleting all statefulset in ns statefulset-947
Mar  3 12:19:03.855: INFO: Scaling statefulset ss2 to 0
Mar  3 12:19:33.959: INFO: Waiting for statefulset status.replicas updated to 0
Mar  3 12:19:33.964: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:19:33.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-947" for this suite.
Mar  3 12:19:42.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:19:42.243: INFO: namespace statefulset-947 deletion completed in 8.253584635s

• [SLOW TEST:98.784 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:19:42.243: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar  3 12:19:44.360: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:19:44.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9024" for this suite.
Mar  3 12:19:50.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:19:50.595: INFO: namespace container-runtime-9024 deletion completed in 6.204501848s

• [SLOW TEST:8.352 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:19:50.595: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-0640d07f-563c-4d96-9da6-1923e59c4709
STEP: Creating a pod to test consume secrets
Mar  3 12:19:50.719: INFO: Waiting up to 5m0s for pod "pod-secrets-527ac5a5-562e-4679-879c-bdad181676ef" in namespace "secrets-1295" to be "success or failure"
Mar  3 12:19:50.724: INFO: Pod "pod-secrets-527ac5a5-562e-4679-879c-bdad181676ef": Phase="Pending", Reason="", readiness=false. Elapsed: 4.541441ms
Mar  3 12:19:52.729: INFO: Pod "pod-secrets-527ac5a5-562e-4679-879c-bdad181676ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009557247s
STEP: Saw pod success
Mar  3 12:19:52.729: INFO: Pod "pod-secrets-527ac5a5-562e-4679-879c-bdad181676ef" satisfied condition "success or failure"
Mar  3 12:19:52.733: INFO: Trying to get logs from node 10.0.2.119 pod pod-secrets-527ac5a5-562e-4679-879c-bdad181676ef container secret-volume-test: <nil>
STEP: delete the pod
Mar  3 12:19:52.767: INFO: Waiting for pod pod-secrets-527ac5a5-562e-4679-879c-bdad181676ef to disappear
Mar  3 12:19:52.770: INFO: Pod pod-secrets-527ac5a5-562e-4679-879c-bdad181676ef no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:19:52.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1295" for this suite.
Mar  3 12:19:58.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:19:59.046: INFO: namespace secrets-1295 deletion completed in 6.270755942s
STEP: Destroying namespace "secret-namespace-120" for this suite.
Mar  3 12:20:05.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:20:05.301: INFO: namespace secret-namespace-120 deletion completed in 6.254749614s

• [SLOW TEST:14.705 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:20:05.301: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Mar  3 12:20:05.413: INFO: Waiting up to 5m0s for pod "downward-api-baef95ec-067e-4d38-b8f3-93c684d8eab3" in namespace "downward-api-6915" to be "success or failure"
Mar  3 12:20:05.417: INFO: Pod "downward-api-baef95ec-067e-4d38-b8f3-93c684d8eab3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.223983ms
Mar  3 12:20:07.422: INFO: Pod "downward-api-baef95ec-067e-4d38-b8f3-93c684d8eab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009280051s
STEP: Saw pod success
Mar  3 12:20:07.422: INFO: Pod "downward-api-baef95ec-067e-4d38-b8f3-93c684d8eab3" satisfied condition "success or failure"
Mar  3 12:20:07.426: INFO: Trying to get logs from node 10.0.2.74 pod downward-api-baef95ec-067e-4d38-b8f3-93c684d8eab3 container dapi-container: <nil>
STEP: delete the pod
Mar  3 12:20:07.469: INFO: Waiting for pod downward-api-baef95ec-067e-4d38-b8f3-93c684d8eab3 to disappear
Mar  3 12:20:07.473: INFO: Pod downward-api-baef95ec-067e-4d38-b8f3-93c684d8eab3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:20:07.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6915" for this suite.
Mar  3 12:20:13.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:20:13.714: INFO: namespace downward-api-6915 deletion completed in 6.235682209s

• [SLOW TEST:8.413 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:20:13.715: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:20:18.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6612" for this suite.
Mar  3 12:20:25.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:20:25.212: INFO: namespace watch-6612 deletion completed in 6.288293642s

• [SLOW TEST:11.497 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:20:25.212: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 12:20:25.299: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:20:25.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-74" for this suite.
Mar  3 12:20:32.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:20:32.245: INFO: namespace custom-resource-definition-74 deletion completed in 6.306528782s

• [SLOW TEST:7.033 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:20:32.246: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Mar  3 12:20:42.400: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:20:42.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0303 12:20:42.400945      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-4919" for this suite.
Mar  3 12:20:48.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:20:48.662: INFO: namespace gc-4919 deletion completed in 6.255491376s

• [SLOW TEST:16.416 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:20:48.662: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  3 12:20:49.470: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  3 12:20:51.488: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718834849, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718834849, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718834849, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718834849, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7f4f78fb6b\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  3 12:20:54.534: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 12:20:54.540: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1510-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:20:55.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6189" for this suite.
Mar  3 12:21:01.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:21:02.062: INFO: namespace webhook-6189 deletion completed in 6.318271069s
STEP: Destroying namespace "webhook-6189-markers" for this suite.
Mar  3 12:21:08.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:21:08.294: INFO: namespace webhook-6189-markers deletion completed in 6.231640058s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.675 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:21:08.338: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-70996922-aaf5-4c31-95de-f8e6b086eff6
STEP: Creating secret with name s-test-opt-upd-8b57c5fe-1550-4efa-aa7b-04bd0c893ccc
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-70996922-aaf5-4c31-95de-f8e6b086eff6
STEP: Updating secret s-test-opt-upd-8b57c5fe-1550-4efa-aa7b-04bd0c893ccc
STEP: Creating secret with name s-test-opt-create-ad2d2299-995f-4926-a78f-7fcd85ebbe03
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:22:45.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2109" for this suite.
Mar  3 12:22:57.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:22:57.762: INFO: namespace secrets-2109 deletion completed in 12.226101818s

• [SLOW TEST:109.424 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:22:57.762: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7898.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7898.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  3 12:23:21.888: INFO: DNS probes using dns-7898/dns-test-3caa1256-238b-4ba7-b2cc-8ce0fe33361b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:23:21.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7898" for this suite.
Mar  3 12:23:27.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:23:28.161: INFO: namespace dns-7898 deletion completed in 6.249416486s

• [SLOW TEST:30.399 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:23:28.162: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Mar  3 12:23:28.227: INFO: Pod name pod-release: Found 0 pods out of 1
Mar  3 12:23:33.233: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:23:34.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7109" for this suite.
Mar  3 12:23:40.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:23:40.585: INFO: namespace replication-controller-7109 deletion completed in 6.32407259s

• [SLOW TEST:12.423 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:23:40.586: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:24:40.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9320" for this suite.
Mar  3 12:24:52.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:24:52.947: INFO: namespace container-probe-9320 deletion completed in 12.271611434s

• [SLOW TEST:72.361 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:24:52.947: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar  3 12:24:53.012: INFO: Waiting up to 5m0s for pod "pod-3fb2977f-7859-4452-8b83-c31f328d9c3a" in namespace "emptydir-464" to be "success or failure"
Mar  3 12:24:53.017: INFO: Pod "pod-3fb2977f-7859-4452-8b83-c31f328d9c3a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.20203ms
Mar  3 12:24:55.022: INFO: Pod "pod-3fb2977f-7859-4452-8b83-c31f328d9c3a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009976637s
Mar  3 12:24:57.029: INFO: Pod "pod-3fb2977f-7859-4452-8b83-c31f328d9c3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016971325s
STEP: Saw pod success
Mar  3 12:24:57.029: INFO: Pod "pod-3fb2977f-7859-4452-8b83-c31f328d9c3a" satisfied condition "success or failure"
Mar  3 12:24:57.035: INFO: Trying to get logs from node 10.0.2.74 pod pod-3fb2977f-7859-4452-8b83-c31f328d9c3a container test-container: <nil>
STEP: delete the pod
Mar  3 12:24:57.068: INFO: Waiting for pod pod-3fb2977f-7859-4452-8b83-c31f328d9c3a to disappear
Mar  3 12:24:57.072: INFO: Pod pod-3fb2977f-7859-4452-8b83-c31f328d9c3a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:24:57.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-464" for this suite.
Mar  3 12:25:03.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:25:03.372: INFO: namespace emptydir-464 deletion completed in 6.292913492s

• [SLOW TEST:10.425 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:25:03.372: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-0eb06c24-7161-4a29-963d-c8db8c362bc1
STEP: Creating a pod to test consume secrets
Mar  3 12:25:03.445: INFO: Waiting up to 5m0s for pod "pod-secrets-c92621f9-7bb0-4bb8-a5c3-11cdc287e2a1" in namespace "secrets-6724" to be "success or failure"
Mar  3 12:25:03.449: INFO: Pod "pod-secrets-c92621f9-7bb0-4bb8-a5c3-11cdc287e2a1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0413ms
Mar  3 12:25:05.454: INFO: Pod "pod-secrets-c92621f9-7bb0-4bb8-a5c3-11cdc287e2a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009135357s
STEP: Saw pod success
Mar  3 12:25:05.454: INFO: Pod "pod-secrets-c92621f9-7bb0-4bb8-a5c3-11cdc287e2a1" satisfied condition "success or failure"
Mar  3 12:25:05.459: INFO: Trying to get logs from node 10.0.2.74 pod pod-secrets-c92621f9-7bb0-4bb8-a5c3-11cdc287e2a1 container secret-volume-test: <nil>
STEP: delete the pod
Mar  3 12:25:05.489: INFO: Waiting for pod pod-secrets-c92621f9-7bb0-4bb8-a5c3-11cdc287e2a1 to disappear
Mar  3 12:25:05.493: INFO: Pod pod-secrets-c92621f9-7bb0-4bb8-a5c3-11cdc287e2a1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:25:05.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6724" for this suite.
Mar  3 12:25:11.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:25:11.789: INFO: namespace secrets-6724 deletion completed in 6.290853687s

• [SLOW TEST:8.416 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:25:11.789: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar  3 12:25:16.089: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  3 12:25:16.096: INFO: Pod pod-with-prestop-http-hook still exists
Mar  3 12:25:18.096: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  3 12:25:18.102: INFO: Pod pod-with-prestop-http-hook still exists
Mar  3 12:25:20.097: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  3 12:25:20.102: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:25:20.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6989" for this suite.
Mar  3 12:25:48.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:25:48.378: INFO: namespace container-lifecycle-hook-6989 deletion completed in 28.260130937s

• [SLOW TEST:36.589 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:25:48.379: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Mar  3 12:26:18.504: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:26:18.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0303 12:26:18.504550      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-5590" for this suite.
Mar  3 12:26:24.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:26:24.713: INFO: namespace gc-5590 deletion completed in 6.20415706s

• [SLOW TEST:36.334 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:26:24.714: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Mar  3 12:26:24.770: INFO: namespace kubectl-4917
Mar  3 12:26:24.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 create -f - --namespace=kubectl-4917'
Mar  3 12:26:25.374: INFO: stderr: ""
Mar  3 12:26:25.374: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  3 12:26:26.382: INFO: Selector matched 1 pods for map[app:redis]
Mar  3 12:26:26.382: INFO: Found 0 / 1
Mar  3 12:26:27.380: INFO: Selector matched 1 pods for map[app:redis]
Mar  3 12:26:27.380: INFO: Found 0 / 1
Mar  3 12:26:28.379: INFO: Selector matched 1 pods for map[app:redis]
Mar  3 12:26:28.379: INFO: Found 0 / 1
Mar  3 12:26:29.380: INFO: Selector matched 1 pods for map[app:redis]
Mar  3 12:26:29.380: INFO: Found 0 / 1
Mar  3 12:26:30.380: INFO: Selector matched 1 pods for map[app:redis]
Mar  3 12:26:30.380: INFO: Found 0 / 1
Mar  3 12:26:31.380: INFO: Selector matched 1 pods for map[app:redis]
Mar  3 12:26:31.380: INFO: Found 1 / 1
Mar  3 12:26:31.380: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  3 12:26:31.390: INFO: Selector matched 1 pods for map[app:redis]
Mar  3 12:26:31.390: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  3 12:26:31.390: INFO: wait on redis-master startup in kubectl-4917 
Mar  3 12:26:31.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 logs redis-master-zblfj redis-master --namespace=kubectl-4917'
Mar  3 12:26:31.496: INFO: stderr: ""
Mar  3 12:26:31.496: INFO: stdout: "1:C 03 Mar 2020 12:26:30.759 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 03 Mar 2020 12:26:30.759 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 03 Mar 2020 12:26:30.759 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 03 Mar 2020 12:26:30.761 * Running mode=standalone, port=6379.\n1:M 03 Mar 2020 12:26:30.761 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Mar 2020 12:26:30.761 # Server initialized\n1:M 03 Mar 2020 12:26:30.761 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Mar 2020 12:26:30.761 * Ready to accept connections\n"
STEP: exposing RC
Mar  3 12:26:31.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-4917'
Mar  3 12:26:31.614: INFO: stderr: ""
Mar  3 12:26:31.614: INFO: stdout: "service/rm2 exposed\n"
Mar  3 12:26:31.620: INFO: Service rm2 in namespace kubectl-4917 found.
STEP: exposing service
Mar  3 12:26:33.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-4917'
Mar  3 12:26:33.744: INFO: stderr: ""
Mar  3 12:26:33.744: INFO: stdout: "service/rm3 exposed\n"
Mar  3 12:26:33.750: INFO: Service rm3 in namespace kubectl-4917 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:26:35.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4917" for this suite.
Mar  3 12:26:47.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:26:48.193: INFO: namespace kubectl-4917 deletion completed in 12.423361797s

• [SLOW TEST:23.479 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:26:48.193: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:27:04.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1589" for this suite.
Mar  3 12:27:10.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:27:10.937: INFO: namespace resourcequota-1589 deletion completed in 6.291844745s

• [SLOW TEST:22.744 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:27:10.938: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Mar  3 12:27:11.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 create -f - --namespace=kubectl-2687'
Mar  3 12:27:11.210: INFO: stderr: ""
Mar  3 12:27:11.210: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  3 12:27:11.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2687'
Mar  3 12:27:11.316: INFO: stderr: ""
Mar  3 12:27:11.316: INFO: stdout: "update-demo-nautilus-68hvf update-demo-nautilus-d9kf2 "
Mar  3 12:27:11.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-68hvf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2687'
Mar  3 12:27:11.399: INFO: stderr: ""
Mar  3 12:27:11.399: INFO: stdout: ""
Mar  3 12:27:11.399: INFO: update-demo-nautilus-68hvf is created but not running
Mar  3 12:27:16.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2687'
Mar  3 12:27:16.515: INFO: stderr: ""
Mar  3 12:27:16.515: INFO: stdout: "update-demo-nautilus-68hvf update-demo-nautilus-d9kf2 "
Mar  3 12:27:16.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-68hvf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2687'
Mar  3 12:27:16.605: INFO: stderr: ""
Mar  3 12:27:16.605: INFO: stdout: "true"
Mar  3 12:27:16.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-68hvf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2687'
Mar  3 12:27:16.692: INFO: stderr: ""
Mar  3 12:27:16.692: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  3 12:27:16.692: INFO: validating pod update-demo-nautilus-68hvf
Mar  3 12:27:16.699: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  3 12:27:16.699: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  3 12:27:16.699: INFO: update-demo-nautilus-68hvf is verified up and running
Mar  3 12:27:16.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-d9kf2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2687'
Mar  3 12:27:16.787: INFO: stderr: ""
Mar  3 12:27:16.787: INFO: stdout: "true"
Mar  3 12:27:16.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-d9kf2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2687'
Mar  3 12:27:16.870: INFO: stderr: ""
Mar  3 12:27:16.870: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  3 12:27:16.870: INFO: validating pod update-demo-nautilus-d9kf2
Mar  3 12:27:16.877: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  3 12:27:16.877: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  3 12:27:16.877: INFO: update-demo-nautilus-d9kf2 is verified up and running
STEP: rolling-update to new replication controller
Mar  3 12:27:16.879: INFO: scanned /root for discovery docs: <nil>
Mar  3 12:27:16.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-2687'
Mar  3 12:27:39.566: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar  3 12:27:39.566: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  3 12:27:39.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2687'
Mar  3 12:27:39.653: INFO: stderr: ""
Mar  3 12:27:39.653: INFO: stdout: "update-demo-kitten-dfqfb update-demo-kitten-dprj7 "
Mar  3 12:27:39.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-kitten-dfqfb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2687'
Mar  3 12:27:39.741: INFO: stderr: ""
Mar  3 12:27:39.741: INFO: stdout: "true"
Mar  3 12:27:39.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-kitten-dfqfb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2687'
Mar  3 12:27:39.831: INFO: stderr: ""
Mar  3 12:27:39.831: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar  3 12:27:39.831: INFO: validating pod update-demo-kitten-dfqfb
Mar  3 12:27:39.838: INFO: got data: {
  "image": "kitten.jpg"
}

Mar  3 12:27:39.838: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar  3 12:27:39.838: INFO: update-demo-kitten-dfqfb is verified up and running
Mar  3 12:27:39.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-kitten-dprj7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2687'
Mar  3 12:27:39.920: INFO: stderr: ""
Mar  3 12:27:39.920: INFO: stdout: "true"
Mar  3 12:27:39.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-kitten-dprj7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2687'
Mar  3 12:27:40.018: INFO: stderr: ""
Mar  3 12:27:40.018: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar  3 12:27:40.018: INFO: validating pod update-demo-kitten-dprj7
Mar  3 12:27:40.029: INFO: got data: {
  "image": "kitten.jpg"
}

Mar  3 12:27:40.029: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar  3 12:27:40.029: INFO: update-demo-kitten-dprj7 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:27:40.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2687" for this suite.
Mar  3 12:28:08.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:28:08.339: INFO: namespace kubectl-2687 deletion completed in 28.304399684s

• [SLOW TEST:57.402 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:28:08.340: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-531b94fb-36f1-42f2-8ace-39bb909d82ad
STEP: Creating a pod to test consume secrets
Mar  3 12:28:08.417: INFO: Waiting up to 5m0s for pod "pod-secrets-a7115a46-9e1a-4aed-ab07-d5debe4be6d0" in namespace "secrets-4208" to be "success or failure"
Mar  3 12:28:08.422: INFO: Pod "pod-secrets-a7115a46-9e1a-4aed-ab07-d5debe4be6d0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.621138ms
Mar  3 12:28:10.435: INFO: Pod "pod-secrets-a7115a46-9e1a-4aed-ab07-d5debe4be6d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017391235s
STEP: Saw pod success
Mar  3 12:28:10.435: INFO: Pod "pod-secrets-a7115a46-9e1a-4aed-ab07-d5debe4be6d0" satisfied condition "success or failure"
Mar  3 12:28:10.439: INFO: Trying to get logs from node 10.0.2.74 pod pod-secrets-a7115a46-9e1a-4aed-ab07-d5debe4be6d0 container secret-volume-test: <nil>
STEP: delete the pod
Mar  3 12:28:10.472: INFO: Waiting for pod pod-secrets-a7115a46-9e1a-4aed-ab07-d5debe4be6d0 to disappear
Mar  3 12:28:10.477: INFO: Pod pod-secrets-a7115a46-9e1a-4aed-ab07-d5debe4be6d0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:28:10.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4208" for this suite.
Mar  3 12:28:16.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:28:16.747: INFO: namespace secrets-4208 deletion completed in 6.25405892s

• [SLOW TEST:8.407 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:28:16.747: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-b3e62f6c-104c-4ecb-bdfa-e193201ded7b
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:28:16.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2003" for this suite.
Mar  3 12:28:22.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:28:23.064: INFO: namespace secrets-2003 deletion completed in 6.258458591s

• [SLOW TEST:6.317 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:28:23.064: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-8d4b82fa-4e90-46c5-bf11-0ebed63e15a5
STEP: Creating a pod to test consume configMaps
Mar  3 12:28:23.136: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-65d9241a-4aa5-4bbe-9dd4-1ff660387ce7" in namespace "projected-7115" to be "success or failure"
Mar  3 12:28:23.140: INFO: Pod "pod-projected-configmaps-65d9241a-4aa5-4bbe-9dd4-1ff660387ce7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.048018ms
Mar  3 12:28:25.146: INFO: Pod "pod-projected-configmaps-65d9241a-4aa5-4bbe-9dd4-1ff660387ce7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009680792s
STEP: Saw pod success
Mar  3 12:28:25.146: INFO: Pod "pod-projected-configmaps-65d9241a-4aa5-4bbe-9dd4-1ff660387ce7" satisfied condition "success or failure"
Mar  3 12:28:25.180: INFO: Trying to get logs from node 10.0.2.74 pod pod-projected-configmaps-65d9241a-4aa5-4bbe-9dd4-1ff660387ce7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  3 12:28:25.218: INFO: Waiting for pod pod-projected-configmaps-65d9241a-4aa5-4bbe-9dd4-1ff660387ce7 to disappear
Mar  3 12:28:25.222: INFO: Pod pod-projected-configmaps-65d9241a-4aa5-4bbe-9dd4-1ff660387ce7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:28:25.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7115" for this suite.
Mar  3 12:28:31.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:28:31.536: INFO: namespace projected-7115 deletion completed in 6.309315534s

• [SLOW TEST:8.472 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:28:31.536: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Mar  3 12:28:31.626: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:28:45.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3832" for this suite.
Mar  3 12:28:51.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:28:51.640: INFO: namespace pods-3832 deletion completed in 6.295395151s

• [SLOW TEST:20.104 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:28:51.640: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-2640c1f8-c6b4-477f-8947-aeb392e6bc31
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-2640c1f8-c6b4-477f-8947-aeb392e6bc31
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:28:55.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3133" for this suite.
Mar  3 12:29:07.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:29:08.029: INFO: namespace projected-3133 deletion completed in 12.229231515s

• [SLOW TEST:16.389 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:29:08.030: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Mar  3 12:29:08.104: INFO: Waiting up to 5m0s for pod "pod-100007b9-afe9-49c6-be49-f3dc04dc89ad" in namespace "emptydir-9162" to be "success or failure"
Mar  3 12:29:08.108: INFO: Pod "pod-100007b9-afe9-49c6-be49-f3dc04dc89ad": Phase="Pending", Reason="", readiness=false. Elapsed: 4.227057ms
Mar  3 12:29:10.114: INFO: Pod "pod-100007b9-afe9-49c6-be49-f3dc04dc89ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009539109s
STEP: Saw pod success
Mar  3 12:29:10.114: INFO: Pod "pod-100007b9-afe9-49c6-be49-f3dc04dc89ad" satisfied condition "success or failure"
Mar  3 12:29:10.118: INFO: Trying to get logs from node 10.0.2.119 pod pod-100007b9-afe9-49c6-be49-f3dc04dc89ad container test-container: <nil>
STEP: delete the pod
Mar  3 12:29:10.150: INFO: Waiting for pod pod-100007b9-afe9-49c6-be49-f3dc04dc89ad to disappear
Mar  3 12:29:10.155: INFO: Pod pod-100007b9-afe9-49c6-be49-f3dc04dc89ad no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:29:10.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9162" for this suite.
Mar  3 12:29:16.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:29:16.444: INFO: namespace emptydir-9162 deletion completed in 6.284105832s

• [SLOW TEST:8.415 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:29:16.445: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 12:29:16.532: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Mar  3 12:29:20.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=crd-publish-openapi-2268 create -f -'
Mar  3 12:29:20.975: INFO: stderr: ""
Mar  3 12:29:20.975: INFO: stdout: "e2e-test-crd-publish-openapi-9383-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Mar  3 12:29:20.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=crd-publish-openapi-2268 delete e2e-test-crd-publish-openapi-9383-crds test-cr'
Mar  3 12:29:21.091: INFO: stderr: ""
Mar  3 12:29:21.091: INFO: stdout: "e2e-test-crd-publish-openapi-9383-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Mar  3 12:29:21.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=crd-publish-openapi-2268 apply -f -'
Mar  3 12:29:21.315: INFO: stderr: ""
Mar  3 12:29:21.315: INFO: stdout: "e2e-test-crd-publish-openapi-9383-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Mar  3 12:29:21.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=crd-publish-openapi-2268 delete e2e-test-crd-publish-openapi-9383-crds test-cr'
Mar  3 12:29:21.424: INFO: stderr: ""
Mar  3 12:29:21.424: INFO: stdout: "e2e-test-crd-publish-openapi-9383-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Mar  3 12:29:21.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 explain e2e-test-crd-publish-openapi-9383-crds'
Mar  3 12:29:21.623: INFO: stderr: ""
Mar  3 12:29:21.623: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9383-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:29:25.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2268" for this suite.
Mar  3 12:29:31.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:29:31.569: INFO: namespace crd-publish-openapi-2268 deletion completed in 6.191877049s

• [SLOW TEST:15.124 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:29:31.569: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar  3 12:29:31.640: INFO: Waiting up to 5m0s for pod "pod-16a75e59-12b7-4462-8858-8700639ce4f3" in namespace "emptydir-4562" to be "success or failure"
Mar  3 12:29:31.643: INFO: Pod "pod-16a75e59-12b7-4462-8858-8700639ce4f3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.951477ms
Mar  3 12:29:33.649: INFO: Pod "pod-16a75e59-12b7-4462-8858-8700639ce4f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00972384s
STEP: Saw pod success
Mar  3 12:29:33.649: INFO: Pod "pod-16a75e59-12b7-4462-8858-8700639ce4f3" satisfied condition "success or failure"
Mar  3 12:29:33.654: INFO: Trying to get logs from node 10.0.2.119 pod pod-16a75e59-12b7-4462-8858-8700639ce4f3 container test-container: <nil>
STEP: delete the pod
Mar  3 12:29:33.684: INFO: Waiting for pod pod-16a75e59-12b7-4462-8858-8700639ce4f3 to disappear
Mar  3 12:29:33.689: INFO: Pod pod-16a75e59-12b7-4462-8858-8700639ce4f3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:29:33.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4562" for this suite.
Mar  3 12:29:39.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:29:40.013: INFO: namespace emptydir-4562 deletion completed in 6.319031543s

• [SLOW TEST:8.443 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:29:40.013: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar  3 12:29:40.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-3074'
Mar  3 12:29:40.174: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  3 12:29:40.174: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Mar  3 12:29:44.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 delete deployment e2e-test-httpd-deployment --namespace=kubectl-3074'
Mar  3 12:29:44.342: INFO: stderr: ""
Mar  3 12:29:44.342: INFO: stdout: "deployment.extensions \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:29:44.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3074" for this suite.
Mar  3 12:29:56.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:29:56.640: INFO: namespace kubectl-3074 deletion completed in 12.292175271s

• [SLOW TEST:16.627 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:29:56.640: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 12:29:56.733: INFO: Creating deployment "webserver-deployment"
Mar  3 12:29:56.739: INFO: Waiting for observed generation 1
Mar  3 12:29:58.754: INFO: Waiting for all required pods to come up
Mar  3 12:29:58.761: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Mar  3 12:30:00.806: INFO: Waiting for deployment "webserver-deployment" to complete
Mar  3 12:30:00.815: INFO: Updating deployment "webserver-deployment" with a non-existent image
Mar  3 12:30:00.833: INFO: Updating deployment webserver-deployment
Mar  3 12:30:00.833: INFO: Waiting for observed generation 2
Mar  3 12:30:02.849: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar  3 12:30:02.856: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar  3 12:30:02.861: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Mar  3 12:30:02.880: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar  3 12:30:02.880: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar  3 12:30:02.887: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Mar  3 12:30:02.898: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Mar  3 12:30:02.898: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Mar  3 12:30:02.915: INFO: Updating deployment webserver-deployment
Mar  3 12:30:02.915: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Mar  3 12:30:02.929: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar  3 12:30:02.939: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Mar  3 12:30:02.966: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-4882 /apis/apps/v1/namespaces/deployment-4882/deployments/webserver-deployment 3b0db33c-b68f-4afe-aec2-2a39082fb652 1243541387 3 2020-03-03 12:29:56 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004f9bdb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2020-03-03 12:30:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:56 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-03-03 12:30:02 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Mar  3 12:30:03.039: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-4882 /apis/apps/v1/namespaces/deployment-4882/replicasets/webserver-deployment-c7997dcc8 8653f74c-bc74-4b95-8fa1-72e070682f0e 1243541371 3 2020-03-03 12:30:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 3b0db33c-b68f-4afe-aec2-2a39082fb652 0xc004eec477 0xc004eec478}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004eec548 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar  3 12:30:03.039: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Mar  3 12:30:03.039: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-4882 /apis/apps/v1/namespaces/deployment-4882/replicasets/webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 1243541366 3 2020-03-03 12:29:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 3b0db33c-b68f-4afe-aec2-2a39082fb652 0xc004eec387 0xc004eec388}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004eec408 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Mar  3 12:30:03.074: INFO: Pod "webserver-deployment-595b5b9587-5wc8l" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-5wc8l webserver-deployment-595b5b9587- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-595b5b9587-5wc8l 1fa701ad-42c5-4adc-b8db-4c94d7320d6d 1243540511 0 2020-03-03 12:29:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[tke.cloud.tencent.com/networks-status:[{
    "name": "tke-bridge",
    "ips": [
        "172.27.0.115"
    ],
    "default": true,
    "dns": {}
}]] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 0xc004f49527 0xc004f49528}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.74,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.74,PodIP:172.27.0.115,StartTime:2020-03-03 12:29:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-03 12:29:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://d4ba556428be6a38583d348363efc0a0b4364cf8ee7ce8784c5cf73ff5abf9fe,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.27.0.115,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.074: INFO: Pod "webserver-deployment-595b5b9587-67xjp" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-67xjp webserver-deployment-595b5b9587- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-595b5b9587-67xjp a6180dbf-850c-42b6-876f-78b4de6b880f 1243541431 0 2020-03-03 12:30:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 0xc004f49707 0xc004f49708}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.74,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.074: INFO: Pod "webserver-deployment-595b5b9587-8xp98" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-8xp98 webserver-deployment-595b5b9587- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-595b5b9587-8xp98 9dd02d13-f898-4ea2-b717-bb651f940e7c 1243541408 0 2020-03-03 12:30:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 0xc004f497e7 0xc004f497e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.119,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.075: INFO: Pod "webserver-deployment-595b5b9587-8z9tb" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-8z9tb webserver-deployment-595b5b9587- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-595b5b9587-8z9tb 421d46f8-3191-4052-8187-941abd0dbdab 1243541422 0 2020-03-03 12:30:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 0xc004f498c7 0xc004f498c8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.74,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.74,PodIP:,StartTime:2020-03-03 12:30:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.075: INFO: Pod "webserver-deployment-595b5b9587-9n5ll" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9n5ll webserver-deployment-595b5b9587- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-595b5b9587-9n5ll 8b5235fd-90dc-4f63-b74e-20b26a037259 1243540474 0 2020-03-03 12:29:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[tke.cloud.tencent.com/networks-status:[{
    "name": "tke-bridge",
    "ips": [
        "172.27.0.50"
    ],
    "default": true,
    "dns": {}
}]] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 0xc004f49a27 0xc004f49a28}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.119,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.119,PodIP:172.27.0.50,StartTime:2020-03-03 12:29:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-03 12:29:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://d389d2ecb47247c509d78cb88c4018ad947e806ac6b6a20a504a6dc242064824,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.27.0.50,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.075: INFO: Pod "webserver-deployment-595b5b9587-f2n5p" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-f2n5p webserver-deployment-595b5b9587- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-595b5b9587-f2n5p 8aa42db0-e387-4efd-9672-95f1041d6f0f 1243541430 0 2020-03-03 12:30:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 0xc004f49b77 0xc004f49b78}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.119,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.075: INFO: Pod "webserver-deployment-595b5b9587-j298z" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-j298z webserver-deployment-595b5b9587- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-595b5b9587-j298z ddbc76db-79e5-4e97-9e7b-b006257d600a 1243541429 0 2020-03-03 12:30:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 0xc004f49c57 0xc004f49c58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.119,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.075: INFO: Pod "webserver-deployment-595b5b9587-jmmfk" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-jmmfk webserver-deployment-595b5b9587- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-595b5b9587-jmmfk 93f600d4-7e3a-4354-bba9-04451f75318f 1243540413 0 2020-03-03 12:29:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[tke.cloud.tencent.com/networks-status:[{
    "name": "tke-bridge",
    "ips": [
        "172.27.0.113"
    ],
    "default": true,
    "dns": {}
}]] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 0xc004f49d87 0xc004f49d88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.74,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.74,PodIP:172.27.0.113,StartTime:2020-03-03 12:29:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-03 12:29:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://7398a27bffcd2b6df50752fc55a3378f3a465d60a3c3c9f17015d854b00e248e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.27.0.113,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.075: INFO: Pod "webserver-deployment-595b5b9587-kqlrx" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-kqlrx webserver-deployment-595b5b9587- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-595b5b9587-kqlrx 17c0dfa9-d96e-4a5a-95d0-192974e6cf19 1243541407 0 2020-03-03 12:30:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 0xc004f49f57 0xc004f49f58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.119,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.076: INFO: Pod "webserver-deployment-595b5b9587-kt4w6" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-kt4w6 webserver-deployment-595b5b9587- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-595b5b9587-kt4w6 c22c965d-e996-4465-bf41-e4a4bcda22d8 1243540482 0 2020-03-03 12:29:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[tke.cloud.tencent.com/networks-status:[{
    "name": "tke-bridge",
    "ips": [
        "172.27.0.51"
    ],
    "default": true,
    "dns": {}
}]] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 0xc0068b8057 0xc0068b8058}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.119,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.119,PodIP:172.27.0.51,StartTime:2020-03-03 12:29:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-03 12:29:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://09d2247b40088965a0d8209414340556fc56b632b08f7b3d6071ece3f1d3ede7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.27.0.51,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.076: INFO: Pod "webserver-deployment-595b5b9587-lq69x" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-lq69x webserver-deployment-595b5b9587- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-595b5b9587-lq69x 47bfc69b-68e9-408e-8971-37d4825b3822 1243541417 0 2020-03-03 12:30:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 0xc0068b8207 0xc0068b8208}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.74,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.076: INFO: Pod "webserver-deployment-595b5b9587-nc5hp" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-nc5hp webserver-deployment-595b5b9587- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-595b5b9587-nc5hp e2b9db7f-43a0-49a3-9b1e-c871a81352c8 1243541426 0 2020-03-03 12:30:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 0xc0068b8357 0xc0068b8358}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.119,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.076: INFO: Pod "webserver-deployment-595b5b9587-p2fnx" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-p2fnx webserver-deployment-595b5b9587- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-595b5b9587-p2fnx 5fee0bca-ab73-4c85-8f4d-94b1b3adb8ed 1243540420 0 2020-03-03 12:29:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[tke.cloud.tencent.com/networks-status:[{
    "name": "tke-bridge",
    "ips": [
        "172.27.0.114"
    ],
    "default": true,
    "dns": {}
}]] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 0xc0068b8497 0xc0068b8498}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.74,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.74,PodIP:172.27.0.114,StartTime:2020-03-03 12:29:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-03 12:29:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://e77ac0580c86e5254fc0cc111902b2fb15c4df25a6a7a739449b7295476819c6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.27.0.114,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.076: INFO: Pod "webserver-deployment-595b5b9587-r5jv9" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-r5jv9 webserver-deployment-595b5b9587- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-595b5b9587-r5jv9 de9f2097-7f55-44fe-b1a9-b9c77599b967 1243540428 0 2020-03-03 12:29:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[tke.cloud.tencent.com/networks-status:[{
    "name": "tke-bridge",
    "ips": [
        "172.27.0.116"
    ],
    "default": true,
    "dns": {}
}]] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 0xc0068b8717 0xc0068b8718}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.74,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.74,PodIP:172.27.0.116,StartTime:2020-03-03 12:29:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-03 12:29:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://2a9c94c7cae2cf80a0b24b6859878fde323fe912ff4501273d66921d40c58b59,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.27.0.116,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.077: INFO: Pod "webserver-deployment-595b5b9587-r9ncc" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-r9ncc webserver-deployment-595b5b9587- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-595b5b9587-r9ncc 36b1fe1f-1a86-4fb8-a66b-e71a272f7fec 1243541391 0 2020-03-03 12:30:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 0xc0068b8907 0xc0068b8908}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.74,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.077: INFO: Pod "webserver-deployment-595b5b9587-rkbwh" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-rkbwh webserver-deployment-595b5b9587- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-595b5b9587-rkbwh b83089e9-69ce-45b2-967f-91ba5812528d 1243540469 0 2020-03-03 12:29:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[tke.cloud.tencent.com/networks-status:[{
    "name": "tke-bridge",
    "ips": [
        "172.27.0.48"
    ],
    "default": true,
    "dns": {}
}]] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 0xc0068b8a97 0xc0068b8a98}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.119,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.119,PodIP:172.27.0.48,StartTime:2020-03-03 12:29:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-03 12:29:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://78a64e2aba6694c7ec4069434b0c60b464ee3c651fcb53d92a82d66afc330ded,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.27.0.48,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.077: INFO: Pod "webserver-deployment-595b5b9587-t2bzh" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-t2bzh webserver-deployment-595b5b9587- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-595b5b9587-t2bzh 414611bc-1d1e-4801-97ef-ca6bb92ce163 1243541434 0 2020-03-03 12:30:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 0xc0068b8c57 0xc0068b8c58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.119,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.119,PodIP:,StartTime:2020-03-03 12:30:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.077: INFO: Pod "webserver-deployment-595b5b9587-vd64c" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vd64c webserver-deployment-595b5b9587- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-595b5b9587-vd64c 9cbe0221-e4f3-4a2b-a16a-1a0378890d59 1243540479 0 2020-03-03 12:29:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[tke.cloud.tencent.com/networks-status:[{
    "name": "tke-bridge",
    "ips": [
        "172.27.0.49"
    ],
    "default": true,
    "dns": {}
}]] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 0xc0068b8dd7 0xc0068b8dd8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.119,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:29:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.119,PodIP:172.27.0.49,StartTime:2020-03-03 12:29:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-03 12:29:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://4158e202de175d243907b3c6fbf793eac1044855b99469800b1182d45cc85d58,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.27.0.49,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.077: INFO: Pod "webserver-deployment-595b5b9587-w7bm8" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-w7bm8 webserver-deployment-595b5b9587- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-595b5b9587-w7bm8 8130ce48-cd67-4682-9c34-eee1dae2693f 1243541428 0 2020-03-03 12:30:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 0xc0068b8f77 0xc0068b8f78}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.74,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.078: INFO: Pod "webserver-deployment-595b5b9587-z9zdj" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-z9zdj webserver-deployment-595b5b9587- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-595b5b9587-z9zdj 2a846367-5044-456d-ba7e-25d41b33e415 1243541411 0 2020-03-03 12:30:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb6baa15-1797-4c17-a23d-e2818d80a2bb 0xc0068b9057 0xc0068b9058}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.74,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.078: INFO: Pod "webserver-deployment-c7997dcc8-2w24p" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-2w24p webserver-deployment-c7997dcc8- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-c7997dcc8-2w24p 155e726e-94d1-440d-ac31-b868e8611acf 1243541386 0 2020-03-03 12:30:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 8653f74c-bc74-4b95-8fa1-72e070682f0e 0xc0068b9207 0xc0068b9208}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.74,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.078: INFO: Pod "webserver-deployment-c7997dcc8-4jk9l" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-4jk9l webserver-deployment-c7997dcc8- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-c7997dcc8-4jk9l c1bcf1fd-6c00-4244-b965-bda237e8ce75 1243541399 0 2020-03-03 12:30:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 8653f74c-bc74-4b95-8fa1-72e070682f0e 0xc0068b9367 0xc0068b9368}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.119,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.078: INFO: Pod "webserver-deployment-c7997dcc8-67fwv" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-67fwv webserver-deployment-c7997dcc8- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-c7997dcc8-67fwv c8727ca8-3d4d-4201-aa42-e33290118250 1243541144 0 2020-03-03 12:30:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[tke.cloud.tencent.com/networks-status:[{
    "name": "tke-bridge",
    "ips": [
        "172.27.0.118"
    ],
    "default": true,
    "dns": {}
}]] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 8653f74c-bc74-4b95-8fa1-72e070682f0e 0xc0068b9487 0xc0068b9488}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.74,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.74,PodIP:,StartTime:2020-03-03 12:30:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.078: INFO: Pod "webserver-deployment-c7997dcc8-7w9vt" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-7w9vt webserver-deployment-c7997dcc8- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-c7997dcc8-7w9vt 7f36e3b8-ae33-4673-af5a-5e65ec709b47 1243541150 0 2020-03-03 12:30:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[tke.cloud.tencent.com/networks-status:[{
    "name": "tke-bridge",
    "ips": [
        "172.27.0.54"
    ],
    "default": true,
    "dns": {}
}]] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 8653f74c-bc74-4b95-8fa1-72e070682f0e 0xc0068b9637 0xc0068b9638}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.119,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.119,PodIP:,StartTime:2020-03-03 12:30:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.078: INFO: Pod "webserver-deployment-c7997dcc8-88lbd" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-88lbd webserver-deployment-c7997dcc8- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-c7997dcc8-88lbd 560692eb-3c3e-4559-93d5-a88e409d8147 1243541419 0 2020-03-03 12:30:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 8653f74c-bc74-4b95-8fa1-72e070682f0e 0xc0068b97a7 0xc0068b97a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.119,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.079: INFO: Pod "webserver-deployment-c7997dcc8-9bwq9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-9bwq9 webserver-deployment-c7997dcc8- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-c7997dcc8-9bwq9 a6b04330-5b25-4e06-b7da-8009167c72de 1243541169 0 2020-03-03 12:30:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[tke.cloud.tencent.com/networks-status:[{
    "name": "tke-bridge",
    "ips": [
        "172.27.0.55"
    ],
    "default": true,
    "dns": {}
}]] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 8653f74c-bc74-4b95-8fa1-72e070682f0e 0xc0068b98e7 0xc0068b98e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.119,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.119,PodIP:,StartTime:2020-03-03 12:30:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.079: INFO: Pod "webserver-deployment-c7997dcc8-dttgt" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-dttgt webserver-deployment-c7997dcc8- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-c7997dcc8-dttgt 32e28474-2743-4c27-840b-4c6f2f076f7f 1243541427 0 2020-03-03 12:30:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 8653f74c-bc74-4b95-8fa1-72e070682f0e 0xc0068b9a67 0xc0068b9a68}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.74,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.079: INFO: Pod "webserver-deployment-c7997dcc8-dxfqd" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-dxfqd webserver-deployment-c7997dcc8- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-c7997dcc8-dxfqd 985fceba-1abe-4b5e-92df-76f6427bf8e4 1243541139 0 2020-03-03 12:30:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[tke.cloud.tencent.com/networks-status:[{
    "name": "tke-bridge",
    "ips": [
        "172.27.0.53"
    ],
    "default": true,
    "dns": {}
}]] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 8653f74c-bc74-4b95-8fa1-72e070682f0e 0xc0068b9b77 0xc0068b9b78}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.119,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.119,PodIP:,StartTime:2020-03-03 12:30:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.079: INFO: Pod "webserver-deployment-c7997dcc8-f8wr9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-f8wr9 webserver-deployment-c7997dcc8- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-c7997dcc8-f8wr9 ae01759a-1b26-4350-b33f-8a7b024bac42 1243541418 0 2020-03-03 12:30:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 8653f74c-bc74-4b95-8fa1-72e070682f0e 0xc0068b9d07 0xc0068b9d08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.74,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.079: INFO: Pod "webserver-deployment-c7997dcc8-lkdln" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-lkdln webserver-deployment-c7997dcc8- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-c7997dcc8-lkdln f3fa8b24-82fa-477f-8dff-bd8eccaea519 1243541130 0 2020-03-03 12:30:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[tke.cloud.tencent.com/networks-status:[{
    "name": "tke-bridge",
    "ips": [
        "172.27.0.117"
    ],
    "default": true,
    "dns": {}
}]] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 8653f74c-bc74-4b95-8fa1-72e070682f0e 0xc0068b9e67 0xc0068b9e68}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.74,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.74,PodIP:,StartTime:2020-03-03 12:30:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.080: INFO: Pod "webserver-deployment-c7997dcc8-njmff" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-njmff webserver-deployment-c7997dcc8- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-c7997dcc8-njmff 631fa82c-94e4-4bff-882b-e9b2b703381a 1243541397 0 2020-03-03 12:30:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 8653f74c-bc74-4b95-8fa1-72e070682f0e 0xc0068b9fb7 0xc0068b9fb8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.119,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.080: INFO: Pod "webserver-deployment-c7997dcc8-svdxc" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-svdxc webserver-deployment-c7997dcc8- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-c7997dcc8-svdxc 4ea88941-62ec-41df-a8c6-32245a9c245e 1243541421 0 2020-03-03 12:30:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 8653f74c-bc74-4b95-8fa1-72e070682f0e 0xc00689e0f7 0xc00689e0f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.119,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 12:30:03.080: INFO: Pod "webserver-deployment-c7997dcc8-z6mpz" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-z6mpz webserver-deployment-c7997dcc8- deployment-4882 /api/v1/namespaces/deployment-4882/pods/webserver-deployment-c7997dcc8-z6mpz cab2259b-b75e-445d-a48f-d8f037800ae7 1243541420 0 2020-03-03 12:30:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 8653f74c-bc74-4b95-8fa1-72e070682f0e 0xc00689e237 0xc00689e238}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4g75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4g75,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4g75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.74,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:30:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:30:03.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4882" for this suite.
Mar  3 12:30:11.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:30:11.314: INFO: namespace deployment-4882 deletion completed in 8.226923216s

• [SLOW TEST:14.675 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:30:11.315: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-e418e325-0942-4735-9df5-307126e7e4b7
STEP: Creating a pod to test consume secrets
Mar  3 12:30:11.396: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-065fe271-b578-4aad-8b6a-d786a31c568f" in namespace "projected-3380" to be "success or failure"
Mar  3 12:30:11.400: INFO: Pod "pod-projected-secrets-065fe271-b578-4aad-8b6a-d786a31c568f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.12144ms
Mar  3 12:30:13.407: INFO: Pod "pod-projected-secrets-065fe271-b578-4aad-8b6a-d786a31c568f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010174871s
Mar  3 12:30:15.411: INFO: Pod "pod-projected-secrets-065fe271-b578-4aad-8b6a-d786a31c568f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015095442s
STEP: Saw pod success
Mar  3 12:30:15.411: INFO: Pod "pod-projected-secrets-065fe271-b578-4aad-8b6a-d786a31c568f" satisfied condition "success or failure"
Mar  3 12:30:15.416: INFO: Trying to get logs from node 10.0.2.119 pod pod-projected-secrets-065fe271-b578-4aad-8b6a-d786a31c568f container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  3 12:30:15.444: INFO: Waiting for pod pod-projected-secrets-065fe271-b578-4aad-8b6a-d786a31c568f to disappear
Mar  3 12:30:15.453: INFO: Pod pod-projected-secrets-065fe271-b578-4aad-8b6a-d786a31c568f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:30:15.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3380" for this suite.
Mar  3 12:30:21.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:30:21.685: INFO: namespace projected-3380 deletion completed in 6.227284796s

• [SLOW TEST:10.371 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:30:21.686: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-6510
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  3 12:30:21.735: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  3 12:30:43.833: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.27.0.71:8080/dial?request=hostName&protocol=http&host=172.27.0.8&port=8080&tries=1'] Namespace:pod-network-test-6510 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  3 12:30:43.833: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 12:30:43.949: INFO: Waiting for endpoints: map[]
Mar  3 12:30:43.953: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.27.0.71:8080/dial?request=hostName&protocol=http&host=172.27.0.70&port=8080&tries=1'] Namespace:pod-network-test-6510 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  3 12:30:43.953: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 12:30:44.061: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:30:44.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6510" for this suite.
Mar  3 12:30:56.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:30:56.358: INFO: namespace pod-network-test-6510 deletion completed in 12.29171498s

• [SLOW TEST:34.673 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:30:56.358: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Mar  3 12:30:56.428: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-187709168 proxy --unix-socket=/tmp/kubectl-proxy-unix699899203/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:30:56.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4874" for this suite.
Mar  3 12:31:02.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:31:02.740: INFO: namespace kubectl-4874 deletion completed in 6.240042721s

• [SLOW TEST:6.382 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:31:02.741: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Mar  3 12:31:02.825: INFO: Waiting up to 5m0s for pod "downward-api-08a32a16-6b6b-4d5f-9162-e13aaf981d86" in namespace "downward-api-6745" to be "success or failure"
Mar  3 12:31:02.830: INFO: Pod "downward-api-08a32a16-6b6b-4d5f-9162-e13aaf981d86": Phase="Pending", Reason="", readiness=false. Elapsed: 4.128138ms
Mar  3 12:31:04.835: INFO: Pod "downward-api-08a32a16-6b6b-4d5f-9162-e13aaf981d86": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009094567s
STEP: Saw pod success
Mar  3 12:31:04.835: INFO: Pod "downward-api-08a32a16-6b6b-4d5f-9162-e13aaf981d86" satisfied condition "success or failure"
Mar  3 12:31:04.844: INFO: Trying to get logs from node 10.0.2.74 pod downward-api-08a32a16-6b6b-4d5f-9162-e13aaf981d86 container dapi-container: <nil>
STEP: delete the pod
Mar  3 12:31:04.878: INFO: Waiting for pod downward-api-08a32a16-6b6b-4d5f-9162-e13aaf981d86 to disappear
Mar  3 12:31:04.882: INFO: Pod downward-api-08a32a16-6b6b-4d5f-9162-e13aaf981d86 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:31:04.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6745" for this suite.
Mar  3 12:31:10.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:31:11.113: INFO: namespace downward-api-6745 deletion completed in 6.225553616s

• [SLOW TEST:8.372 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:31:11.113: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Mar  3 12:31:11.188: INFO: PodSpec: initContainers in spec.initContainers
Mar  3 12:31:54.961: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-e008b0ed-4619-4da8-94a9-3177dd8b122b", GenerateName:"", Namespace:"init-container-6033", SelfLink:"/api/v1/namespaces/init-container-6033/pods/pod-init-e008b0ed-4619-4da8-94a9-3177dd8b122b", UID:"cbfb869c-be43-49f1-a1e9-18fe3feebabb", ResourceVersion:"1243564123", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63718835471, loc:(*time.Location)(0x84bfb00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"188397384"}, Annotations:map[string]string{"tke.cloud.tencent.com/networks-status":"[{\n    \"name\": \"tke-bridge\",\n    \"ips\": [\n        \"172.27.0.73\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-k86dt", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002db2440), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-k86dt", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-k86dt", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-k86dt", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00354a2b8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.0.2.74", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0022da060), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00354a340), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835471, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835471, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835471, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835471, loc:(*time.Location)(0x84bfb00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.2.74", PodIP:"172.27.0.73", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.27.0.73"}}, StartTime:(*v1.Time)(0xc001d4a220), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0010c2150)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0010c21c0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://8647ee74935b8058f68ac197732a3787662404d9db6d44beefe998a8dba60f54", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001d4a280), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001d4a260), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc00354a3bf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:31:54.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6033" for this suite.
Mar  3 12:32:06.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:32:07.203: INFO: namespace init-container-6033 deletion completed in 12.233897706s

• [SLOW TEST:56.090 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:32:07.203: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:32:14.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2752" for this suite.
Mar  3 12:32:20.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:32:20.568: INFO: namespace resourcequota-2752 deletion completed in 6.255831492s

• [SLOW TEST:13.365 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:32:20.569: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  3 12:32:20.644: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ae6af063-8ec5-4ba8-964b-92a23b497e3a" in namespace "projected-8244" to be "success or failure"
Mar  3 12:32:20.648: INFO: Pod "downwardapi-volume-ae6af063-8ec5-4ba8-964b-92a23b497e3a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.109929ms
Mar  3 12:32:22.653: INFO: Pod "downwardapi-volume-ae6af063-8ec5-4ba8-964b-92a23b497e3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009040105s
STEP: Saw pod success
Mar  3 12:32:22.653: INFO: Pod "downwardapi-volume-ae6af063-8ec5-4ba8-964b-92a23b497e3a" satisfied condition "success or failure"
Mar  3 12:32:22.657: INFO: Trying to get logs from node 10.0.2.119 pod downwardapi-volume-ae6af063-8ec5-4ba8-964b-92a23b497e3a container client-container: <nil>
STEP: delete the pod
Mar  3 12:32:22.687: INFO: Waiting for pod downwardapi-volume-ae6af063-8ec5-4ba8-964b-92a23b497e3a to disappear
Mar  3 12:32:22.691: INFO: Pod downwardapi-volume-ae6af063-8ec5-4ba8-964b-92a23b497e3a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:32:22.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8244" for this suite.
Mar  3 12:32:28.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:32:29.009: INFO: namespace projected-8244 deletion completed in 6.313150513s

• [SLOW TEST:8.440 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:32:29.009: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar  3 12:32:31.088: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:32:31.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8744" for this suite.
Mar  3 12:32:37.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:32:37.333: INFO: namespace container-runtime-8744 deletion completed in 6.217979722s

• [SLOW TEST:8.324 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:32:37.333: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  3 12:32:38.048: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  3 12:32:40.072: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835558, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835558, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835558, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835558, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7f4f78fb6b\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  3 12:32:43.092: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:32:53.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7823" for this suite.
Mar  3 12:32:59.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:32:59.545: INFO: namespace webhook-7823 deletion completed in 6.238301807s
STEP: Destroying namespace "webhook-7823-markers" for this suite.
Mar  3 12:33:05.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:33:05.772: INFO: namespace webhook-7823-markers deletion completed in 6.227833284s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.480 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:33:05.813: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Mar  3 12:33:08.485: INFO: Successfully updated pod "annotationupdatebd6177a9-c6f3-431d-bf2e-26754b73d790"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:33:12.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3697" for this suite.
Mar  3 12:33:40.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:33:40.883: INFO: namespace projected-3697 deletion completed in 28.330393215s

• [SLOW TEST:35.070 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:33:40.883: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Mar  3 12:33:40.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 api-versions'
Mar  3 12:33:41.037: INFO: stderr: ""
Mar  3 12:33:41.037: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncustom.metrics.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:33:41.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9937" for this suite.
Mar  3 12:33:47.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:33:47.306: INFO: namespace kubectl-9937 deletion completed in 6.255376019s

• [SLOW TEST:6.422 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:33:47.306: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-09d00fe0-bfea-41fc-9685-b2379f6289f6
STEP: Creating a pod to test consume secrets
Mar  3 12:33:47.391: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8d845ef6-68ae-496c-864c-9ee662038ca8" in namespace "projected-4830" to be "success or failure"
Mar  3 12:33:47.395: INFO: Pod "pod-projected-secrets-8d845ef6-68ae-496c-864c-9ee662038ca8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.086142ms
Mar  3 12:33:49.400: INFO: Pod "pod-projected-secrets-8d845ef6-68ae-496c-864c-9ee662038ca8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009076899s
STEP: Saw pod success
Mar  3 12:33:49.400: INFO: Pod "pod-projected-secrets-8d845ef6-68ae-496c-864c-9ee662038ca8" satisfied condition "success or failure"
Mar  3 12:33:49.404: INFO: Trying to get logs from node 10.0.2.74 pod pod-projected-secrets-8d845ef6-68ae-496c-864c-9ee662038ca8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  3 12:33:49.436: INFO: Waiting for pod pod-projected-secrets-8d845ef6-68ae-496c-864c-9ee662038ca8 to disappear
Mar  3 12:33:49.443: INFO: Pod pod-projected-secrets-8d845ef6-68ae-496c-864c-9ee662038ca8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:33:49.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4830" for this suite.
Mar  3 12:33:55.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:33:55.778: INFO: namespace projected-4830 deletion completed in 6.329291116s

• [SLOW TEST:8.472 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:33:55.778: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:34:06.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6152" for this suite.
Mar  3 12:34:12.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:34:13.207: INFO: namespace resourcequota-6152 deletion completed in 6.283512204s

• [SLOW TEST:17.429 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:34:13.207: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar  3 12:34:13.281: INFO: Waiting up to 5m0s for pod "pod-fe0360f4-cfc5-4e7d-9751-dcec4327acfb" in namespace "emptydir-5544" to be "success or failure"
Mar  3 12:34:13.286: INFO: Pod "pod-fe0360f4-cfc5-4e7d-9751-dcec4327acfb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.117071ms
Mar  3 12:34:15.291: INFO: Pod "pod-fe0360f4-cfc5-4e7d-9751-dcec4327acfb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00963245s
Mar  3 12:34:17.296: INFO: Pod "pod-fe0360f4-cfc5-4e7d-9751-dcec4327acfb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014536316s
STEP: Saw pod success
Mar  3 12:34:17.296: INFO: Pod "pod-fe0360f4-cfc5-4e7d-9751-dcec4327acfb" satisfied condition "success or failure"
Mar  3 12:34:17.300: INFO: Trying to get logs from node 10.0.2.119 pod pod-fe0360f4-cfc5-4e7d-9751-dcec4327acfb container test-container: <nil>
STEP: delete the pod
Mar  3 12:34:17.327: INFO: Waiting for pod pod-fe0360f4-cfc5-4e7d-9751-dcec4327acfb to disappear
Mar  3 12:34:17.332: INFO: Pod pod-fe0360f4-cfc5-4e7d-9751-dcec4327acfb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:34:17.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5544" for this suite.
Mar  3 12:34:23.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:34:23.603: INFO: namespace emptydir-5544 deletion completed in 6.264717708s

• [SLOW TEST:10.396 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:34:23.603: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-5374
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5374 to expose endpoints map[]
Mar  3 12:34:23.690: INFO: successfully validated that service multi-endpoint-test in namespace services-5374 exposes endpoints map[] (16.371315ms elapsed)
STEP: Creating pod pod1 in namespace services-5374
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5374 to expose endpoints map[pod1:[100]]
Mar  3 12:34:25.738: INFO: successfully validated that service multi-endpoint-test in namespace services-5374 exposes endpoints map[pod1:[100]] (2.033026103s elapsed)
STEP: Creating pod pod2 in namespace services-5374
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5374 to expose endpoints map[pod1:[100] pod2:[101]]
Mar  3 12:34:27.799: INFO: successfully validated that service multi-endpoint-test in namespace services-5374 exposes endpoints map[pod1:[100] pod2:[101]] (2.051775496s elapsed)
STEP: Deleting pod pod1 in namespace services-5374
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5374 to expose endpoints map[pod2:[101]]
Mar  3 12:34:28.851: INFO: successfully validated that service multi-endpoint-test in namespace services-5374 exposes endpoints map[pod2:[101]] (1.040879185s elapsed)
STEP: Deleting pod pod2 in namespace services-5374
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5374 to expose endpoints map[]
Mar  3 12:34:28.877: INFO: successfully validated that service multi-endpoint-test in namespace services-5374 exposes endpoints map[] (10.875602ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:34:28.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5374" for this suite.
Mar  3 12:34:40.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:34:41.159: INFO: namespace services-5374 deletion completed in 12.234048298s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:17.556 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:34:41.160: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-c967809f-2a67-4fed-8fcb-a1f6b173770a
STEP: Creating a pod to test consume configMaps
Mar  3 12:34:41.230: INFO: Waiting up to 5m0s for pod "pod-configmaps-9b780da4-86ba-493b-a74b-51a725902b5e" in namespace "configmap-783" to be "success or failure"
Mar  3 12:34:41.237: INFO: Pod "pod-configmaps-9b780da4-86ba-493b-a74b-51a725902b5e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.754847ms
Mar  3 12:34:43.242: INFO: Pod "pod-configmaps-9b780da4-86ba-493b-a74b-51a725902b5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011858915s
STEP: Saw pod success
Mar  3 12:34:43.242: INFO: Pod "pod-configmaps-9b780da4-86ba-493b-a74b-51a725902b5e" satisfied condition "success or failure"
Mar  3 12:34:43.246: INFO: Trying to get logs from node 10.0.2.119 pod pod-configmaps-9b780da4-86ba-493b-a74b-51a725902b5e container configmap-volume-test: <nil>
STEP: delete the pod
Mar  3 12:34:43.283: INFO: Waiting for pod pod-configmaps-9b780da4-86ba-493b-a74b-51a725902b5e to disappear
Mar  3 12:34:43.287: INFO: Pod pod-configmaps-9b780da4-86ba-493b-a74b-51a725902b5e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:34:43.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-783" for this suite.
Mar  3 12:34:49.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:34:49.541: INFO: namespace configmap-783 deletion completed in 6.243989294s

• [SLOW TEST:8.381 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:34:49.541: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Mar  3 12:34:50.098: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Mar  3 12:34:52.114: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835690, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835690, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835690, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835690, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-66795bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  3 12:34:55.145: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 12:34:55.153: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:34:56.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-8305" for this suite.
Mar  3 12:35:02.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:35:02.779: INFO: namespace crd-webhook-8305 deletion completed in 6.325169071s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:13.287 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:35:02.828: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:35:02.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6527" for this suite.
Mar  3 12:35:08.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:35:09.211: INFO: namespace kubelet-test-6527 deletion completed in 6.279585236s

• [SLOW TEST:6.383 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:35:09.211: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-79b327c6-7147-4770-baba-853dd6e413e9
STEP: Creating a pod to test consume secrets
Mar  3 12:35:09.304: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7b334f49-5d2f-45e6-93c0-f4bf61982044" in namespace "projected-8378" to be "success or failure"
Mar  3 12:35:09.313: INFO: Pod "pod-projected-secrets-7b334f49-5d2f-45e6-93c0-f4bf61982044": Phase="Pending", Reason="", readiness=false. Elapsed: 9.226964ms
Mar  3 12:35:11.318: INFO: Pod "pod-projected-secrets-7b334f49-5d2f-45e6-93c0-f4bf61982044": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014446457s
STEP: Saw pod success
Mar  3 12:35:11.318: INFO: Pod "pod-projected-secrets-7b334f49-5d2f-45e6-93c0-f4bf61982044" satisfied condition "success or failure"
Mar  3 12:35:11.322: INFO: Trying to get logs from node 10.0.2.119 pod pod-projected-secrets-7b334f49-5d2f-45e6-93c0-f4bf61982044 container secret-volume-test: <nil>
STEP: delete the pod
Mar  3 12:35:11.358: INFO: Waiting for pod pod-projected-secrets-7b334f49-5d2f-45e6-93c0-f4bf61982044 to disappear
Mar  3 12:35:11.363: INFO: Pod pod-projected-secrets-7b334f49-5d2f-45e6-93c0-f4bf61982044 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:35:11.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8378" for this suite.
Mar  3 12:35:17.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:35:17.579: INFO: namespace projected-8378 deletion completed in 6.210838499s

• [SLOW TEST:8.368 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:35:17.579: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 12:35:17.667: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:35:19.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4313" for this suite.
Mar  3 12:36:05.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:36:05.969: INFO: namespace pods-4313 deletion completed in 46.207320204s

• [SLOW TEST:48.389 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:36:05.969: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 12:36:06.046: INFO: Pod name rollover-pod: Found 0 pods out of 1
Mar  3 12:36:11.059: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  3 12:36:11.059: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar  3 12:36:13.064: INFO: Creating deployment "test-rollover-deployment"
Mar  3 12:36:13.078: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar  3 12:36:15.090: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar  3 12:36:15.106: INFO: Ensure that both replica sets have 1 created replica
Mar  3 12:36:15.115: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar  3 12:36:15.126: INFO: Updating deployment test-rollover-deployment
Mar  3 12:36:15.126: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar  3 12:36:17.136: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar  3 12:36:17.146: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar  3 12:36:17.157: INFO: all replica sets need to contain the pod-template-hash label
Mar  3 12:36:17.157: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835773, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835773, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835776, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835773, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  3 12:36:19.171: INFO: all replica sets need to contain the pod-template-hash label
Mar  3 12:36:19.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835773, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835773, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835776, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835773, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  3 12:36:21.168: INFO: all replica sets need to contain the pod-template-hash label
Mar  3 12:36:21.168: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835773, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835773, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835776, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835773, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  3 12:36:23.168: INFO: all replica sets need to contain the pod-template-hash label
Mar  3 12:36:23.168: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835773, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835773, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835776, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835773, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  3 12:36:25.171: INFO: all replica sets need to contain the pod-template-hash label
Mar  3 12:36:25.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835773, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835773, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835776, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718835773, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  3 12:36:27.169: INFO: 
Mar  3 12:36:27.169: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Mar  3 12:36:27.182: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-3324 /apis/apps/v1/namespaces/deployment-3324/deployments/test-rollover-deployment 9f8bb55c-7a4f-4a6b-8a21-629787ee0c8e 1243618873 2 2020-03-03 12:36:13 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0033eb5b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-03-03 12:36:13 +0000 UTC,LastTransitionTime:2020-03-03 12:36:13 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2020-03-03 12:36:26 +0000 UTC,LastTransitionTime:2020-03-03 12:36:13 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Mar  3 12:36:27.190: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-3324 /apis/apps/v1/namespaces/deployment-3324/replicasets/test-rollover-deployment-7d7dc6548c 75132a1f-d36c-4e3f-9b41-3a1b97749e1d 1243618856 2 2020-03-03 12:36:15 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 9f8bb55c-7a4f-4a6b-8a21-629787ee0c8e 0xc0033eba87 0xc0033eba88}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0033ebae8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Mar  3 12:36:27.190: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar  3 12:36:27.190: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-3324 /apis/apps/v1/namespaces/deployment-3324/replicasets/test-rollover-controller c92489a8-bb13-47e2-a04c-64cbaf3db6b8 1243618870 2 2020-03-03 12:36:06 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 9f8bb55c-7a4f-4a6b-8a21-629787ee0c8e 0xc0033eb9b7 0xc0033eb9b8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0033eba18 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar  3 12:36:27.190: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-3324 /apis/apps/v1/namespaces/deployment-3324/replicasets/test-rollover-deployment-f6c94f66c 5204625e-2e19-4cea-bd99-c1e99ad35d20 1243616533 2 2020-03-03 12:36:13 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 9f8bb55c-7a4f-4a6b-8a21-629787ee0c8e 0xc0033ebb50 0xc0033ebb51}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0033ebbc8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar  3 12:36:27.199: INFO: Pod "test-rollover-deployment-7d7dc6548c-575p6" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-575p6 test-rollover-deployment-7d7dc6548c- deployment-3324 /api/v1/namespaces/deployment-3324/pods/test-rollover-deployment-7d7dc6548c-575p6 1e9ccd42-5ee3-4440-90c7-c7a62c360075 1243616881 0 2020-03-03 12:36:15 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[tke.cloud.tencent.com/networks-status:[{
    "name": "tke-bridge",
    "ips": [
        "172.27.0.17"
    ],
    "default": true,
    "dns": {}
}]] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c 75132a1f-d36c-4e3f-9b41-3a1b97749e1d 0xc00580e147 0xc00580e148}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-754b4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-754b4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-754b4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.119,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:36:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:36:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:36:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:36:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.119,PodIP:172.27.0.17,StartTime:2020-03-03 12:36:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-03 12:36:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://e48de8a8d837e3af338e818eaedd3d8ec37e00f2db6bb2424edd22e3d2bea4f9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.27.0.17,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:36:27.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3324" for this suite.
Mar  3 12:36:33.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:36:33.402: INFO: namespace deployment-3324 deletion completed in 6.197332359s

• [SLOW TEST:27.433 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:36:33.402: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Mar  3 12:36:33.464: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-187709168 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:36:33.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3392" for this suite.
Mar  3 12:36:39.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:36:40.028: INFO: namespace kubectl-3392 deletion completed in 6.479876891s

• [SLOW TEST:6.625 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:36:40.028: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar  3 12:36:40.106: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-390 /api/v1/namespaces/watch-390/configmaps/e2e-watch-test-configmap-a 8ec0fb02-7e12-46f9-8d13-0d4da0f5b4dd 1243621533 0 2020-03-03 12:36:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  3 12:36:40.106: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-390 /api/v1/namespaces/watch-390/configmaps/e2e-watch-test-configmap-a 8ec0fb02-7e12-46f9-8d13-0d4da0f5b4dd 1243621533 0 2020-03-03 12:36:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Mar  3 12:36:50.120: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-390 /api/v1/namespaces/watch-390/configmaps/e2e-watch-test-configmap-a 8ec0fb02-7e12-46f9-8d13-0d4da0f5b4dd 1243623504 0 2020-03-03 12:36:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar  3 12:36:50.120: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-390 /api/v1/namespaces/watch-390/configmaps/e2e-watch-test-configmap-a 8ec0fb02-7e12-46f9-8d13-0d4da0f5b4dd 1243623504 0 2020-03-03 12:36:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Mar  3 12:37:00.135: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-390 /api/v1/namespaces/watch-390/configmaps/e2e-watch-test-configmap-a 8ec0fb02-7e12-46f9-8d13-0d4da0f5b4dd 1243625478 0 2020-03-03 12:36:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  3 12:37:00.135: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-390 /api/v1/namespaces/watch-390/configmaps/e2e-watch-test-configmap-a 8ec0fb02-7e12-46f9-8d13-0d4da0f5b4dd 1243625478 0 2020-03-03 12:36:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Mar  3 12:37:10.151: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-390 /api/v1/namespaces/watch-390/configmaps/e2e-watch-test-configmap-a 8ec0fb02-7e12-46f9-8d13-0d4da0f5b4dd 1243627463 0 2020-03-03 12:36:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  3 12:37:10.151: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-390 /api/v1/namespaces/watch-390/configmaps/e2e-watch-test-configmap-a 8ec0fb02-7e12-46f9-8d13-0d4da0f5b4dd 1243627463 0 2020-03-03 12:36:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar  3 12:37:20.164: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-390 /api/v1/namespaces/watch-390/configmaps/e2e-watch-test-configmap-b c820a4e4-9a5c-484a-8a30-def11804300c 1243629507 0 2020-03-03 12:37:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  3 12:37:20.164: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-390 /api/v1/namespaces/watch-390/configmaps/e2e-watch-test-configmap-b c820a4e4-9a5c-484a-8a30-def11804300c 1243629507 0 2020-03-03 12:37:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Mar  3 12:37:30.179: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-390 /api/v1/namespaces/watch-390/configmaps/e2e-watch-test-configmap-b c820a4e4-9a5c-484a-8a30-def11804300c 1243631491 0 2020-03-03 12:37:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  3 12:37:30.179: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-390 /api/v1/namespaces/watch-390/configmaps/e2e-watch-test-configmap-b c820a4e4-9a5c-484a-8a30-def11804300c 1243631491 0 2020-03-03 12:37:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:37:40.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-390" for this suite.
Mar  3 12:37:46.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:37:46.442: INFO: namespace watch-390 deletion completed in 6.25672201s

• [SLOW TEST:66.414 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:37:46.442: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Mar  3 12:37:48.549: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-187709168 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Mar  3 12:37:53.653: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:37:53.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9705" for this suite.
Mar  3 12:37:59.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:37:59.873: INFO: namespace pods-9705 deletion completed in 6.205395111s

• [SLOW TEST:13.431 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:37:59.874: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:38:00.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8323" for this suite.
Mar  3 12:38:12.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:38:12.277: INFO: namespace pods-8323 deletion completed in 12.23357636s

• [SLOW TEST:12.404 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:38:12.278: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-aeb1a391-cb7f-4a50-8fc7-80ae74e10070 in namespace container-probe-3189
Mar  3 12:38:14.347: INFO: Started pod busybox-aeb1a391-cb7f-4a50-8fc7-80ae74e10070 in namespace container-probe-3189
STEP: checking the pod's current state and verifying that restartCount is present
Mar  3 12:38:14.352: INFO: Initial restart count of pod busybox-aeb1a391-cb7f-4a50-8fc7-80ae74e10070 is 0
Mar  3 12:39:00.625: INFO: Restart count of pod container-probe-3189/busybox-aeb1a391-cb7f-4a50-8fc7-80ae74e10070 is now 1 (46.273863336s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:39:00.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3189" for this suite.
Mar  3 12:39:06.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:39:06.973: INFO: namespace container-probe-3189 deletion completed in 6.288714584s

• [SLOW TEST:54.695 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:39:06.973: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  3 12:39:07.059: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dec011a8-6b53-4dd0-b025-4e970627c9fe" in namespace "projected-4428" to be "success or failure"
Mar  3 12:39:07.063: INFO: Pod "downwardapi-volume-dec011a8-6b53-4dd0-b025-4e970627c9fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.180139ms
Mar  3 12:39:09.069: INFO: Pod "downwardapi-volume-dec011a8-6b53-4dd0-b025-4e970627c9fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00990928s
STEP: Saw pod success
Mar  3 12:39:09.069: INFO: Pod "downwardapi-volume-dec011a8-6b53-4dd0-b025-4e970627c9fe" satisfied condition "success or failure"
Mar  3 12:39:09.074: INFO: Trying to get logs from node 10.0.2.119 pod downwardapi-volume-dec011a8-6b53-4dd0-b025-4e970627c9fe container client-container: <nil>
STEP: delete the pod
Mar  3 12:39:09.104: INFO: Waiting for pod downwardapi-volume-dec011a8-6b53-4dd0-b025-4e970627c9fe to disappear
Mar  3 12:39:09.116: INFO: Pod downwardapi-volume-dec011a8-6b53-4dd0-b025-4e970627c9fe no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:39:09.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4428" for this suite.
Mar  3 12:39:15.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:39:15.332: INFO: namespace projected-4428 deletion completed in 6.208559292s

• [SLOW TEST:8.359 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:39:15.332: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-7g7z
STEP: Creating a pod to test atomic-volume-subpath
Mar  3 12:39:15.409: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-7g7z" in namespace "subpath-1134" to be "success or failure"
Mar  3 12:39:15.416: INFO: Pod "pod-subpath-test-projected-7g7z": Phase="Pending", Reason="", readiness=false. Elapsed: 6.446498ms
Mar  3 12:39:17.421: INFO: Pod "pod-subpath-test-projected-7g7z": Phase="Running", Reason="", readiness=true. Elapsed: 2.011530592s
Mar  3 12:39:19.427: INFO: Pod "pod-subpath-test-projected-7g7z": Phase="Running", Reason="", readiness=true. Elapsed: 4.017231704s
Mar  3 12:39:21.434: INFO: Pod "pod-subpath-test-projected-7g7z": Phase="Running", Reason="", readiness=true. Elapsed: 6.025071151s
Mar  3 12:39:23.441: INFO: Pod "pod-subpath-test-projected-7g7z": Phase="Running", Reason="", readiness=true. Elapsed: 8.031856086s
Mar  3 12:39:25.446: INFO: Pod "pod-subpath-test-projected-7g7z": Phase="Running", Reason="", readiness=true. Elapsed: 10.036925013s
Mar  3 12:39:27.452: INFO: Pod "pod-subpath-test-projected-7g7z": Phase="Running", Reason="", readiness=true. Elapsed: 12.04272394s
Mar  3 12:39:29.457: INFO: Pod "pod-subpath-test-projected-7g7z": Phase="Running", Reason="", readiness=true. Elapsed: 14.047691456s
Mar  3 12:39:31.470: INFO: Pod "pod-subpath-test-projected-7g7z": Phase="Running", Reason="", readiness=true. Elapsed: 16.0602751s
Mar  3 12:39:33.477: INFO: Pod "pod-subpath-test-projected-7g7z": Phase="Running", Reason="", readiness=true. Elapsed: 18.0680714s
Mar  3 12:39:35.482: INFO: Pod "pod-subpath-test-projected-7g7z": Phase="Running", Reason="", readiness=true. Elapsed: 20.073133031s
Mar  3 12:39:37.487: INFO: Pod "pod-subpath-test-projected-7g7z": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.077953549s
STEP: Saw pod success
Mar  3 12:39:37.487: INFO: Pod "pod-subpath-test-projected-7g7z" satisfied condition "success or failure"
Mar  3 12:39:37.491: INFO: Trying to get logs from node 10.0.2.119 pod pod-subpath-test-projected-7g7z container test-container-subpath-projected-7g7z: <nil>
STEP: delete the pod
Mar  3 12:39:37.518: INFO: Waiting for pod pod-subpath-test-projected-7g7z to disappear
Mar  3 12:39:37.522: INFO: Pod pod-subpath-test-projected-7g7z no longer exists
STEP: Deleting pod pod-subpath-test-projected-7g7z
Mar  3 12:39:37.522: INFO: Deleting pod "pod-subpath-test-projected-7g7z" in namespace "subpath-1134"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:39:37.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1134" for this suite.
Mar  3 12:39:43.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:39:43.738: INFO: namespace subpath-1134 deletion completed in 6.208142401s

• [SLOW TEST:28.406 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:39:43.739: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-9128
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-9128
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9128
Mar  3 12:39:43.850: INFO: Found 0 stateful pods, waiting for 1
Mar  3 12:39:53.859: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar  3 12:39:53.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=statefulset-9128 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  3 12:39:54.405: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  3 12:39:54.405: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  3 12:39:54.405: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  3 12:39:54.444: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar  3 12:40:04.449: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  3 12:40:04.449: INFO: Waiting for statefulset status.replicas updated to 0
Mar  3 12:40:04.580: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Mar  3 12:40:04.580: INFO: ss-0  10.0.2.119  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:39:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:39:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:39:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:39:43 +0000 UTC  }]
Mar  3 12:40:04.580: INFO: 
Mar  3 12:40:04.580: INFO: StatefulSet ss has not reached scale 3, at 1
Mar  3 12:40:05.587: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995618911s
Mar  3 12:40:06.639: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988587668s
Mar  3 12:40:07.644: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.93748965s
Mar  3 12:40:08.650: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.932112624s
Mar  3 12:40:09.660: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.925463595s
Mar  3 12:40:10.666: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.915947032s
Mar  3 12:40:11.671: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.910454674s
Mar  3 12:40:12.677: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.904953784s
Mar  3 12:40:13.682: INFO: Verifying statefulset ss doesn't scale past 3 for another 899.415129ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9128
Mar  3 12:40:14.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=statefulset-9128 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  3 12:40:14.896: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar  3 12:40:14.896: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  3 12:40:14.896: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  3 12:40:14.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=statefulset-9128 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  3 12:40:15.096: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Mar  3 12:40:15.096: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  3 12:40:15.096: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  3 12:40:15.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=statefulset-9128 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  3 12:40:15.320: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Mar  3 12:40:15.320: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  3 12:40:15.320: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  3 12:40:15.326: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Mar  3 12:40:25.333: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  3 12:40:25.333: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  3 12:40:25.333: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Mar  3 12:40:25.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=statefulset-9128 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  3 12:40:25.540: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  3 12:40:25.540: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  3 12:40:25.540: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  3 12:40:25.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=statefulset-9128 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  3 12:40:25.745: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  3 12:40:25.745: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  3 12:40:25.745: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  3 12:40:25.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=statefulset-9128 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  3 12:40:25.959: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  3 12:40:25.959: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  3 12:40:25.959: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  3 12:40:25.959: INFO: Waiting for statefulset status.replicas updated to 0
Mar  3 12:40:25.963: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Mar  3 12:40:35.977: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  3 12:40:35.977: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar  3 12:40:35.977: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar  3 12:40:35.995: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Mar  3 12:40:35.995: INFO: ss-0  10.0.2.119  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:39:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:25 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:25 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:39:43 +0000 UTC  }]
Mar  3 12:40:35.995: INFO: ss-1  10.0.2.74   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  }]
Mar  3 12:40:35.995: INFO: ss-2  10.0.2.74   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  }]
Mar  3 12:40:35.995: INFO: 
Mar  3 12:40:35.995: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  3 12:40:37.058: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Mar  3 12:40:37.058: INFO: ss-0  10.0.2.119  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:39:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:25 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:25 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:39:43 +0000 UTC  }]
Mar  3 12:40:37.059: INFO: ss-1  10.0.2.74   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  }]
Mar  3 12:40:37.059: INFO: ss-2  10.0.2.74   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  }]
Mar  3 12:40:37.059: INFO: 
Mar  3 12:40:37.059: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  3 12:40:38.064: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Mar  3 12:40:38.064: INFO: ss-1  10.0.2.74  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  }]
Mar  3 12:40:38.064: INFO: 
Mar  3 12:40:38.064: INFO: StatefulSet ss has not reached scale 0, at 1
Mar  3 12:40:39.070: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Mar  3 12:40:39.070: INFO: ss-1  10.0.2.74  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  }]
Mar  3 12:40:39.070: INFO: 
Mar  3 12:40:39.070: INFO: StatefulSet ss has not reached scale 0, at 1
Mar  3 12:40:40.081: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Mar  3 12:40:40.081: INFO: ss-1  10.0.2.74  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  }]
Mar  3 12:40:40.081: INFO: 
Mar  3 12:40:40.081: INFO: StatefulSet ss has not reached scale 0, at 1
Mar  3 12:40:41.089: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Mar  3 12:40:41.089: INFO: ss-1  10.0.2.74  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  }]
Mar  3 12:40:41.089: INFO: 
Mar  3 12:40:41.089: INFO: StatefulSet ss has not reached scale 0, at 1
Mar  3 12:40:42.095: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Mar  3 12:40:42.095: INFO: ss-1  10.0.2.74  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  }]
Mar  3 12:40:42.095: INFO: 
Mar  3 12:40:42.095: INFO: StatefulSet ss has not reached scale 0, at 1
Mar  3 12:40:43.100: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Mar  3 12:40:43.100: INFO: ss-1  10.0.2.74  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  }]
Mar  3 12:40:43.100: INFO: 
Mar  3 12:40:43.100: INFO: StatefulSet ss has not reached scale 0, at 1
Mar  3 12:40:44.106: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Mar  3 12:40:44.106: INFO: ss-1  10.0.2.74  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  }]
Mar  3 12:40:44.106: INFO: 
Mar  3 12:40:44.106: INFO: StatefulSet ss has not reached scale 0, at 1
Mar  3 12:40:45.111: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Mar  3 12:40:45.111: INFO: ss-1  10.0.2.74  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-03 12:40:04 +0000 UTC  }]
Mar  3 12:40:45.111: INFO: 
Mar  3 12:40:45.111: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9128
Mar  3 12:40:46.117: INFO: Scaling statefulset ss to 0
Mar  3 12:40:46.130: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Mar  3 12:40:46.134: INFO: Deleting all statefulset in ns statefulset-9128
Mar  3 12:40:46.138: INFO: Scaling statefulset ss to 0
Mar  3 12:40:46.152: INFO: Waiting for statefulset status.replicas updated to 0
Mar  3 12:40:46.157: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:40:46.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9128" for this suite.
Mar  3 12:40:52.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:40:52.403: INFO: namespace statefulset-9128 deletion completed in 6.215774682s

• [SLOW TEST:68.665 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:40:52.403: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:40:54.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4819" for this suite.
Mar  3 12:41:38.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:41:38.766: INFO: namespace kubelet-test-4819 deletion completed in 44.248380969s

• [SLOW TEST:46.363 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:41:38.767: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 12:41:38.830: INFO: (0) /api/v1/nodes/10.0.2.119:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.421289ms)
Mar  3 12:41:38.836: INFO: (1) /api/v1/nodes/10.0.2.119:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.868302ms)
Mar  3 12:41:38.843: INFO: (2) /api/v1/nodes/10.0.2.119:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.29219ms)
Mar  3 12:41:38.850: INFO: (3) /api/v1/nodes/10.0.2.119:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.591039ms)
Mar  3 12:41:38.857: INFO: (4) /api/v1/nodes/10.0.2.119:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.566575ms)
Mar  3 12:41:38.865: INFO: (5) /api/v1/nodes/10.0.2.119:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.480326ms)
Mar  3 12:41:38.871: INFO: (6) /api/v1/nodes/10.0.2.119:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.907728ms)
Mar  3 12:41:38.877: INFO: (7) /api/v1/nodes/10.0.2.119:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.874416ms)
Mar  3 12:41:38.882: INFO: (8) /api/v1/nodes/10.0.2.119:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.715844ms)
Mar  3 12:41:38.888: INFO: (9) /api/v1/nodes/10.0.2.119:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.652826ms)
Mar  3 12:41:38.898: INFO: (10) /api/v1/nodes/10.0.2.119:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.748622ms)
Mar  3 12:41:38.904: INFO: (11) /api/v1/nodes/10.0.2.119:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.707905ms)
Mar  3 12:41:38.910: INFO: (12) /api/v1/nodes/10.0.2.119:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.241631ms)
Mar  3 12:41:38.916: INFO: (13) /api/v1/nodes/10.0.2.119:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.755378ms)
Mar  3 12:41:38.927: INFO: (14) /api/v1/nodes/10.0.2.119:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.809934ms)
Mar  3 12:41:38.932: INFO: (15) /api/v1/nodes/10.0.2.119:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.932252ms)
Mar  3 12:41:38.943: INFO: (16) /api/v1/nodes/10.0.2.119:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.480565ms)
Mar  3 12:41:38.949: INFO: (17) /api/v1/nodes/10.0.2.119:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.885874ms)
Mar  3 12:41:38.955: INFO: (18) /api/v1/nodes/10.0.2.119:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.982541ms)
Mar  3 12:41:38.963: INFO: (19) /api/v1/nodes/10.0.2.119:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.088661ms)
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:41:38.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8970" for this suite.
Mar  3 12:41:44.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:41:45.255: INFO: namespace proxy-8970 deletion completed in 6.283358199s

• [SLOW TEST:6.488 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:41:45.255: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-902e2c25-ec44-41ca-b0a2-d4e567e95616
STEP: Creating a pod to test consume secrets
Mar  3 12:41:45.331: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8f6ee365-dd27-4626-94ac-39b19332c8c0" in namespace "projected-5610" to be "success or failure"
Mar  3 12:41:45.335: INFO: Pod "pod-projected-secrets-8f6ee365-dd27-4626-94ac-39b19332c8c0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.956278ms
Mar  3 12:41:47.340: INFO: Pod "pod-projected-secrets-8f6ee365-dd27-4626-94ac-39b19332c8c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008812195s
STEP: Saw pod success
Mar  3 12:41:47.340: INFO: Pod "pod-projected-secrets-8f6ee365-dd27-4626-94ac-39b19332c8c0" satisfied condition "success or failure"
Mar  3 12:41:47.344: INFO: Trying to get logs from node 10.0.2.119 pod pod-projected-secrets-8f6ee365-dd27-4626-94ac-39b19332c8c0 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  3 12:41:47.376: INFO: Waiting for pod pod-projected-secrets-8f6ee365-dd27-4626-94ac-39b19332c8c0 to disappear
Mar  3 12:41:47.381: INFO: Pod pod-projected-secrets-8f6ee365-dd27-4626-94ac-39b19332c8c0 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:41:47.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5610" for this suite.
Mar  3 12:41:53.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:41:53.661: INFO: namespace projected-5610 deletion completed in 6.273041954s

• [SLOW TEST:8.406 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:41:53.661: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 12:41:53.810: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Mar  3 12:41:55.870: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:41:55.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-782" for this suite.
Mar  3 12:42:01.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:42:02.166: INFO: namespace replication-controller-782 deletion completed in 6.271105334s

• [SLOW TEST:8.505 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:42:02.166: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-x5mvx in namespace proxy-1440
I0303 12:42:02.287491      23 runners.go:184] Created replication controller with name: proxy-service-x5mvx, namespace: proxy-1440, replica count: 1
I0303 12:42:03.337805      23 runners.go:184] proxy-service-x5mvx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0303 12:42:04.337964      23 runners.go:184] proxy-service-x5mvx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0303 12:42:05.338144      23 runners.go:184] proxy-service-x5mvx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0303 12:42:06.338339      23 runners.go:184] proxy-service-x5mvx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0303 12:42:07.338497      23 runners.go:184] proxy-service-x5mvx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0303 12:42:08.338695      23 runners.go:184] proxy-service-x5mvx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0303 12:42:09.338885      23 runners.go:184] proxy-service-x5mvx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0303 12:42:10.339094      23 runners.go:184] proxy-service-x5mvx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0303 12:42:11.339276      23 runners.go:184] proxy-service-x5mvx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0303 12:42:12.339464      23 runners.go:184] proxy-service-x5mvx Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  3 12:42:12.344: INFO: setup took 10.093085018s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Mar  3 12:42:12.351: INFO: (0) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/rewriteme">test</a> (200; 6.712ms)
Mar  3 12:42:12.353: INFO: (0) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">... (200; 7.978735ms)
Mar  3 12:42:12.353: INFO: (0) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 7.89165ms)
Mar  3 12:42:12.355: INFO: (0) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">test<... (200; 10.398153ms)
Mar  3 12:42:12.355: INFO: (0) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 10.499258ms)
Mar  3 12:42:12.355: INFO: (0) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 10.686999ms)
Mar  3 12:42:12.355: INFO: (0) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 10.521052ms)
Mar  3 12:42:12.356: INFO: (0) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname1/proxy/: foo (200; 10.770361ms)
Mar  3 12:42:12.358: INFO: (0) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname1/proxy/: foo (200; 12.912931ms)
Mar  3 12:42:12.358: INFO: (0) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:460/proxy/: tls baz (200; 13.776031ms)
Mar  3 12:42:12.358: INFO: (0) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/tlsrewritem... (200; 13.688194ms)
Mar  3 12:42:12.358: INFO: (0) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname2/proxy/: bar (200; 13.444612ms)
Mar  3 12:42:12.358: INFO: (0) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname2/proxy/: bar (200; 13.934726ms)
Mar  3 12:42:12.360: INFO: (0) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:462/proxy/: tls qux (200; 14.868303ms)
Mar  3 12:42:12.364: INFO: (0) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname1/proxy/: tls baz (200; 18.868651ms)
Mar  3 12:42:12.365: INFO: (0) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname2/proxy/: tls qux (200; 19.887886ms)
Mar  3 12:42:12.370: INFO: (1) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:462/proxy/: tls qux (200; 5.305696ms)
Mar  3 12:42:12.371: INFO: (1) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 5.550109ms)
Mar  3 12:42:12.371: INFO: (1) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:460/proxy/: tls baz (200; 5.701783ms)
Mar  3 12:42:12.371: INFO: (1) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 5.565158ms)
Mar  3 12:42:12.371: INFO: (1) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 6.019594ms)
Mar  3 12:42:12.371: INFO: (1) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">... (200; 6.363478ms)
Mar  3 12:42:12.371: INFO: (1) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/rewriteme">test</a> (200; 5.921037ms)
Mar  3 12:42:12.372: INFO: (1) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 6.261404ms)
Mar  3 12:42:12.372: INFO: (1) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/tlsrewritem... (200; 6.212469ms)
Mar  3 12:42:12.372: INFO: (1) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">test<... (200; 6.408882ms)
Mar  3 12:42:12.374: INFO: (1) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname1/proxy/: foo (200; 8.465329ms)
Mar  3 12:42:12.376: INFO: (1) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname2/proxy/: bar (200; 10.177288ms)
Mar  3 12:42:12.376: INFO: (1) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname2/proxy/: bar (200; 10.79171ms)
Mar  3 12:42:12.376: INFO: (1) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname1/proxy/: tls baz (200; 10.836595ms)
Mar  3 12:42:12.377: INFO: (1) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname1/proxy/: foo (200; 11.351833ms)
Mar  3 12:42:12.377: INFO: (1) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname2/proxy/: tls qux (200; 11.012067ms)
Mar  3 12:42:12.382: INFO: (2) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 5.229002ms)
Mar  3 12:42:12.383: INFO: (2) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">... (200; 5.416781ms)
Mar  3 12:42:12.383: INFO: (2) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 5.357124ms)
Mar  3 12:42:12.383: INFO: (2) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/tlsrewritem... (200; 5.719857ms)
Mar  3 12:42:12.383: INFO: (2) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/rewriteme">test</a> (200; 5.277067ms)
Mar  3 12:42:12.383: INFO: (2) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:460/proxy/: tls baz (200; 5.625651ms)
Mar  3 12:42:12.383: INFO: (2) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:462/proxy/: tls qux (200; 5.956264ms)
Mar  3 12:42:12.383: INFO: (2) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">test<... (200; 5.73694ms)
Mar  3 12:42:12.383: INFO: (2) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 5.698354ms)
Mar  3 12:42:12.383: INFO: (2) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 5.700345ms)
Mar  3 12:42:12.385: INFO: (2) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname2/proxy/: tls qux (200; 7.840174ms)
Mar  3 12:42:12.386: INFO: (2) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname1/proxy/: foo (200; 8.429859ms)
Mar  3 12:42:12.394: INFO: (2) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname1/proxy/: foo (200; 16.60433ms)
Mar  3 12:42:12.394: INFO: (2) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname2/proxy/: bar (200; 16.590119ms)
Mar  3 12:42:12.394: INFO: (2) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname2/proxy/: bar (200; 16.799239ms)
Mar  3 12:42:12.395: INFO: (2) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname1/proxy/: tls baz (200; 16.881894ms)
Mar  3 12:42:12.401: INFO: (3) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 6.017799ms)
Mar  3 12:42:12.404: INFO: (3) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">... (200; 9.254803ms)
Mar  3 12:42:12.404: INFO: (3) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:462/proxy/: tls qux (200; 9.412305ms)
Mar  3 12:42:12.405: INFO: (3) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:460/proxy/: tls baz (200; 9.415642ms)
Mar  3 12:42:12.405: INFO: (3) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 9.585882ms)
Mar  3 12:42:12.405: INFO: (3) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 9.767481ms)
Mar  3 12:42:12.405: INFO: (3) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/tlsrewritem... (200; 10.065295ms)
Mar  3 12:42:12.406: INFO: (3) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 11.182309ms)
Mar  3 12:42:12.407: INFO: (3) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/rewriteme">test</a> (200; 10.983188ms)
Mar  3 12:42:12.407: INFO: (3) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname2/proxy/: tls qux (200; 11.992568ms)
Mar  3 12:42:12.407: INFO: (3) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">test<... (200; 10.963193ms)
Mar  3 12:42:12.408: INFO: (3) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname1/proxy/: foo (200; 12.314242ms)
Mar  3 12:42:12.415: INFO: (3) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname2/proxy/: bar (200; 19.18986ms)
Mar  3 12:42:12.415: INFO: (3) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname1/proxy/: foo (200; 19.397672ms)
Mar  3 12:42:12.415: INFO: (3) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname1/proxy/: tls baz (200; 19.283199ms)
Mar  3 12:42:12.415: INFO: (3) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname2/proxy/: bar (200; 19.105119ms)
Mar  3 12:42:12.424: INFO: (4) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:462/proxy/: tls qux (200; 9.525066ms)
Mar  3 12:42:12.424: INFO: (4) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 8.775134ms)
Mar  3 12:42:12.425: INFO: (4) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/tlsrewritem... (200; 9.216463ms)
Mar  3 12:42:12.425: INFO: (4) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 9.358652ms)
Mar  3 12:42:12.425: INFO: (4) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">... (200; 9.875111ms)
Mar  3 12:42:12.425: INFO: (4) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 9.78948ms)
Mar  3 12:42:12.425: INFO: (4) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:460/proxy/: tls baz (200; 9.692908ms)
Mar  3 12:42:12.425: INFO: (4) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 9.270544ms)
Mar  3 12:42:12.425: INFO: (4) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/rewriteme">test</a> (200; 9.452798ms)
Mar  3 12:42:12.426: INFO: (4) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">test<... (200; 10.473145ms)
Mar  3 12:42:12.429: INFO: (4) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname2/proxy/: bar (200; 13.26214ms)
Mar  3 12:42:12.429: INFO: (4) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname2/proxy/: tls qux (200; 13.178528ms)
Mar  3 12:42:12.429: INFO: (4) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname2/proxy/: bar (200; 13.574403ms)
Mar  3 12:42:12.429: INFO: (4) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname1/proxy/: tls baz (200; 13.732177ms)
Mar  3 12:42:12.429: INFO: (4) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname1/proxy/: foo (200; 13.846113ms)
Mar  3 12:42:12.429: INFO: (4) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname1/proxy/: foo (200; 14.007764ms)
Mar  3 12:42:12.439: INFO: (5) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/tlsrewritem... (200; 9.577038ms)
Mar  3 12:42:12.439: INFO: (5) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 9.339966ms)
Mar  3 12:42:12.439: INFO: (5) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:462/proxy/: tls qux (200; 9.835962ms)
Mar  3 12:42:12.439: INFO: (5) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 10.203767ms)
Mar  3 12:42:12.440: INFO: (5) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">... (200; 10.094058ms)
Mar  3 12:42:12.442: INFO: (5) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname2/proxy/: tls qux (200; 12.658553ms)
Mar  3 12:42:12.442: INFO: (5) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:460/proxy/: tls baz (200; 12.214852ms)
Mar  3 12:42:12.444: INFO: (5) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/rewriteme">test</a> (200; 13.607059ms)
Mar  3 12:42:12.444: INFO: (5) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 13.464975ms)
Mar  3 12:42:12.444: INFO: (5) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">test<... (200; 13.697234ms)
Mar  3 12:42:12.444: INFO: (5) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 13.579315ms)
Mar  3 12:42:12.445: INFO: (5) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname1/proxy/: foo (200; 15.062113ms)
Mar  3 12:42:12.446: INFO: (5) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname1/proxy/: foo (200; 16.010418ms)
Mar  3 12:42:12.446: INFO: (5) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname2/proxy/: bar (200; 15.937234ms)
Mar  3 12:42:12.446: INFO: (5) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname1/proxy/: tls baz (200; 15.906642ms)
Mar  3 12:42:12.446: INFO: (5) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname2/proxy/: bar (200; 15.872882ms)
Mar  3 12:42:12.453: INFO: (6) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:462/proxy/: tls qux (200; 6.226535ms)
Mar  3 12:42:12.453: INFO: (6) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 6.554062ms)
Mar  3 12:42:12.453: INFO: (6) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">... (200; 6.692712ms)
Mar  3 12:42:12.453: INFO: (6) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 6.268145ms)
Mar  3 12:42:12.453: INFO: (6) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">test<... (200; 6.518849ms)
Mar  3 12:42:12.454: INFO: (6) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:460/proxy/: tls baz (200; 7.043529ms)
Mar  3 12:42:12.454: INFO: (6) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 6.938168ms)
Mar  3 12:42:12.454: INFO: (6) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/tlsrewritem... (200; 6.738823ms)
Mar  3 12:42:12.455: INFO: (6) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/rewriteme">test</a> (200; 7.318262ms)
Mar  3 12:42:12.455: INFO: (6) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 7.25398ms)
Mar  3 12:42:12.456: INFO: (6) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname1/proxy/: foo (200; 8.720779ms)
Mar  3 12:42:12.456: INFO: (6) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname1/proxy/: foo (200; 9.20209ms)
Mar  3 12:42:12.457: INFO: (6) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname2/proxy/: bar (200; 9.840902ms)
Mar  3 12:42:12.458: INFO: (6) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname2/proxy/: tls qux (200; 10.138458ms)
Mar  3 12:42:12.458: INFO: (6) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname2/proxy/: bar (200; 10.26478ms)
Mar  3 12:42:12.458: INFO: (6) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname1/proxy/: tls baz (200; 10.401891ms)
Mar  3 12:42:12.463: INFO: (7) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 4.889507ms)
Mar  3 12:42:12.464: INFO: (7) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 6.102415ms)
Mar  3 12:42:12.472: INFO: (7) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 13.471773ms)
Mar  3 12:42:12.472: INFO: (7) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">... (200; 14.253759ms)
Mar  3 12:42:12.472: INFO: (7) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/rewriteme">test</a> (200; 13.731567ms)
Mar  3 12:42:12.472: INFO: (7) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 13.655548ms)
Mar  3 12:42:12.473: INFO: (7) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:462/proxy/: tls qux (200; 14.454515ms)
Mar  3 12:42:12.473: INFO: (7) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">test<... (200; 13.762711ms)
Mar  3 12:42:12.473: INFO: (7) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname1/proxy/: foo (200; 14.019499ms)
Mar  3 12:42:12.473: INFO: (7) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname2/proxy/: bar (200; 13.613251ms)
Mar  3 12:42:12.473: INFO: (7) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname1/proxy/: foo (200; 14.131874ms)
Mar  3 12:42:12.473: INFO: (7) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:460/proxy/: tls baz (200; 14.235482ms)
Mar  3 12:42:12.473: INFO: (7) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname2/proxy/: bar (200; 14.011611ms)
Mar  3 12:42:12.473: INFO: (7) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/tlsrewritem... (200; 14.645789ms)
Mar  3 12:42:12.473: INFO: (7) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname2/proxy/: tls qux (200; 14.769486ms)
Mar  3 12:42:12.473: INFO: (7) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname1/proxy/: tls baz (200; 13.975671ms)
Mar  3 12:42:12.478: INFO: (8) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:460/proxy/: tls baz (200; 5.235412ms)
Mar  3 12:42:12.478: INFO: (8) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 5.412765ms)
Mar  3 12:42:12.479: INFO: (8) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/rewriteme">test</a> (200; 5.865597ms)
Mar  3 12:42:12.479: INFO: (8) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">test<... (200; 5.856195ms)
Mar  3 12:42:12.479: INFO: (8) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 6.198183ms)
Mar  3 12:42:12.480: INFO: (8) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/tlsrewritem... (200; 6.580153ms)
Mar  3 12:42:12.480: INFO: (8) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 6.517042ms)
Mar  3 12:42:12.480: INFO: (8) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:462/proxy/: tls qux (200; 6.879903ms)
Mar  3 12:42:12.480: INFO: (8) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">... (200; 6.872982ms)
Mar  3 12:42:12.480: INFO: (8) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 6.867615ms)
Mar  3 12:42:12.481: INFO: (8) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname1/proxy/: foo (200; 8.048669ms)
Mar  3 12:42:12.482: INFO: (8) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname1/proxy/: foo (200; 9.242399ms)
Mar  3 12:42:12.484: INFO: (8) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname2/proxy/: bar (200; 11.181894ms)
Mar  3 12:42:12.484: INFO: (8) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname1/proxy/: tls baz (200; 11.176037ms)
Mar  3 12:42:12.485: INFO: (8) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname2/proxy/: tls qux (200; 11.219095ms)
Mar  3 12:42:12.485: INFO: (8) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname2/proxy/: bar (200; 11.325917ms)
Mar  3 12:42:12.490: INFO: (9) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 5.475556ms)
Mar  3 12:42:12.491: INFO: (9) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:460/proxy/: tls baz (200; 5.444408ms)
Mar  3 12:42:12.491: INFO: (9) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:462/proxy/: tls qux (200; 5.878604ms)
Mar  3 12:42:12.491: INFO: (9) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 5.608338ms)
Mar  3 12:42:12.491: INFO: (9) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">... (200; 5.870526ms)
Mar  3 12:42:12.491: INFO: (9) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 5.822728ms)
Mar  3 12:42:12.491: INFO: (9) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 5.519001ms)
Mar  3 12:42:12.491: INFO: (9) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/tlsrewritem... (200; 6.267346ms)
Mar  3 12:42:12.491: INFO: (9) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/rewriteme">test</a> (200; 5.700211ms)
Mar  3 12:42:12.492: INFO: (9) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">test<... (200; 6.045773ms)
Mar  3 12:42:12.494: INFO: (9) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname2/proxy/: tls qux (200; 9.196925ms)
Mar  3 12:42:12.494: INFO: (9) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname1/proxy/: foo (200; 9.025085ms)
Mar  3 12:42:12.501: INFO: (9) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname1/proxy/: tls baz (200; 15.321053ms)
Mar  3 12:42:12.501: INFO: (9) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname2/proxy/: bar (200; 15.813128ms)
Mar  3 12:42:12.502: INFO: (9) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname1/proxy/: foo (200; 16.27468ms)
Mar  3 12:42:12.502: INFO: (9) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname2/proxy/: bar (200; 16.009126ms)
Mar  3 12:42:12.507: INFO: (10) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 5.315659ms)
Mar  3 12:42:12.507: INFO: (10) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:462/proxy/: tls qux (200; 5.141199ms)
Mar  3 12:42:12.508: INFO: (10) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/tlsrewritem... (200; 5.61445ms)
Mar  3 12:42:12.508: INFO: (10) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">... (200; 5.42843ms)
Mar  3 12:42:12.508: INFO: (10) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/rewriteme">test</a> (200; 5.569294ms)
Mar  3 12:42:12.508: INFO: (10) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:460/proxy/: tls baz (200; 5.672787ms)
Mar  3 12:42:12.538: INFO: (10) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">test<... (200; 35.77529ms)
Mar  3 12:42:12.538: INFO: (10) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 35.698092ms)
Mar  3 12:42:12.539: INFO: (10) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 36.792715ms)
Mar  3 12:42:12.540: INFO: (10) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 37.815604ms)
Mar  3 12:42:12.542: INFO: (10) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname1/proxy/: tls baz (200; 39.30311ms)
Mar  3 12:42:12.542: INFO: (10) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname2/proxy/: tls qux (200; 39.789368ms)
Mar  3 12:42:12.542: INFO: (10) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname1/proxy/: foo (200; 39.034775ms)
Mar  3 12:42:12.542: INFO: (10) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname1/proxy/: foo (200; 40.019741ms)
Mar  3 12:42:12.545: INFO: (10) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname2/proxy/: bar (200; 42.853717ms)
Mar  3 12:42:12.546: INFO: (10) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname2/proxy/: bar (200; 43.73841ms)
Mar  3 12:42:12.552: INFO: (11) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">... (200; 5.587786ms)
Mar  3 12:42:12.552: INFO: (11) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:462/proxy/: tls qux (200; 5.86128ms)
Mar  3 12:42:12.552: INFO: (11) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 5.665676ms)
Mar  3 12:42:12.552: INFO: (11) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:460/proxy/: tls baz (200; 5.732732ms)
Mar  3 12:42:12.552: INFO: (11) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/rewriteme">test</a> (200; 5.687186ms)
Mar  3 12:42:12.553: INFO: (11) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">test<... (200; 6.063876ms)
Mar  3 12:42:12.553: INFO: (11) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 6.309696ms)
Mar  3 12:42:12.553: INFO: (11) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 6.500252ms)
Mar  3 12:42:12.554: INFO: (11) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 6.129759ms)
Mar  3 12:42:12.554: INFO: (11) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/tlsrewritem... (200; 6.4159ms)
Mar  3 12:42:12.643: INFO: (11) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname2/proxy/: bar (200; 95.459468ms)
Mar  3 12:42:12.643: INFO: (11) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname1/proxy/: foo (200; 95.673413ms)
Mar  3 12:42:12.643: INFO: (11) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname1/proxy/: foo (200; 95.631835ms)
Mar  3 12:42:12.644: INFO: (11) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname2/proxy/: bar (200; 96.041707ms)
Mar  3 12:42:12.644: INFO: (11) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname2/proxy/: tls qux (200; 95.94482ms)
Mar  3 12:42:12.644: INFO: (11) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname1/proxy/: tls baz (200; 96.181217ms)
Mar  3 12:42:12.649: INFO: (12) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 5.454079ms)
Mar  3 12:42:12.649: INFO: (12) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/tlsrewritem... (200; 5.5435ms)
Mar  3 12:42:12.650: INFO: (12) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">... (200; 5.680771ms)
Mar  3 12:42:12.650: INFO: (12) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:460/proxy/: tls baz (200; 6.041445ms)
Mar  3 12:42:12.650: INFO: (12) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:462/proxy/: tls qux (200; 6.422367ms)
Mar  3 12:42:12.651: INFO: (12) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 6.516971ms)
Mar  3 12:42:12.651: INFO: (12) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">test<... (200; 6.065648ms)
Mar  3 12:42:12.652: INFO: (12) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/rewriteme">test</a> (200; 6.850991ms)
Mar  3 12:42:12.652: INFO: (12) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 7.012368ms)
Mar  3 12:42:12.653: INFO: (12) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname2/proxy/: tls qux (200; 8.769552ms)
Mar  3 12:42:12.654: INFO: (12) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname1/proxy/: foo (200; 9.084354ms)
Mar  3 12:42:12.654: INFO: (12) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname1/proxy/: foo (200; 9.559797ms)
Mar  3 12:42:12.654: INFO: (12) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname1/proxy/: tls baz (200; 9.744478ms)
Mar  3 12:42:12.655: INFO: (12) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname2/proxy/: bar (200; 9.648757ms)
Mar  3 12:42:12.738: INFO: (12) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname2/proxy/: bar (200; 93.751299ms)
Mar  3 12:42:12.738: INFO: (12) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 93.468715ms)
Mar  3 12:42:12.753: INFO: (13) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 14.113265ms)
Mar  3 12:42:12.755: INFO: (13) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:462/proxy/: tls qux (200; 15.841572ms)
Mar  3 12:42:12.755: INFO: (13) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname1/proxy/: foo (200; 16.050267ms)
Mar  3 12:42:12.755: INFO: (13) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:460/proxy/: tls baz (200; 16.113484ms)
Mar  3 12:42:12.755: INFO: (13) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/rewriteme">test</a> (200; 16.211153ms)
Mar  3 12:42:12.755: INFO: (13) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname1/proxy/: tls baz (200; 16.337822ms)
Mar  3 12:42:12.756: INFO: (13) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname2/proxy/: tls qux (200; 17.240182ms)
Mar  3 12:42:12.756: INFO: (13) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname1/proxy/: foo (200; 16.859214ms)
Mar  3 12:42:12.756: INFO: (13) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 16.650266ms)
Mar  3 12:42:12.756: INFO: (13) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 17.113127ms)
Mar  3 12:42:12.756: INFO: (13) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname2/proxy/: bar (200; 16.890195ms)
Mar  3 12:42:12.756: INFO: (13) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/tlsrewritem... (200; 17.315746ms)
Mar  3 12:42:12.756: INFO: (13) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">... (200; 17.248737ms)
Mar  3 12:42:12.756: INFO: (13) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 17.185929ms)
Mar  3 12:42:12.759: INFO: (13) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname2/proxy/: bar (200; 19.742436ms)
Mar  3 12:42:12.838: INFO: (13) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">test<... (200; 99.062592ms)
Mar  3 12:42:12.848: INFO: (14) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">... (200; 7.920254ms)
Mar  3 12:42:12.848: INFO: (14) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/tlsrewritem... (200; 8.422802ms)
Mar  3 12:42:12.848: INFO: (14) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:460/proxy/: tls baz (200; 8.380325ms)
Mar  3 12:42:12.849: INFO: (14) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/rewriteme">test</a> (200; 10.022153ms)
Mar  3 12:42:12.849: INFO: (14) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:462/proxy/: tls qux (200; 9.238551ms)
Mar  3 12:42:12.849: INFO: (14) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 9.350116ms)
Mar  3 12:42:12.849: INFO: (14) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname2/proxy/: bar (200; 10.36446ms)
Mar  3 12:42:12.849: INFO: (14) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 10.617969ms)
Mar  3 12:42:12.849: INFO: (14) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 9.864396ms)
Mar  3 12:42:12.849: INFO: (14) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">test<... (200; 10.087176ms)
Mar  3 12:42:12.849: INFO: (14) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 10.424198ms)
Mar  3 12:42:12.852: INFO: (14) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname1/proxy/: tls baz (200; 13.707295ms)
Mar  3 12:42:12.853: INFO: (14) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname1/proxy/: foo (200; 13.536055ms)
Mar  3 12:42:12.853: INFO: (14) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname2/proxy/: bar (200; 13.370202ms)
Mar  3 12:42:12.853: INFO: (14) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname2/proxy/: tls qux (200; 13.163053ms)
Mar  3 12:42:12.853: INFO: (14) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname1/proxy/: foo (200; 13.549869ms)
Mar  3 12:42:12.858: INFO: (15) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:462/proxy/: tls qux (200; 5.286762ms)
Mar  3 12:42:12.859: INFO: (15) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">... (200; 5.768729ms)
Mar  3 12:42:12.859: INFO: (15) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/rewriteme">test</a> (200; 5.437761ms)
Mar  3 12:42:12.859: INFO: (15) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:460/proxy/: tls baz (200; 5.655253ms)
Mar  3 12:42:12.859: INFO: (15) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">test<... (200; 5.492863ms)
Mar  3 12:42:12.859: INFO: (15) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 5.919774ms)
Mar  3 12:42:12.859: INFO: (15) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 5.541274ms)
Mar  3 12:42:12.859: INFO: (15) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 5.781453ms)
Mar  3 12:42:12.860: INFO: (15) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/tlsrewritem... (200; 5.807255ms)
Mar  3 12:42:12.860: INFO: (15) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 5.99252ms)
Mar  3 12:42:12.862: INFO: (15) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname1/proxy/: tls baz (200; 8.438229ms)
Mar  3 12:42:12.862: INFO: (15) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname1/proxy/: foo (200; 8.637909ms)
Mar  3 12:42:12.863: INFO: (15) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname2/proxy/: bar (200; 9.334538ms)
Mar  3 12:42:12.864: INFO: (15) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname2/proxy/: tls qux (200; 9.796903ms)
Mar  3 12:42:12.864: INFO: (15) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname2/proxy/: bar (200; 10.192324ms)
Mar  3 12:42:12.864: INFO: (15) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname1/proxy/: foo (200; 10.279767ms)
Mar  3 12:42:12.869: INFO: (16) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 5.117905ms)
Mar  3 12:42:12.869: INFO: (16) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:462/proxy/: tls qux (200; 5.069924ms)
Mar  3 12:42:12.870: INFO: (16) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/tlsrewritem... (200; 5.210948ms)
Mar  3 12:42:12.871: INFO: (16) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 5.950533ms)
Mar  3 12:42:12.872: INFO: (16) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/rewriteme">test</a> (200; 7.290728ms)
Mar  3 12:42:12.872: INFO: (16) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 7.22398ms)
Mar  3 12:42:12.872: INFO: (16) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">test<... (200; 7.292598ms)
Mar  3 12:42:12.872: INFO: (16) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:460/proxy/: tls baz (200; 7.34433ms)
Mar  3 12:42:12.872: INFO: (16) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">... (200; 7.247732ms)
Mar  3 12:42:12.872: INFO: (16) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 7.24197ms)
Mar  3 12:42:12.873: INFO: (16) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname1/proxy/: foo (200; 9.500509ms)
Mar  3 12:42:12.874: INFO: (16) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname2/proxy/: tls qux (200; 9.083429ms)
Mar  3 12:42:12.876: INFO: (16) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname2/proxy/: bar (200; 11.197642ms)
Mar  3 12:42:12.876: INFO: (16) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname1/proxy/: tls baz (200; 11.223899ms)
Mar  3 12:42:12.876: INFO: (16) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname2/proxy/: bar (200; 11.604948ms)
Mar  3 12:42:12.876: INFO: (16) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname1/proxy/: foo (200; 11.485815ms)
Mar  3 12:42:12.882: INFO: (17) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 5.207047ms)
Mar  3 12:42:12.882: INFO: (17) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:462/proxy/: tls qux (200; 5.466036ms)
Mar  3 12:42:12.882: INFO: (17) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 5.301672ms)
Mar  3 12:42:12.883: INFO: (17) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 5.513882ms)
Mar  3 12:42:12.883: INFO: (17) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/tlsrewritem... (200; 6.232232ms)
Mar  3 12:42:12.883: INFO: (17) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:460/proxy/: tls baz (200; 6.177467ms)
Mar  3 12:42:12.883: INFO: (17) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">... (200; 6.25691ms)
Mar  3 12:42:12.884: INFO: (17) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/rewriteme">test</a> (200; 6.601521ms)
Mar  3 12:42:12.884: INFO: (17) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 6.442445ms)
Mar  3 12:42:12.884: INFO: (17) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">test<... (200; 6.601254ms)
Mar  3 12:42:12.885: INFO: (17) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname2/proxy/: bar (200; 7.946413ms)
Mar  3 12:42:12.886: INFO: (17) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname2/proxy/: tls qux (200; 9.02883ms)
Mar  3 12:42:12.887: INFO: (17) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname2/proxy/: bar (200; 8.904485ms)
Mar  3 12:42:12.887: INFO: (17) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname1/proxy/: tls baz (200; 9.902577ms)
Mar  3 12:42:12.887: INFO: (17) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname1/proxy/: foo (200; 9.612187ms)
Mar  3 12:42:12.887: INFO: (17) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname1/proxy/: foo (200; 9.569086ms)
Mar  3 12:42:12.893: INFO: (18) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/tlsrewritem... (200; 5.179701ms)
Mar  3 12:42:12.893: INFO: (18) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 5.697075ms)
Mar  3 12:42:12.893: INFO: (18) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">... (200; 5.824543ms)
Mar  3 12:42:12.893: INFO: (18) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 6.234192ms)
Mar  3 12:42:12.894: INFO: (18) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 5.678299ms)
Mar  3 12:42:12.894: INFO: (18) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/rewriteme">test</a> (200; 5.92842ms)
Mar  3 12:42:12.894: INFO: (18) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:462/proxy/: tls qux (200; 6.312704ms)
Mar  3 12:42:12.894: INFO: (18) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:460/proxy/: tls baz (200; 6.065681ms)
Mar  3 12:42:12.894: INFO: (18) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">test<... (200; 6.23357ms)
Mar  3 12:42:12.894: INFO: (18) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 6.193077ms)
Mar  3 12:42:12.898: INFO: (18) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname1/proxy/: foo (200; 9.938161ms)
Mar  3 12:42:12.938: INFO: (18) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname2/proxy/: bar (200; 49.980836ms)
Mar  3 12:42:12.938: INFO: (18) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname1/proxy/: foo (200; 50.025112ms)
Mar  3 12:42:12.938: INFO: (18) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname2/proxy/: bar (200; 49.829059ms)
Mar  3 12:42:12.938: INFO: (18) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname1/proxy/: tls baz (200; 49.945542ms)
Mar  3 12:42:12.939: INFO: (18) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname2/proxy/: tls qux (200; 51.734505ms)
Mar  3 12:42:12.945: INFO: (19) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 5.709078ms)
Mar  3 12:42:12.945: INFO: (19) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:462/proxy/: tls qux (200; 5.83313ms)
Mar  3 12:42:12.945: INFO: (19) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 5.788772ms)
Mar  3 12:42:12.946: INFO: (19) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:443/proxy/tlsrewritem... (200; 6.459972ms)
Mar  3 12:42:12.946: INFO: (19) /api/v1/namespaces/proxy-1440/pods/https:proxy-service-x5mvx-q5kk9:460/proxy/: tls baz (200; 6.279882ms)
Mar  3 12:42:12.946: INFO: (19) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:160/proxy/: foo (200; 6.7226ms)
Mar  3 12:42:12.946: INFO: (19) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9/proxy/rewriteme">test</a> (200; 6.297063ms)
Mar  3 12:42:12.946: INFO: (19) /api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/http:proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">... (200; 6.472802ms)
Mar  3 12:42:12.946: INFO: (19) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:162/proxy/: bar (200; 6.374704ms)
Mar  3 12:42:12.947: INFO: (19) /api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/: <a href="/api/v1/namespaces/proxy-1440/pods/proxy-service-x5mvx-q5kk9:1080/proxy/rewriteme">test<... (200; 6.781053ms)
Mar  3 12:42:12.949: INFO: (19) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname1/proxy/: foo (200; 9.444049ms)
Mar  3 12:42:12.950: INFO: (19) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname2/proxy/: tls qux (200; 11.046623ms)
Mar  3 12:42:12.951: INFO: (19) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname2/proxy/: bar (200; 10.812273ms)
Mar  3 12:42:12.951: INFO: (19) /api/v1/namespaces/proxy-1440/services/http:proxy-service-x5mvx:portname1/proxy/: foo (200; 11.061792ms)
Mar  3 12:42:12.951: INFO: (19) /api/v1/namespaces/proxy-1440/services/https:proxy-service-x5mvx:tlsportname1/proxy/: tls baz (200; 11.351819ms)
Mar  3 12:42:12.951: INFO: (19) /api/v1/namespaces/proxy-1440/services/proxy-service-x5mvx:portname2/proxy/: bar (200; 11.68857ms)
STEP: deleting ReplicationController proxy-service-x5mvx in namespace proxy-1440, will wait for the garbage collector to delete the pods
Mar  3 12:42:13.020: INFO: Deleting ReplicationController proxy-service-x5mvx took: 13.731855ms
Mar  3 12:42:13.521: INFO: Terminating ReplicationController proxy-service-x5mvx pods took: 500.206767ms
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:42:15.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1440" for this suite.
Mar  3 12:42:21.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:42:21.537: INFO: namespace proxy-1440 deletion completed in 6.209437678s

• [SLOW TEST:19.371 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:42:21.537: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Mar  3 12:42:21.587: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  3 12:42:21.609: INFO: Waiting for terminating namespaces to be deleted...
Mar  3 12:42:21.613: INFO: 
Logging pods the kubelet thinks is on node 10.0.2.119 before test
Mar  3 12:42:21.622: INFO: sonobuoy-systemd-logs-daemon-set-046f08d908064245-vrhb2 from sonobuoy started at 2020-03-03 12:02:34 +0000 UTC (2 container statuses recorded)
Mar  3 12:42:21.622: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  3 12:42:21.622: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  3 12:42:21.622: INFO: tke-bridge-agent-qb5s8 from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:42:21.622: INFO: 	Container tke-bridge-agent ready: true, restart count 0
Mar  3 12:42:21.622: INFO: l7-lb-controller-66b9d774dc-2jgkk from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:42:21.622: INFO: 	Container l7-lb-controller ready: true, restart count 0
Mar  3 12:42:21.622: INFO: tke-cni-agent-nqwxr from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:42:21.622: INFO: 	Container tke-cni-agent ready: true, restart count 0
Mar  3 12:42:21.622: INFO: ip-masq-agent-67jk9 from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:42:21.622: INFO: 	Container ip-masq-agent ready: true, restart count 0
Mar  3 12:42:21.622: INFO: coredns-79444468c6-nwjdn from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:42:21.622: INFO: 	Container coredns ready: true, restart count 0
Mar  3 12:42:21.622: INFO: 
Logging pods the kubelet thinks is on node 10.0.2.74 before test
Mar  3 12:42:21.630: INFO: ip-masq-agent-vfrbd from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:42:21.630: INFO: 	Container ip-masq-agent ready: true, restart count 0
Mar  3 12:42:21.630: INFO: sonobuoy-systemd-logs-daemon-set-046f08d908064245-mvl4g from sonobuoy started at 2020-03-03 12:02:34 +0000 UTC (2 container statuses recorded)
Mar  3 12:42:21.630: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  3 12:42:21.630: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  3 12:42:21.630: INFO: tke-cni-agent-8jgsc from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:42:21.630: INFO: 	Container tke-cni-agent ready: true, restart count 0
Mar  3 12:42:21.630: INFO: sonobuoy from sonobuoy started at 2020-03-03 12:02:28 +0000 UTC (1 container statuses recorded)
Mar  3 12:42:21.630: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  3 12:42:21.630: INFO: sonobuoy-e2e-job-d53d4d2134fd4748 from sonobuoy started at 2020-03-03 12:02:34 +0000 UTC (2 container statuses recorded)
Mar  3 12:42:21.630: INFO: 	Container e2e ready: true, restart count 0
Mar  3 12:42:21.631: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  3 12:42:21.631: INFO: tke-bridge-agent-lrfvg from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:42:21.631: INFO: 	Container tke-bridge-agent ready: true, restart count 0
Mar  3 12:42:21.631: INFO: coredns-79444468c6-b7cdk from kube-system started at 2020-03-03 12:08:15 +0000 UTC (1 container statuses recorded)
Mar  3 12:42:21.631: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15f8cbcaf9eaac6a], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:42:22.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2601" for this suite.
Mar  3 12:42:28.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:42:28.931: INFO: namespace sched-pred-2601 deletion completed in 6.262030849s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.393 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:42:28.931: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 12:42:29.019: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Mar  3 12:42:29.034: INFO: Number of nodes with available pods: 0
Mar  3 12:42:29.034: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Mar  3 12:42:29.062: INFO: Number of nodes with available pods: 0
Mar  3 12:42:29.062: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:42:30.067: INFO: Number of nodes with available pods: 0
Mar  3 12:42:30.067: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:42:31.141: INFO: Number of nodes with available pods: 1
Mar  3 12:42:31.141: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Mar  3 12:42:31.170: INFO: Number of nodes with available pods: 1
Mar  3 12:42:31.170: INFO: Number of running nodes: 0, number of available pods: 1
Mar  3 12:42:32.175: INFO: Number of nodes with available pods: 0
Mar  3 12:42:32.175: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar  3 12:42:32.192: INFO: Number of nodes with available pods: 0
Mar  3 12:42:32.192: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:42:33.198: INFO: Number of nodes with available pods: 0
Mar  3 12:42:33.198: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:42:34.209: INFO: Number of nodes with available pods: 0
Mar  3 12:42:34.209: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:42:35.211: INFO: Number of nodes with available pods: 0
Mar  3 12:42:35.211: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:42:36.200: INFO: Number of nodes with available pods: 0
Mar  3 12:42:36.200: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:42:37.197: INFO: Number of nodes with available pods: 0
Mar  3 12:42:37.197: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:42:38.200: INFO: Number of nodes with available pods: 0
Mar  3 12:42:38.200: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:42:39.239: INFO: Number of nodes with available pods: 0
Mar  3 12:42:39.239: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:42:40.200: INFO: Number of nodes with available pods: 0
Mar  3 12:42:40.200: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:42:41.198: INFO: Number of nodes with available pods: 0
Mar  3 12:42:41.198: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:42:42.197: INFO: Number of nodes with available pods: 0
Mar  3 12:42:42.197: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:42:43.217: INFO: Number of nodes with available pods: 0
Mar  3 12:42:43.217: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:42:44.197: INFO: Number of nodes with available pods: 0
Mar  3 12:42:44.197: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:42:45.197: INFO: Number of nodes with available pods: 0
Mar  3 12:42:45.197: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:42:46.201: INFO: Number of nodes with available pods: 0
Mar  3 12:42:46.201: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:42:47.199: INFO: Number of nodes with available pods: 1
Mar  3 12:42:47.199: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7205, will wait for the garbage collector to delete the pods
Mar  3 12:42:47.282: INFO: Deleting DaemonSet.extensions daemon-set took: 13.087189ms
Mar  3 12:42:47.782: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.195927ms
Mar  3 12:42:54.987: INFO: Number of nodes with available pods: 0
Mar  3 12:42:54.987: INFO: Number of running nodes: 0, number of available pods: 0
Mar  3 12:42:54.992: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7205/daemonsets","resourceVersion":"1243696731"},"items":null}

Mar  3 12:42:54.999: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7205/pods","resourceVersion":"1243696732"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:42:55.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7205" for this suite.
Mar  3 12:43:01.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:43:01.268: INFO: namespace daemonsets-7205 deletion completed in 6.235310415s

• [SLOW TEST:32.337 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:43:01.269: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  3 12:43:01.815: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  3 12:43:03.858: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718836181, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718836181, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718836181, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718836181, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7f4f78fb6b\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  3 12:43:06.879: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:43:06.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-847" for this suite.
Mar  3 12:43:12.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:43:13.190: INFO: namespace webhook-847 deletion completed in 6.246594783s
STEP: Destroying namespace "webhook-847-markers" for this suite.
Mar  3 12:43:19.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:43:19.435: INFO: namespace webhook-847-markers deletion completed in 6.245060197s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.199 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:43:19.468: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-6d8fe8ce-5820-460e-93be-7786dbf8b3cc
STEP: Creating a pod to test consume configMaps
Mar  3 12:43:19.527: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1b96a0e1-6a17-4c13-92bd-e6e57d3db8af" in namespace "projected-1305" to be "success or failure"
Mar  3 12:43:19.531: INFO: Pod "pod-projected-configmaps-1b96a0e1-6a17-4c13-92bd-e6e57d3db8af": Phase="Pending", Reason="", readiness=false. Elapsed: 4.158995ms
Mar  3 12:43:21.536: INFO: Pod "pod-projected-configmaps-1b96a0e1-6a17-4c13-92bd-e6e57d3db8af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009244043s
STEP: Saw pod success
Mar  3 12:43:21.536: INFO: Pod "pod-projected-configmaps-1b96a0e1-6a17-4c13-92bd-e6e57d3db8af" satisfied condition "success or failure"
Mar  3 12:43:21.540: INFO: Trying to get logs from node 10.0.2.119 pod pod-projected-configmaps-1b96a0e1-6a17-4c13-92bd-e6e57d3db8af container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  3 12:43:21.574: INFO: Waiting for pod pod-projected-configmaps-1b96a0e1-6a17-4c13-92bd-e6e57d3db8af to disappear
Mar  3 12:43:21.578: INFO: Pod pod-projected-configmaps-1b96a0e1-6a17-4c13-92bd-e6e57d3db8af no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:43:21.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1305" for this suite.
Mar  3 12:43:27.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:43:27.818: INFO: namespace projected-1305 deletion completed in 6.234159623s

• [SLOW TEST:8.350 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:43:27.818: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Mar  3 12:43:27.915: INFO: Waiting up to 5m0s for pod "client-containers-2fac4d19-aeba-4187-b9e7-f7c3f458bb5d" in namespace "containers-6686" to be "success or failure"
Mar  3 12:43:27.919: INFO: Pod "client-containers-2fac4d19-aeba-4187-b9e7-f7c3f458bb5d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.213948ms
Mar  3 12:43:29.927: INFO: Pod "client-containers-2fac4d19-aeba-4187-b9e7-f7c3f458bb5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011706067s
STEP: Saw pod success
Mar  3 12:43:29.927: INFO: Pod "client-containers-2fac4d19-aeba-4187-b9e7-f7c3f458bb5d" satisfied condition "success or failure"
Mar  3 12:43:29.934: INFO: Trying to get logs from node 10.0.2.74 pod client-containers-2fac4d19-aeba-4187-b9e7-f7c3f458bb5d container test-container: <nil>
STEP: delete the pod
Mar  3 12:43:29.969: INFO: Waiting for pod client-containers-2fac4d19-aeba-4187-b9e7-f7c3f458bb5d to disappear
Mar  3 12:43:29.974: INFO: Pod client-containers-2fac4d19-aeba-4187-b9e7-f7c3f458bb5d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:43:29.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6686" for this suite.
Mar  3 12:43:36.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:43:36.247: INFO: namespace containers-6686 deletion completed in 6.264396565s

• [SLOW TEST:8.429 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:43:36.247: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  3 12:43:36.314: INFO: Waiting up to 5m0s for pod "downwardapi-volume-19f4f07e-5029-4166-9663-4ccf2b7e7695" in namespace "downward-api-6897" to be "success or failure"
Mar  3 12:43:36.318: INFO: Pod "downwardapi-volume-19f4f07e-5029-4166-9663-4ccf2b7e7695": Phase="Pending", Reason="", readiness=false. Elapsed: 4.112261ms
Mar  3 12:43:38.324: INFO: Pod "downwardapi-volume-19f4f07e-5029-4166-9663-4ccf2b7e7695": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010130323s
STEP: Saw pod success
Mar  3 12:43:38.324: INFO: Pod "downwardapi-volume-19f4f07e-5029-4166-9663-4ccf2b7e7695" satisfied condition "success or failure"
Mar  3 12:43:38.328: INFO: Trying to get logs from node 10.0.2.74 pod downwardapi-volume-19f4f07e-5029-4166-9663-4ccf2b7e7695 container client-container: <nil>
STEP: delete the pod
Mar  3 12:43:38.354: INFO: Waiting for pod downwardapi-volume-19f4f07e-5029-4166-9663-4ccf2b7e7695 to disappear
Mar  3 12:43:38.360: INFO: Pod downwardapi-volume-19f4f07e-5029-4166-9663-4ccf2b7e7695 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:43:38.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6897" for this suite.
Mar  3 12:43:44.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:43:44.651: INFO: namespace downward-api-6897 deletion completed in 6.28601665s

• [SLOW TEST:8.404 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:43:44.652: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-rd6t
STEP: Creating a pod to test atomic-volume-subpath
Mar  3 12:43:44.748: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-rd6t" in namespace "subpath-5796" to be "success or failure"
Mar  3 12:43:44.755: INFO: Pod "pod-subpath-test-configmap-rd6t": Phase="Pending", Reason="", readiness=false. Elapsed: 7.373057ms
Mar  3 12:43:46.760: INFO: Pod "pod-subpath-test-configmap-rd6t": Phase="Running", Reason="", readiness=true. Elapsed: 2.012230399s
Mar  3 12:43:48.765: INFO: Pod "pod-subpath-test-configmap-rd6t": Phase="Running", Reason="", readiness=true. Elapsed: 4.017170627s
Mar  3 12:43:50.788: INFO: Pod "pod-subpath-test-configmap-rd6t": Phase="Running", Reason="", readiness=true. Elapsed: 6.040327701s
Mar  3 12:43:52.793: INFO: Pod "pod-subpath-test-configmap-rd6t": Phase="Running", Reason="", readiness=true. Elapsed: 8.045074333s
Mar  3 12:43:54.799: INFO: Pod "pod-subpath-test-configmap-rd6t": Phase="Running", Reason="", readiness=true. Elapsed: 10.051096135s
Mar  3 12:43:56.805: INFO: Pod "pod-subpath-test-configmap-rd6t": Phase="Running", Reason="", readiness=true. Elapsed: 12.056705464s
Mar  3 12:43:58.810: INFO: Pod "pod-subpath-test-configmap-rd6t": Phase="Running", Reason="", readiness=true. Elapsed: 14.062352836s
Mar  3 12:44:00.817: INFO: Pod "pod-subpath-test-configmap-rd6t": Phase="Running", Reason="", readiness=true. Elapsed: 16.068795914s
Mar  3 12:44:02.822: INFO: Pod "pod-subpath-test-configmap-rd6t": Phase="Running", Reason="", readiness=true. Elapsed: 18.073912559s
Mar  3 12:44:04.829: INFO: Pod "pod-subpath-test-configmap-rd6t": Phase="Running", Reason="", readiness=true. Elapsed: 20.08074492s
Mar  3 12:44:06.834: INFO: Pod "pod-subpath-test-configmap-rd6t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.086369615s
STEP: Saw pod success
Mar  3 12:44:06.835: INFO: Pod "pod-subpath-test-configmap-rd6t" satisfied condition "success or failure"
Mar  3 12:44:06.840: INFO: Trying to get logs from node 10.0.2.119 pod pod-subpath-test-configmap-rd6t container test-container-subpath-configmap-rd6t: <nil>
STEP: delete the pod
Mar  3 12:44:06.873: INFO: Waiting for pod pod-subpath-test-configmap-rd6t to disappear
Mar  3 12:44:06.877: INFO: Pod pod-subpath-test-configmap-rd6t no longer exists
STEP: Deleting pod pod-subpath-test-configmap-rd6t
Mar  3 12:44:06.877: INFO: Deleting pod "pod-subpath-test-configmap-rd6t" in namespace "subpath-5796"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:44:06.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5796" for this suite.
Mar  3 12:44:12.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:44:13.159: INFO: namespace subpath-5796 deletion completed in 6.272233064s

• [SLOW TEST:28.507 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:44:13.159: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:44:24.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3024" for this suite.
Mar  3 12:44:30.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:44:30.543: INFO: namespace resourcequota-3024 deletion completed in 6.247292408s

• [SLOW TEST:17.384 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:44:30.543: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-7869
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  3 12:44:30.598: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  3 12:44:48.713: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.27.0.29 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7869 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  3 12:44:48.713: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 12:44:49.828: INFO: Found all expected endpoints: [netserver-0]
Mar  3 12:44:49.833: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.27.0.90 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7869 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  3 12:44:49.833: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 12:44:50.937: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:44:50.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7869" for this suite.
Mar  3 12:45:03.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:45:03.302: INFO: namespace pod-network-test-7869 deletion completed in 12.354990878s

• [SLOW TEST:32.759 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:45:03.303: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  3 12:45:04.002: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  3 12:45:07.043: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:45:07.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5809" for this suite.
Mar  3 12:45:13.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:45:13.400: INFO: namespace webhook-5809 deletion completed in 6.217960548s
STEP: Destroying namespace "webhook-5809-markers" for this suite.
Mar  3 12:45:19.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:45:19.610: INFO: namespace webhook-5809-markers deletion completed in 6.20990801s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.361 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:45:19.664: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 12:45:19.822: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Mar  3 12:45:19.842: INFO: Number of nodes with available pods: 0
Mar  3 12:45:19.842: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 12:45:20.854: INFO: Number of nodes with available pods: 1
Mar  3 12:45:20.854: INFO: Node 10.0.2.74 is running more than one daemon pod
Mar  3 12:45:21.855: INFO: Number of nodes with available pods: 2
Mar  3 12:45:21.855: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Mar  3 12:45:21.983: INFO: Wrong image for pod: daemon-set-tkwvv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:21.983: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:22.993: INFO: Wrong image for pod: daemon-set-tkwvv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:22.993: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:23.993: INFO: Wrong image for pod: daemon-set-tkwvv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:23.993: INFO: Pod daemon-set-tkwvv is not available
Mar  3 12:45:23.993: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:25.015: INFO: Wrong image for pod: daemon-set-tkwvv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:25.015: INFO: Pod daemon-set-tkwvv is not available
Mar  3 12:45:25.015: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:25.993: INFO: Wrong image for pod: daemon-set-tkwvv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:25.993: INFO: Pod daemon-set-tkwvv is not available
Mar  3 12:45:25.993: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:26.993: INFO: Wrong image for pod: daemon-set-tkwvv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:26.993: INFO: Pod daemon-set-tkwvv is not available
Mar  3 12:45:26.993: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:27.997: INFO: Wrong image for pod: daemon-set-tkwvv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:27.997: INFO: Pod daemon-set-tkwvv is not available
Mar  3 12:45:27.997: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:28.997: INFO: Wrong image for pod: daemon-set-tkwvv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:28.997: INFO: Pod daemon-set-tkwvv is not available
Mar  3 12:45:28.997: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:30.013: INFO: Wrong image for pod: daemon-set-tkwvv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:30.013: INFO: Pod daemon-set-tkwvv is not available
Mar  3 12:45:30.013: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:30.993: INFO: Wrong image for pod: daemon-set-tkwvv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:30.993: INFO: Pod daemon-set-tkwvv is not available
Mar  3 12:45:30.993: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:31.994: INFO: Wrong image for pod: daemon-set-tkwvv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:31.994: INFO: Pod daemon-set-tkwvv is not available
Mar  3 12:45:31.994: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:32.998: INFO: Wrong image for pod: daemon-set-tkwvv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:32.998: INFO: Pod daemon-set-tkwvv is not available
Mar  3 12:45:32.998: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:33.993: INFO: Wrong image for pod: daemon-set-tkwvv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:33.993: INFO: Pod daemon-set-tkwvv is not available
Mar  3 12:45:33.993: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:34.996: INFO: Pod daemon-set-rs2qz is not available
Mar  3 12:45:34.996: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:35.993: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:36.993: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:37.993: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:37.993: INFO: Pod daemon-set-vtr6l is not available
Mar  3 12:45:38.998: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:38.998: INFO: Pod daemon-set-vtr6l is not available
Mar  3 12:45:39.994: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:39.994: INFO: Pod daemon-set-vtr6l is not available
Mar  3 12:45:40.993: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:40.993: INFO: Pod daemon-set-vtr6l is not available
Mar  3 12:45:41.993: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:41.993: INFO: Pod daemon-set-vtr6l is not available
Mar  3 12:45:42.997: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:42.997: INFO: Pod daemon-set-vtr6l is not available
Mar  3 12:45:43.994: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:43.994: INFO: Pod daemon-set-vtr6l is not available
Mar  3 12:45:44.993: INFO: Wrong image for pod: daemon-set-vtr6l. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Mar  3 12:45:44.993: INFO: Pod daemon-set-vtr6l is not available
Mar  3 12:45:45.996: INFO: Pod daemon-set-5q96g is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Mar  3 12:45:46.018: INFO: Number of nodes with available pods: 1
Mar  3 12:45:46.018: INFO: Node 10.0.2.74 is running more than one daemon pod
Mar  3 12:45:47.030: INFO: Number of nodes with available pods: 2
Mar  3 12:45:47.030: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7042, will wait for the garbage collector to delete the pods
Mar  3 12:45:47.132: INFO: Deleting DaemonSet.extensions daemon-set took: 19.828936ms
Mar  3 12:45:47.632: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.171783ms
Mar  3 12:45:55.358: INFO: Number of nodes with available pods: 0
Mar  3 12:45:55.358: INFO: Number of running nodes: 0, number of available pods: 0
Mar  3 12:45:55.362: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7042/daemonsets","resourceVersion":"1243733244"},"items":null}

Mar  3 12:45:55.366: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7042/pods","resourceVersion":"1243733245"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:45:55.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7042" for this suite.
Mar  3 12:46:01.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:46:01.631: INFO: namespace daemonsets-7042 deletion completed in 6.24558903s

• [SLOW TEST:41.967 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:46:01.632: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1399.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-1399.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1399.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1399.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-1399.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1399.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  3 12:46:05.810: INFO: DNS probes using dns-1399/dns-test-3f0368ab-92d9-4485-b06b-f0b09f947e3f succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:46:05.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1399" for this suite.
Mar  3 12:46:11.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:46:12.072: INFO: namespace dns-1399 deletion completed in 6.213441269s

• [SLOW TEST:10.440 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:46:12.072: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Mar  3 12:46:12.143: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:46:31.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7255" for this suite.
Mar  3 12:46:37.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:46:37.814: INFO: namespace crd-publish-openapi-7255 deletion completed in 6.202981276s

• [SLOW TEST:25.742 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:46:37.814: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-787e7cf5-ae9f-4e3b-8f28-4b1bebe7e508
STEP: Creating configMap with name cm-test-opt-upd-4751ae70-45a6-425b-9b00-7f5534a4a0c4
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-787e7cf5-ae9f-4e3b-8f28-4b1bebe7e508
STEP: Updating configmap cm-test-opt-upd-4751ae70-45a6-425b-9b00-7f5534a4a0c4
STEP: Creating configMap with name cm-test-opt-create-11854425-1a6f-45d7-8afe-84177864ac14
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:46:42.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9663" for this suite.
Mar  3 12:46:56.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:46:56.409: INFO: namespace configmap-9663 deletion completed in 14.297078694s

• [SLOW TEST:18.595 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:46:56.409: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-5hkw
STEP: Creating a pod to test atomic-volume-subpath
Mar  3 12:46:56.493: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-5hkw" in namespace "subpath-1713" to be "success or failure"
Mar  3 12:46:56.499: INFO: Pod "pod-subpath-test-secret-5hkw": Phase="Pending", Reason="", readiness=false. Elapsed: 6.172132ms
Mar  3 12:46:58.508: INFO: Pod "pod-subpath-test-secret-5hkw": Phase="Running", Reason="", readiness=true. Elapsed: 2.014491922s
Mar  3 12:47:00.513: INFO: Pod "pod-subpath-test-secret-5hkw": Phase="Running", Reason="", readiness=true. Elapsed: 4.019496308s
Mar  3 12:47:02.519: INFO: Pod "pod-subpath-test-secret-5hkw": Phase="Running", Reason="", readiness=true. Elapsed: 6.025814466s
Mar  3 12:47:04.529: INFO: Pod "pod-subpath-test-secret-5hkw": Phase="Running", Reason="", readiness=true. Elapsed: 8.036001112s
Mar  3 12:47:06.538: INFO: Pod "pod-subpath-test-secret-5hkw": Phase="Running", Reason="", readiness=true. Elapsed: 10.045208813s
Mar  3 12:47:08.543: INFO: Pod "pod-subpath-test-secret-5hkw": Phase="Running", Reason="", readiness=true. Elapsed: 12.050238831s
Mar  3 12:47:10.549: INFO: Pod "pod-subpath-test-secret-5hkw": Phase="Running", Reason="", readiness=true. Elapsed: 14.055598609s
Mar  3 12:47:12.561: INFO: Pod "pod-subpath-test-secret-5hkw": Phase="Running", Reason="", readiness=true. Elapsed: 16.068121861s
Mar  3 12:47:14.566: INFO: Pod "pod-subpath-test-secret-5hkw": Phase="Running", Reason="", readiness=true. Elapsed: 18.073166197s
Mar  3 12:47:16.571: INFO: Pod "pod-subpath-test-secret-5hkw": Phase="Running", Reason="", readiness=true. Elapsed: 20.07827689s
Mar  3 12:47:18.577: INFO: Pod "pod-subpath-test-secret-5hkw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.083429346s
STEP: Saw pod success
Mar  3 12:47:18.577: INFO: Pod "pod-subpath-test-secret-5hkw" satisfied condition "success or failure"
Mar  3 12:47:18.581: INFO: Trying to get logs from node 10.0.2.119 pod pod-subpath-test-secret-5hkw container test-container-subpath-secret-5hkw: <nil>
STEP: delete the pod
Mar  3 12:47:18.611: INFO: Waiting for pod pod-subpath-test-secret-5hkw to disappear
Mar  3 12:47:18.615: INFO: Pod pod-subpath-test-secret-5hkw no longer exists
STEP: Deleting pod pod-subpath-test-secret-5hkw
Mar  3 12:47:18.615: INFO: Deleting pod "pod-subpath-test-secret-5hkw" in namespace "subpath-1713"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:47:18.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1713" for this suite.
Mar  3 12:47:24.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:47:24.855: INFO: namespace subpath-1713 deletion completed in 6.227965663s

• [SLOW TEST:28.445 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:47:24.855: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 12:47:24.920: INFO: Waiting up to 5m0s for pod "busybox-user-65534-5cb8538b-17e1-4fb9-99b1-b6caeb658203" in namespace "security-context-test-660" to be "success or failure"
Mar  3 12:47:24.924: INFO: Pod "busybox-user-65534-5cb8538b-17e1-4fb9-99b1-b6caeb658203": Phase="Pending", Reason="", readiness=false. Elapsed: 3.973041ms
Mar  3 12:47:26.945: INFO: Pod "busybox-user-65534-5cb8538b-17e1-4fb9-99b1-b6caeb658203": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024887249s
Mar  3 12:47:28.950: INFO: Pod "busybox-user-65534-5cb8538b-17e1-4fb9-99b1-b6caeb658203": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030168824s
Mar  3 12:47:30.955: INFO: Pod "busybox-user-65534-5cb8538b-17e1-4fb9-99b1-b6caeb658203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035252913s
Mar  3 12:47:30.955: INFO: Pod "busybox-user-65534-5cb8538b-17e1-4fb9-99b1-b6caeb658203" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:47:30.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-660" for this suite.
Mar  3 12:47:36.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:47:37.380: INFO: namespace security-context-test-660 deletion completed in 6.419824524s

• [SLOW TEST:12.525 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:47:37.380: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Mar  3 12:47:47.548: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0303 12:47:47.548848      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:47:47.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9539" for this suite.
Mar  3 12:47:55.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:47:55.771: INFO: namespace gc-9539 deletion completed in 8.216782604s

• [SLOW TEST:18.391 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:47:55.771: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Mar  3 12:47:55.829: INFO: Waiting up to 5m0s for pod "downward-api-cfb8e9dc-9c86-433b-8d42-15955b9d2aaf" in namespace "downward-api-705" to be "success or failure"
Mar  3 12:47:55.833: INFO: Pod "downward-api-cfb8e9dc-9c86-433b-8d42-15955b9d2aaf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.980364ms
Mar  3 12:47:57.838: INFO: Pod "downward-api-cfb8e9dc-9c86-433b-8d42-15955b9d2aaf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009007872s
STEP: Saw pod success
Mar  3 12:47:57.838: INFO: Pod "downward-api-cfb8e9dc-9c86-433b-8d42-15955b9d2aaf" satisfied condition "success or failure"
Mar  3 12:47:57.842: INFO: Trying to get logs from node 10.0.2.119 pod downward-api-cfb8e9dc-9c86-433b-8d42-15955b9d2aaf container dapi-container: <nil>
STEP: delete the pod
Mar  3 12:47:57.882: INFO: Waiting for pod downward-api-cfb8e9dc-9c86-433b-8d42-15955b9d2aaf to disappear
Mar  3 12:47:57.886: INFO: Pod downward-api-cfb8e9dc-9c86-433b-8d42-15955b9d2aaf no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:47:57.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-705" for this suite.
Mar  3 12:48:03.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:48:04.106: INFO: namespace downward-api-705 deletion completed in 6.21542323s

• [SLOW TEST:8.335 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:48:04.106: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Mar  3 12:48:04.163: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Mar  3 12:48:04.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 create -f - --namespace=kubectl-3692'
Mar  3 12:48:04.485: INFO: stderr: ""
Mar  3 12:48:04.485: INFO: stdout: "service/redis-slave created\n"
Mar  3 12:48:04.486: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Mar  3 12:48:04.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 create -f - --namespace=kubectl-3692'
Mar  3 12:48:04.721: INFO: stderr: ""
Mar  3 12:48:04.721: INFO: stdout: "service/redis-master created\n"
Mar  3 12:48:04.722: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar  3 12:48:04.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 create -f - --namespace=kubectl-3692'
Mar  3 12:48:04.947: INFO: stderr: ""
Mar  3 12:48:04.947: INFO: stdout: "service/frontend created\n"
Mar  3 12:48:04.947: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Mar  3 12:48:04.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 create -f - --namespace=kubectl-3692'
Mar  3 12:48:05.153: INFO: stderr: ""
Mar  3 12:48:05.153: INFO: stdout: "deployment.apps/frontend created\n"
Mar  3 12:48:05.153: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar  3 12:48:05.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 create -f - --namespace=kubectl-3692'
Mar  3 12:48:05.363: INFO: stderr: ""
Mar  3 12:48:05.363: INFO: stdout: "deployment.apps/redis-master created\n"
Mar  3 12:48:05.363: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Mar  3 12:48:05.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 create -f - --namespace=kubectl-3692'
Mar  3 12:48:05.570: INFO: stderr: ""
Mar  3 12:48:05.570: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Mar  3 12:48:05.570: INFO: Waiting for all frontend pods to be Running.
Mar  3 12:48:35.621: INFO: Waiting for frontend to serve content.
Mar  3 12:48:35.640: INFO: Trying to add a new entry to the guestbook.
Mar  3 12:48:35.659: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Mar  3 12:48:35.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 delete --grace-period=0 --force -f - --namespace=kubectl-3692'
Mar  3 12:48:35.786: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  3 12:48:35.786: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Mar  3 12:48:35.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 delete --grace-period=0 --force -f - --namespace=kubectl-3692'
Mar  3 12:48:35.906: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  3 12:48:35.906: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar  3 12:48:35.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 delete --grace-period=0 --force -f - --namespace=kubectl-3692'
Mar  3 12:48:36.025: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  3 12:48:36.025: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar  3 12:48:36.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 delete --grace-period=0 --force -f - --namespace=kubectl-3692'
Mar  3 12:48:36.129: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  3 12:48:36.129: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar  3 12:48:36.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 delete --grace-period=0 --force -f - --namespace=kubectl-3692'
Mar  3 12:48:36.257: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  3 12:48:36.257: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar  3 12:48:36.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 delete --grace-period=0 --force -f - --namespace=kubectl-3692'
Mar  3 12:48:36.355: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  3 12:48:36.355: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:48:36.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3692" for this suite.
Mar  3 12:48:48.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:48:48.773: INFO: namespace kubectl-3692 deletion completed in 12.411596987s

• [SLOW TEST:44.667 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:48:48.773: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-8c909da7-ea81-48b1-a575-60cff889320b in namespace container-probe-8112
Mar  3 12:48:50.845: INFO: Started pod busybox-8c909da7-ea81-48b1-a575-60cff889320b in namespace container-probe-8112
STEP: checking the pod's current state and verifying that restartCount is present
Mar  3 12:48:50.849: INFO: Initial restart count of pod busybox-8c909da7-ea81-48b1-a575-60cff889320b is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:52:51.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8112" for this suite.
Mar  3 12:52:57.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:52:58.032: INFO: namespace container-probe-8112 deletion completed in 6.226416087s

• [SLOW TEST:249.259 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:52:58.033: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9400.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9400.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9400.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9400.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9400.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9400.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9400.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9400.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9400.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9400.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9400.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 179.253.27.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.27.253.179_udp@PTR;check="$$(dig +tcp +noall +answer +search 179.253.27.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.27.253.179_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9400.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9400.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9400.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9400.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9400.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9400.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9400.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9400.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9400.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9400.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9400.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 179.253.27.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.27.253.179_udp@PTR;check="$$(dig +tcp +noall +answer +search 179.253.27.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.27.253.179_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  3 12:53:00.196: INFO: Unable to read wheezy_udp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:00.201: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:00.207: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:00.213: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:00.262: INFO: Unable to read jessie_udp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:00.267: INFO: Unable to read jessie_tcp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:00.273: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:00.279: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:00.322: INFO: Lookups using dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415 failed for: [wheezy_udp@dns-test-service.dns-9400.svc.cluster.local wheezy_tcp@dns-test-service.dns-9400.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local jessie_udp@dns-test-service.dns-9400.svc.cluster.local jessie_tcp@dns-test-service.dns-9400.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local]

Mar  3 12:53:05.329: INFO: Unable to read wheezy_udp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:05.335: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:05.341: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:05.347: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:05.390: INFO: Unable to read jessie_udp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:05.401: INFO: Unable to read jessie_tcp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:05.406: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:05.411: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:05.446: INFO: Lookups using dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415 failed for: [wheezy_udp@dns-test-service.dns-9400.svc.cluster.local wheezy_tcp@dns-test-service.dns-9400.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local jessie_udp@dns-test-service.dns-9400.svc.cluster.local jessie_tcp@dns-test-service.dns-9400.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local]

Mar  3 12:53:10.328: INFO: Unable to read wheezy_udp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:10.336: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:10.341: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:10.346: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:10.391: INFO: Unable to read jessie_udp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:10.400: INFO: Unable to read jessie_tcp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:10.405: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:10.410: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:10.445: INFO: Lookups using dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415 failed for: [wheezy_udp@dns-test-service.dns-9400.svc.cluster.local wheezy_tcp@dns-test-service.dns-9400.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local jessie_udp@dns-test-service.dns-9400.svc.cluster.local jessie_tcp@dns-test-service.dns-9400.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local]

Mar  3 12:53:15.328: INFO: Unable to read wheezy_udp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:15.334: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:15.339: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:15.345: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:15.391: INFO: Unable to read jessie_udp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:15.396: INFO: Unable to read jessie_tcp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:15.402: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:15.407: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:15.441: INFO: Lookups using dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415 failed for: [wheezy_udp@dns-test-service.dns-9400.svc.cluster.local wheezy_tcp@dns-test-service.dns-9400.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local jessie_udp@dns-test-service.dns-9400.svc.cluster.local jessie_tcp@dns-test-service.dns-9400.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local]

Mar  3 12:53:20.328: INFO: Unable to read wheezy_udp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:20.334: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:20.343: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:20.349: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:20.433: INFO: Unable to read jessie_udp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:20.439: INFO: Unable to read jessie_tcp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:20.444: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:20.450: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:20.490: INFO: Lookups using dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415 failed for: [wheezy_udp@dns-test-service.dns-9400.svc.cluster.local wheezy_tcp@dns-test-service.dns-9400.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local jessie_udp@dns-test-service.dns-9400.svc.cluster.local jessie_tcp@dns-test-service.dns-9400.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local]

Mar  3 12:53:25.330: INFO: Unable to read wheezy_udp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:25.335: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:25.340: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:25.346: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:25.396: INFO: Unable to read jessie_udp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:25.405: INFO: Unable to read jessie_tcp@dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:25.410: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:25.416: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local from pod dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415: the server could not find the requested resource (get pods dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415)
Mar  3 12:53:25.452: INFO: Lookups using dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415 failed for: [wheezy_udp@dns-test-service.dns-9400.svc.cluster.local wheezy_tcp@dns-test-service.dns-9400.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local jessie_udp@dns-test-service.dns-9400.svc.cluster.local jessie_tcp@dns-test-service.dns-9400.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9400.svc.cluster.local]

Mar  3 12:53:30.446: INFO: DNS probes using dns-9400/dns-test-2b59a58a-2bae-49e2-b67d-053bd878a415 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:53:30.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9400" for this suite.
Mar  3 12:53:36.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:53:36.792: INFO: namespace dns-9400 deletion completed in 6.211605335s

• [SLOW TEST:38.759 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:53:36.792: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar  3 12:53:38.873: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:53:38.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9722" for this suite.
Mar  3 12:53:44.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:53:45.163: INFO: namespace container-runtime-9722 deletion completed in 6.264045269s

• [SLOW TEST:8.371 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:53:45.163: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Mar  3 12:53:45.621: INFO: Pod name wrapped-volume-race-1708a7ff-5ec1-4e44-a274-c494c7296bc7: Found 0 pods out of 5
Mar  3 12:53:50.631: INFO: Pod name wrapped-volume-race-1708a7ff-5ec1-4e44-a274-c494c7296bc7: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-1708a7ff-5ec1-4e44-a274-c494c7296bc7 in namespace emptydir-wrapper-5361, will wait for the garbage collector to delete the pods
Mar  3 12:54:00.732: INFO: Deleting ReplicationController wrapped-volume-race-1708a7ff-5ec1-4e44-a274-c494c7296bc7 took: 13.785733ms
Mar  3 12:54:01.232: INFO: Terminating ReplicationController wrapped-volume-race-1708a7ff-5ec1-4e44-a274-c494c7296bc7 pods took: 500.256825ms
STEP: Creating RC which spawns configmap-volume pods
Mar  3 12:54:38.163: INFO: Pod name wrapped-volume-race-b1929000-fd6b-46ae-bd2c-613a65dde879: Found 0 pods out of 5
Mar  3 12:54:43.177: INFO: Pod name wrapped-volume-race-b1929000-fd6b-46ae-bd2c-613a65dde879: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-b1929000-fd6b-46ae-bd2c-613a65dde879 in namespace emptydir-wrapper-5361, will wait for the garbage collector to delete the pods
Mar  3 12:54:55.293: INFO: Deleting ReplicationController wrapped-volume-race-b1929000-fd6b-46ae-bd2c-613a65dde879 took: 15.519793ms
Mar  3 12:54:55.793: INFO: Terminating ReplicationController wrapped-volume-race-b1929000-fd6b-46ae-bd2c-613a65dde879 pods took: 500.255605ms
STEP: Creating RC which spawns configmap-volume pods
Mar  3 12:55:30.023: INFO: Pod name wrapped-volume-race-30bfc10c-d4c4-419e-9a0e-c1668441aed4: Found 0 pods out of 5
Mar  3 12:55:35.036: INFO: Pod name wrapped-volume-race-30bfc10c-d4c4-419e-9a0e-c1668441aed4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-30bfc10c-d4c4-419e-9a0e-c1668441aed4 in namespace emptydir-wrapper-5361, will wait for the garbage collector to delete the pods
Mar  3 12:55:45.151: INFO: Deleting ReplicationController wrapped-volume-race-30bfc10c-d4c4-419e-9a0e-c1668441aed4 took: 16.509291ms
Mar  3 12:55:45.651: INFO: Terminating ReplicationController wrapped-volume-race-30bfc10c-d4c4-419e-9a0e-c1668441aed4 pods took: 500.168463ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:56:25.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5361" for this suite.
Mar  3 12:56:35.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:56:36.476: INFO: namespace emptydir-wrapper-5361 deletion completed in 10.679854528s

• [SLOW TEST:171.313 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:56:36.476: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  3 12:56:36.563: INFO: Waiting up to 5m0s for pod "downwardapi-volume-febba667-17df-4073-a18c-9d15fb840d56" in namespace "downward-api-9987" to be "success or failure"
Mar  3 12:56:36.568: INFO: Pod "downwardapi-volume-febba667-17df-4073-a18c-9d15fb840d56": Phase="Pending", Reason="", readiness=false. Elapsed: 5.7058ms
Mar  3 12:56:38.588: INFO: Pod "downwardapi-volume-febba667-17df-4073-a18c-9d15fb840d56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02507802s
STEP: Saw pod success
Mar  3 12:56:38.588: INFO: Pod "downwardapi-volume-febba667-17df-4073-a18c-9d15fb840d56" satisfied condition "success or failure"
Mar  3 12:56:38.592: INFO: Trying to get logs from node 10.0.2.119 pod downwardapi-volume-febba667-17df-4073-a18c-9d15fb840d56 container client-container: <nil>
STEP: delete the pod
Mar  3 12:56:38.621: INFO: Waiting for pod downwardapi-volume-febba667-17df-4073-a18c-9d15fb840d56 to disappear
Mar  3 12:56:38.626: INFO: Pod downwardapi-volume-febba667-17df-4073-a18c-9d15fb840d56 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:56:38.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9987" for this suite.
Mar  3 12:56:44.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:56:44.836: INFO: namespace downward-api-9987 deletion completed in 6.203773639s

• [SLOW TEST:8.361 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:56:44.836: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-5827
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  3 12:56:44.894: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  3 12:57:03.093: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.27.0.6:8080/dial?request=hostName&protocol=udp&host=172.27.0.5&port=8081&tries=1'] Namespace:pod-network-test-5827 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  3 12:57:03.093: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 12:57:03.205: INFO: Waiting for endpoints: map[]
Mar  3 12:57:03.210: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.27.0.6:8080/dial?request=hostName&protocol=udp&host=172.27.0.103&port=8081&tries=1'] Namespace:pod-network-test-5827 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  3 12:57:03.210: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 12:57:03.321: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:57:03.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5827" for this suite.
Mar  3 12:57:15.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:57:15.583: INFO: namespace pod-network-test-5827 deletion completed in 12.255224408s

• [SLOW TEST:30.746 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:57:15.583: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-1a70fdf1-f860-4f8f-9a31-df58da50c30c
Mar  3 12:57:15.637: INFO: Pod name my-hostname-basic-1a70fdf1-f860-4f8f-9a31-df58da50c30c: Found 0 pods out of 1
Mar  3 12:57:20.673: INFO: Pod name my-hostname-basic-1a70fdf1-f860-4f8f-9a31-df58da50c30c: Found 1 pods out of 1
Mar  3 12:57:20.673: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-1a70fdf1-f860-4f8f-9a31-df58da50c30c" are running
Mar  3 12:57:20.680: INFO: Pod "my-hostname-basic-1a70fdf1-f860-4f8f-9a31-df58da50c30c-jmhl4" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-03 12:57:15 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-03 12:57:17 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-03 12:57:17 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-03 12:57:15 +0000 UTC Reason: Message:}])
Mar  3 12:57:20.680: INFO: Trying to dial the pod
Mar  3 12:57:25.745: INFO: Controller my-hostname-basic-1a70fdf1-f860-4f8f-9a31-df58da50c30c: Got expected result from replica 1 [my-hostname-basic-1a70fdf1-f860-4f8f-9a31-df58da50c30c-jmhl4]: "my-hostname-basic-1a70fdf1-f860-4f8f-9a31-df58da50c30c-jmhl4", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:57:25.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9773" for this suite.
Mar  3 12:57:31.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:57:32.076: INFO: namespace replication-controller-9773 deletion completed in 6.324399477s

• [SLOW TEST:16.494 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:57:32.077: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-909533cd-5101-4a44-aae0-9a124a219123
STEP: Creating a pod to test consume secrets
Mar  3 12:57:32.150: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8120bf9d-5b3c-4e18-aac1-5841f65833fd" in namespace "projected-4188" to be "success or failure"
Mar  3 12:57:32.154: INFO: Pod "pod-projected-secrets-8120bf9d-5b3c-4e18-aac1-5841f65833fd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.963779ms
Mar  3 12:57:34.161: INFO: Pod "pod-projected-secrets-8120bf9d-5b3c-4e18-aac1-5841f65833fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011239588s
STEP: Saw pod success
Mar  3 12:57:34.161: INFO: Pod "pod-projected-secrets-8120bf9d-5b3c-4e18-aac1-5841f65833fd" satisfied condition "success or failure"
Mar  3 12:57:34.165: INFO: Trying to get logs from node 10.0.2.74 pod pod-projected-secrets-8120bf9d-5b3c-4e18-aac1-5841f65833fd container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  3 12:57:34.202: INFO: Waiting for pod pod-projected-secrets-8120bf9d-5b3c-4e18-aac1-5841f65833fd to disappear
Mar  3 12:57:34.206: INFO: Pod pod-projected-secrets-8120bf9d-5b3c-4e18-aac1-5841f65833fd no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:57:34.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4188" for this suite.
Mar  3 12:57:40.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:57:40.484: INFO: namespace projected-4188 deletion completed in 6.265661569s

• [SLOW TEST:8.407 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:57:40.484: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:57:42.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-105" for this suite.
Mar  3 12:57:48.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:57:48.936: INFO: namespace emptydir-wrapper-105 deletion completed in 6.299295226s

• [SLOW TEST:8.453 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:57:48.937: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:57:54.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6695" for this suite.
Mar  3 12:58:01.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:58:01.215: INFO: namespace job-6695 deletion completed in 6.213310929s

• [SLOW TEST:12.278 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:58:01.215: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 12:58:01.292: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-97d45722-99a4-477f-a2be-aec8b688de24" in namespace "security-context-test-5961" to be "success or failure"
Mar  3 12:58:01.296: INFO: Pod "busybox-privileged-false-97d45722-99a4-477f-a2be-aec8b688de24": Phase="Pending", Reason="", readiness=false. Elapsed: 3.968492ms
Mar  3 12:58:03.305: INFO: Pod "busybox-privileged-false-97d45722-99a4-477f-a2be-aec8b688de24": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012400853s
Mar  3 12:58:03.305: INFO: Pod "busybox-privileged-false-97d45722-99a4-477f-a2be-aec8b688de24" satisfied condition "success or failure"
Mar  3 12:58:03.316: INFO: Got logs for pod "busybox-privileged-false-97d45722-99a4-477f-a2be-aec8b688de24": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:58:03.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5961" for this suite.
Mar  3 12:58:09.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:58:09.530: INFO: namespace security-context-test-5961 deletion completed in 6.20865841s

• [SLOW TEST:8.315 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:58:09.530: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 12:58:09.590: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar  3 12:58:09.606: INFO: Pod name sample-pod: Found 0 pods out of 1
Mar  3 12:58:14.611: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  3 12:58:14.611: INFO: Creating deployment "test-rolling-update-deployment"
Mar  3 12:58:14.619: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar  3 12:58:14.632: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Mar  3 12:58:16.649: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar  3 12:58:16.657: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Mar  3 12:58:16.674: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-5770 /apis/apps/v1/namespaces/deployment-5770/deployments/test-rolling-update-deployment fe1c6e1e-dd57-4ca1-b38b-05122c9255f4 1243882548 1 2020-03-03 12:58:14 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002f9ef48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-03-03 12:58:14 +0000 UTC,LastTransitionTime:2020-03-03 12:58:14 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2020-03-03 12:58:16 +0000 UTC,LastTransitionTime:2020-03-03 12:58:14 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Mar  3 12:58:16.678: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-5770 /apis/apps/v1/namespaces/deployment-5770/replicasets/test-rolling-update-deployment-55d946486 1c946b69-95e2-4b08-8008-cf8e12149cb8 1243882525 1 2020-03-03 12:58:14 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment fe1c6e1e-dd57-4ca1-b38b-05122c9255f4 0xc002f9f430 0xc002f9f431}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002f9f498 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Mar  3 12:58:16.678: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar  3 12:58:16.679: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-5770 /apis/apps/v1/namespaces/deployment-5770/replicasets/test-rolling-update-controller 282e9cde-7149-4645-a4b1-74b673e8d49c 1243882547 2 2020-03-03 12:58:09 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment fe1c6e1e-dd57-4ca1-b38b-05122c9255f4 0xc002f9f367 0xc002f9f368}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002f9f3c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar  3 12:58:16.683: INFO: Pod "test-rolling-update-deployment-55d946486-2cnb9" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-2cnb9 test-rolling-update-deployment-55d946486- deployment-5770 /api/v1/namespaces/deployment-5770/pods/test-rolling-update-deployment-55d946486-2cnb9 e7ebea06-680a-41cf-9ac1-317309c6834d 1243882522 0 2020-03-03 12:58:14 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[tke.cloud.tencent.com/networks-status:[{
    "name": "tke-bridge",
    "ips": [
        "172.27.0.112"
    ],
    "default": true,
    "dns": {}
}]] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 1c946b69-95e2-4b08-8008-cf8e12149cb8 0xc002f9f900 0xc002f9f901}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jwrv5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jwrv5,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jwrv5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.74,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:58:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:58:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:58:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 12:58:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.74,PodIP:172.27.0.112,StartTime:2020-03-03 12:58:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-03 12:58:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://cee0a0017b4428f81bbb3176faf8b356d210e4ad21f9dd11a0111e8faf7d64db,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.27.0.112,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:58:16.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5770" for this suite.
Mar  3 12:58:22.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:58:23.105: INFO: namespace deployment-5770 deletion completed in 6.416262625s

• [SLOW TEST:13.574 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:58:23.105: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  3 12:58:23.157: INFO: Waiting up to 5m0s for pod "downwardapi-volume-68674bd7-5a46-40b0-804c-cb4dde88e55b" in namespace "downward-api-3037" to be "success or failure"
Mar  3 12:58:23.161: INFO: Pod "downwardapi-volume-68674bd7-5a46-40b0-804c-cb4dde88e55b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02813ms
Mar  3 12:58:25.167: INFO: Pod "downwardapi-volume-68674bd7-5a46-40b0-804c-cb4dde88e55b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009243839s
STEP: Saw pod success
Mar  3 12:58:25.167: INFO: Pod "downwardapi-volume-68674bd7-5a46-40b0-804c-cb4dde88e55b" satisfied condition "success or failure"
Mar  3 12:58:25.171: INFO: Trying to get logs from node 10.0.2.119 pod downwardapi-volume-68674bd7-5a46-40b0-804c-cb4dde88e55b container client-container: <nil>
STEP: delete the pod
Mar  3 12:58:25.197: INFO: Waiting for pod downwardapi-volume-68674bd7-5a46-40b0-804c-cb4dde88e55b to disappear
Mar  3 12:58:25.202: INFO: Pod downwardapi-volume-68674bd7-5a46-40b0-804c-cb4dde88e55b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:58:25.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3037" for this suite.
Mar  3 12:58:31.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:58:31.418: INFO: namespace downward-api-3037 deletion completed in 6.211785908s

• [SLOW TEST:8.314 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:58:31.419: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar  3 12:58:35.530: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  3 12:58:35.535: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  3 12:58:37.535: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  3 12:58:37.544: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  3 12:58:39.535: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  3 12:58:39.539: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:58:39.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8703" for this suite.
Mar  3 12:59:07.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:59:07.805: INFO: namespace container-lifecycle-hook-8703 deletion completed in 28.244083219s

• [SLOW TEST:36.386 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:59:07.805: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Mar  3 12:59:07.861: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  3 12:59:07.876: INFO: Waiting for terminating namespaces to be deleted...
Mar  3 12:59:07.883: INFO: 
Logging pods the kubelet thinks is on node 10.0.2.119 before test
Mar  3 12:59:07.893: INFO: sonobuoy-systemd-logs-daemon-set-046f08d908064245-vrhb2 from sonobuoy started at 2020-03-03 12:02:34 +0000 UTC (2 container statuses recorded)
Mar  3 12:59:07.893: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  3 12:59:07.893: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  3 12:59:07.893: INFO: tke-bridge-agent-qb5s8 from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:59:07.893: INFO: 	Container tke-bridge-agent ready: true, restart count 0
Mar  3 12:59:07.893: INFO: l7-lb-controller-66b9d774dc-2jgkk from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:59:07.893: INFO: 	Container l7-lb-controller ready: true, restart count 0
Mar  3 12:59:07.893: INFO: tke-cni-agent-nqwxr from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:59:07.893: INFO: 	Container tke-cni-agent ready: true, restart count 0
Mar  3 12:59:07.893: INFO: ip-masq-agent-67jk9 from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:59:07.893: INFO: 	Container ip-masq-agent ready: true, restart count 0
Mar  3 12:59:07.893: INFO: coredns-79444468c6-nwjdn from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:59:07.893: INFO: 	Container coredns ready: true, restart count 0
Mar  3 12:59:07.893: INFO: 
Logging pods the kubelet thinks is on node 10.0.2.74 before test
Mar  3 12:59:07.901: INFO: tke-cni-agent-8jgsc from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:59:07.901: INFO: 	Container tke-cni-agent ready: true, restart count 0
Mar  3 12:59:07.901: INFO: sonobuoy from sonobuoy started at 2020-03-03 12:02:28 +0000 UTC (1 container statuses recorded)
Mar  3 12:59:07.901: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  3 12:59:07.901: INFO: sonobuoy-e2e-job-d53d4d2134fd4748 from sonobuoy started at 2020-03-03 12:02:34 +0000 UTC (2 container statuses recorded)
Mar  3 12:59:07.901: INFO: 	Container e2e ready: true, restart count 0
Mar  3 12:59:07.901: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  3 12:59:07.901: INFO: tke-bridge-agent-lrfvg from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:59:07.901: INFO: 	Container tke-bridge-agent ready: true, restart count 0
Mar  3 12:59:07.901: INFO: coredns-79444468c6-b7cdk from kube-system started at 2020-03-03 12:08:15 +0000 UTC (1 container statuses recorded)
Mar  3 12:59:07.901: INFO: 	Container coredns ready: true, restart count 0
Mar  3 12:59:07.901: INFO: ip-masq-agent-vfrbd from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:59:07.901: INFO: 	Container ip-masq-agent ready: true, restart count 0
Mar  3 12:59:07.901: INFO: sonobuoy-systemd-logs-daemon-set-046f08d908064245-mvl4g from sonobuoy started at 2020-03-03 12:02:34 +0000 UTC (2 container statuses recorded)
Mar  3 12:59:07.901: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  3 12:59:07.901: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node 10.0.2.119
STEP: verifying the node has the label node 10.0.2.74
Mar  3 12:59:07.951: INFO: Pod coredns-79444468c6-b7cdk requesting resource cpu=100m on Node 10.0.2.74
Mar  3 12:59:07.951: INFO: Pod coredns-79444468c6-nwjdn requesting resource cpu=100m on Node 10.0.2.119
Mar  3 12:59:07.951: INFO: Pod ip-masq-agent-67jk9 requesting resource cpu=0m on Node 10.0.2.119
Mar  3 12:59:07.951: INFO: Pod ip-masq-agent-vfrbd requesting resource cpu=0m on Node 10.0.2.74
Mar  3 12:59:07.951: INFO: Pod l7-lb-controller-66b9d774dc-2jgkk requesting resource cpu=0m on Node 10.0.2.119
Mar  3 12:59:07.951: INFO: Pod tke-bridge-agent-lrfvg requesting resource cpu=0m on Node 10.0.2.74
Mar  3 12:59:07.951: INFO: Pod tke-bridge-agent-qb5s8 requesting resource cpu=0m on Node 10.0.2.119
Mar  3 12:59:07.951: INFO: Pod tke-cni-agent-8jgsc requesting resource cpu=0m on Node 10.0.2.74
Mar  3 12:59:07.951: INFO: Pod tke-cni-agent-nqwxr requesting resource cpu=0m on Node 10.0.2.119
Mar  3 12:59:07.951: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.0.2.74
Mar  3 12:59:07.951: INFO: Pod sonobuoy-e2e-job-d53d4d2134fd4748 requesting resource cpu=0m on Node 10.0.2.74
Mar  3 12:59:07.951: INFO: Pod sonobuoy-systemd-logs-daemon-set-046f08d908064245-mvl4g requesting resource cpu=0m on Node 10.0.2.74
Mar  3 12:59:07.951: INFO: Pod sonobuoy-systemd-logs-daemon-set-046f08d908064245-vrhb2 requesting resource cpu=0m on Node 10.0.2.119
STEP: Starting Pods to consume most of the cluster CPU.
Mar  3 12:59:07.951: INFO: Creating a pod which consumes cpu=2674m on Node 10.0.2.74
Mar  3 12:59:07.960: INFO: Creating a pod which consumes cpu=2674m on Node 10.0.2.119
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0a771ac8-2f56-4ab7-8254-d3e18dbe293a.15f8ccb5471b35a5], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5629/filler-pod-0a771ac8-2f56-4ab7-8254-d3e18dbe293a to 10.0.2.119]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0a771ac8-2f56-4ab7-8254-d3e18dbe293a.15f8ccb570fd1969], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0a771ac8-2f56-4ab7-8254-d3e18dbe293a.15f8ccb57636660f], Reason = [Created], Message = [Created container filler-pod-0a771ac8-2f56-4ab7-8254-d3e18dbe293a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0a771ac8-2f56-4ab7-8254-d3e18dbe293a.15f8ccb57cd1892a], Reason = [Started], Message = [Started container filler-pod-0a771ac8-2f56-4ab7-8254-d3e18dbe293a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-daf5c54b-f971-4bff-806a-21f964f16724.15f8ccb546acba3c], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5629/filler-pod-daf5c54b-f971-4bff-806a-21f964f16724 to 10.0.2.74]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-daf5c54b-f971-4bff-806a-21f964f16724.15f8ccb570598aa0], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-daf5c54b-f971-4bff-806a-21f964f16724.15f8ccb57546d659], Reason = [Created], Message = [Created container filler-pod-daf5c54b-f971-4bff-806a-21f964f16724]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-daf5c54b-f971-4bff-806a-21f964f16724.15f8ccb57ba524d4], Reason = [Started], Message = [Started container filler-pod-daf5c54b-f971-4bff-806a-21f964f16724]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15f8ccb5bfe0c294], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node 10.0.2.119
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.0.2.74
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:59:11.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5629" for this suite.
Mar  3 12:59:17.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:59:17.339: INFO: namespace sched-pred-5629 deletion completed in 6.282952553s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:9.534 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:59:17.340: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Mar  3 12:59:17.411: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:59:20.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9003" for this suite.
Mar  3 12:59:26.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:59:26.810: INFO: namespace init-container-9003 deletion completed in 6.253243721s

• [SLOW TEST:9.471 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:59:26.810: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar  3 12:59:29.441: INFO: Successfully updated pod "pod-update-activedeadlineseconds-95a7cde2-b807-4909-876e-69aae3ac00be"
Mar  3 12:59:29.441: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-95a7cde2-b807-4909-876e-69aae3ac00be" in namespace "pods-641" to be "terminated due to deadline exceeded"
Mar  3 12:59:29.445: INFO: Pod "pod-update-activedeadlineseconds-95a7cde2-b807-4909-876e-69aae3ac00be": Phase="Running", Reason="", readiness=true. Elapsed: 4.0985ms
Mar  3 12:59:31.450: INFO: Pod "pod-update-activedeadlineseconds-95a7cde2-b807-4909-876e-69aae3ac00be": Phase="Running", Reason="", readiness=true. Elapsed: 2.008910995s
Mar  3 12:59:33.455: INFO: Pod "pod-update-activedeadlineseconds-95a7cde2-b807-4909-876e-69aae3ac00be": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.013926466s
Mar  3 12:59:33.456: INFO: Pod "pod-update-activedeadlineseconds-95a7cde2-b807-4909-876e-69aae3ac00be" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:59:33.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-641" for this suite.
Mar  3 12:59:39.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:59:39.957: INFO: namespace pods-641 deletion completed in 6.493927541s

• [SLOW TEST:13.146 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:59:39.957: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  3 12:59:40.421: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  3 12:59:42.437: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718837180, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718837180, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718837180, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718837180, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7f4f78fb6b\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  3 12:59:45.460: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 12:59:45.468: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3138-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 12:59:47.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3480" for this suite.
Mar  3 12:59:53.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:59:53.342: INFO: namespace webhook-3480 deletion completed in 6.226849907s
STEP: Destroying namespace "webhook-3480-markers" for this suite.
Mar  3 12:59:59.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 12:59:59.555: INFO: namespace webhook-3480-markers deletion completed in 6.213848181s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.631 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 12:59:59.589: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Mar  3 12:59:59.644: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  3 12:59:59.664: INFO: Waiting for terminating namespaces to be deleted...
Mar  3 12:59:59.668: INFO: 
Logging pods the kubelet thinks is on node 10.0.2.119 before test
Mar  3 12:59:59.681: INFO: coredns-79444468c6-nwjdn from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:59:59.681: INFO: 	Container coredns ready: true, restart count 0
Mar  3 12:59:59.681: INFO: sonobuoy-systemd-logs-daemon-set-046f08d908064245-vrhb2 from sonobuoy started at 2020-03-03 12:02:34 +0000 UTC (2 container statuses recorded)
Mar  3 12:59:59.681: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  3 12:59:59.681: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  3 12:59:59.681: INFO: tke-bridge-agent-qb5s8 from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:59:59.681: INFO: 	Container tke-bridge-agent ready: true, restart count 0
Mar  3 12:59:59.681: INFO: l7-lb-controller-66b9d774dc-2jgkk from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:59:59.681: INFO: 	Container l7-lb-controller ready: true, restart count 0
Mar  3 12:59:59.681: INFO: tke-cni-agent-nqwxr from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:59:59.681: INFO: 	Container tke-cni-agent ready: true, restart count 0
Mar  3 12:59:59.681: INFO: ip-masq-agent-67jk9 from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:59:59.681: INFO: 	Container ip-masq-agent ready: true, restart count 0
Mar  3 12:59:59.681: INFO: 
Logging pods the kubelet thinks is on node 10.0.2.74 before test
Mar  3 12:59:59.690: INFO: coredns-79444468c6-b7cdk from kube-system started at 2020-03-03 12:08:15 +0000 UTC (1 container statuses recorded)
Mar  3 12:59:59.690: INFO: 	Container coredns ready: true, restart count 0
Mar  3 12:59:59.690: INFO: tke-bridge-agent-lrfvg from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:59:59.690: INFO: 	Container tke-bridge-agent ready: true, restart count 0
Mar  3 12:59:59.690: INFO: sonobuoy-systemd-logs-daemon-set-046f08d908064245-mvl4g from sonobuoy started at 2020-03-03 12:02:34 +0000 UTC (2 container statuses recorded)
Mar  3 12:59:59.690: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  3 12:59:59.690: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  3 12:59:59.690: INFO: ip-masq-agent-vfrbd from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:59:59.690: INFO: 	Container ip-masq-agent ready: true, restart count 0
Mar  3 12:59:59.690: INFO: sonobuoy from sonobuoy started at 2020-03-03 12:02:28 +0000 UTC (1 container statuses recorded)
Mar  3 12:59:59.690: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  3 12:59:59.690: INFO: sonobuoy-e2e-job-d53d4d2134fd4748 from sonobuoy started at 2020-03-03 12:02:34 +0000 UTC (2 container statuses recorded)
Mar  3 12:59:59.690: INFO: 	Container e2e ready: true, restart count 0
Mar  3 12:59:59.690: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  3 12:59:59.690: INFO: tke-cni-agent-8jgsc from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 12:59:59.690: INFO: 	Container tke-cni-agent ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-b9fc1971-e1e5-455c-8e91-dee66985382a 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-b9fc1971-e1e5-455c-8e91-dee66985382a off the node 10.0.2.119
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b9fc1971-e1e5-455c-8e91-dee66985382a
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:00:03.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2786" for this suite.
Mar  3 13:00:17.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:00:18.169: INFO: namespace sched-pred-2786 deletion completed in 14.298152085s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:18.580 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:00:18.169: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  3 13:00:18.251: INFO: Waiting up to 5m0s for pod "downwardapi-volume-142dc038-d76b-402d-9c4c-6301d0d79d8d" in namespace "projected-2928" to be "success or failure"
Mar  3 13:00:18.256: INFO: Pod "downwardapi-volume-142dc038-d76b-402d-9c4c-6301d0d79d8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.712153ms
Mar  3 13:00:20.262: INFO: Pod "downwardapi-volume-142dc038-d76b-402d-9c4c-6301d0d79d8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011078286s
STEP: Saw pod success
Mar  3 13:00:20.262: INFO: Pod "downwardapi-volume-142dc038-d76b-402d-9c4c-6301d0d79d8d" satisfied condition "success or failure"
Mar  3 13:00:20.266: INFO: Trying to get logs from node 10.0.2.119 pod downwardapi-volume-142dc038-d76b-402d-9c4c-6301d0d79d8d container client-container: <nil>
STEP: delete the pod
Mar  3 13:00:20.297: INFO: Waiting for pod downwardapi-volume-142dc038-d76b-402d-9c4c-6301d0d79d8d to disappear
Mar  3 13:00:20.301: INFO: Pod downwardapi-volume-142dc038-d76b-402d-9c4c-6301d0d79d8d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:00:20.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2928" for this suite.
Mar  3 13:00:26.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:00:26.538: INFO: namespace projected-2928 deletion completed in 6.232438618s

• [SLOW TEST:8.369 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:00:26.539: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar  3 13:00:26.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-4022'
Mar  3 13:00:27.077: INFO: stderr: ""
Mar  3 13:00:27.078: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Mar  3 13:00:32.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pod e2e-test-httpd-pod --namespace=kubectl-4022 -o json'
Mar  3 13:00:32.242: INFO: stderr: ""
Mar  3 13:00:32.242: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"tke.cloud.tencent.com/networks-status\": \"[{\\n    \\\"name\\\": \\\"tke-bridge\\\",\\n    \\\"ips\\\": [\\n        \\\"172.27.0.117\\\"\\n    ],\\n    \\\"default\\\": true,\\n    \\\"dns\\\": {}\\n}]\"\n        },\n        \"creationTimestamp\": \"2020-03-03T13:00:27Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-4022\",\n        \"resourceVersion\": \"1243909312\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-4022/pods/e2e-test-httpd-pod\",\n        \"uid\": \"cbb053f9-9ff7-45fc-87cd-ff7f73075e74\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-tml6c\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.0.2.74\",\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"volumes\": [\n            {\n                \"name\": \"default-token-tml6c\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-tml6c\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-03T13:00:27Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-03T13:00:28Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-03T13:00:28Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-03T13:00:27Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://0fcc9fffae11281cae887fd2523805e0055023508fae3afc61b4c73a37e65865\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-03-03T13:00:27Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.2.74\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.27.0.117\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.27.0.117\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-03-03T13:00:27Z\"\n    }\n}\n"
STEP: replace the image in the pod
Mar  3 13:00:32.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 replace -f - --namespace=kubectl-4022'
Mar  3 13:00:32.584: INFO: stderr: ""
Mar  3 13:00:32.584: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Mar  3 13:00:32.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 delete pods e2e-test-httpd-pod --namespace=kubectl-4022'
Mar  3 13:00:45.275: INFO: stderr: ""
Mar  3 13:00:45.275: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:00:45.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4022" for this suite.
Mar  3 13:00:51.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:00:51.578: INFO: namespace kubectl-4022 deletion completed in 6.293969704s

• [SLOW TEST:25.039 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:00:51.578: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-494
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-494
STEP: creating replication controller externalsvc in namespace services-494
I0303 13:00:51.700752      23 runners.go:184] Created replication controller with name: externalsvc, namespace: services-494, replica count: 2
I0303 13:00:54.751168      23 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Mar  3 13:00:54.800: INFO: Creating new exec pod
Mar  3 13:00:56.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=services-494 execpodbhwc4 -- /bin/sh -x -c nslookup clusterip-service'
Mar  3 13:00:57.032: INFO: stderr: "+ nslookup clusterip-service\n"
Mar  3 13:00:57.032: INFO: stdout: "Server:\t\t172.27.252.53\nAddress:\t172.27.252.53#53\n\nclusterip-service.services-494.svc.cluster.local\tcanonical name = externalsvc.services-494.svc.cluster.local.\nName:\texternalsvc.services-494.svc.cluster.local\nAddress: 172.27.253.48\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-494, will wait for the garbage collector to delete the pods
Mar  3 13:00:57.099: INFO: Deleting ReplicationController externalsvc took: 11.546943ms
Mar  3 13:00:57.599: INFO: Terminating ReplicationController externalsvc pods took: 500.200563ms
Mar  3 13:01:01.949: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:01:02.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-494" for this suite.
Mar  3 13:01:08.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:01:08.248: INFO: namespace services-494 deletion completed in 6.237481952s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:16.670 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:01:08.248: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  3 13:01:08.322: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9f4ed4e8-3834-40bd-9464-f851418e8533" in namespace "downward-api-8829" to be "success or failure"
Mar  3 13:01:08.327: INFO: Pod "downwardapi-volume-9f4ed4e8-3834-40bd-9464-f851418e8533": Phase="Pending", Reason="", readiness=false. Elapsed: 4.072445ms
Mar  3 13:01:10.335: INFO: Pod "downwardapi-volume-9f4ed4e8-3834-40bd-9464-f851418e8533": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012097019s
STEP: Saw pod success
Mar  3 13:01:10.335: INFO: Pod "downwardapi-volume-9f4ed4e8-3834-40bd-9464-f851418e8533" satisfied condition "success or failure"
Mar  3 13:01:10.344: INFO: Trying to get logs from node 10.0.2.74 pod downwardapi-volume-9f4ed4e8-3834-40bd-9464-f851418e8533 container client-container: <nil>
STEP: delete the pod
Mar  3 13:01:10.372: INFO: Waiting for pod downwardapi-volume-9f4ed4e8-3834-40bd-9464-f851418e8533 to disappear
Mar  3 13:01:10.377: INFO: Pod downwardapi-volume-9f4ed4e8-3834-40bd-9464-f851418e8533 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:01:10.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8829" for this suite.
Mar  3 13:01:16.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:01:16.611: INFO: namespace downward-api-8829 deletion completed in 6.228350754s

• [SLOW TEST:8.363 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:01:16.611: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar  3 13:01:16.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-5474'
Mar  3 13:01:16.817: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  3 13:01:16.817: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Mar  3 13:01:16.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 delete jobs e2e-test-httpd-job --namespace=kubectl-5474'
Mar  3 13:01:16.926: INFO: stderr: ""
Mar  3 13:01:16.926: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:01:16.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5474" for this suite.
Mar  3 13:01:28.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:01:29.242: INFO: namespace kubectl-5474 deletion completed in 12.309565711s

• [SLOW TEST:12.631 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:01:29.243: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Mar  3 13:01:31.852: INFO: Successfully updated pod "labelsupdate0c0befac-bb67-4fbb-8aed-c3ed2e49a84c"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:01:35.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-349" for this suite.
Mar  3 13:01:47.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:01:48.192: INFO: namespace downward-api-349 deletion completed in 12.279259501s

• [SLOW TEST:18.950 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:01:48.193: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 13:01:48.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 create -f - --namespace=kubectl-4695'
Mar  3 13:01:48.542: INFO: stderr: ""
Mar  3 13:01:48.542: INFO: stdout: "replicationcontroller/redis-master created\n"
Mar  3 13:01:48.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 create -f - --namespace=kubectl-4695'
Mar  3 13:01:48.755: INFO: stderr: ""
Mar  3 13:01:48.755: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  3 13:01:49.761: INFO: Selector matched 1 pods for map[app:redis]
Mar  3 13:01:49.761: INFO: Found 0 / 1
Mar  3 13:01:50.760: INFO: Selector matched 1 pods for map[app:redis]
Mar  3 13:01:50.760: INFO: Found 1 / 1
Mar  3 13:01:50.760: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  3 13:01:50.765: INFO: Selector matched 1 pods for map[app:redis]
Mar  3 13:01:50.765: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  3 13:01:50.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 describe pod redis-master-gbdcn --namespace=kubectl-4695'
Mar  3 13:01:50.888: INFO: stderr: ""
Mar  3 13:01:50.888: INFO: stdout: "Name:         redis-master-gbdcn\nNamespace:    kubectl-4695\nNode:         10.0.2.74/10.0.2.74\nStart Time:   Tue, 03 Mar 2020 13:01:48 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  tke.cloud.tencent.com/networks-status:\n                [{\n                    \"name\": \"tke-bridge\",\n                    \"ips\": [\n                        \"172.27.0.122\"\n                    ],\n                    \"default\": true,\n                    \"dns\": {}\n                }]\nStatus:       Running\nIP:           172.27.0.122\nIPs:\n  IP:           172.27.0.122\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://a5fa868719bdfb8c8c6f9da982e0ddc6e1652fed14a3b56df0c8843385aa7aec\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 03 Mar 2020 13:01:49 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-kcjtr (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-kcjtr:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-kcjtr\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     <none>\nEvents:\n  Type    Reason     Age   From                Message\n  ----    ------     ----  ----                -------\n  Normal  Scheduled  2s    default-scheduler   Successfully assigned kubectl-4695/redis-master-gbdcn to 10.0.2.74\n  Normal  Pulled     1s    kubelet, 10.0.2.74  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    1s    kubelet, 10.0.2.74  Created container redis-master\n  Normal  Started    1s    kubelet, 10.0.2.74  Started container redis-master\n"
Mar  3 13:01:50.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 describe rc redis-master --namespace=kubectl-4695'
Mar  3 13:01:51.006: INFO: stderr: ""
Mar  3 13:01:51.006: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-4695\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-gbdcn\n"
Mar  3 13:01:51.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 describe service redis-master --namespace=kubectl-4695'
Mar  3 13:01:51.116: INFO: stderr: ""
Mar  3 13:01:51.116: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-4695\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.27.254.95\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.27.0.122:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar  3 13:01:51.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 describe node 10.0.2.119'
Mar  3 13:01:51.268: INFO: stderr: ""
Mar  3 13:01:51.268: INFO: stdout: "Name:               10.0.2.119\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=QCLOUD\n                    beta.kubernetes.io/os=linux\n                    cloud.tencent.com/node-instance-id=ins-an2yymlm\n                    failure-domain.beta.kubernetes.io/region=hk\n                    failure-domain.beta.kubernetes.io/zone=300002\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.0.2.119\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 03 Mar 2020 11:52:55 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 03 Mar 2020 11:52:59 +0000   Tue, 03 Mar 2020 11:52:59 +0000   RouteCreated                 RouteController created a route\n  MemoryPressure       False   Tue, 03 Mar 2020 13:01:28 +0000   Tue, 03 Mar 2020 11:52:55 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 03 Mar 2020 13:01:28 +0000   Tue, 03 Mar 2020 11:52:55 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 03 Mar 2020 13:01:28 +0000   Tue, 03 Mar 2020 11:52:55 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 03 Mar 2020 13:01:28 +0000   Tue, 03 Mar 2020 11:53:25 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.2.119\n  ExternalIP:  150.109.125.235\n  Hostname:    10.0.2.119\nCapacity:\n cpu:                4\n ephemeral-storage:  51473868Ki\n hugepages-2Mi:      0\n memory:             8008824Ki\n pods:               61\nAllocatable:\n cpu:                3920m\n ephemeral-storage:  47438316671\n hugepages-2Mi:      0\n memory:             7056504Ki\n pods:               61\nSystem Info:\n Machine ID:                 0ea734564f9a4e2881b866b82d679dfc\n System UUID:                701CC721-69F2-4A3C-AE7E-D470A64A1336\n Boot ID:                    2ab7ef2c-edc5-4630-b436-2167c5d8d04f\n Kernel Version:             3.10.0-1062.9.1.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.16.3-tke.2\n Kube-Proxy Version:         v1.16.3-tke.2\nPodCIDR:                     172.27.0.0/26\nPodCIDRs:                    172.27.0.0/26\nProviderID:                  qcloud:///300002/ins-an2yymlm\nNon-terminated Pods:         (6 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                coredns-79444468c6-nwjdn                                   100m (2%)     0 (0%)      30M (0%)         170M (2%)      70m\n  kube-system                ip-masq-agent-67jk9                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         68m\n  kube-system                l7-lb-controller-66b9d774dc-2jgkk                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         70m\n  kube-system                tke-bridge-agent-qb5s8                                     0 (0%)        0 (0%)      0 (0%)           0 (0%)         68m\n  kube-system                tke-cni-agent-nqwxr                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         68m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-046f08d908064245-vrhb2    0 (0%)        0 (0%)      0 (0%)           0 (0%)         59m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests   Limits\n  --------           --------   ------\n  cpu                100m (2%)  0 (0%)\n  memory             30M (0%)   170M (2%)\n  ephemeral-storage  0 (0%)     0 (0%)\nEvents:              <none>\n"
Mar  3 13:01:51.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 describe namespace kubectl-4695'
Mar  3 13:01:51.374: INFO: stderr: ""
Mar  3 13:01:51.374: INFO: stdout: "Name:         kubectl-4695\nLabels:       e2e-framework=kubectl\n              e2e-run=6aeb7322-f5a9-4ed7-a887-33f1e4217edf\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:01:51.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4695" for this suite.
Mar  3 13:02:19.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:02:19.606: INFO: namespace kubectl-4695 deletion completed in 28.227366392s

• [SLOW TEST:31.414 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:02:19.607: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  3 13:02:20.065: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  3 13:02:22.080: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718837340, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718837340, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718837340, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718837340, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7f4f78fb6b\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  3 13:02:25.161: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:02:25.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5383" for this suite.
Mar  3 13:02:31.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:02:31.833: INFO: namespace webhook-5383 deletion completed in 6.255088574s
STEP: Destroying namespace "webhook-5383-markers" for this suite.
Mar  3 13:02:37.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:02:38.066: INFO: namespace webhook-5383-markers deletion completed in 6.233392279s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.495 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:02:38.102: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 13:02:38.215: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Mar  3 13:02:41.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=crd-publish-openapi-707 create -f -'
Mar  3 13:02:42.587: INFO: stderr: ""
Mar  3 13:02:42.587: INFO: stdout: "e2e-test-crd-publish-openapi-4935-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Mar  3 13:02:42.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=crd-publish-openapi-707 delete e2e-test-crd-publish-openapi-4935-crds test-cr'
Mar  3 13:02:42.699: INFO: stderr: ""
Mar  3 13:02:42.699: INFO: stdout: "e2e-test-crd-publish-openapi-4935-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Mar  3 13:02:42.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=crd-publish-openapi-707 apply -f -'
Mar  3 13:02:42.920: INFO: stderr: ""
Mar  3 13:02:42.920: INFO: stdout: "e2e-test-crd-publish-openapi-4935-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Mar  3 13:02:42.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=crd-publish-openapi-707 delete e2e-test-crd-publish-openapi-4935-crds test-cr'
Mar  3 13:02:43.023: INFO: stderr: ""
Mar  3 13:02:43.023: INFO: stdout: "e2e-test-crd-publish-openapi-4935-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Mar  3 13:02:43.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 explain e2e-test-crd-publish-openapi-4935-crds'
Mar  3 13:02:43.219: INFO: stderr: ""
Mar  3 13:02:43.219: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4935-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:02:47.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-707" for this suite.
Mar  3 13:02:53.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:02:53.736: INFO: namespace crd-publish-openapi-707 deletion completed in 6.298200896s

• [SLOW TEST:15.634 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:02:53.736: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-xmc6
STEP: Creating a pod to test atomic-volume-subpath
Mar  3 13:02:53.820: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-xmc6" in namespace "subpath-4453" to be "success or failure"
Mar  3 13:02:53.828: INFO: Pod "pod-subpath-test-downwardapi-xmc6": Phase="Pending", Reason="", readiness=false. Elapsed: 7.842322ms
Mar  3 13:02:55.834: INFO: Pod "pod-subpath-test-downwardapi-xmc6": Phase="Running", Reason="", readiness=true. Elapsed: 2.013953668s
Mar  3 13:02:57.843: INFO: Pod "pod-subpath-test-downwardapi-xmc6": Phase="Running", Reason="", readiness=true. Elapsed: 4.022958066s
Mar  3 13:02:59.853: INFO: Pod "pod-subpath-test-downwardapi-xmc6": Phase="Running", Reason="", readiness=true. Elapsed: 6.032833331s
Mar  3 13:03:01.859: INFO: Pod "pod-subpath-test-downwardapi-xmc6": Phase="Running", Reason="", readiness=true. Elapsed: 8.038513122s
Mar  3 13:03:03.864: INFO: Pod "pod-subpath-test-downwardapi-xmc6": Phase="Running", Reason="", readiness=true. Elapsed: 10.044014817s
Mar  3 13:03:05.870: INFO: Pod "pod-subpath-test-downwardapi-xmc6": Phase="Running", Reason="", readiness=true. Elapsed: 12.049748623s
Mar  3 13:03:07.877: INFO: Pod "pod-subpath-test-downwardapi-xmc6": Phase="Running", Reason="", readiness=true. Elapsed: 14.056467938s
Mar  3 13:03:09.882: INFO: Pod "pod-subpath-test-downwardapi-xmc6": Phase="Running", Reason="", readiness=true. Elapsed: 16.061757868s
Mar  3 13:03:11.890: INFO: Pod "pod-subpath-test-downwardapi-xmc6": Phase="Running", Reason="", readiness=true. Elapsed: 18.069508311s
Mar  3 13:03:13.895: INFO: Pod "pod-subpath-test-downwardapi-xmc6": Phase="Running", Reason="", readiness=true. Elapsed: 20.07447002s
Mar  3 13:03:15.900: INFO: Pod "pod-subpath-test-downwardapi-xmc6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.079431954s
STEP: Saw pod success
Mar  3 13:03:15.900: INFO: Pod "pod-subpath-test-downwardapi-xmc6" satisfied condition "success or failure"
Mar  3 13:03:15.904: INFO: Trying to get logs from node 10.0.2.74 pod pod-subpath-test-downwardapi-xmc6 container test-container-subpath-downwardapi-xmc6: <nil>
STEP: delete the pod
Mar  3 13:03:15.970: INFO: Waiting for pod pod-subpath-test-downwardapi-xmc6 to disappear
Mar  3 13:03:15.974: INFO: Pod pod-subpath-test-downwardapi-xmc6 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-xmc6
Mar  3 13:03:15.974: INFO: Deleting pod "pod-subpath-test-downwardapi-xmc6" in namespace "subpath-4453"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:03:15.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4453" for this suite.
Mar  3 13:03:21.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:03:22.184: INFO: namespace subpath-4453 deletion completed in 6.201218696s

• [SLOW TEST:28.448 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:03:22.184: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar  3 13:03:22.265: INFO: Waiting up to 5m0s for pod "pod-92486e67-b62f-4e96-9615-6101e3545f92" in namespace "emptydir-9884" to be "success or failure"
Mar  3 13:03:22.274: INFO: Pod "pod-92486e67-b62f-4e96-9615-6101e3545f92": Phase="Pending", Reason="", readiness=false. Elapsed: 9.003806ms
Mar  3 13:03:24.281: INFO: Pod "pod-92486e67-b62f-4e96-9615-6101e3545f92": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016850776s
STEP: Saw pod success
Mar  3 13:03:24.281: INFO: Pod "pod-92486e67-b62f-4e96-9615-6101e3545f92" satisfied condition "success or failure"
Mar  3 13:03:24.287: INFO: Trying to get logs from node 10.0.2.119 pod pod-92486e67-b62f-4e96-9615-6101e3545f92 container test-container: <nil>
STEP: delete the pod
Mar  3 13:03:24.323: INFO: Waiting for pod pod-92486e67-b62f-4e96-9615-6101e3545f92 to disappear
Mar  3 13:03:24.330: INFO: Pod pod-92486e67-b62f-4e96-9615-6101e3545f92 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:03:24.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9884" for this suite.
Mar  3 13:03:30.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:03:30.543: INFO: namespace emptydir-9884 deletion completed in 6.207052615s

• [SLOW TEST:8.359 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:03:30.543: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-67abf4f2-ddb6-4d03-b5f6-43d4054e6e2f
STEP: Creating a pod to test consume configMaps
Mar  3 13:03:30.616: INFO: Waiting up to 5m0s for pod "pod-configmaps-477b4dc2-580b-4bc3-892e-64183734e166" in namespace "configmap-6014" to be "success or failure"
Mar  3 13:03:30.622: INFO: Pod "pod-configmaps-477b4dc2-580b-4bc3-892e-64183734e166": Phase="Pending", Reason="", readiness=false. Elapsed: 6.038196ms
Mar  3 13:03:32.643: INFO: Pod "pod-configmaps-477b4dc2-580b-4bc3-892e-64183734e166": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026419684s
STEP: Saw pod success
Mar  3 13:03:32.643: INFO: Pod "pod-configmaps-477b4dc2-580b-4bc3-892e-64183734e166" satisfied condition "success or failure"
Mar  3 13:03:32.650: INFO: Trying to get logs from node 10.0.2.74 pod pod-configmaps-477b4dc2-580b-4bc3-892e-64183734e166 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  3 13:03:32.678: INFO: Waiting for pod pod-configmaps-477b4dc2-580b-4bc3-892e-64183734e166 to disappear
Mar  3 13:03:32.682: INFO: Pod pod-configmaps-477b4dc2-580b-4bc3-892e-64183734e166 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:03:32.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6014" for this suite.
Mar  3 13:03:38.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:03:38.918: INFO: namespace configmap-6014 deletion completed in 6.214899532s

• [SLOW TEST:8.375 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:03:38.918: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:03:38.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1850" for this suite.
Mar  3 13:03:45.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:03:45.353: INFO: namespace services-1850 deletion completed in 6.362504424s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.435 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:03:45.354: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 13:04:05.443: INFO: Container started at 2020-03-03 13:03:46 +0000 UTC, pod became ready at 2020-03-03 13:04:04 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:04:05.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9424" for this suite.
Mar  3 13:04:17.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:04:17.706: INFO: namespace container-probe-9424 deletion completed in 12.257536158s

• [SLOW TEST:32.352 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:04:17.706: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Mar  3 13:04:17.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-3004 -- logs-generator --log-lines-total 100 --run-duration 20s'
Mar  3 13:04:17.884: INFO: stderr: ""
Mar  3 13:04:17.884: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Mar  3 13:04:17.884: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Mar  3 13:04:17.884: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-3004" to be "running and ready, or succeeded"
Mar  3 13:04:17.888: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.226308ms
Mar  3 13:04:19.923: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.039035008s
Mar  3 13:04:19.923: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Mar  3 13:04:19.923: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Mar  3 13:04:19.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 logs logs-generator logs-generator --namespace=kubectl-3004'
Mar  3 13:04:20.024: INFO: stderr: ""
Mar  3 13:04:20.024: INFO: stdout: "I0303 13:04:18.717386       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/c746 370\nI0303 13:04:18.917567       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/td7 545\nI0303 13:04:19.117557       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/zdc 359\nI0303 13:04:19.317516       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/hwmr 528\nI0303 13:04:19.517497       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/t82 225\nI0303 13:04:19.717535       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/kjqq 204\nI0303 13:04:19.917509       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/v9b7 486\n"
STEP: limiting log lines
Mar  3 13:04:20.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 logs logs-generator logs-generator --namespace=kubectl-3004 --tail=1'
Mar  3 13:04:20.121: INFO: stderr: ""
Mar  3 13:04:20.121: INFO: stdout: "I0303 13:04:20.117522       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/v765 332\n"
STEP: limiting log bytes
Mar  3 13:04:20.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 logs logs-generator logs-generator --namespace=kubectl-3004 --limit-bytes=1'
Mar  3 13:04:20.222: INFO: stderr: ""
Mar  3 13:04:20.222: INFO: stdout: "I"
STEP: exposing timestamps
Mar  3 13:04:20.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 logs logs-generator logs-generator --namespace=kubectl-3004 --tail=1 --timestamps'
Mar  3 13:04:20.321: INFO: stderr: ""
Mar  3 13:04:20.321: INFO: stdout: "2020-03-03T13:04:20.317615588Z I0303 13:04:20.317515       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/crb 588\n"
STEP: restricting to a time range
Mar  3 13:04:22.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 logs logs-generator logs-generator --namespace=kubectl-3004 --since=1s'
Mar  3 13:04:22.926: INFO: stderr: ""
Mar  3 13:04:22.926: INFO: stdout: "I0303 13:04:22.117494       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/nw8 586\nI0303 13:04:22.317517       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/4mxz 219\nI0303 13:04:22.517502       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/f26v 571\nI0303 13:04:22.717502       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/tbt 405\nI0303 13:04:22.917519       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/47v 241\n"
Mar  3 13:04:22.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 logs logs-generator logs-generator --namespace=kubectl-3004 --since=24h'
Mar  3 13:04:23.047: INFO: stderr: ""
Mar  3 13:04:23.047: INFO: stdout: "I0303 13:04:18.717386       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/c746 370\nI0303 13:04:18.917567       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/td7 545\nI0303 13:04:19.117557       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/zdc 359\nI0303 13:04:19.317516       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/hwmr 528\nI0303 13:04:19.517497       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/t82 225\nI0303 13:04:19.717535       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/kjqq 204\nI0303 13:04:19.917509       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/v9b7 486\nI0303 13:04:20.117522       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/v765 332\nI0303 13:04:20.317515       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/crb 588\nI0303 13:04:20.517513       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/default/pods/9cz 505\nI0303 13:04:20.717503       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/554l 297\nI0303 13:04:20.917496       1 logs_generator.go:76] 11 GET /api/v1/namespaces/ns/pods/l2jn 211\nI0303 13:04:21.117496       1 logs_generator.go:76] 12 GET /api/v1/namespaces/ns/pods/2ht 218\nI0303 13:04:21.317488       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/wwg 320\nI0303 13:04:21.517489       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/fhq 464\nI0303 13:04:21.717494       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/ns/pods/66cg 218\nI0303 13:04:21.917515       1 logs_generator.go:76] 16 POST /api/v1/namespaces/kube-system/pods/btvc 204\nI0303 13:04:22.117494       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/nw8 586\nI0303 13:04:22.317517       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/4mxz 219\nI0303 13:04:22.517502       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/f26v 571\nI0303 13:04:22.717502       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/tbt 405\nI0303 13:04:22.917519       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/47v 241\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Mar  3 13:04:23.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 delete pod logs-generator --namespace=kubectl-3004'
Mar  3 13:04:35.297: INFO: stderr: ""
Mar  3 13:04:35.297: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:04:35.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3004" for this suite.
Mar  3 13:04:41.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:04:41.499: INFO: namespace kubectl-3004 deletion completed in 6.196819975s

• [SLOW TEST:23.793 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:04:41.500: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-2786
STEP: creating replication controller nodeport-test in namespace services-2786
I0303 13:04:41.604439      23 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-2786, replica count: 2
Mar  3 13:04:44.654: INFO: Creating new exec pod
I0303 13:04:44.654773      23 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  3 13:04:47.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=services-2786 execpodmhkxr -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Mar  3 13:04:47.885: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Mar  3 13:04:47.885: INFO: stdout: ""
Mar  3 13:04:47.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=services-2786 execpodmhkxr -- /bin/sh -x -c nc -zv -t -w 2 172.27.254.110 80'
Mar  3 13:04:48.082: INFO: stderr: "+ nc -zv -t -w 2 172.27.254.110 80\nConnection to 172.27.254.110 80 port [tcp/http] succeeded!\n"
Mar  3 13:04:48.082: INFO: stdout: ""
Mar  3 13:04:48.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=services-2786 execpodmhkxr -- /bin/sh -x -c nc -zv -t -w 2 10.0.2.119 31361'
Mar  3 13:04:48.279: INFO: stderr: "+ nc -zv -t -w 2 10.0.2.119 31361\nConnection to 10.0.2.119 31361 port [tcp/31361] succeeded!\n"
Mar  3 13:04:48.279: INFO: stdout: ""
Mar  3 13:04:48.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=services-2786 execpodmhkxr -- /bin/sh -x -c nc -zv -t -w 2 10.0.2.74 31361'
Mar  3 13:04:48.487: INFO: stderr: "+ nc -zv -t -w 2 10.0.2.74 31361\nConnection to 10.0.2.74 31361 port [tcp/31361] succeeded!\n"
Mar  3 13:04:48.487: INFO: stdout: ""
Mar  3 13:04:48.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=services-2786 execpodmhkxr -- /bin/sh -x -c nc -zv -t -w 2 150.109.125.235 31361'
Mar  3 13:04:48.688: INFO: stderr: "+ nc -zv -t -w 2 150.109.125.235 31361\nConnection to 150.109.125.235 31361 port [tcp/31361] succeeded!\n"
Mar  3 13:04:48.688: INFO: stdout: ""
Mar  3 13:04:48.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=services-2786 execpodmhkxr -- /bin/sh -x -c nc -zv -t -w 2 129.226.52.233 31361'
Mar  3 13:04:48.891: INFO: stderr: "+ nc -zv -t -w 2 129.226.52.233 31361\nConnection to 129.226.52.233 31361 port [tcp/31361] succeeded!\n"
Mar  3 13:04:48.891: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:04:48.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2786" for this suite.
Mar  3 13:04:54.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:04:55.139: INFO: namespace services-2786 deletion completed in 6.241990896s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.639 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:04:55.139: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Mar  3 13:04:55.216: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-1655" to be "success or failure"
Mar  3 13:04:55.220: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.142602ms
Mar  3 13:04:57.226: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009385194s
STEP: Saw pod success
Mar  3 13:04:57.226: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar  3 13:04:57.230: INFO: Trying to get logs from node 10.0.2.119 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Mar  3 13:04:57.258: INFO: Waiting for pod pod-host-path-test to disappear
Mar  3 13:04:57.262: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:04:57.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-1655" for this suite.
Mar  3 13:05:03.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:05:03.468: INFO: namespace hostpath-1655 deletion completed in 6.200447701s

• [SLOW TEST:8.329 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:05:03.468: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar  3 13:05:03.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-8923'
Mar  3 13:05:03.625: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  3 13:05:03.625: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Mar  3 13:05:03.637: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Mar  3 13:05:03.641: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Mar  3 13:05:03.650: INFO: scanned /root for discovery docs: <nil>
Mar  3 13:05:03.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-8923'
Mar  3 13:05:19.540: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar  3 13:05:19.540: INFO: stdout: "Created e2e-test-httpd-rc-a8a8036527d9e45f943e382dbc389edd\nScaling up e2e-test-httpd-rc-a8a8036527d9e45f943e382dbc389edd from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-a8a8036527d9e45f943e382dbc389edd up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-a8a8036527d9e45f943e382dbc389edd to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Mar  3 13:05:19.540: INFO: stdout: "Created e2e-test-httpd-rc-a8a8036527d9e45f943e382dbc389edd\nScaling up e2e-test-httpd-rc-a8a8036527d9e45f943e382dbc389edd from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-a8a8036527d9e45f943e382dbc389edd up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-a8a8036527d9e45f943e382dbc389edd to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Mar  3 13:05:19.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-8923'
Mar  3 13:05:19.627: INFO: stderr: ""
Mar  3 13:05:19.627: INFO: stdout: "e2e-test-httpd-rc-a8a8036527d9e45f943e382dbc389edd-g7jz2 "
Mar  3 13:05:19.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods e2e-test-httpd-rc-a8a8036527d9e45f943e382dbc389edd-g7jz2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8923'
Mar  3 13:05:19.712: INFO: stderr: ""
Mar  3 13:05:19.712: INFO: stdout: "true"
Mar  3 13:05:19.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods e2e-test-httpd-rc-a8a8036527d9e45f943e382dbc389edd-g7jz2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8923'
Mar  3 13:05:19.795: INFO: stderr: ""
Mar  3 13:05:19.795: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Mar  3 13:05:19.796: INFO: e2e-test-httpd-rc-a8a8036527d9e45f943e382dbc389edd-g7jz2 is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Mar  3 13:05:19.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 delete rc e2e-test-httpd-rc --namespace=kubectl-8923'
Mar  3 13:05:19.890: INFO: stderr: ""
Mar  3 13:05:19.890: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:05:19.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8923" for this suite.
Mar  3 13:05:31.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:05:32.146: INFO: namespace kubectl-8923 deletion completed in 12.25040453s

• [SLOW TEST:28.678 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:05:32.147: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-52c1be9a-5250-4f8d-abcf-613ae723788a
STEP: Creating a pod to test consume secrets
Mar  3 13:05:32.273: INFO: Waiting up to 5m0s for pod "pod-secrets-e7400d26-8e9b-421f-ad15-d07b287a5bfc" in namespace "secrets-6977" to be "success or failure"
Mar  3 13:05:32.279: INFO: Pod "pod-secrets-e7400d26-8e9b-421f-ad15-d07b287a5bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.189164ms
Mar  3 13:05:34.293: INFO: Pod "pod-secrets-e7400d26-8e9b-421f-ad15-d07b287a5bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019502849s
STEP: Saw pod success
Mar  3 13:05:34.293: INFO: Pod "pod-secrets-e7400d26-8e9b-421f-ad15-d07b287a5bfc" satisfied condition "success or failure"
Mar  3 13:05:34.297: INFO: Trying to get logs from node 10.0.2.74 pod pod-secrets-e7400d26-8e9b-421f-ad15-d07b287a5bfc container secret-volume-test: <nil>
STEP: delete the pod
Mar  3 13:05:34.333: INFO: Waiting for pod pod-secrets-e7400d26-8e9b-421f-ad15-d07b287a5bfc to disappear
Mar  3 13:05:34.340: INFO: Pod pod-secrets-e7400d26-8e9b-421f-ad15-d07b287a5bfc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:05:34.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6977" for this suite.
Mar  3 13:05:40.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:05:40.570: INFO: namespace secrets-6977 deletion completed in 6.225152337s

• [SLOW TEST:8.423 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:05:40.570: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 13:05:40.635: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Mar  3 13:05:45.640: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  3 13:05:45.640: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Mar  3 13:05:45.670: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-6678 /apis/apps/v1/namespaces/deployment-6678/deployments/test-cleanup-deployment 4b6fcd86-8468-4cbd-9299-fea558c456dc 1243973151 1 2020-03-03 13:05:45 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0057cf718 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Mar  3 13:05:45.681: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-6678 /apis/apps/v1/namespaces/deployment-6678/replicasets/test-cleanup-deployment-65db99849b 27c6f31a-7ddc-4a72-b0f6-0a41d3e20108 1243973155 1 2020-03-03 13:05:45 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 4b6fcd86-8468-4cbd-9299-fea558c456dc 0xc00583a4b7 0xc00583a4b8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00583a528 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar  3 13:05:45.681: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Mar  3 13:05:45.681: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-6678 /apis/apps/v1/namespaces/deployment-6678/replicasets/test-cleanup-controller cd50b73e-7590-4e65-af2d-d873ec4ac4e4 1243973153 1 2020-03-03 13:05:40 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 4b6fcd86-8468-4cbd-9299-fea558c456dc 0xc00583a3e7 0xc00583a3e8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00583a448 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Mar  3 13:05:45.686: INFO: Pod "test-cleanup-controller-spwv8" is available:
&Pod{ObjectMeta:{test-cleanup-controller-spwv8 test-cleanup-controller- deployment-6678 /api/v1/namespaces/deployment-6678/pods/test-cleanup-controller-spwv8 899da82e-9fb7-49e0-a5ca-d55e829cd9ea 1243972540 0 2020-03-03 13:05:40 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[tke.cloud.tencent.com/networks-status:[{
    "name": "tke-bridge",
    "ips": [
        "172.27.0.24"
    ],
    "default": true,
    "dns": {}
}]] [{apps/v1 ReplicaSet test-cleanup-controller cd50b73e-7590-4e65-af2d-d873ec4ac4e4 0xc00583a9b7 0xc00583a9b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h6w9s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h6w9s,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h6w9s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.119,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 13:05:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 13:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 13:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 13:05:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.119,PodIP:172.27.0.24,StartTime:2020-03-03 13:05:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-03 13:05:41 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://2d1cb615c60c565ee0b99c30b646f66c5940d95158ef7f023411aa281bedd41a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.27.0.24,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  3 13:05:45.686: INFO: Pod "test-cleanup-deployment-65db99849b-qfppj" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-qfppj test-cleanup-deployment-65db99849b- deployment-6678 /api/v1/namespaces/deployment-6678/pods/test-cleanup-deployment-65db99849b-qfppj d395863a-2afe-437e-808d-c7e59367a587 1243973156 0 2020-03-03 13:05:45 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b 27c6f31a-7ddc-4a72-b0f6-0a41d3e20108 0xc00583ab07 0xc00583ab08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h6w9s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h6w9s,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h6w9s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:05:45.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6678" for this suite.
Mar  3 13:05:51.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:05:51.911: INFO: namespace deployment-6678 deletion completed in 6.208092177s

• [SLOW TEST:11.341 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:05:51.912: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:05:52.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-729" for this suite.
Mar  3 13:05:58.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:05:58.387: INFO: namespace resourcequota-729 deletion completed in 6.307639304s

• [SLOW TEST:6.476 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:05:58.388: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-0a979041-df51-497e-bd5e-77649f95c930
STEP: Creating a pod to test consume configMaps
Mar  3 13:05:58.457: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bc93c1c3-4a9b-4234-981f-16771c8aeff7" in namespace "projected-68" to be "success or failure"
Mar  3 13:05:58.461: INFO: Pod "pod-projected-configmaps-bc93c1c3-4a9b-4234-981f-16771c8aeff7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.925665ms
Mar  3 13:06:00.485: INFO: Pod "pod-projected-configmaps-bc93c1c3-4a9b-4234-981f-16771c8aeff7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028135117s
STEP: Saw pod success
Mar  3 13:06:00.485: INFO: Pod "pod-projected-configmaps-bc93c1c3-4a9b-4234-981f-16771c8aeff7" satisfied condition "success or failure"
Mar  3 13:06:00.490: INFO: Trying to get logs from node 10.0.2.119 pod pod-projected-configmaps-bc93c1c3-4a9b-4234-981f-16771c8aeff7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  3 13:06:00.520: INFO: Waiting for pod pod-projected-configmaps-bc93c1c3-4a9b-4234-981f-16771c8aeff7 to disappear
Mar  3 13:06:00.526: INFO: Pod pod-projected-configmaps-bc93c1c3-4a9b-4234-981f-16771c8aeff7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:06:00.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-68" for this suite.
Mar  3 13:06:06.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:06:06.725: INFO: namespace projected-68 deletion completed in 6.193512823s

• [SLOW TEST:8.337 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:06:06.725: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar  3 13:06:06.784: INFO: Waiting up to 5m0s for pod "pod-3d5006f1-c0be-4087-a9e3-1a938b2bf277" in namespace "emptydir-4794" to be "success or failure"
Mar  3 13:06:06.788: INFO: Pod "pod-3d5006f1-c0be-4087-a9e3-1a938b2bf277": Phase="Pending", Reason="", readiness=false. Elapsed: 4.261964ms
Mar  3 13:06:08.793: INFO: Pod "pod-3d5006f1-c0be-4087-a9e3-1a938b2bf277": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009316489s
STEP: Saw pod success
Mar  3 13:06:08.793: INFO: Pod "pod-3d5006f1-c0be-4087-a9e3-1a938b2bf277" satisfied condition "success or failure"
Mar  3 13:06:08.797: INFO: Trying to get logs from node 10.0.2.119 pod pod-3d5006f1-c0be-4087-a9e3-1a938b2bf277 container test-container: <nil>
STEP: delete the pod
Mar  3 13:06:08.825: INFO: Waiting for pod pod-3d5006f1-c0be-4087-a9e3-1a938b2bf277 to disappear
Mar  3 13:06:08.830: INFO: Pod pod-3d5006f1-c0be-4087-a9e3-1a938b2bf277 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:06:08.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4794" for this suite.
Mar  3 13:06:14.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:06:15.038: INFO: namespace emptydir-4794 deletion completed in 6.199001033s

• [SLOW TEST:8.313 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:06:15.038: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar  3 13:06:15.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-5016'
Mar  3 13:06:15.199: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  3 13:06:15.199: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Mar  3 13:06:17.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 delete deployment e2e-test-httpd-deployment --namespace=kubectl-5016'
Mar  3 13:06:17.310: INFO: stderr: ""
Mar  3 13:06:17.310: INFO: stdout: "deployment.extensions \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:06:17.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5016" for this suite.
Mar  3 13:06:29.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:06:29.545: INFO: namespace kubectl-5016 deletion completed in 12.228944688s

• [SLOW TEST:14.507 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:06:29.545: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 13:06:29.598: INFO: Creating deployment "test-recreate-deployment"
Mar  3 13:06:29.608: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar  3 13:06:29.627: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Mar  3 13:06:31.638: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar  3 13:06:31.643: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar  3 13:06:31.656: INFO: Updating deployment test-recreate-deployment
Mar  3 13:06:31.656: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Mar  3 13:06:31.757: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-2228 /apis/apps/v1/namespaces/deployment-2228/deployments/test-recreate-deployment 7316e1d4-ba97-40c5-a174-ac55577bdbe5 1243982513 2 2020-03-03 13:06:29 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005a7e938 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-03-03 13:06:31 +0000 UTC,LastTransitionTime:2020-03-03 13:06:31 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2020-03-03 13:06:31 +0000 UTC,LastTransitionTime:2020-03-03 13:06:29 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Mar  3 13:06:31.762: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-2228 /apis/apps/v1/namespaces/deployment-2228/replicasets/test-recreate-deployment-5f94c574ff fbcc12fd-8c49-4dec-aed7-52347a053edf 1243982508 1 2020-03-03 13:06:31 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 7316e1d4-ba97-40c5-a174-ac55577bdbe5 0xc005a7ed17 0xc005a7ed18}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005a7ed78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar  3 13:06:31.762: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar  3 13:06:31.762: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-2228 /apis/apps/v1/namespaces/deployment-2228/replicasets/test-recreate-deployment-68fc85c7bb 2f68f58e-1a19-4080-ac8b-b7009888e0fe 1243982491 2 2020-03-03 13:06:29 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 7316e1d4-ba97-40c5-a174-ac55577bdbe5 0xc005a7ede7 0xc005a7ede8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005a7ee48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar  3 13:06:31.768: INFO: Pod "test-recreate-deployment-5f94c574ff-w2gb8" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-w2gb8 test-recreate-deployment-5f94c574ff- deployment-2228 /api/v1/namespaces/deployment-2228/pods/test-recreate-deployment-5f94c574ff-w2gb8 bd21b9b0-cd6c-4422-9228-94293224c870 1243982514 0 2020-03-03 13:06:31 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff fbcc12fd-8c49-4dec-aed7-52347a053edf 0xc002270477 0xc002270478}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-p7nd2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-p7nd2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-p7nd2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.74,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 13:06:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 13:06:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 13:06:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 13:06:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.74,PodIP:,StartTime:2020-03-03 13:06:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:06:31.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2228" for this suite.
Mar  3 13:06:37.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:06:38.011: INFO: namespace deployment-2228 deletion completed in 6.231989942s

• [SLOW TEST:8.465 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:06:38.011: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar  3 13:06:38.075: INFO: Waiting up to 5m0s for pod "pod-2b008ffa-f23c-4ebe-8416-4c6b53f51ceb" in namespace "emptydir-8405" to be "success or failure"
Mar  3 13:06:38.079: INFO: Pod "pod-2b008ffa-f23c-4ebe-8416-4c6b53f51ceb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.990804ms
Mar  3 13:06:40.085: INFO: Pod "pod-2b008ffa-f23c-4ebe-8416-4c6b53f51ceb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010129596s
STEP: Saw pod success
Mar  3 13:06:40.085: INFO: Pod "pod-2b008ffa-f23c-4ebe-8416-4c6b53f51ceb" satisfied condition "success or failure"
Mar  3 13:06:40.089: INFO: Trying to get logs from node 10.0.2.74 pod pod-2b008ffa-f23c-4ebe-8416-4c6b53f51ceb container test-container: <nil>
STEP: delete the pod
Mar  3 13:06:40.121: INFO: Waiting for pod pod-2b008ffa-f23c-4ebe-8416-4c6b53f51ceb to disappear
Mar  3 13:06:40.126: INFO: Pod pod-2b008ffa-f23c-4ebe-8416-4c6b53f51ceb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:06:40.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8405" for this suite.
Mar  3 13:06:46.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:06:46.370: INFO: namespace emptydir-8405 deletion completed in 6.238880837s

• [SLOW TEST:8.359 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:06:46.370: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  3 13:06:46.448: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e7cee5de-b00c-4c89-b561-1c8eb5b4399a" in namespace "projected-9700" to be "success or failure"
Mar  3 13:06:46.452: INFO: Pod "downwardapi-volume-e7cee5de-b00c-4c89-b561-1c8eb5b4399a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.238702ms
Mar  3 13:06:48.460: INFO: Pod "downwardapi-volume-e7cee5de-b00c-4c89-b561-1c8eb5b4399a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012145083s
STEP: Saw pod success
Mar  3 13:06:48.460: INFO: Pod "downwardapi-volume-e7cee5de-b00c-4c89-b561-1c8eb5b4399a" satisfied condition "success or failure"
Mar  3 13:06:48.542: INFO: Trying to get logs from node 10.0.2.119 pod downwardapi-volume-e7cee5de-b00c-4c89-b561-1c8eb5b4399a container client-container: <nil>
STEP: delete the pod
Mar  3 13:06:48.595: INFO: Waiting for pod downwardapi-volume-e7cee5de-b00c-4c89-b561-1c8eb5b4399a to disappear
Mar  3 13:06:48.601: INFO: Pod downwardapi-volume-e7cee5de-b00c-4c89-b561-1c8eb5b4399a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:06:48.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9700" for this suite.
Mar  3 13:06:54.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:06:54.935: INFO: namespace projected-9700 deletion completed in 6.324951611s

• [SLOW TEST:8.565 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:06:54.935: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-8221
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8221
STEP: creating replication controller externalsvc in namespace services-8221
I0303 13:06:55.037931      23 runners.go:184] Created replication controller with name: externalsvc, namespace: services-8221, replica count: 2
I0303 13:06:58.088265      23 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Mar  3 13:06:58.164: INFO: Creating new exec pod
Mar  3 13:07:00.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=services-8221 execpod22rbr -- /bin/sh -x -c nslookup nodeport-service'
Mar  3 13:07:00.406: INFO: stderr: "+ nslookup nodeport-service\n"
Mar  3 13:07:00.406: INFO: stdout: "Server:\t\t172.27.252.53\nAddress:\t172.27.252.53#53\n\nnodeport-service.services-8221.svc.cluster.local\tcanonical name = externalsvc.services-8221.svc.cluster.local.\nName:\texternalsvc.services-8221.svc.cluster.local\nAddress: 172.27.252.216\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8221, will wait for the garbage collector to delete the pods
Mar  3 13:07:00.477: INFO: Deleting ReplicationController externalsvc took: 15.499172ms
Mar  3 13:07:00.577: INFO: Terminating ReplicationController externalsvc pods took: 100.181384ms
Mar  3 13:07:15.409: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:07:15.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8221" for this suite.
Mar  3 13:07:21.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:07:21.640: INFO: namespace services-8221 deletion completed in 6.195888401s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:26.705 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:07:21.640: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 13:07:21.689: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Creating first CR 
Mar  3 13:07:22.400: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-03T13:07:22Z generation:1 name:name1 resourceVersion:1243992764 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:65c1d9ff-30f1-41ee-a02a-87b4c5ae00d5] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Mar  3 13:07:32.407: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-03T13:07:32Z generation:1 name:name2 resourceVersion:1243994727 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:45ea8387-7b12-475c-8322-09e4adf0c6eb] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Mar  3 13:07:42.416: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-03T13:07:22Z generation:2 name:name1 resourceVersion:1243996699 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:65c1d9ff-30f1-41ee-a02a-87b4c5ae00d5] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Mar  3 13:07:52.423: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-03T13:07:32Z generation:2 name:name2 resourceVersion:1243998673 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:45ea8387-7b12-475c-8322-09e4adf0c6eb] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Mar  3 13:08:02.439: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-03T13:07:22Z generation:2 name:name1 resourceVersion:1244000667 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:65c1d9ff-30f1-41ee-a02a-87b4c5ae00d5] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Mar  3 13:08:12.465: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-03T13:07:32Z generation:2 name:name2 resourceVersion:1244002670 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:45ea8387-7b12-475c-8322-09e4adf0c6eb] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:08:22.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-5842" for this suite.
Mar  3 13:08:29.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:08:29.207: INFO: namespace crd-watch-5842 deletion completed in 6.210112518s

• [SLOW TEST:67.566 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:08:29.207: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Mar  3 13:08:29.267: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  3 13:08:29.286: INFO: Waiting for terminating namespaces to be deleted...
Mar  3 13:08:29.294: INFO: 
Logging pods the kubelet thinks is on node 10.0.2.119 before test
Mar  3 13:08:29.305: INFO: l7-lb-controller-66b9d774dc-2jgkk from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 13:08:29.305: INFO: 	Container l7-lb-controller ready: true, restart count 0
Mar  3 13:08:29.305: INFO: tke-cni-agent-nqwxr from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 13:08:29.305: INFO: 	Container tke-cni-agent ready: true, restart count 0
Mar  3 13:08:29.305: INFO: ip-masq-agent-67jk9 from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 13:08:29.305: INFO: 	Container ip-masq-agent ready: true, restart count 0
Mar  3 13:08:29.305: INFO: coredns-79444468c6-nwjdn from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 13:08:29.305: INFO: 	Container coredns ready: true, restart count 0
Mar  3 13:08:29.305: INFO: sonobuoy-systemd-logs-daemon-set-046f08d908064245-vrhb2 from sonobuoy started at 2020-03-03 12:02:34 +0000 UTC (2 container statuses recorded)
Mar  3 13:08:29.305: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar  3 13:08:29.305: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  3 13:08:29.305: INFO: tke-bridge-agent-qb5s8 from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 13:08:29.305: INFO: 	Container tke-bridge-agent ready: true, restart count 0
Mar  3 13:08:29.305: INFO: 
Logging pods the kubelet thinks is on node 10.0.2.74 before test
Mar  3 13:08:29.317: INFO: ip-masq-agent-vfrbd from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 13:08:29.317: INFO: 	Container ip-masq-agent ready: true, restart count 0
Mar  3 13:08:29.317: INFO: sonobuoy-systemd-logs-daemon-set-046f08d908064245-mvl4g from sonobuoy started at 2020-03-03 12:02:34 +0000 UTC (2 container statuses recorded)
Mar  3 13:08:29.317: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar  3 13:08:29.317: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  3 13:08:29.317: INFO: tke-cni-agent-8jgsc from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 13:08:29.317: INFO: 	Container tke-cni-agent ready: true, restart count 0
Mar  3 13:08:29.317: INFO: sonobuoy from sonobuoy started at 2020-03-03 12:02:28 +0000 UTC (1 container statuses recorded)
Mar  3 13:08:29.317: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  3 13:08:29.317: INFO: sonobuoy-e2e-job-d53d4d2134fd4748 from sonobuoy started at 2020-03-03 12:02:34 +0000 UTC (2 container statuses recorded)
Mar  3 13:08:29.317: INFO: 	Container e2e ready: true, restart count 0
Mar  3 13:08:29.317: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  3 13:08:29.317: INFO: tke-bridge-agent-lrfvg from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 13:08:29.317: INFO: 	Container tke-bridge-agent ready: true, restart count 0
Mar  3 13:08:29.317: INFO: coredns-79444468c6-b7cdk from kube-system started at 2020-03-03 12:08:15 +0000 UTC (1 container statuses recorded)
Mar  3 13:08:29.317: INFO: 	Container coredns ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-44fa9e61-9578-4d09-802d-cd280b6b5866 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-44fa9e61-9578-4d09-802d-cd280b6b5866 off the node 10.0.2.74
STEP: verifying the node doesn't have the label kubernetes.io/e2e-44fa9e61-9578-4d09-802d-cd280b6b5866
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:13:33.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8021" for this suite.
Mar  3 13:13:47.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:13:47.683: INFO: namespace sched-pred-8021 deletion completed in 14.213853059s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:318.476 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:13:47.683: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-6nh5
STEP: Creating a pod to test atomic-volume-subpath
Mar  3 13:13:47.773: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-6nh5" in namespace "subpath-9387" to be "success or failure"
Mar  3 13:13:47.780: INFO: Pod "pod-subpath-test-configmap-6nh5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.994664ms
Mar  3 13:13:49.785: INFO: Pod "pod-subpath-test-configmap-6nh5": Phase="Running", Reason="", readiness=true. Elapsed: 2.012156438s
Mar  3 13:13:51.790: INFO: Pod "pod-subpath-test-configmap-6nh5": Phase="Running", Reason="", readiness=true. Elapsed: 4.017198428s
Mar  3 13:13:53.795: INFO: Pod "pod-subpath-test-configmap-6nh5": Phase="Running", Reason="", readiness=true. Elapsed: 6.022115773s
Mar  3 13:13:55.842: INFO: Pod "pod-subpath-test-configmap-6nh5": Phase="Running", Reason="", readiness=true. Elapsed: 8.069143616s
Mar  3 13:13:57.847: INFO: Pod "pod-subpath-test-configmap-6nh5": Phase="Running", Reason="", readiness=true. Elapsed: 10.07478059s
Mar  3 13:13:59.855: INFO: Pod "pod-subpath-test-configmap-6nh5": Phase="Running", Reason="", readiness=true. Elapsed: 12.082778327s
Mar  3 13:14:01.861: INFO: Pod "pod-subpath-test-configmap-6nh5": Phase="Running", Reason="", readiness=true. Elapsed: 14.088214558s
Mar  3 13:14:03.868: INFO: Pod "pod-subpath-test-configmap-6nh5": Phase="Running", Reason="", readiness=true. Elapsed: 16.09546038s
Mar  3 13:14:05.874: INFO: Pod "pod-subpath-test-configmap-6nh5": Phase="Running", Reason="", readiness=true. Elapsed: 18.101131184s
Mar  3 13:14:07.879: INFO: Pod "pod-subpath-test-configmap-6nh5": Phase="Running", Reason="", readiness=true. Elapsed: 20.106095336s
Mar  3 13:14:09.884: INFO: Pod "pod-subpath-test-configmap-6nh5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.111153405s
STEP: Saw pod success
Mar  3 13:14:09.884: INFO: Pod "pod-subpath-test-configmap-6nh5" satisfied condition "success or failure"
Mar  3 13:14:09.888: INFO: Trying to get logs from node 10.0.2.74 pod pod-subpath-test-configmap-6nh5 container test-container-subpath-configmap-6nh5: <nil>
STEP: delete the pod
Mar  3 13:14:09.917: INFO: Waiting for pod pod-subpath-test-configmap-6nh5 to disappear
Mar  3 13:14:09.921: INFO: Pod pod-subpath-test-configmap-6nh5 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-6nh5
Mar  3 13:14:09.921: INFO: Deleting pod "pod-subpath-test-configmap-6nh5" in namespace "subpath-9387"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:14:09.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9387" for this suite.
Mar  3 13:14:15.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:14:16.169: INFO: namespace subpath-9387 deletion completed in 6.238649749s

• [SLOW TEST:28.486 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:14:16.169: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar  3 13:14:16.238: INFO: Waiting up to 5m0s for pod "pod-b23181a5-eb34-4ca5-84e6-a2777568e9b3" in namespace "emptydir-3999" to be "success or failure"
Mar  3 13:14:16.242: INFO: Pod "pod-b23181a5-eb34-4ca5-84e6-a2777568e9b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.202337ms
Mar  3 13:14:18.248: INFO: Pod "pod-b23181a5-eb34-4ca5-84e6-a2777568e9b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009416557s
STEP: Saw pod success
Mar  3 13:14:18.248: INFO: Pod "pod-b23181a5-eb34-4ca5-84e6-a2777568e9b3" satisfied condition "success or failure"
Mar  3 13:14:18.252: INFO: Trying to get logs from node 10.0.2.119 pod pod-b23181a5-eb34-4ca5-84e6-a2777568e9b3 container test-container: <nil>
STEP: delete the pod
Mar  3 13:14:18.284: INFO: Waiting for pod pod-b23181a5-eb34-4ca5-84e6-a2777568e9b3 to disappear
Mar  3 13:14:18.287: INFO: Pod pod-b23181a5-eb34-4ca5-84e6-a2777568e9b3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:14:18.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3999" for this suite.
Mar  3 13:14:24.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:14:24.489: INFO: namespace emptydir-3999 deletion completed in 6.196584072s

• [SLOW TEST:8.319 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:14:24.489: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar  3 13:14:24.843: INFO: Waiting up to 5m0s for pod "pod-420c9283-1708-4c86-bbdb-39628f2c9974" in namespace "emptydir-3193" to be "success or failure"
Mar  3 13:14:24.851: INFO: Pod "pod-420c9283-1708-4c86-bbdb-39628f2c9974": Phase="Pending", Reason="", readiness=false. Elapsed: 7.352358ms
Mar  3 13:14:26.866: INFO: Pod "pod-420c9283-1708-4c86-bbdb-39628f2c9974": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022373609s
STEP: Saw pod success
Mar  3 13:14:26.866: INFO: Pod "pod-420c9283-1708-4c86-bbdb-39628f2c9974" satisfied condition "success or failure"
Mar  3 13:14:26.873: INFO: Trying to get logs from node 10.0.2.119 pod pod-420c9283-1708-4c86-bbdb-39628f2c9974 container test-container: <nil>
STEP: delete the pod
Mar  3 13:14:26.903: INFO: Waiting for pod pod-420c9283-1708-4c86-bbdb-39628f2c9974 to disappear
Mar  3 13:14:26.907: INFO: Pod pod-420c9283-1708-4c86-bbdb-39628f2c9974 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:14:26.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3193" for this suite.
Mar  3 13:14:32.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:14:33.147: INFO: namespace emptydir-3193 deletion completed in 6.23295704s

• [SLOW TEST:8.659 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:14:33.147: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  3 13:14:33.650: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  3 13:14:35.739: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838073, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838073, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838073, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838073, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7f4f78fb6b\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  3 13:14:38.846: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:14:38.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9777" for this suite.
Mar  3 13:14:44.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:14:45.187: INFO: namespace webhook-9777 deletion completed in 6.325025865s
STEP: Destroying namespace "webhook-9777-markers" for this suite.
Mar  3 13:14:51.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:14:51.419: INFO: namespace webhook-9777-markers deletion completed in 6.232122094s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.315 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:14:51.463: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-033cac86-77d9-4e3f-b8ae-7e162e5fda47
STEP: Creating a pod to test consume configMaps
Mar  3 13:14:51.543: INFO: Waiting up to 5m0s for pod "pod-configmaps-fcc47f01-a249-44a8-9902-8eb51e0727c7" in namespace "configmap-7973" to be "success or failure"
Mar  3 13:14:51.547: INFO: Pod "pod-configmaps-fcc47f01-a249-44a8-9902-8eb51e0727c7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.181648ms
Mar  3 13:14:53.552: INFO: Pod "pod-configmaps-fcc47f01-a249-44a8-9902-8eb51e0727c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009345191s
STEP: Saw pod success
Mar  3 13:14:53.552: INFO: Pod "pod-configmaps-fcc47f01-a249-44a8-9902-8eb51e0727c7" satisfied condition "success or failure"
Mar  3 13:14:53.557: INFO: Trying to get logs from node 10.0.2.119 pod pod-configmaps-fcc47f01-a249-44a8-9902-8eb51e0727c7 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  3 13:14:53.584: INFO: Waiting for pod pod-configmaps-fcc47f01-a249-44a8-9902-8eb51e0727c7 to disappear
Mar  3 13:14:53.591: INFO: Pod pod-configmaps-fcc47f01-a249-44a8-9902-8eb51e0727c7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:14:53.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7973" for this suite.
Mar  3 13:14:59.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:14:59.843: INFO: namespace configmap-7973 deletion completed in 6.242955596s

• [SLOW TEST:8.381 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:14:59.843: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Mar  3 13:14:59.939: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9868 /api/v1/namespaces/watch-9868/configmaps/e2e-watch-test-resource-version c638cd19-a79e-43d0-806e-454e663e782b 1244084176 0 2020-03-03 13:14:59 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  3 13:14:59.939: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9868 /api/v1/namespaces/watch-9868/configmaps/e2e-watch-test-resource-version c638cd19-a79e-43d0-806e-454e663e782b 1244084177 0 2020-03-03 13:14:59 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:14:59.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9868" for this suite.
Mar  3 13:15:05.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:15:06.230: INFO: namespace watch-9868 deletion completed in 6.280345163s

• [SLOW TEST:6.387 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:15:06.231: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 13:15:06.296: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Mar  3 13:15:10.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=crd-publish-openapi-1693 create -f -'
Mar  3 13:15:10.705: INFO: stderr: ""
Mar  3 13:15:10.705: INFO: stdout: "e2e-test-crd-publish-openapi-3728-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Mar  3 13:15:10.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=crd-publish-openapi-1693 delete e2e-test-crd-publish-openapi-3728-crds test-cr'
Mar  3 13:15:10.809: INFO: stderr: ""
Mar  3 13:15:10.809: INFO: stdout: "e2e-test-crd-publish-openapi-3728-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Mar  3 13:15:10.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=crd-publish-openapi-1693 apply -f -'
Mar  3 13:15:11.024: INFO: stderr: ""
Mar  3 13:15:11.024: INFO: stdout: "e2e-test-crd-publish-openapi-3728-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Mar  3 13:15:11.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=crd-publish-openapi-1693 delete e2e-test-crd-publish-openapi-3728-crds test-cr'
Mar  3 13:15:11.147: INFO: stderr: ""
Mar  3 13:15:11.147: INFO: stdout: "e2e-test-crd-publish-openapi-3728-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Mar  3 13:15:11.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 explain e2e-test-crd-publish-openapi-3728-crds'
Mar  3 13:15:11.344: INFO: stderr: ""
Mar  3 13:15:11.344: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3728-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:15:15.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1693" for this suite.
Mar  3 13:15:21.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:15:21.353: INFO: namespace crd-publish-openapi-1693 deletion completed in 6.279449183s

• [SLOW TEST:15.123 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:15:21.353: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 13:15:21.412: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:15:23.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1942" for this suite.
Mar  3 13:16:07.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:16:07.790: INFO: namespace pods-1942 deletion completed in 44.24009421s

• [SLOW TEST:46.436 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:16:07.791: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  3 13:16:07.862: INFO: Waiting up to 5m0s for pod "downwardapi-volume-998bad1c-3097-45bb-8fb4-6fbe17b0008d" in namespace "projected-3632" to be "success or failure"
Mar  3 13:16:07.868: INFO: Pod "downwardapi-volume-998bad1c-3097-45bb-8fb4-6fbe17b0008d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.778119ms
Mar  3 13:16:09.874: INFO: Pod "downwardapi-volume-998bad1c-3097-45bb-8fb4-6fbe17b0008d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011642129s
STEP: Saw pod success
Mar  3 13:16:09.874: INFO: Pod "downwardapi-volume-998bad1c-3097-45bb-8fb4-6fbe17b0008d" satisfied condition "success or failure"
Mar  3 13:16:09.878: INFO: Trying to get logs from node 10.0.2.74 pod downwardapi-volume-998bad1c-3097-45bb-8fb4-6fbe17b0008d container client-container: <nil>
STEP: delete the pod
Mar  3 13:16:09.907: INFO: Waiting for pod downwardapi-volume-998bad1c-3097-45bb-8fb4-6fbe17b0008d to disappear
Mar  3 13:16:09.911: INFO: Pod downwardapi-volume-998bad1c-3097-45bb-8fb4-6fbe17b0008d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:16:09.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3632" for this suite.
Mar  3 13:16:15.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:16:16.203: INFO: namespace projected-3632 deletion completed in 6.287367575s

• [SLOW TEST:8.412 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:16:16.203: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-5210602c-125e-48ab-83cd-3233f619410a
STEP: Creating a pod to test consume configMaps
Mar  3 13:16:16.338: INFO: Waiting up to 5m0s for pod "pod-configmaps-4e079076-4793-4a90-b01e-2ebd758bbc8f" in namespace "configmap-1221" to be "success or failure"
Mar  3 13:16:16.343: INFO: Pod "pod-configmaps-4e079076-4793-4a90-b01e-2ebd758bbc8f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.951841ms
Mar  3 13:16:18.352: INFO: Pod "pod-configmaps-4e079076-4793-4a90-b01e-2ebd758bbc8f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01444204s
STEP: Saw pod success
Mar  3 13:16:18.352: INFO: Pod "pod-configmaps-4e079076-4793-4a90-b01e-2ebd758bbc8f" satisfied condition "success or failure"
Mar  3 13:16:18.358: INFO: Trying to get logs from node 10.0.2.74 pod pod-configmaps-4e079076-4793-4a90-b01e-2ebd758bbc8f container configmap-volume-test: <nil>
STEP: delete the pod
Mar  3 13:16:18.390: INFO: Waiting for pod pod-configmaps-4e079076-4793-4a90-b01e-2ebd758bbc8f to disappear
Mar  3 13:16:18.401: INFO: Pod pod-configmaps-4e079076-4793-4a90-b01e-2ebd758bbc8f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:16:18.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1221" for this suite.
Mar  3 13:16:24.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:16:24.682: INFO: namespace configmap-1221 deletion completed in 6.243168526s

• [SLOW TEST:8.479 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:16:24.683: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  3 13:16:24.976: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  3 13:16:28.014: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:16:28.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5529" for this suite.
Mar  3 13:16:34.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:16:34.315: INFO: namespace webhook-5529 deletion completed in 6.203893564s
STEP: Destroying namespace "webhook-5529-markers" for this suite.
Mar  3 13:16:40.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:16:40.565: INFO: namespace webhook-5529-markers deletion completed in 6.249501864s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.918 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:16:40.601: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Mar  3 13:16:40.660: INFO: Waiting up to 1m0s for all nodes to be ready
Mar  3 13:17:40.678: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 13:17:40.691: INFO: Starting informer...
STEP: Starting pods...
Mar  3 13:17:40.922: INFO: Pod1 is running on 10.0.2.119. Tainting Node
Mar  3 13:17:43.146: INFO: Pod2 is running on 10.0.2.119. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Mar  3 13:17:49.761: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Mar  3 13:18:14.949: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:18:14.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-8123" for this suite.
Mar  3 13:18:21.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:18:21.294: INFO: namespace taint-multiple-pods-8123 deletion completed in 6.310861247s

• [SLOW TEST:100.693 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:18:21.294: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  3 13:18:21.356: INFO: Waiting up to 5m0s for pod "downwardapi-volume-511cb066-2ee4-4fad-8103-d4b314f29cf6" in namespace "downward-api-5454" to be "success or failure"
Mar  3 13:18:21.360: INFO: Pod "downwardapi-volume-511cb066-2ee4-4fad-8103-d4b314f29cf6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04592ms
Mar  3 13:18:23.365: INFO: Pod "downwardapi-volume-511cb066-2ee4-4fad-8103-d4b314f29cf6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008911263s
STEP: Saw pod success
Mar  3 13:18:23.365: INFO: Pod "downwardapi-volume-511cb066-2ee4-4fad-8103-d4b314f29cf6" satisfied condition "success or failure"
Mar  3 13:18:23.375: INFO: Trying to get logs from node 10.0.2.119 pod downwardapi-volume-511cb066-2ee4-4fad-8103-d4b314f29cf6 container client-container: <nil>
STEP: delete the pod
Mar  3 13:18:23.409: INFO: Waiting for pod downwardapi-volume-511cb066-2ee4-4fad-8103-d4b314f29cf6 to disappear
Mar  3 13:18:23.412: INFO: Pod downwardapi-volume-511cb066-2ee4-4fad-8103-d4b314f29cf6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:18:23.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5454" for this suite.
Mar  3 13:18:29.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:18:29.621: INFO: namespace downward-api-5454 deletion completed in 6.203115768s

• [SLOW TEST:8.327 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:18:29.621: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-6308/configmap-test-b23cd073-a6c6-481f-97e2-0ae5478cdbaf
STEP: Creating a pod to test consume configMaps
Mar  3 13:18:29.704: INFO: Waiting up to 5m0s for pod "pod-configmaps-d51681d8-1edd-4614-b270-efb277ce27ff" in namespace "configmap-6308" to be "success or failure"
Mar  3 13:18:29.708: INFO: Pod "pod-configmaps-d51681d8-1edd-4614-b270-efb277ce27ff": Phase="Pending", Reason="", readiness=false. Elapsed: 4.003552ms
Mar  3 13:18:31.714: INFO: Pod "pod-configmaps-d51681d8-1edd-4614-b270-efb277ce27ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009744164s
STEP: Saw pod success
Mar  3 13:18:31.714: INFO: Pod "pod-configmaps-d51681d8-1edd-4614-b270-efb277ce27ff" satisfied condition "success or failure"
Mar  3 13:18:31.719: INFO: Trying to get logs from node 10.0.2.119 pod pod-configmaps-d51681d8-1edd-4614-b270-efb277ce27ff container env-test: <nil>
STEP: delete the pod
Mar  3 13:18:31.760: INFO: Waiting for pod pod-configmaps-d51681d8-1edd-4614-b270-efb277ce27ff to disappear
Mar  3 13:18:31.769: INFO: Pod pod-configmaps-d51681d8-1edd-4614-b270-efb277ce27ff no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:18:31.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6308" for this suite.
Mar  3 13:18:37.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:18:38.045: INFO: namespace configmap-6308 deletion completed in 6.271170247s

• [SLOW TEST:8.424 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:18:38.045: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3042.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3042.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3042.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3042.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  3 13:18:42.153: INFO: DNS probes using dns-test-78123aa0-c873-4d20-84cf-c5d665445f8d succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3042.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3042.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3042.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3042.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  3 13:18:46.237: INFO: DNS probes using dns-test-042f22cd-bb26-490f-9d5d-e6bfa6892774 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3042.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3042.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3042.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3042.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  3 13:18:50.327: INFO: DNS probes using dns-test-3d75f2a7-e18f-4e36-a26e-053348bfb416 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:18:50.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3042" for this suite.
Mar  3 13:18:58.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:18:58.715: INFO: namespace dns-3042 deletion completed in 8.323068589s

• [SLOW TEST:20.670 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:18:58.715: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-c6015b94-eb42-454c-a002-c59ee8dadc48
STEP: Creating a pod to test consume configMaps
Mar  3 13:18:58.787: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e12f27d0-30fe-479e-900a-85ad6bf300a8" in namespace "projected-6249" to be "success or failure"
Mar  3 13:18:58.791: INFO: Pod "pod-projected-configmaps-e12f27d0-30fe-479e-900a-85ad6bf300a8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.135249ms
Mar  3 13:19:00.795: INFO: Pod "pod-projected-configmaps-e12f27d0-30fe-479e-900a-85ad6bf300a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00886375s
STEP: Saw pod success
Mar  3 13:19:00.796: INFO: Pod "pod-projected-configmaps-e12f27d0-30fe-479e-900a-85ad6bf300a8" satisfied condition "success or failure"
Mar  3 13:19:00.800: INFO: Trying to get logs from node 10.0.2.119 pod pod-projected-configmaps-e12f27d0-30fe-479e-900a-85ad6bf300a8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  3 13:19:00.835: INFO: Waiting for pod pod-projected-configmaps-e12f27d0-30fe-479e-900a-85ad6bf300a8 to disappear
Mar  3 13:19:00.839: INFO: Pod pod-projected-configmaps-e12f27d0-30fe-479e-900a-85ad6bf300a8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:19:00.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6249" for this suite.
Mar  3 13:19:06.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:19:07.089: INFO: namespace projected-6249 deletion completed in 6.239907003s

• [SLOW TEST:8.374 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:19:07.090: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1443.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-1443.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1443.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-1443.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1443.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1443.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-1443.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1443.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-1443.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1443.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  3 13:19:09.178: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:09.184: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:09.189: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:09.195: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:09.211: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:09.216: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:09.222: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:09.228: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:09.240: INFO: Lookups using dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1443.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1443.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local jessie_udp@dns-test-service-2.dns-1443.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1443.svc.cluster.local]

Mar  3 13:19:14.250: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:14.263: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:14.281: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:14.294: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:14.328: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:14.335: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:14.388: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:14.400: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:14.417: INFO: Lookups using dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1443.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1443.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local jessie_udp@dns-test-service-2.dns-1443.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1443.svc.cluster.local]

Mar  3 13:19:19.247: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:19.253: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:19.258: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:19.263: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:19.286: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:19.291: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:19.297: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:19.304: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:19.315: INFO: Lookups using dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1443.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1443.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local jessie_udp@dns-test-service-2.dns-1443.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1443.svc.cluster.local]

Mar  3 13:19:24.249: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:24.255: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:24.340: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:24.346: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:24.363: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:24.369: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:24.375: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:24.380: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:24.391: INFO: Lookups using dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1443.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1443.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local jessie_udp@dns-test-service-2.dns-1443.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1443.svc.cluster.local]

Mar  3 13:19:29.246: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:29.251: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:29.257: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:29.262: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:29.296: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:29.301: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:29.306: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:29.311: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:29.323: INFO: Lookups using dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1443.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1443.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local jessie_udp@dns-test-service-2.dns-1443.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1443.svc.cluster.local]

Mar  3 13:19:34.247: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:34.253: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:34.343: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:34.351: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:34.369: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:34.374: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:34.380: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:34.385: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1443.svc.cluster.local from pod dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949: the server could not find the requested resource (get pods dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949)
Mar  3 13:19:34.403: INFO: Lookups using dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1443.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1443.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1443.svc.cluster.local jessie_udp@dns-test-service-2.dns-1443.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1443.svc.cluster.local]

Mar  3 13:19:39.310: INFO: DNS probes using dns-1443/dns-test-bbffb8e4-c0d4-41d9-bd31-d59dd9629949 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:19:39.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1443" for this suite.
Mar  3 13:19:45.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:19:45.608: INFO: namespace dns-1443 deletion completed in 6.23108078s

• [SLOW TEST:38.518 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:19:45.608: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  3 13:19:45.675: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c38393fb-ce4b-462d-82cc-2343a609e2f2" in namespace "downward-api-9221" to be "success or failure"
Mar  3 13:19:45.683: INFO: Pod "downwardapi-volume-c38393fb-ce4b-462d-82cc-2343a609e2f2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.877153ms
Mar  3 13:19:47.688: INFO: Pod "downwardapi-volume-c38393fb-ce4b-462d-82cc-2343a609e2f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0131155s
STEP: Saw pod success
Mar  3 13:19:47.688: INFO: Pod "downwardapi-volume-c38393fb-ce4b-462d-82cc-2343a609e2f2" satisfied condition "success or failure"
Mar  3 13:19:47.692: INFO: Trying to get logs from node 10.0.2.119 pod downwardapi-volume-c38393fb-ce4b-462d-82cc-2343a609e2f2 container client-container: <nil>
STEP: delete the pod
Mar  3 13:19:47.777: INFO: Waiting for pod downwardapi-volume-c38393fb-ce4b-462d-82cc-2343a609e2f2 to disappear
Mar  3 13:19:47.781: INFO: Pod downwardapi-volume-c38393fb-ce4b-462d-82cc-2343a609e2f2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:19:47.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9221" for this suite.
Mar  3 13:19:53.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:19:54.016: INFO: namespace downward-api-9221 deletion completed in 6.230427635s

• [SLOW TEST:8.408 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:19:54.016: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:19:54.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-9832" for this suite.
Mar  3 13:20:00.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:20:00.267: INFO: namespace tables-9832 deletion completed in 6.189042457s

• [SLOW TEST:6.251 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:20:00.267: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-37625ae9-3375-4343-93cd-2a3195beb0e5
STEP: Creating a pod to test consume secrets
Mar  3 13:20:00.336: INFO: Waiting up to 5m0s for pod "pod-secrets-b9155e20-1034-40e7-b89a-eb03c6edb18c" in namespace "secrets-6495" to be "success or failure"
Mar  3 13:20:00.340: INFO: Pod "pod-secrets-b9155e20-1034-40e7-b89a-eb03c6edb18c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.647889ms
Mar  3 13:20:02.352: INFO: Pod "pod-secrets-b9155e20-1034-40e7-b89a-eb03c6edb18c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016693085s
STEP: Saw pod success
Mar  3 13:20:02.352: INFO: Pod "pod-secrets-b9155e20-1034-40e7-b89a-eb03c6edb18c" satisfied condition "success or failure"
Mar  3 13:20:02.357: INFO: Trying to get logs from node 10.0.2.119 pod pod-secrets-b9155e20-1034-40e7-b89a-eb03c6edb18c container secret-volume-test: <nil>
STEP: delete the pod
Mar  3 13:20:02.398: INFO: Waiting for pod pod-secrets-b9155e20-1034-40e7-b89a-eb03c6edb18c to disappear
Mar  3 13:20:02.404: INFO: Pod pod-secrets-b9155e20-1034-40e7-b89a-eb03c6edb18c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:20:02.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6495" for this suite.
Mar  3 13:20:08.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:20:08.630: INFO: namespace secrets-6495 deletion completed in 6.219198542s

• [SLOW TEST:8.363 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:20:08.630: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-120
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  3 13:20:08.684: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  3 13:20:30.781: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.27.0.86:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-120 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  3 13:20:30.781: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 13:20:30.893: INFO: Found all expected endpoints: [netserver-0]
Mar  3 13:20:30.897: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.27.0.47:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-120 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  3 13:20:30.897: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 13:20:31.013: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:20:31.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-120" for this suite.
Mar  3 13:20:43.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:20:43.249: INFO: namespace pod-network-test-120 deletion completed in 12.230516628s

• [SLOW TEST:34.620 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:20:43.250: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 13:20:43.313: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:20:44.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6504" for this suite.
Mar  3 13:20:50.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:20:50.572: INFO: namespace custom-resource-definition-6504 deletion completed in 6.204603084s

• [SLOW TEST:7.323 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:20:50.573: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-3907, will wait for the garbage collector to delete the pods
Mar  3 13:20:52.710: INFO: Deleting Job.batch foo took: 10.844865ms
Mar  3 13:20:53.210: INFO: Terminating Job.batch foo pods took: 500.175034ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:21:35.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3907" for this suite.
Mar  3 13:21:41.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:21:41.368: INFO: namespace job-3907 deletion completed in 6.243609142s

• [SLOW TEST:50.795 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:21:41.368: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar  3 13:21:45.529: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  3 13:21:45.534: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  3 13:21:47.534: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  3 13:21:47.539: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  3 13:21:49.534: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  3 13:21:49.539: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  3 13:21:51.534: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  3 13:21:51.539: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  3 13:21:53.534: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  3 13:21:53.541: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  3 13:21:55.534: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  3 13:21:55.542: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:21:55.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9033" for this suite.
Mar  3 13:22:07.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:22:07.830: INFO: namespace container-lifecycle-hook-9033 deletion completed in 12.281105448s

• [SLOW TEST:26.462 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:22:07.831: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Mar  3 13:22:07.920: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7870 /api/v1/namespaces/watch-7870/configmaps/e2e-watch-test-watch-closed b6a4144f-c6a8-458e-85dd-4d296b7f7bd6 1244169953 0 2020-03-03 13:22:07 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  3 13:22:07.921: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7870 /api/v1/namespaces/watch-7870/configmaps/e2e-watch-test-watch-closed b6a4144f-c6a8-458e-85dd-4d296b7f7bd6 1244169954 0 2020-03-03 13:22:07 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar  3 13:22:07.945: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7870 /api/v1/namespaces/watch-7870/configmaps/e2e-watch-test-watch-closed b6a4144f-c6a8-458e-85dd-4d296b7f7bd6 1244169957 0 2020-03-03 13:22:07 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  3 13:22:07.945: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7870 /api/v1/namespaces/watch-7870/configmaps/e2e-watch-test-watch-closed b6a4144f-c6a8-458e-85dd-4d296b7f7bd6 1244169960 0 2020-03-03 13:22:07 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:22:07.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7870" for this suite.
Mar  3 13:22:13.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:22:14.178: INFO: namespace watch-7870 deletion completed in 6.22728216s

• [SLOW TEST:6.347 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:22:14.179: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:22:16.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1342" for this suite.
Mar  3 13:23:08.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:23:08.513: INFO: namespace kubelet-test-1342 deletion completed in 52.218115875s

• [SLOW TEST:54.334 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:23:08.513: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-def44d97-4cbc-4239-971e-09baca230d2f
STEP: Creating a pod to test consume configMaps
Mar  3 13:23:08.654: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4eeec4c8-f444-4ea6-bae4-fc9ad95149e4" in namespace "projected-6873" to be "success or failure"
Mar  3 13:23:08.658: INFO: Pod "pod-projected-configmaps-4eeec4c8-f444-4ea6-bae4-fc9ad95149e4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.130478ms
Mar  3 13:23:10.663: INFO: Pod "pod-projected-configmaps-4eeec4c8-f444-4ea6-bae4-fc9ad95149e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009762128s
STEP: Saw pod success
Mar  3 13:23:10.663: INFO: Pod "pod-projected-configmaps-4eeec4c8-f444-4ea6-bae4-fc9ad95149e4" satisfied condition "success or failure"
Mar  3 13:23:10.670: INFO: Trying to get logs from node 10.0.2.119 pod pod-projected-configmaps-4eeec4c8-f444-4ea6-bae4-fc9ad95149e4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  3 13:23:10.757: INFO: Waiting for pod pod-projected-configmaps-4eeec4c8-f444-4ea6-bae4-fc9ad95149e4 to disappear
Mar  3 13:23:10.761: INFO: Pod pod-projected-configmaps-4eeec4c8-f444-4ea6-bae4-fc9ad95149e4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:23:10.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6873" for this suite.
Mar  3 13:23:16.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:23:16.988: INFO: namespace projected-6873 deletion completed in 6.216726061s

• [SLOW TEST:8.474 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:23:16.988: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 13:23:17.048: INFO: Creating ReplicaSet my-hostname-basic-44b96543-dc0f-4d2f-a1f4-2d94f1b69d24
Mar  3 13:23:17.064: INFO: Pod name my-hostname-basic-44b96543-dc0f-4d2f-a1f4-2d94f1b69d24: Found 0 pods out of 1
Mar  3 13:23:22.072: INFO: Pod name my-hostname-basic-44b96543-dc0f-4d2f-a1f4-2d94f1b69d24: Found 1 pods out of 1
Mar  3 13:23:22.072: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-44b96543-dc0f-4d2f-a1f4-2d94f1b69d24" is running
Mar  3 13:23:22.076: INFO: Pod "my-hostname-basic-44b96543-dc0f-4d2f-a1f4-2d94f1b69d24-lx9z7" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-03 13:23:17 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-03 13:23:18 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-03 13:23:18 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-03 13:23:17 +0000 UTC Reason: Message:}])
Mar  3 13:23:22.076: INFO: Trying to dial the pod
Mar  3 13:23:27.092: INFO: Controller my-hostname-basic-44b96543-dc0f-4d2f-a1f4-2d94f1b69d24: Got expected result from replica 1 [my-hostname-basic-44b96543-dc0f-4d2f-a1f4-2d94f1b69d24-lx9z7]: "my-hostname-basic-44b96543-dc0f-4d2f-a1f4-2d94f1b69d24-lx9z7", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:23:27.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9031" for this suite.
Mar  3 13:23:33.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:23:33.325: INFO: namespace replicaset-9031 deletion completed in 6.224154817s

• [SLOW TEST:16.337 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:23:33.325: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-866/configmap-test-e0215346-ad13-4442-9e48-a67b79c822f5
STEP: Creating a pod to test consume configMaps
Mar  3 13:23:33.394: INFO: Waiting up to 5m0s for pod "pod-configmaps-f5624a01-4407-41b7-803d-b79f71c73c70" in namespace "configmap-866" to be "success or failure"
Mar  3 13:23:33.404: INFO: Pod "pod-configmaps-f5624a01-4407-41b7-803d-b79f71c73c70": Phase="Pending", Reason="", readiness=false. Elapsed: 10.301458ms
Mar  3 13:23:35.410: INFO: Pod "pod-configmaps-f5624a01-4407-41b7-803d-b79f71c73c70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015544073s
STEP: Saw pod success
Mar  3 13:23:35.410: INFO: Pod "pod-configmaps-f5624a01-4407-41b7-803d-b79f71c73c70" satisfied condition "success or failure"
Mar  3 13:23:35.418: INFO: Trying to get logs from node 10.0.2.119 pod pod-configmaps-f5624a01-4407-41b7-803d-b79f71c73c70 container env-test: <nil>
STEP: delete the pod
Mar  3 13:23:35.459: INFO: Waiting for pod pod-configmaps-f5624a01-4407-41b7-803d-b79f71c73c70 to disappear
Mar  3 13:23:35.465: INFO: Pod pod-configmaps-f5624a01-4407-41b7-803d-b79f71c73c70 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:23:35.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-866" for this suite.
Mar  3 13:23:41.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:23:41.699: INFO: namespace configmap-866 deletion completed in 6.228102985s

• [SLOW TEST:8.374 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:23:41.699: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar  3 13:23:41.762: INFO: Waiting up to 5m0s for pod "pod-f47c77eb-c373-4c3f-9119-4b9ef50154d5" in namespace "emptydir-5126" to be "success or failure"
Mar  3 13:23:41.769: INFO: Pod "pod-f47c77eb-c373-4c3f-9119-4b9ef50154d5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.020055ms
Mar  3 13:23:43.775: INFO: Pod "pod-f47c77eb-c373-4c3f-9119-4b9ef50154d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013935032s
STEP: Saw pod success
Mar  3 13:23:43.776: INFO: Pod "pod-f47c77eb-c373-4c3f-9119-4b9ef50154d5" satisfied condition "success or failure"
Mar  3 13:23:43.783: INFO: Trying to get logs from node 10.0.2.119 pod pod-f47c77eb-c373-4c3f-9119-4b9ef50154d5 container test-container: <nil>
STEP: delete the pod
Mar  3 13:23:43.811: INFO: Waiting for pod pod-f47c77eb-c373-4c3f-9119-4b9ef50154d5 to disappear
Mar  3 13:23:43.817: INFO: Pod pod-f47c77eb-c373-4c3f-9119-4b9ef50154d5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:23:43.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5126" for this suite.
Mar  3 13:23:49.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:23:50.108: INFO: namespace emptydir-5126 deletion completed in 6.286279571s

• [SLOW TEST:8.409 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:23:50.108: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Mar  3 13:23:50.171: INFO: Waiting up to 5m0s for pod "var-expansion-c9e401ff-b235-4a8b-a7fc-d1a9060ded5e" in namespace "var-expansion-1092" to be "success or failure"
Mar  3 13:23:50.178: INFO: Pod "var-expansion-c9e401ff-b235-4a8b-a7fc-d1a9060ded5e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.857034ms
Mar  3 13:23:52.186: INFO: Pod "var-expansion-c9e401ff-b235-4a8b-a7fc-d1a9060ded5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014901555s
STEP: Saw pod success
Mar  3 13:23:52.186: INFO: Pod "var-expansion-c9e401ff-b235-4a8b-a7fc-d1a9060ded5e" satisfied condition "success or failure"
Mar  3 13:23:52.190: INFO: Trying to get logs from node 10.0.2.119 pod var-expansion-c9e401ff-b235-4a8b-a7fc-d1a9060ded5e container dapi-container: <nil>
STEP: delete the pod
Mar  3 13:23:52.222: INFO: Waiting for pod var-expansion-c9e401ff-b235-4a8b-a7fc-d1a9060ded5e to disappear
Mar  3 13:23:52.227: INFO: Pod var-expansion-c9e401ff-b235-4a8b-a7fc-d1a9060ded5e no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:23:52.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1092" for this suite.
Mar  3 13:23:58.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:23:58.459: INFO: namespace var-expansion-1092 deletion completed in 6.226979171s

• [SLOW TEST:8.351 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:23:58.459: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  3 13:23:58.532: INFO: Waiting up to 5m0s for pod "downwardapi-volume-78d7ffbd-47aa-4b14-94bb-305d49ec6dde" in namespace "projected-8536" to be "success or failure"
Mar  3 13:23:58.536: INFO: Pod "downwardapi-volume-78d7ffbd-47aa-4b14-94bb-305d49ec6dde": Phase="Pending", Reason="", readiness=false. Elapsed: 4.385552ms
Mar  3 13:24:00.549: INFO: Pod "downwardapi-volume-78d7ffbd-47aa-4b14-94bb-305d49ec6dde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017591294s
STEP: Saw pod success
Mar  3 13:24:00.549: INFO: Pod "downwardapi-volume-78d7ffbd-47aa-4b14-94bb-305d49ec6dde" satisfied condition "success or failure"
Mar  3 13:24:00.555: INFO: Trying to get logs from node 10.0.2.119 pod downwardapi-volume-78d7ffbd-47aa-4b14-94bb-305d49ec6dde container client-container: <nil>
STEP: delete the pod
Mar  3 13:24:00.586: INFO: Waiting for pod downwardapi-volume-78d7ffbd-47aa-4b14-94bb-305d49ec6dde to disappear
Mar  3 13:24:00.590: INFO: Pod downwardapi-volume-78d7ffbd-47aa-4b14-94bb-305d49ec6dde no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:24:00.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8536" for this suite.
Mar  3 13:24:06.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:24:06.814: INFO: namespace projected-8536 deletion completed in 6.217604376s

• [SLOW TEST:8.355 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:24:06.814: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Mar  3 13:24:06.864: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:24:09.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4651" for this suite.
Mar  3 13:24:15.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:24:15.880: INFO: namespace init-container-4651 deletion completed in 6.246514925s

• [SLOW TEST:9.066 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:24:15.881: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Mar  3 13:24:16.039: INFO: Waiting up to 5m0s for pod "var-expansion-00dd8325-1678-45ef-a392-629856b22fe3" in namespace "var-expansion-2366" to be "success or failure"
Mar  3 13:24:16.043: INFO: Pod "var-expansion-00dd8325-1678-45ef-a392-629856b22fe3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.128743ms
Mar  3 13:24:18.056: INFO: Pod "var-expansion-00dd8325-1678-45ef-a392-629856b22fe3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016910982s
STEP: Saw pod success
Mar  3 13:24:18.056: INFO: Pod "var-expansion-00dd8325-1678-45ef-a392-629856b22fe3" satisfied condition "success or failure"
Mar  3 13:24:18.139: INFO: Trying to get logs from node 10.0.2.119 pod var-expansion-00dd8325-1678-45ef-a392-629856b22fe3 container dapi-container: <nil>
STEP: delete the pod
Mar  3 13:24:18.175: INFO: Waiting for pod var-expansion-00dd8325-1678-45ef-a392-629856b22fe3 to disappear
Mar  3 13:24:18.182: INFO: Pod var-expansion-00dd8325-1678-45ef-a392-629856b22fe3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:24:18.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2366" for this suite.
Mar  3 13:24:24.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:24:24.445: INFO: namespace var-expansion-2366 deletion completed in 6.255506248s

• [SLOW TEST:8.564 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:24:24.445: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-30deced2-eaf1-4938-b2d2-2414b9e1cec9
STEP: Creating secret with name s-test-opt-upd-be61dfed-9182-445d-ac02-8a86d9f03366
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-30deced2-eaf1-4938-b2d2-2414b9e1cec9
STEP: Updating secret s-test-opt-upd-be61dfed-9182-445d-ac02-8a86d9f03366
STEP: Creating secret with name s-test-opt-create-b84f8a06-065f-4fa3-a30f-7d2d35c63e5d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:25:51.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5096" for this suite.
Mar  3 13:26:07.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:26:07.559: INFO: namespace projected-5096 deletion completed in 16.193656657s

• [SLOW TEST:103.114 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:26:07.559: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Mar  3 13:26:10.158: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8430 pod-service-account-d3430b6b-7b0b-45e9-8a92-68ced797f2b0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Mar  3 13:26:10.680: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8430 pod-service-account-d3430b6b-7b0b-45e9-8a92-68ced797f2b0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Mar  3 13:26:10.941: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8430 pod-service-account-d3430b6b-7b0b-45e9-8a92-68ced797f2b0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:26:11.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8430" for this suite.
Mar  3 13:26:17.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:26:17.356: INFO: namespace svcaccounts-8430 deletion completed in 6.208044065s

• [SLOW TEST:9.797 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:26:17.357: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-844ae46c-21d4-4520-9194-c0b7996900ff
STEP: Creating secret with name secret-projected-all-test-volume-edfab49c-679e-47d3-aeb2-e9151759b3e0
STEP: Creating a pod to test Check all projections for projected volume plugin
Mar  3 13:26:17.606: INFO: Waiting up to 5m0s for pod "projected-volume-a86b30a4-a846-47a6-a7e9-99a3caf6b2dc" in namespace "projected-890" to be "success or failure"
Mar  3 13:26:17.610: INFO: Pod "projected-volume-a86b30a4-a846-47a6-a7e9-99a3caf6b2dc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.61622ms
Mar  3 13:26:19.619: INFO: Pod "projected-volume-a86b30a4-a846-47a6-a7e9-99a3caf6b2dc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013229957s
STEP: Saw pod success
Mar  3 13:26:19.619: INFO: Pod "projected-volume-a86b30a4-a846-47a6-a7e9-99a3caf6b2dc" satisfied condition "success or failure"
Mar  3 13:26:19.623: INFO: Trying to get logs from node 10.0.2.119 pod projected-volume-a86b30a4-a846-47a6-a7e9-99a3caf6b2dc container projected-all-volume-test: <nil>
STEP: delete the pod
Mar  3 13:26:19.653: INFO: Waiting for pod projected-volume-a86b30a4-a846-47a6-a7e9-99a3caf6b2dc to disappear
Mar  3 13:26:19.658: INFO: Pod projected-volume-a86b30a4-a846-47a6-a7e9-99a3caf6b2dc no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:26:19.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-890" for this suite.
Mar  3 13:26:25.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:26:25.861: INFO: namespace projected-890 deletion completed in 6.198409623s

• [SLOW TEST:8.504 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:26:25.861: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Mar  3 13:26:25.916: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 13:26:29.627: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:26:44.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9901" for this suite.
Mar  3 13:26:50.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:26:50.719: INFO: namespace crd-publish-openapi-9901 deletion completed in 6.2338024s

• [SLOW TEST:24.861 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:26:50.723: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-fa68ecac-93f4-48da-b320-8ad381d65ea4
STEP: Creating a pod to test consume secrets
Mar  3 13:26:50.788: INFO: Waiting up to 5m0s for pod "pod-secrets-0d25964b-2457-43f5-8355-4a0a66b31f7d" in namespace "secrets-3970" to be "success or failure"
Mar  3 13:26:50.798: INFO: Pod "pod-secrets-0d25964b-2457-43f5-8355-4a0a66b31f7d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.542424ms
Mar  3 13:26:52.803: INFO: Pod "pod-secrets-0d25964b-2457-43f5-8355-4a0a66b31f7d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014675922s
STEP: Saw pod success
Mar  3 13:26:52.803: INFO: Pod "pod-secrets-0d25964b-2457-43f5-8355-4a0a66b31f7d" satisfied condition "success or failure"
Mar  3 13:26:52.807: INFO: Trying to get logs from node 10.0.2.119 pod pod-secrets-0d25964b-2457-43f5-8355-4a0a66b31f7d container secret-env-test: <nil>
STEP: delete the pod
Mar  3 13:26:52.864: INFO: Waiting for pod pod-secrets-0d25964b-2457-43f5-8355-4a0a66b31f7d to disappear
Mar  3 13:26:52.868: INFO: Pod pod-secrets-0d25964b-2457-43f5-8355-4a0a66b31f7d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:26:52.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3970" for this suite.
Mar  3 13:26:58.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:26:59.086: INFO: namespace secrets-3970 deletion completed in 6.212245696s

• [SLOW TEST:8.364 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:26:59.086: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-8192f998-4005-48e7-856b-3e3f7d222253
STEP: Creating a pod to test consume secrets
Mar  3 13:26:59.225: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7e1d5ef1-1a8a-4377-b13a-3d02e168d1c8" in namespace "projected-2058" to be "success or failure"
Mar  3 13:26:59.229: INFO: Pod "pod-projected-secrets-7e1d5ef1-1a8a-4377-b13a-3d02e168d1c8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.215214ms
Mar  3 13:27:01.236: INFO: Pod "pod-projected-secrets-7e1d5ef1-1a8a-4377-b13a-3d02e168d1c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010512714s
STEP: Saw pod success
Mar  3 13:27:01.236: INFO: Pod "pod-projected-secrets-7e1d5ef1-1a8a-4377-b13a-3d02e168d1c8" satisfied condition "success or failure"
Mar  3 13:27:01.246: INFO: Trying to get logs from node 10.0.2.119 pod pod-projected-secrets-7e1d5ef1-1a8a-4377-b13a-3d02e168d1c8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  3 13:27:01.276: INFO: Waiting for pod pod-projected-secrets-7e1d5ef1-1a8a-4377-b13a-3d02e168d1c8 to disappear
Mar  3 13:27:01.283: INFO: Pod pod-projected-secrets-7e1d5ef1-1a8a-4377-b13a-3d02e168d1c8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:27:01.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2058" for this suite.
Mar  3 13:27:07.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:27:07.635: INFO: namespace projected-2058 deletion completed in 6.345822811s

• [SLOW TEST:8.549 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:27:07.635: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  3 13:27:07.944: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  3 13:27:10.977: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
Mar  3 13:27:11.016: INFO: Waiting for webhook configuration to be ready...
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:27:11.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9224" for this suite.
Mar  3 13:27:17.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:27:17.470: INFO: namespace webhook-9224 deletion completed in 6.23109035s
STEP: Destroying namespace "webhook-9224-markers" for this suite.
Mar  3 13:27:23.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:27:23.748: INFO: namespace webhook-9224-markers deletion completed in 6.278128616s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.165 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:27:23.800: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Mar  3 13:27:23.910: INFO: Waiting up to 5m0s for pod "downward-api-926cae8f-703f-4ccc-8f05-d637186855fc" in namespace "downward-api-9407" to be "success or failure"
Mar  3 13:27:23.918: INFO: Pod "downward-api-926cae8f-703f-4ccc-8f05-d637186855fc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.61825ms
Mar  3 13:27:25.923: INFO: Pod "downward-api-926cae8f-703f-4ccc-8f05-d637186855fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012533551s
STEP: Saw pod success
Mar  3 13:27:25.923: INFO: Pod "downward-api-926cae8f-703f-4ccc-8f05-d637186855fc" satisfied condition "success or failure"
Mar  3 13:27:25.930: INFO: Trying to get logs from node 10.0.2.119 pod downward-api-926cae8f-703f-4ccc-8f05-d637186855fc container dapi-container: <nil>
STEP: delete the pod
Mar  3 13:27:25.958: INFO: Waiting for pod downward-api-926cae8f-703f-4ccc-8f05-d637186855fc to disappear
Mar  3 13:27:25.962: INFO: Pod downward-api-926cae8f-703f-4ccc-8f05-d637186855fc no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:27:25.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9407" for this suite.
Mar  3 13:27:31.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:27:32.214: INFO: namespace downward-api-9407 deletion completed in 6.244831892s

• [SLOW TEST:8.414 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:27:32.214: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Mar  3 13:27:32.265: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Mar  3 13:27:32.962: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Mar  3 13:27:35.034: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6cdbb58958\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  3 13:27:37.041: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6cdbb58958\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  3 13:27:39.040: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6cdbb58958\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  3 13:27:41.042: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6cdbb58958\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  3 13:27:43.039: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6cdbb58958\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  3 13:27:45.041: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6cdbb58958\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  3 13:27:47.039: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6cdbb58958\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  3 13:27:49.043: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6cdbb58958\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  3 13:27:51.039: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6cdbb58958\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  3 13:27:53.039: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718838852, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6cdbb58958\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  3 13:27:55.825: INFO: Waited 771.981842ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:27:56.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-8785" for this suite.
Mar  3 13:28:02.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:28:02.754: INFO: namespace aggregator-8785 deletion completed in 6.31120361s

• [SLOW TEST:30.540 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:28:02.755: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Mar  3 13:28:04.869: INFO: Pod pod-hostip-a97c2f2b-e08a-4bfc-b519-343b80c48007 has hostIP: 10.0.2.119
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:28:04.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8461" for this suite.
Mar  3 13:28:16.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:28:17.133: INFO: namespace pods-8461 deletion completed in 12.258401022s

• [SLOW TEST:14.379 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:28:17.134: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:28:17.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8486" for this suite.
Mar  3 13:28:23.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:28:23.435: INFO: namespace custom-resource-definition-8486 deletion completed in 6.223067021s

• [SLOW TEST:6.302 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:28:23.436: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2606
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-2606
STEP: Creating statefulset with conflicting port in namespace statefulset-2606
STEP: Waiting until pod test-pod will start running in namespace statefulset-2606
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-2606
Mar  3 13:28:25.539: INFO: Observed stateful pod in namespace: statefulset-2606, name: ss-0, uid: 26a0a669-c939-4617-a9a6-d1d891cab3d2, status phase: Failed. Waiting for statefulset controller to delete.
Mar  3 13:28:25.544: INFO: Observed stateful pod in namespace: statefulset-2606, name: ss-0, uid: 26a0a669-c939-4617-a9a6-d1d891cab3d2, status phase: Failed. Waiting for statefulset controller to delete.
Mar  3 13:28:25.553: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-2606
STEP: Removing pod with conflicting port in namespace statefulset-2606
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-2606 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Mar  3 13:28:29.623: INFO: Deleting all statefulset in ns statefulset-2606
Mar  3 13:28:29.629: INFO: Scaling statefulset ss to 0
Mar  3 13:28:39.650: INFO: Waiting for statefulset status.replicas updated to 0
Mar  3 13:28:39.657: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:28:39.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2606" for this suite.
Mar  3 13:28:45.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:28:45.944: INFO: namespace statefulset-2606 deletion completed in 6.254986262s

• [SLOW TEST:22.508 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:28:45.944: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  3 13:28:46.613: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  3 13:28:49.642: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:28:49.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4626" for this suite.
Mar  3 13:28:55.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:28:55.935: INFO: namespace webhook-4626 deletion completed in 6.218764344s
STEP: Destroying namespace "webhook-4626-markers" for this suite.
Mar  3 13:29:01.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:29:02.272: INFO: namespace webhook-4626-markers deletion completed in 6.337646705s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.366 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:29:02.310: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 13:29:02.425: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-56bf7853-8c65-4ad6-8512-0ad4288421fe" in namespace "security-context-test-2534" to be "success or failure"
Mar  3 13:29:02.429: INFO: Pod "busybox-readonly-false-56bf7853-8c65-4ad6-8512-0ad4288421fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.669241ms
Mar  3 13:29:04.434: INFO: Pod "busybox-readonly-false-56bf7853-8c65-4ad6-8512-0ad4288421fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009791977s
Mar  3 13:29:04.435: INFO: Pod "busybox-readonly-false-56bf7853-8c65-4ad6-8512-0ad4288421fe" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:29:04.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2534" for this suite.
Mar  3 13:29:10.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:29:10.743: INFO: namespace security-context-test-2534 deletion completed in 6.302115588s

• [SLOW TEST:8.433 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:29:10.743: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:29:14.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1548" for this suite.
Mar  3 13:29:20.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:29:21.091: INFO: namespace kubelet-test-1548 deletion completed in 6.26418059s

• [SLOW TEST:10.348 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:29:21.093: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Mar  3 13:29:21.166: INFO: Waiting up to 5m0s for pod "downward-api-fe237c04-a104-4539-b341-f72332ff3216" in namespace "downward-api-1951" to be "success or failure"
Mar  3 13:29:21.172: INFO: Pod "downward-api-fe237c04-a104-4539-b341-f72332ff3216": Phase="Pending", Reason="", readiness=false. Elapsed: 5.742748ms
Mar  3 13:29:23.180: INFO: Pod "downward-api-fe237c04-a104-4539-b341-f72332ff3216": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01358845s
STEP: Saw pod success
Mar  3 13:29:23.180: INFO: Pod "downward-api-fe237c04-a104-4539-b341-f72332ff3216" satisfied condition "success or failure"
Mar  3 13:29:23.184: INFO: Trying to get logs from node 10.0.2.119 pod downward-api-fe237c04-a104-4539-b341-f72332ff3216 container dapi-container: <nil>
STEP: delete the pod
Mar  3 13:29:23.213: INFO: Waiting for pod downward-api-fe237c04-a104-4539-b341-f72332ff3216 to disappear
Mar  3 13:29:23.217: INFO: Pod downward-api-fe237c04-a104-4539-b341-f72332ff3216 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:29:23.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1951" for this suite.
Mar  3 13:29:29.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:29:29.432: INFO: namespace downward-api-1951 deletion completed in 6.20947566s

• [SLOW TEST:8.339 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:29:29.432: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Mar  3 13:29:31.530: INFO: &Pod{ObjectMeta:{send-events-34695de4-7e6c-49aa-abd7-6d9c8315c169  events-1898 /api/v1/namespaces/events-1898/pods/send-events-34695de4-7e6c-49aa-abd7-6d9c8315c169 d22d7acb-e2de-48f0-91ff-2e30780974b5 1244259139 0 2020-03-03 13:29:29 +0000 UTC <nil> <nil> map[name:foo time:485244232] map[tke.cloud.tencent.com/networks-status:[{
    "name": "tke-bridge",
    "ips": [
        "172.27.0.15"
    ],
    "default": true,
    "dns": {}
}]] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-dlxjq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-dlxjq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-dlxjq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.2.119,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 13:29:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 13:29:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 13:29:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-03 13:29:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.119,PodIP:172.27.0.15,StartTime:2020-03-03 13:29:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-03 13:29:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:docker://f36d2ddb4e040a6676214e826d6dadeda1b6c7690b185baf681f8f32743d3389,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.27.0.15,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Mar  3 13:29:33.537: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Mar  3 13:29:35.545: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:29:35.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1898" for this suite.
Mar  3 13:30:19.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:30:19.784: INFO: namespace events-1898 deletion completed in 44.22369635s

• [SLOW TEST:50.352 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:30:19.784: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:30:36.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8198" for this suite.
Mar  3 13:30:42.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:30:43.140: INFO: namespace resourcequota-8198 deletion completed in 6.209453254s

• [SLOW TEST:23.355 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:30:43.140: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:31:04.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1932" for this suite.
Mar  3 13:31:10.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:31:10.837: INFO: namespace container-runtime-1932 deletion completed in 6.273104404s

• [SLOW TEST:27.697 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:31:10.837: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  3 13:31:11.284: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  3 13:31:14.326: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:31:14.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3342" for this suite.
Mar  3 13:31:20.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:31:20.896: INFO: namespace webhook-3342 deletion completed in 6.187368699s
STEP: Destroying namespace "webhook-3342-markers" for this suite.
Mar  3 13:31:26.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:31:27.327: INFO: namespace webhook-3342-markers deletion completed in 6.431011731s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.525 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:31:27.363: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Mar  3 13:31:27.422: INFO: Waiting up to 5m0s for pod "client-containers-875fcf9f-f638-4ee2-922e-70b575d4ee03" in namespace "containers-1998" to be "success or failure"
Mar  3 13:31:27.427: INFO: Pod "client-containers-875fcf9f-f638-4ee2-922e-70b575d4ee03": Phase="Pending", Reason="", readiness=false. Elapsed: 4.793158ms
Mar  3 13:31:29.433: INFO: Pod "client-containers-875fcf9f-f638-4ee2-922e-70b575d4ee03": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01030585s
STEP: Saw pod success
Mar  3 13:31:29.433: INFO: Pod "client-containers-875fcf9f-f638-4ee2-922e-70b575d4ee03" satisfied condition "success or failure"
Mar  3 13:31:29.437: INFO: Trying to get logs from node 10.0.2.119 pod client-containers-875fcf9f-f638-4ee2-922e-70b575d4ee03 container test-container: <nil>
STEP: delete the pod
Mar  3 13:31:29.473: INFO: Waiting for pod client-containers-875fcf9f-f638-4ee2-922e-70b575d4ee03 to disappear
Mar  3 13:31:29.478: INFO: Pod client-containers-875fcf9f-f638-4ee2-922e-70b575d4ee03 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:31:29.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1998" for this suite.
Mar  3 13:31:35.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:31:35.744: INFO: namespace containers-1998 deletion completed in 6.258379504s

• [SLOW TEST:8.381 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:31:35.744: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-85117174-7977-4400-b6fd-bf498a003161
STEP: Creating configMap with name cm-test-opt-upd-80399286-aeb7-4fd1-922e-1d6e9e2513ac
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-85117174-7977-4400-b6fd-bf498a003161
STEP: Updating configmap cm-test-opt-upd-80399286-aeb7-4fd1-922e-1d6e9e2513ac
STEP: Creating configMap with name cm-test-opt-create-f6816229-0d62-478c-8623-c80334d37f4a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:31:39.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8589" for this suite.
Mar  3 13:31:52.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:31:52.294: INFO: namespace projected-8589 deletion completed in 12.299791114s

• [SLOW TEST:16.550 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:31:52.294: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Mar  3 13:31:52.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 create -f - --namespace=kubectl-852'
Mar  3 13:31:52.624: INFO: stderr: ""
Mar  3 13:31:52.624: INFO: stdout: "pod/pause created\n"
Mar  3 13:31:52.624: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar  3 13:31:52.624: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-852" to be "running and ready"
Mar  3 13:31:52.628: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.144072ms
Mar  3 13:31:54.633: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.009092967s
Mar  3 13:31:54.633: INFO: Pod "pause" satisfied condition "running and ready"
Mar  3 13:31:54.633: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Mar  3 13:31:54.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 label pods pause testing-label=testing-label-value --namespace=kubectl-852'
Mar  3 13:31:54.723: INFO: stderr: ""
Mar  3 13:31:54.723: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Mar  3 13:31:54.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pod pause -L testing-label --namespace=kubectl-852'
Mar  3 13:31:54.821: INFO: stderr: ""
Mar  3 13:31:54.821: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Mar  3 13:31:54.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 label pods pause testing-label- --namespace=kubectl-852'
Mar  3 13:31:54.911: INFO: stderr: ""
Mar  3 13:31:54.912: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Mar  3 13:31:54.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pod pause -L testing-label --namespace=kubectl-852'
Mar  3 13:31:54.995: INFO: stderr: ""
Mar  3 13:31:54.995: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Mar  3 13:31:54.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 delete --grace-period=0 --force -f - --namespace=kubectl-852'
Mar  3 13:31:55.089: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  3 13:31:55.089: INFO: stdout: "pod \"pause\" force deleted\n"
Mar  3 13:31:55.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get rc,svc -l name=pause --no-headers --namespace=kubectl-852'
Mar  3 13:31:55.184: INFO: stderr: "No resources found in kubectl-852 namespace.\n"
Mar  3 13:31:55.184: INFO: stdout: ""
Mar  3 13:31:55.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods -l name=pause --namespace=kubectl-852 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  3 13:31:55.273: INFO: stderr: ""
Mar  3 13:31:55.273: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:31:55.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-852" for this suite.
Mar  3 13:32:01.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:32:01.505: INFO: namespace kubectl-852 deletion completed in 6.227226967s

• [SLOW TEST:9.211 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:32:01.506: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 13:32:01.572: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Mar  3 13:32:05.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=crd-publish-openapi-5078 create -f -'
Mar  3 13:32:05.990: INFO: stderr: ""
Mar  3 13:32:05.990: INFO: stdout: "e2e-test-crd-publish-openapi-465-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Mar  3 13:32:05.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=crd-publish-openapi-5078 delete e2e-test-crd-publish-openapi-465-crds test-foo'
Mar  3 13:32:06.089: INFO: stderr: ""
Mar  3 13:32:06.089: INFO: stdout: "e2e-test-crd-publish-openapi-465-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Mar  3 13:32:06.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=crd-publish-openapi-5078 apply -f -'
Mar  3 13:32:06.370: INFO: stderr: ""
Mar  3 13:32:06.370: INFO: stdout: "e2e-test-crd-publish-openapi-465-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Mar  3 13:32:06.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=crd-publish-openapi-5078 delete e2e-test-crd-publish-openapi-465-crds test-foo'
Mar  3 13:32:06.466: INFO: stderr: ""
Mar  3 13:32:06.466: INFO: stdout: "e2e-test-crd-publish-openapi-465-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Mar  3 13:32:06.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=crd-publish-openapi-5078 create -f -'
Mar  3 13:32:06.665: INFO: rc: 1
Mar  3 13:32:06.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=crd-publish-openapi-5078 apply -f -'
Mar  3 13:32:06.860: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Mar  3 13:32:06.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=crd-publish-openapi-5078 create -f -'
Mar  3 13:32:07.042: INFO: rc: 1
Mar  3 13:32:07.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=crd-publish-openapi-5078 apply -f -'
Mar  3 13:32:07.248: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Mar  3 13:32:07.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 explain e2e-test-crd-publish-openapi-465-crds'
Mar  3 13:32:07.470: INFO: stderr: ""
Mar  3 13:32:07.471: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-465-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Mar  3 13:32:07.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 explain e2e-test-crd-publish-openapi-465-crds.metadata'
Mar  3 13:32:07.681: INFO: stderr: ""
Mar  3 13:32:07.681: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-465-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Mar  3 13:32:07.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 explain e2e-test-crd-publish-openapi-465-crds.spec'
Mar  3 13:32:07.888: INFO: stderr: ""
Mar  3 13:32:07.888: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-465-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Mar  3 13:32:07.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 explain e2e-test-crd-publish-openapi-465-crds.spec.bars'
Mar  3 13:32:08.092: INFO: stderr: ""
Mar  3 13:32:08.093: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-465-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Mar  3 13:32:08.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 explain e2e-test-crd-publish-openapi-465-crds.spec.bars2'
Mar  3 13:32:08.331: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:32:10.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5078" for this suite.
Mar  3 13:32:16.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:32:16.819: INFO: namespace crd-publish-openapi-5078 deletion completed in 6.279254147s

• [SLOW TEST:15.313 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:32:16.819: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar  3 13:32:17.052: INFO: Waiting up to 5m0s for pod "pod-a0c5eefa-26cc-4ef2-9bd4-57a67c6c905e" in namespace "emptydir-438" to be "success or failure"
Mar  3 13:32:17.057: INFO: Pod "pod-a0c5eefa-26cc-4ef2-9bd4-57a67c6c905e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.210704ms
Mar  3 13:32:19.063: INFO: Pod "pod-a0c5eefa-26cc-4ef2-9bd4-57a67c6c905e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011588653s
STEP: Saw pod success
Mar  3 13:32:19.063: INFO: Pod "pod-a0c5eefa-26cc-4ef2-9bd4-57a67c6c905e" satisfied condition "success or failure"
Mar  3 13:32:19.068: INFO: Trying to get logs from node 10.0.2.119 pod pod-a0c5eefa-26cc-4ef2-9bd4-57a67c6c905e container test-container: <nil>
STEP: delete the pod
Mar  3 13:32:19.095: INFO: Waiting for pod pod-a0c5eefa-26cc-4ef2-9bd4-57a67c6c905e to disappear
Mar  3 13:32:19.099: INFO: Pod pod-a0c5eefa-26cc-4ef2-9bd4-57a67c6c905e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:32:19.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-438" for this suite.
Mar  3 13:32:25.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:32:25.339: INFO: namespace emptydir-438 deletion completed in 6.235463658s

• [SLOW TEST:8.520 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:32:25.340: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  3 13:32:25.968: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  3 13:32:29.007: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 13:32:29.013: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6614-crds.webhook.example.com via the AdmissionRegistration API
Mar  3 13:32:29.615: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:32:30.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4428" for this suite.
Mar  3 13:32:36.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:32:36.665: INFO: namespace webhook-4428 deletion completed in 6.199979817s
STEP: Destroying namespace "webhook-4428-markers" for this suite.
Mar  3 13:32:42.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:32:42.960: INFO: namespace webhook-4428-markers deletion completed in 6.294513522s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.649 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:32:42.990: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Mar  3 13:32:43.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 --namespace=kubectl-3326 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar  3 13:32:44.332: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar  3 13:32:44.332: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:32:46.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3326" for this suite.
Mar  3 13:32:56.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:32:56.578: INFO: namespace kubectl-3326 deletion completed in 10.223545015s

• [SLOW TEST:13.588 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:32:56.578: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 13:32:56.715: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:33:02.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9810" for this suite.
Mar  3 13:33:08.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:33:09.001: INFO: namespace custom-resource-definition-9810 deletion completed in 6.461389584s

• [SLOW TEST:12.423 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:33:09.002: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-759
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-759
I0303 13:33:09.142170      23 runners.go:184] Created replication controller with name: externalname-service, namespace: services-759, replica count: 2
I0303 13:33:12.192490      23 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  3 13:33:12.192: INFO: Creating new exec pod
Mar  3 13:33:15.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=services-759 execpoddl5pl -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Mar  3 13:33:15.466: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Mar  3 13:33:15.466: INFO: stdout: ""
Mar  3 13:33:15.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=services-759 execpoddl5pl -- /bin/sh -x -c nc -zv -t -w 2 172.27.255.53 80'
Mar  3 13:33:15.657: INFO: stderr: "+ nc -zv -t -w 2 172.27.255.53 80\nConnection to 172.27.255.53 80 port [tcp/http] succeeded!\n"
Mar  3 13:33:15.657: INFO: stdout: ""
Mar  3 13:33:15.657: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:33:15.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-759" for this suite.
Mar  3 13:33:21.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:33:21.919: INFO: namespace services-759 deletion completed in 6.189778037s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:12.917 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:33:21.920: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-b997743d-b35a-47f6-9500-cdfc54ad5d08
STEP: Creating a pod to test consume secrets
Mar  3 13:33:21.988: INFO: Waiting up to 5m0s for pod "pod-secrets-827e8fd6-e0a2-487f-a3e9-775f801ff4a4" in namespace "secrets-9013" to be "success or failure"
Mar  3 13:33:21.992: INFO: Pod "pod-secrets-827e8fd6-e0a2-487f-a3e9-775f801ff4a4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.942098ms
Mar  3 13:33:23.998: INFO: Pod "pod-secrets-827e8fd6-e0a2-487f-a3e9-775f801ff4a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01026675s
STEP: Saw pod success
Mar  3 13:33:23.998: INFO: Pod "pod-secrets-827e8fd6-e0a2-487f-a3e9-775f801ff4a4" satisfied condition "success or failure"
Mar  3 13:33:24.002: INFO: Trying to get logs from node 10.0.2.119 pod pod-secrets-827e8fd6-e0a2-487f-a3e9-775f801ff4a4 container secret-volume-test: <nil>
STEP: delete the pod
Mar  3 13:33:24.037: INFO: Waiting for pod pod-secrets-827e8fd6-e0a2-487f-a3e9-775f801ff4a4 to disappear
Mar  3 13:33:24.044: INFO: Pod pod-secrets-827e8fd6-e0a2-487f-a3e9-775f801ff4a4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:33:24.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9013" for this suite.
Mar  3 13:33:30.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:33:30.300: INFO: namespace secrets-9013 deletion completed in 6.251526849s

• [SLOW TEST:8.381 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:33:30.301: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-7e523bbe-cf04-483a-9edd-29119643be31 in namespace container-probe-8504
Mar  3 13:33:32.374: INFO: Started pod liveness-7e523bbe-cf04-483a-9edd-29119643be31 in namespace container-probe-8504
STEP: checking the pod's current state and verifying that restartCount is present
Mar  3 13:33:32.378: INFO: Initial restart count of pod liveness-7e523bbe-cf04-483a-9edd-29119643be31 is 0
Mar  3 13:33:50.440: INFO: Restart count of pod container-probe-8504/liveness-7e523bbe-cf04-483a-9edd-29119643be31 is now 1 (18.061184229s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:33:50.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8504" for this suite.
Mar  3 13:33:56.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:33:56.745: INFO: namespace container-probe-8504 deletion completed in 6.275349324s

• [SLOW TEST:26.444 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:33:56.745: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:34:27.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4138" for this suite.
Mar  3 13:34:33.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:34:33.301: INFO: namespace namespaces-4138 deletion completed in 6.272840937s
STEP: Destroying namespace "nsdeletetest-8020" for this suite.
Mar  3 13:34:33.305: INFO: Namespace nsdeletetest-8020 was already deleted
STEP: Destroying namespace "nsdeletetest-6341" for this suite.
Mar  3 13:34:39.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:34:39.516: INFO: namespace nsdeletetest-6341 deletion completed in 6.21077147s

• [SLOW TEST:42.771 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:34:39.516: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Mar  3 13:34:41.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec pod-sharedvolume-aaec37bc-719a-4c7a-a372-da7bf575a999 -c busybox-main-container --namespace=emptydir-8957 -- cat /usr/share/volumeshare/shareddata.txt'
Mar  3 13:34:41.943: INFO: stderr: ""
Mar  3 13:34:41.943: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:34:41.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8957" for this suite.
Mar  3 13:34:47.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:34:48.172: INFO: namespace emptydir-8957 deletion completed in 6.223357984s

• [SLOW TEST:8.656 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:34:48.172: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Mar  3 13:34:48.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 create -f - --namespace=kubectl-6519'
Mar  3 13:34:48.563: INFO: stderr: ""
Mar  3 13:34:48.563: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  3 13:34:48.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6519'
Mar  3 13:34:48.655: INFO: stderr: ""
Mar  3 13:34:48.655: INFO: stdout: "update-demo-nautilus-5d4zl update-demo-nautilus-sjq5x "
Mar  3 13:34:48.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-5d4zl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6519'
Mar  3 13:34:48.742: INFO: stderr: ""
Mar  3 13:34:48.742: INFO: stdout: ""
Mar  3 13:34:48.742: INFO: update-demo-nautilus-5d4zl is created but not running
Mar  3 13:34:53.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6519'
Mar  3 13:34:53.831: INFO: stderr: ""
Mar  3 13:34:53.831: INFO: stdout: "update-demo-nautilus-5d4zl update-demo-nautilus-sjq5x "
Mar  3 13:34:53.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-5d4zl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6519'
Mar  3 13:34:53.924: INFO: stderr: ""
Mar  3 13:34:53.924: INFO: stdout: "true"
Mar  3 13:34:53.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-5d4zl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6519'
Mar  3 13:34:54.012: INFO: stderr: ""
Mar  3 13:34:54.012: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  3 13:34:54.012: INFO: validating pod update-demo-nautilus-5d4zl
Mar  3 13:34:54.019: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  3 13:34:54.019: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  3 13:34:54.019: INFO: update-demo-nautilus-5d4zl is verified up and running
Mar  3 13:34:54.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-sjq5x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6519'
Mar  3 13:34:54.105: INFO: stderr: ""
Mar  3 13:34:54.105: INFO: stdout: "true"
Mar  3 13:34:54.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-sjq5x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6519'
Mar  3 13:34:54.216: INFO: stderr: ""
Mar  3 13:34:54.216: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  3 13:34:54.216: INFO: validating pod update-demo-nautilus-sjq5x
Mar  3 13:34:54.225: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  3 13:34:54.225: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  3 13:34:54.225: INFO: update-demo-nautilus-sjq5x is verified up and running
STEP: scaling down the replication controller
Mar  3 13:34:54.227: INFO: scanned /root for discovery docs: <nil>
Mar  3 13:34:54.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-6519'
Mar  3 13:34:55.353: INFO: stderr: ""
Mar  3 13:34:55.353: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  3 13:34:55.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6519'
Mar  3 13:34:55.440: INFO: stderr: ""
Mar  3 13:34:55.440: INFO: stdout: "update-demo-nautilus-5d4zl update-demo-nautilus-sjq5x "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar  3 13:35:00.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6519'
Mar  3 13:35:00.519: INFO: stderr: ""
Mar  3 13:35:00.519: INFO: stdout: "update-demo-nautilus-5d4zl update-demo-nautilus-sjq5x "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar  3 13:35:05.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6519'
Mar  3 13:35:05.616: INFO: stderr: ""
Mar  3 13:35:05.616: INFO: stdout: "update-demo-nautilus-sjq5x "
Mar  3 13:35:05.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-sjq5x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6519'
Mar  3 13:35:05.700: INFO: stderr: ""
Mar  3 13:35:05.700: INFO: stdout: "true"
Mar  3 13:35:05.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-sjq5x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6519'
Mar  3 13:35:05.785: INFO: stderr: ""
Mar  3 13:35:05.785: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  3 13:35:05.785: INFO: validating pod update-demo-nautilus-sjq5x
Mar  3 13:35:05.791: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  3 13:35:05.791: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  3 13:35:05.791: INFO: update-demo-nautilus-sjq5x is verified up and running
STEP: scaling up the replication controller
Mar  3 13:35:05.792: INFO: scanned /root for discovery docs: <nil>
Mar  3 13:35:05.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-6519'
Mar  3 13:35:06.899: INFO: stderr: ""
Mar  3 13:35:06.899: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  3 13:35:06.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6519'
Mar  3 13:35:06.999: INFO: stderr: ""
Mar  3 13:35:06.999: INFO: stdout: "update-demo-nautilus-l7jc5 update-demo-nautilus-sjq5x "
Mar  3 13:35:07.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-l7jc5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6519'
Mar  3 13:35:07.089: INFO: stderr: ""
Mar  3 13:35:07.089: INFO: stdout: ""
Mar  3 13:35:07.089: INFO: update-demo-nautilus-l7jc5 is created but not running
Mar  3 13:35:12.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6519'
Mar  3 13:35:12.175: INFO: stderr: ""
Mar  3 13:35:12.175: INFO: stdout: "update-demo-nautilus-l7jc5 update-demo-nautilus-sjq5x "
Mar  3 13:35:12.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-l7jc5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6519'
Mar  3 13:35:12.256: INFO: stderr: ""
Mar  3 13:35:12.256: INFO: stdout: "true"
Mar  3 13:35:12.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-l7jc5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6519'
Mar  3 13:35:12.339: INFO: stderr: ""
Mar  3 13:35:12.339: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  3 13:35:12.339: INFO: validating pod update-demo-nautilus-l7jc5
Mar  3 13:35:12.347: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  3 13:35:12.347: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  3 13:35:12.347: INFO: update-demo-nautilus-l7jc5 is verified up and running
Mar  3 13:35:12.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-sjq5x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6519'
Mar  3 13:35:12.426: INFO: stderr: ""
Mar  3 13:35:12.426: INFO: stdout: "true"
Mar  3 13:35:12.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods update-demo-nautilus-sjq5x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6519'
Mar  3 13:35:12.510: INFO: stderr: ""
Mar  3 13:35:12.510: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  3 13:35:12.510: INFO: validating pod update-demo-nautilus-sjq5x
Mar  3 13:35:12.518: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  3 13:35:12.518: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  3 13:35:12.519: INFO: update-demo-nautilus-sjq5x is verified up and running
STEP: using delete to clean up resources
Mar  3 13:35:12.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 delete --grace-period=0 --force -f - --namespace=kubectl-6519'
Mar  3 13:35:12.613: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  3 13:35:12.613: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar  3 13:35:12.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6519'
Mar  3 13:35:12.706: INFO: stderr: "No resources found in kubectl-6519 namespace.\n"
Mar  3 13:35:12.706: INFO: stdout: ""
Mar  3 13:35:12.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods -l name=update-demo --namespace=kubectl-6519 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  3 13:35:12.796: INFO: stderr: ""
Mar  3 13:35:12.796: INFO: stdout: "update-demo-nautilus-l7jc5\nupdate-demo-nautilus-sjq5x\n"
Mar  3 13:35:13.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6519'
Mar  3 13:35:13.409: INFO: stderr: "No resources found in kubectl-6519 namespace.\n"
Mar  3 13:35:13.409: INFO: stdout: ""
Mar  3 13:35:13.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 get pods -l name=update-demo --namespace=kubectl-6519 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  3 13:35:13.508: INFO: stderr: ""
Mar  3 13:35:13.508: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:35:13.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6519" for this suite.
Mar  3 13:35:41.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:35:41.785: INFO: namespace kubectl-6519 deletion completed in 28.267866986s

• [SLOW TEST:53.613 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:35:41.785: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0303 13:35:42.912199      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  3 13:35:42.912: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:35:42.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2190" for this suite.
Mar  3 13:35:48.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:35:49.166: INFO: namespace gc-2190 deletion completed in 6.245220563s

• [SLOW TEST:7.381 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:35:49.166: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:36:00.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-763" for this suite.
Mar  3 13:36:06.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:36:06.550: INFO: namespace resourcequota-763 deletion completed in 6.233441417s

• [SLOW TEST:17.385 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:36:06.551: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Mar  3 13:36:06.629: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
Mar  3 13:36:10.365: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:36:24.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3711" for this suite.
Mar  3 13:36:30.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:36:31.153: INFO: namespace crd-publish-openapi-3711 deletion completed in 6.199744355s

• [SLOW TEST:24.602 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:36:31.154: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-1110
I0303 13:36:31.222471      23 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1110, replica count: 1
I0303 13:36:32.272853      23 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  3 13:36:32.386: INFO: Created: latency-svc-f9rtd
Mar  3 13:36:32.399: INFO: Got endpoints: latency-svc-f9rtd [26.928367ms]
Mar  3 13:36:32.418: INFO: Created: latency-svc-gjc9h
Mar  3 13:36:32.421: INFO: Created: latency-svc-cq26x
Mar  3 13:36:32.426: INFO: Got endpoints: latency-svc-gjc9h [26.292653ms]
Mar  3 13:36:32.429: INFO: Got endpoints: latency-svc-cq26x [28.256896ms]
Mar  3 13:36:32.435: INFO: Created: latency-svc-pvjj8
Mar  3 13:36:32.441: INFO: Created: latency-svc-rdfrz
Mar  3 13:36:32.445: INFO: Got endpoints: latency-svc-pvjj8 [44.50482ms]
Mar  3 13:36:32.445: INFO: Got endpoints: latency-svc-rdfrz [44.856933ms]
Mar  3 13:36:32.457: INFO: Created: latency-svc-tg9w6
Mar  3 13:36:32.467: INFO: Created: latency-svc-jmztq
Mar  3 13:36:32.471: INFO: Got endpoints: latency-svc-tg9w6 [70.099699ms]
Mar  3 13:36:32.472: INFO: Created: latency-svc-vb4rb
Mar  3 13:36:32.479: INFO: Got endpoints: latency-svc-jmztq [78.553088ms]
Mar  3 13:36:32.480: INFO: Created: latency-svc-lql6v
Mar  3 13:36:32.483: INFO: Got endpoints: latency-svc-vb4rb [83.199376ms]
Mar  3 13:36:32.489: INFO: Got endpoints: latency-svc-lql6v [88.474706ms]
Mar  3 13:36:32.491: INFO: Created: latency-svc-shqvt
Mar  3 13:36:32.499: INFO: Created: latency-svc-56cwm
Mar  3 13:36:32.499: INFO: Got endpoints: latency-svc-shqvt [98.780036ms]
Mar  3 13:36:32.506: INFO: Created: latency-svc-jrbl4
Mar  3 13:36:32.513: INFO: Got endpoints: latency-svc-56cwm [112.067567ms]
Mar  3 13:36:32.515: INFO: Created: latency-svc-89vft
Mar  3 13:36:32.517: INFO: Got endpoints: latency-svc-jrbl4 [117.456384ms]
Mar  3 13:36:32.523: INFO: Got endpoints: latency-svc-89vft [122.289556ms]
Mar  3 13:36:32.526: INFO: Created: latency-svc-srgn7
Mar  3 13:36:32.538: INFO: Created: latency-svc-v9dq2
Mar  3 13:36:32.542: INFO: Got endpoints: latency-svc-srgn7 [141.275085ms]
Mar  3 13:36:32.547: INFO: Created: latency-svc-nszmw
Mar  3 13:36:32.556: INFO: Got endpoints: latency-svc-v9dq2 [155.413403ms]
Mar  3 13:36:32.558: INFO: Got endpoints: latency-svc-nszmw [157.751367ms]
Mar  3 13:36:32.560: INFO: Created: latency-svc-xrfcr
Mar  3 13:36:32.573: INFO: Got endpoints: latency-svc-xrfcr [146.700276ms]
Mar  3 13:36:32.573: INFO: Created: latency-svc-j45vx
Mar  3 13:36:32.582: INFO: Created: latency-svc-x5cm2
Mar  3 13:36:32.587: INFO: Created: latency-svc-ts77p
Mar  3 13:36:32.587: INFO: Got endpoints: latency-svc-j45vx [158.608036ms]
Mar  3 13:36:32.593: INFO: Got endpoints: latency-svc-x5cm2 [148.374974ms]
Mar  3 13:36:32.597: INFO: Got endpoints: latency-svc-ts77p [151.968022ms]
Mar  3 13:36:32.597: INFO: Created: latency-svc-km2b7
Mar  3 13:36:32.606: INFO: Got endpoints: latency-svc-km2b7 [134.897408ms]
Mar  3 13:36:32.608: INFO: Created: latency-svc-f2pkb
Mar  3 13:36:32.614: INFO: Created: latency-svc-qhtmp
Mar  3 13:36:32.614: INFO: Got endpoints: latency-svc-f2pkb [135.531864ms]
Mar  3 13:36:32.626: INFO: Got endpoints: latency-svc-qhtmp [142.278743ms]
Mar  3 13:36:32.659: INFO: Created: latency-svc-7cgdd
Mar  3 13:36:32.669: INFO: Got endpoints: latency-svc-7cgdd [179.584439ms]
Mar  3 13:36:32.678: INFO: Created: latency-svc-pwfbb
Mar  3 13:36:32.679: INFO: Created: latency-svc-7gqhr
Mar  3 13:36:32.687: INFO: Created: latency-svc-5458w
Mar  3 13:36:32.699: INFO: Created: latency-svc-d5qzm
Mar  3 13:36:32.699: INFO: Got endpoints: latency-svc-7gqhr [186.106569ms]
Mar  3 13:36:32.699: INFO: Got endpoints: latency-svc-pwfbb [200.06626ms]
Mar  3 13:36:32.700: INFO: Created: latency-svc-ksdhr
Mar  3 13:36:32.701: INFO: Got endpoints: latency-svc-5458w [183.028529ms]
Mar  3 13:36:32.709: INFO: Got endpoints: latency-svc-ksdhr [166.934581ms]
Mar  3 13:36:32.709: INFO: Got endpoints: latency-svc-d5qzm [186.392325ms]
Mar  3 13:36:32.712: INFO: Created: latency-svc-fvqhh
Mar  3 13:36:32.724: INFO: Got endpoints: latency-svc-fvqhh [167.597215ms]
Mar  3 13:36:32.724: INFO: Created: latency-svc-chmg4
Mar  3 13:36:32.730: INFO: Got endpoints: latency-svc-chmg4 [172.014579ms]
Mar  3 13:36:32.730: INFO: Created: latency-svc-kp64x
Mar  3 13:36:32.737: INFO: Created: latency-svc-995zb
Mar  3 13:36:32.738: INFO: Got endpoints: latency-svc-kp64x [165.053844ms]
Mar  3 13:36:32.743: INFO: Created: latency-svc-w29hl
Mar  3 13:36:32.749: INFO: Got endpoints: latency-svc-995zb [161.260841ms]
Mar  3 13:36:32.753: INFO: Created: latency-svc-sstmx
Mar  3 13:36:32.756: INFO: Got endpoints: latency-svc-w29hl [162.981051ms]
Mar  3 13:36:32.758: INFO: Got endpoints: latency-svc-sstmx [160.936515ms]
Mar  3 13:36:32.762: INFO: Created: latency-svc-5n8w8
Mar  3 13:36:32.773: INFO: Got endpoints: latency-svc-5n8w8 [167.479448ms]
Mar  3 13:36:32.775: INFO: Created: latency-svc-lkf62
Mar  3 13:36:32.783: INFO: Created: latency-svc-qpgbd
Mar  3 13:36:32.791: INFO: Created: latency-svc-sdcp8
Mar  3 13:36:32.791: INFO: Got endpoints: latency-svc-lkf62 [176.219188ms]
Mar  3 13:36:32.797: INFO: Got endpoints: latency-svc-qpgbd [171.059957ms]
Mar  3 13:36:32.803: INFO: Created: latency-svc-8k5lg
Mar  3 13:36:32.815: INFO: Created: latency-svc-k7gz7
Mar  3 13:36:32.819: INFO: Created: latency-svc-5czsr
Mar  3 13:36:32.827: INFO: Created: latency-svc-62bnz
Mar  3 13:36:32.834: INFO: Created: latency-svc-krqgw
Mar  3 13:36:32.843: INFO: Created: latency-svc-84ljt
Mar  3 13:36:32.844: INFO: Got endpoints: latency-svc-sdcp8 [175.058273ms]
Mar  3 13:36:32.851: INFO: Created: latency-svc-qbsr7
Mar  3 13:36:32.860: INFO: Created: latency-svc-5ns2c
Mar  3 13:36:32.868: INFO: Created: latency-svc-5hm96
Mar  3 13:36:32.875: INFO: Created: latency-svc-h9p4b
Mar  3 13:36:32.888: INFO: Created: latency-svc-rdhmh
Mar  3 13:36:32.892: INFO: Created: latency-svc-vs95w
Mar  3 13:36:32.894: INFO: Got endpoints: latency-svc-8k5lg [195.300163ms]
Mar  3 13:36:32.899: INFO: Created: latency-svc-rq4p4
Mar  3 13:36:32.905: INFO: Created: latency-svc-kwc7v
Mar  3 13:36:32.914: INFO: Created: latency-svc-g7lj6
Mar  3 13:36:32.920: INFO: Created: latency-svc-d8dsq
Mar  3 13:36:32.945: INFO: Got endpoints: latency-svc-k7gz7 [245.892214ms]
Mar  3 13:36:32.962: INFO: Created: latency-svc-b8bkz
Mar  3 13:36:32.995: INFO: Got endpoints: latency-svc-5czsr [294.782869ms]
Mar  3 13:36:33.017: INFO: Created: latency-svc-jpznc
Mar  3 13:36:33.045: INFO: Got endpoints: latency-svc-62bnz [336.285255ms]
Mar  3 13:36:33.058: INFO: Created: latency-svc-tr97s
Mar  3 13:36:33.093: INFO: Got endpoints: latency-svc-krqgw [383.531665ms]
Mar  3 13:36:33.110: INFO: Created: latency-svc-njcsz
Mar  3 13:36:33.142: INFO: Got endpoints: latency-svc-84ljt [418.25896ms]
Mar  3 13:36:33.198: INFO: Created: latency-svc-kd7mt
Mar  3 13:36:33.201: INFO: Got endpoints: latency-svc-qbsr7 [471.218234ms]
Mar  3 13:36:33.219: INFO: Created: latency-svc-cfm25
Mar  3 13:36:33.244: INFO: Got endpoints: latency-svc-5ns2c [506.098771ms]
Mar  3 13:36:33.260: INFO: Created: latency-svc-6gtgt
Mar  3 13:36:33.293: INFO: Got endpoints: latency-svc-5hm96 [543.978781ms]
Mar  3 13:36:33.317: INFO: Created: latency-svc-vpsph
Mar  3 13:36:33.343: INFO: Got endpoints: latency-svc-h9p4b [587.100991ms]
Mar  3 13:36:33.360: INFO: Created: latency-svc-d8cwf
Mar  3 13:36:33.395: INFO: Got endpoints: latency-svc-rdhmh [636.586147ms]
Mar  3 13:36:33.407: INFO: Created: latency-svc-md6pp
Mar  3 13:36:33.442: INFO: Got endpoints: latency-svc-vs95w [668.864621ms]
Mar  3 13:36:33.457: INFO: Created: latency-svc-82fx6
Mar  3 13:36:33.494: INFO: Got endpoints: latency-svc-rq4p4 [703.689877ms]
Mar  3 13:36:33.509: INFO: Created: latency-svc-zpkrv
Mar  3 13:36:33.547: INFO: Got endpoints: latency-svc-kwc7v [749.980803ms]
Mar  3 13:36:33.562: INFO: Created: latency-svc-9nhh7
Mar  3 13:36:33.594: INFO: Got endpoints: latency-svc-g7lj6 [749.83008ms]
Mar  3 13:36:33.612: INFO: Created: latency-svc-b9h7l
Mar  3 13:36:33.643: INFO: Got endpoints: latency-svc-d8dsq [748.909897ms]
Mar  3 13:36:33.662: INFO: Created: latency-svc-zw5pj
Mar  3 13:36:33.693: INFO: Got endpoints: latency-svc-b8bkz [748.293891ms]
Mar  3 13:36:33.732: INFO: Created: latency-svc-plx9z
Mar  3 13:36:33.744: INFO: Got endpoints: latency-svc-jpznc [749.106979ms]
Mar  3 13:36:33.761: INFO: Created: latency-svc-vkqkz
Mar  3 13:36:33.795: INFO: Got endpoints: latency-svc-tr97s [750.050354ms]
Mar  3 13:36:33.812: INFO: Created: latency-svc-6pwns
Mar  3 13:36:33.846: INFO: Got endpoints: latency-svc-njcsz [753.109824ms]
Mar  3 13:36:33.862: INFO: Created: latency-svc-wr64s
Mar  3 13:36:33.895: INFO: Got endpoints: latency-svc-kd7mt [752.75768ms]
Mar  3 13:36:33.912: INFO: Created: latency-svc-s2w6k
Mar  3 13:36:33.947: INFO: Got endpoints: latency-svc-cfm25 [746.377695ms]
Mar  3 13:36:33.960: INFO: Created: latency-svc-mgkd2
Mar  3 13:36:33.993: INFO: Got endpoints: latency-svc-6gtgt [748.799489ms]
Mar  3 13:36:34.012: INFO: Created: latency-svc-9zh68
Mar  3 13:36:34.042: INFO: Got endpoints: latency-svc-vpsph [749.706551ms]
Mar  3 13:36:34.055: INFO: Created: latency-svc-j9d6d
Mar  3 13:36:34.092: INFO: Got endpoints: latency-svc-d8cwf [748.534443ms]
Mar  3 13:36:34.104: INFO: Created: latency-svc-6njgd
Mar  3 13:36:34.145: INFO: Got endpoints: latency-svc-md6pp [750.463593ms]
Mar  3 13:36:34.163: INFO: Created: latency-svc-nz9pm
Mar  3 13:36:34.193: INFO: Got endpoints: latency-svc-82fx6 [751.404214ms]
Mar  3 13:36:34.206: INFO: Created: latency-svc-kgj6w
Mar  3 13:36:34.242: INFO: Got endpoints: latency-svc-zpkrv [747.879866ms]
Mar  3 13:36:34.267: INFO: Created: latency-svc-66kc7
Mar  3 13:36:34.299: INFO: Got endpoints: latency-svc-9nhh7 [751.7247ms]
Mar  3 13:36:34.314: INFO: Created: latency-svc-ntbxw
Mar  3 13:36:34.342: INFO: Got endpoints: latency-svc-b9h7l [747.992747ms]
Mar  3 13:36:34.364: INFO: Created: latency-svc-4k4bs
Mar  3 13:36:34.393: INFO: Got endpoints: latency-svc-zw5pj [749.905466ms]
Mar  3 13:36:34.408: INFO: Created: latency-svc-4v28k
Mar  3 13:36:34.442: INFO: Got endpoints: latency-svc-plx9z [748.532234ms]
Mar  3 13:36:34.455: INFO: Created: latency-svc-4svn4
Mar  3 13:36:34.496: INFO: Got endpoints: latency-svc-vkqkz [751.073373ms]
Mar  3 13:36:34.524: INFO: Created: latency-svc-2h4sc
Mar  3 13:36:34.542: INFO: Got endpoints: latency-svc-6pwns [746.895111ms]
Mar  3 13:36:34.563: INFO: Created: latency-svc-slt7l
Mar  3 13:36:34.597: INFO: Got endpoints: latency-svc-wr64s [750.907676ms]
Mar  3 13:36:34.614: INFO: Created: latency-svc-9jbp7
Mar  3 13:36:34.642: INFO: Got endpoints: latency-svc-s2w6k [747.123704ms]
Mar  3 13:36:34.657: INFO: Created: latency-svc-zkhlq
Mar  3 13:36:34.700: INFO: Got endpoints: latency-svc-mgkd2 [753.148354ms]
Mar  3 13:36:34.716: INFO: Created: latency-svc-vwnbz
Mar  3 13:36:34.742: INFO: Got endpoints: latency-svc-9zh68 [748.909519ms]
Mar  3 13:36:34.787: INFO: Created: latency-svc-ftkrn
Mar  3 13:36:34.808: INFO: Got endpoints: latency-svc-j9d6d [765.510688ms]
Mar  3 13:36:34.829: INFO: Created: latency-svc-8lfqf
Mar  3 13:36:34.847: INFO: Got endpoints: latency-svc-6njgd [755.121613ms]
Mar  3 13:36:34.862: INFO: Created: latency-svc-zdkrp
Mar  3 13:36:34.893: INFO: Got endpoints: latency-svc-nz9pm [747.784326ms]
Mar  3 13:36:34.915: INFO: Created: latency-svc-kqx7t
Mar  3 13:36:34.944: INFO: Got endpoints: latency-svc-kgj6w [750.245757ms]
Mar  3 13:36:34.959: INFO: Created: latency-svc-6xf9x
Mar  3 13:36:34.992: INFO: Got endpoints: latency-svc-66kc7 [749.864534ms]
Mar  3 13:36:35.008: INFO: Created: latency-svc-rmrj9
Mar  3 13:36:35.053: INFO: Got endpoints: latency-svc-ntbxw [754.10513ms]
Mar  3 13:36:35.068: INFO: Created: latency-svc-wlqw4
Mar  3 13:36:35.095: INFO: Got endpoints: latency-svc-4k4bs [753.02687ms]
Mar  3 13:36:35.140: INFO: Created: latency-svc-qgkwn
Mar  3 13:36:35.144: INFO: Got endpoints: latency-svc-4v28k [750.798263ms]
Mar  3 13:36:35.164: INFO: Created: latency-svc-csvjp
Mar  3 13:36:35.195: INFO: Got endpoints: latency-svc-4svn4 [753.103844ms]
Mar  3 13:36:35.209: INFO: Created: latency-svc-vc4sf
Mar  3 13:36:35.251: INFO: Got endpoints: latency-svc-2h4sc [755.914419ms]
Mar  3 13:36:35.287: INFO: Created: latency-svc-bsr5k
Mar  3 13:36:35.303: INFO: Got endpoints: latency-svc-slt7l [760.496959ms]
Mar  3 13:36:35.346: INFO: Got endpoints: latency-svc-9jbp7 [748.512097ms]
Mar  3 13:36:35.362: INFO: Created: latency-svc-tvdb4
Mar  3 13:36:35.366: INFO: Created: latency-svc-rw2l2
Mar  3 13:36:35.396: INFO: Got endpoints: latency-svc-zkhlq [753.94368ms]
Mar  3 13:36:35.408: INFO: Created: latency-svc-8qppb
Mar  3 13:36:35.445: INFO: Got endpoints: latency-svc-vwnbz [744.382648ms]
Mar  3 13:36:35.459: INFO: Created: latency-svc-r7x6l
Mar  3 13:36:35.497: INFO: Got endpoints: latency-svc-ftkrn [754.967454ms]
Mar  3 13:36:35.511: INFO: Created: latency-svc-dsz2n
Mar  3 13:36:35.547: INFO: Got endpoints: latency-svc-8lfqf [739.506892ms]
Mar  3 13:36:35.559: INFO: Created: latency-svc-p84rp
Mar  3 13:36:35.594: INFO: Got endpoints: latency-svc-zdkrp [746.730871ms]
Mar  3 13:36:35.641: INFO: Got endpoints: latency-svc-kqx7t [748.228919ms]
Mar  3 13:36:35.657: INFO: Created: latency-svc-vxvxs
Mar  3 13:36:35.668: INFO: Created: latency-svc-4r4r6
Mar  3 13:36:35.694: INFO: Got endpoints: latency-svc-6xf9x [749.956146ms]
Mar  3 13:36:35.705: INFO: Created: latency-svc-rcjsq
Mar  3 13:36:35.745: INFO: Got endpoints: latency-svc-rmrj9 [752.325639ms]
Mar  3 13:36:35.758: INFO: Created: latency-svc-jdmv4
Mar  3 13:36:35.796: INFO: Got endpoints: latency-svc-wlqw4 [742.907124ms]
Mar  3 13:36:35.813: INFO: Created: latency-svc-ccc6z
Mar  3 13:36:35.850: INFO: Got endpoints: latency-svc-qgkwn [755.165917ms]
Mar  3 13:36:35.895: INFO: Got endpoints: latency-svc-csvjp [751.412827ms]
Mar  3 13:36:35.936: INFO: Created: latency-svc-mz7l4
Mar  3 13:36:35.936: INFO: Created: latency-svc-4bxsg
Mar  3 13:36:35.949: INFO: Got endpoints: latency-svc-vc4sf [753.607633ms]
Mar  3 13:36:35.962: INFO: Created: latency-svc-jgt79
Mar  3 13:36:35.993: INFO: Got endpoints: latency-svc-bsr5k [741.031473ms]
Mar  3 13:36:36.006: INFO: Created: latency-svc-v284b
Mar  3 13:36:36.044: INFO: Got endpoints: latency-svc-tvdb4 [741.023788ms]
Mar  3 13:36:36.059: INFO: Created: latency-svc-wtkh5
Mar  3 13:36:36.096: INFO: Got endpoints: latency-svc-rw2l2 [750.025022ms]
Mar  3 13:36:36.112: INFO: Created: latency-svc-nvvbg
Mar  3 13:36:36.146: INFO: Got endpoints: latency-svc-8qppb [750.070984ms]
Mar  3 13:36:36.161: INFO: Created: latency-svc-4kqp9
Mar  3 13:36:36.249: INFO: Got endpoints: latency-svc-dsz2n [751.869331ms]
Mar  3 13:36:36.249: INFO: Got endpoints: latency-svc-r7x6l [803.711144ms]
Mar  3 13:36:36.349: INFO: Got endpoints: latency-svc-vxvxs [754.795108ms]
Mar  3 13:36:36.349: INFO: Got endpoints: latency-svc-p84rp [801.448633ms]
Mar  3 13:36:36.349: INFO: Created: latency-svc-2hrqt
Mar  3 13:36:36.445: INFO: Created: latency-svc-bw7lv
Mar  3 13:36:36.447: INFO: Got endpoints: latency-svc-rcjsq [753.361321ms]
Mar  3 13:36:36.447: INFO: Got endpoints: latency-svc-4r4r6 [805.76349ms]
Mar  3 13:36:36.456: INFO: Created: latency-svc-cq99r
Mar  3 13:36:36.539: INFO: Created: latency-svc-4mnsn
Mar  3 13:36:36.549: INFO: Got endpoints: latency-svc-4bxsg [698.572937ms]
Mar  3 13:36:36.549: INFO: Got endpoints: latency-svc-jdmv4 [804.379536ms]
Mar  3 13:36:36.550: INFO: Created: latency-svc-44qkk
Mar  3 13:36:36.639: INFO: Created: latency-svc-c6tvd
Mar  3 13:36:36.644: INFO: Created: latency-svc-rg92j
Mar  3 13:36:36.648: INFO: Got endpoints: latency-svc-jgt79 [699.222392ms]
Mar  3 13:36:36.648: INFO: Got endpoints: latency-svc-ccc6z [852.549202ms]
Mar  3 13:36:36.656: INFO: Created: latency-svc-x7qkk
Mar  3 13:36:36.663: INFO: Created: latency-svc-dx6q7
Mar  3 13:36:36.677: INFO: Created: latency-svc-tpgjk
Mar  3 13:36:36.692: INFO: Got endpoints: latency-svc-mz7l4 [796.39082ms]
Mar  3 13:36:36.704: INFO: Created: latency-svc-97qfw
Mar  3 13:36:36.750: INFO: Got endpoints: latency-svc-v284b [756.933706ms]
Mar  3 13:36:36.762: INFO: Created: latency-svc-n5c4p
Mar  3 13:36:36.792: INFO: Got endpoints: latency-svc-wtkh5 [748.264257ms]
Mar  3 13:36:36.811: INFO: Created: latency-svc-vl8g7
Mar  3 13:36:36.847: INFO: Got endpoints: latency-svc-4kqp9 [700.749837ms]
Mar  3 13:36:36.863: INFO: Created: latency-svc-g7jzp
Mar  3 13:36:36.893: INFO: Got endpoints: latency-svc-nvvbg [797.83736ms]
Mar  3 13:36:36.917: INFO: Created: latency-svc-4fggj
Mar  3 13:36:36.946: INFO: Got endpoints: latency-svc-2hrqt [697.32699ms]
Mar  3 13:36:36.964: INFO: Created: latency-svc-rgbd7
Mar  3 13:36:36.996: INFO: Got endpoints: latency-svc-bw7lv [747.014924ms]
Mar  3 13:36:37.008: INFO: Created: latency-svc-ghshs
Mar  3 13:36:37.051: INFO: Got endpoints: latency-svc-cq99r [701.876385ms]
Mar  3 13:36:37.063: INFO: Created: latency-svc-smh9c
Mar  3 13:36:37.092: INFO: Got endpoints: latency-svc-4mnsn [743.2475ms]
Mar  3 13:36:37.107: INFO: Created: latency-svc-klcw8
Mar  3 13:36:37.146: INFO: Got endpoints: latency-svc-44qkk [698.412792ms]
Mar  3 13:36:37.162: INFO: Created: latency-svc-kjbdk
Mar  3 13:36:37.195: INFO: Got endpoints: latency-svc-c6tvd [748.19047ms]
Mar  3 13:36:37.212: INFO: Created: latency-svc-cvzm6
Mar  3 13:36:37.251: INFO: Got endpoints: latency-svc-rg92j [702.236872ms]
Mar  3 13:36:37.303: INFO: Got endpoints: latency-svc-x7qkk [754.450702ms]
Mar  3 13:36:37.329: INFO: Created: latency-svc-sjqt6
Mar  3 13:36:37.368: INFO: Created: latency-svc-fm2nt
Mar  3 13:36:37.368: INFO: Got endpoints: latency-svc-dx6q7 [720.120645ms]
Mar  3 13:36:37.392: INFO: Created: latency-svc-p8ltp
Mar  3 13:36:37.393: INFO: Got endpoints: latency-svc-tpgjk [745.191524ms]
Mar  3 13:36:37.411: INFO: Created: latency-svc-zhvzb
Mar  3 13:36:37.447: INFO: Got endpoints: latency-svc-97qfw [755.150509ms]
Mar  3 13:36:37.463: INFO: Created: latency-svc-rhjn2
Mar  3 13:36:37.493: INFO: Got endpoints: latency-svc-n5c4p [743.369945ms]
Mar  3 13:36:37.507: INFO: Created: latency-svc-kfb6g
Mar  3 13:36:37.542: INFO: Got endpoints: latency-svc-vl8g7 [750.026675ms]
Mar  3 13:36:37.554: INFO: Created: latency-svc-q4rfq
Mar  3 13:36:37.598: INFO: Got endpoints: latency-svc-g7jzp [751.254286ms]
Mar  3 13:36:37.612: INFO: Created: latency-svc-fnmhf
Mar  3 13:36:37.643: INFO: Got endpoints: latency-svc-4fggj [749.469779ms]
Mar  3 13:36:37.656: INFO: Created: latency-svc-j58xv
Mar  3 13:36:37.697: INFO: Got endpoints: latency-svc-rgbd7 [751.071441ms]
Mar  3 13:36:37.711: INFO: Created: latency-svc-8lv7q
Mar  3 13:36:37.745: INFO: Got endpoints: latency-svc-ghshs [748.878117ms]
Mar  3 13:36:37.760: INFO: Created: latency-svc-g5j4d
Mar  3 13:36:37.792: INFO: Got endpoints: latency-svc-smh9c [741.5823ms]
Mar  3 13:36:37.806: INFO: Created: latency-svc-zrf4p
Mar  3 13:36:37.842: INFO: Got endpoints: latency-svc-klcw8 [749.874734ms]
Mar  3 13:36:37.857: INFO: Created: latency-svc-n7q68
Mar  3 13:36:37.898: INFO: Got endpoints: latency-svc-kjbdk [752.269079ms]
Mar  3 13:36:37.917: INFO: Created: latency-svc-dpttf
Mar  3 13:36:37.954: INFO: Got endpoints: latency-svc-cvzm6 [758.763668ms]
Mar  3 13:36:37.991: INFO: Created: latency-svc-t7j6l
Mar  3 13:36:37.995: INFO: Got endpoints: latency-svc-sjqt6 [744.512976ms]
Mar  3 13:36:38.014: INFO: Created: latency-svc-lnzlv
Mar  3 13:36:38.045: INFO: Got endpoints: latency-svc-fm2nt [741.990118ms]
Mar  3 13:36:38.060: INFO: Created: latency-svc-8jgnx
Mar  3 13:36:38.093: INFO: Got endpoints: latency-svc-p8ltp [725.235821ms]
Mar  3 13:36:38.112: INFO: Created: latency-svc-fsb4q
Mar  3 13:36:38.143: INFO: Got endpoints: latency-svc-zhvzb [749.651321ms]
Mar  3 13:36:38.155: INFO: Created: latency-svc-x75xh
Mar  3 13:36:38.199: INFO: Got endpoints: latency-svc-rhjn2 [752.373655ms]
Mar  3 13:36:38.218: INFO: Created: latency-svc-gktxr
Mar  3 13:36:38.244: INFO: Got endpoints: latency-svc-kfb6g [751.263662ms]
Mar  3 13:36:38.256: INFO: Created: latency-svc-wbbht
Mar  3 13:36:38.294: INFO: Got endpoints: latency-svc-q4rfq [751.039248ms]
Mar  3 13:36:38.306: INFO: Created: latency-svc-9ks8r
Mar  3 13:36:38.342: INFO: Got endpoints: latency-svc-fnmhf [743.693287ms]
Mar  3 13:36:38.360: INFO: Created: latency-svc-zb7sd
Mar  3 13:36:38.396: INFO: Got endpoints: latency-svc-j58xv [752.822781ms]
Mar  3 13:36:38.412: INFO: Created: latency-svc-mjpbz
Mar  3 13:36:38.449: INFO: Got endpoints: latency-svc-8lv7q [751.597497ms]
Mar  3 13:36:38.461: INFO: Created: latency-svc-7sqs2
Mar  3 13:36:38.492: INFO: Got endpoints: latency-svc-g5j4d [747.740718ms]
Mar  3 13:36:38.522: INFO: Created: latency-svc-vrd86
Mar  3 13:36:38.544: INFO: Got endpoints: latency-svc-zrf4p [751.805146ms]
Mar  3 13:36:38.556: INFO: Created: latency-svc-dfckq
Mar  3 13:36:38.593: INFO: Got endpoints: latency-svc-n7q68 [750.406306ms]
Mar  3 13:36:38.613: INFO: Created: latency-svc-xfjhh
Mar  3 13:36:38.642: INFO: Got endpoints: latency-svc-dpttf [743.704084ms]
Mar  3 13:36:38.656: INFO: Created: latency-svc-xc45h
Mar  3 13:36:38.717: INFO: Got endpoints: latency-svc-t7j6l [763.367394ms]
Mar  3 13:36:38.734: INFO: Created: latency-svc-4n2z2
Mar  3 13:36:38.750: INFO: Got endpoints: latency-svc-lnzlv [754.126729ms]
Mar  3 13:36:38.762: INFO: Created: latency-svc-65922
Mar  3 13:36:38.806: INFO: Got endpoints: latency-svc-8jgnx [760.669951ms]
Mar  3 13:36:38.822: INFO: Created: latency-svc-q587m
Mar  3 13:36:38.844: INFO: Got endpoints: latency-svc-fsb4q [750.603034ms]
Mar  3 13:36:38.860: INFO: Created: latency-svc-c2d8s
Mar  3 13:36:38.892: INFO: Got endpoints: latency-svc-x75xh [748.663037ms]
Mar  3 13:36:38.904: INFO: Created: latency-svc-nmgx7
Mar  3 13:36:38.946: INFO: Got endpoints: latency-svc-gktxr [746.286964ms]
Mar  3 13:36:38.965: INFO: Created: latency-svc-7xtp7
Mar  3 13:36:38.997: INFO: Got endpoints: latency-svc-wbbht [752.456464ms]
Mar  3 13:36:39.046: INFO: Created: latency-svc-lthrf
Mar  3 13:36:39.046: INFO: Got endpoints: latency-svc-9ks8r [752.897884ms]
Mar  3 13:36:39.061: INFO: Created: latency-svc-kknsh
Mar  3 13:36:39.095: INFO: Got endpoints: latency-svc-zb7sd [753.297967ms]
Mar  3 13:36:39.112: INFO: Created: latency-svc-lwlpb
Mar  3 13:36:39.142: INFO: Got endpoints: latency-svc-mjpbz [746.366945ms]
Mar  3 13:36:39.156: INFO: Created: latency-svc-fggx5
Mar  3 13:36:39.192: INFO: Got endpoints: latency-svc-7sqs2 [743.468911ms]
Mar  3 13:36:39.204: INFO: Created: latency-svc-dcwrl
Mar  3 13:36:39.242: INFO: Got endpoints: latency-svc-vrd86 [749.808853ms]
Mar  3 13:36:39.257: INFO: Created: latency-svc-ms8d2
Mar  3 13:36:39.292: INFO: Got endpoints: latency-svc-dfckq [747.879156ms]
Mar  3 13:36:39.309: INFO: Created: latency-svc-5zpt8
Mar  3 13:36:39.344: INFO: Got endpoints: latency-svc-xfjhh [751.13915ms]
Mar  3 13:36:39.360: INFO: Created: latency-svc-xz7t8
Mar  3 13:36:39.394: INFO: Got endpoints: latency-svc-xc45h [751.945122ms]
Mar  3 13:36:39.408: INFO: Created: latency-svc-cgn72
Mar  3 13:36:39.451: INFO: Got endpoints: latency-svc-4n2z2 [733.045105ms]
Mar  3 13:36:39.463: INFO: Created: latency-svc-lpk6s
Mar  3 13:36:39.492: INFO: Got endpoints: latency-svc-65922 [742.782495ms]
Mar  3 13:36:39.504: INFO: Created: latency-svc-9m2dj
Mar  3 13:36:39.542: INFO: Got endpoints: latency-svc-q587m [736.050953ms]
Mar  3 13:36:39.579: INFO: Created: latency-svc-r7rzm
Mar  3 13:36:39.592: INFO: Got endpoints: latency-svc-c2d8s [748.344893ms]
Mar  3 13:36:39.604: INFO: Created: latency-svc-985nc
Mar  3 13:36:39.642: INFO: Got endpoints: latency-svc-nmgx7 [750.185037ms]
Mar  3 13:36:39.656: INFO: Created: latency-svc-wckgq
Mar  3 13:36:39.695: INFO: Got endpoints: latency-svc-7xtp7 [749.116376ms]
Mar  3 13:36:39.711: INFO: Created: latency-svc-kjbbn
Mar  3 13:36:39.743: INFO: Got endpoints: latency-svc-lthrf [745.911411ms]
Mar  3 13:36:39.758: INFO: Created: latency-svc-wt2x5
Mar  3 13:36:39.793: INFO: Got endpoints: latency-svc-kknsh [746.2265ms]
Mar  3 13:36:39.814: INFO: Created: latency-svc-59hjh
Mar  3 13:36:39.842: INFO: Got endpoints: latency-svc-lwlpb [746.83643ms]
Mar  3 13:36:39.853: INFO: Created: latency-svc-q9d75
Mar  3 13:36:39.898: INFO: Got endpoints: latency-svc-fggx5 [755.793497ms]
Mar  3 13:36:39.911: INFO: Created: latency-svc-hb9xn
Mar  3 13:36:39.943: INFO: Got endpoints: latency-svc-dcwrl [751.005857ms]
Mar  3 13:36:39.955: INFO: Created: latency-svc-nrqgb
Mar  3 13:36:39.997: INFO: Got endpoints: latency-svc-ms8d2 [755.080434ms]
Mar  3 13:36:40.014: INFO: Created: latency-svc-b8wpj
Mar  3 13:36:40.042: INFO: Got endpoints: latency-svc-5zpt8 [750.375714ms]
Mar  3 13:36:40.057: INFO: Created: latency-svc-dr6vt
Mar  3 13:36:40.092: INFO: Got endpoints: latency-svc-xz7t8 [748.190951ms]
Mar  3 13:36:40.114: INFO: Created: latency-svc-5stmj
Mar  3 13:36:40.142: INFO: Got endpoints: latency-svc-cgn72 [747.980694ms]
Mar  3 13:36:40.154: INFO: Created: latency-svc-z2mh2
Mar  3 13:36:40.199: INFO: Got endpoints: latency-svc-lpk6s [748.283286ms]
Mar  3 13:36:40.215: INFO: Created: latency-svc-gbc8k
Mar  3 13:36:40.244: INFO: Got endpoints: latency-svc-9m2dj [751.943428ms]
Mar  3 13:36:40.295: INFO: Got endpoints: latency-svc-r7rzm [752.34469ms]
Mar  3 13:36:40.347: INFO: Got endpoints: latency-svc-985nc [754.581043ms]
Mar  3 13:36:40.392: INFO: Got endpoints: latency-svc-wckgq [750.11536ms]
Mar  3 13:36:40.442: INFO: Got endpoints: latency-svc-kjbbn [747.252932ms]
Mar  3 13:36:40.495: INFO: Got endpoints: latency-svc-wt2x5 [751.873253ms]
Mar  3 13:36:40.545: INFO: Got endpoints: latency-svc-59hjh [751.966259ms]
Mar  3 13:36:40.593: INFO: Got endpoints: latency-svc-q9d75 [750.69088ms]
Mar  3 13:36:40.648: INFO: Got endpoints: latency-svc-hb9xn [749.484512ms]
Mar  3 13:36:40.692: INFO: Got endpoints: latency-svc-nrqgb [748.851844ms]
Mar  3 13:36:40.745: INFO: Got endpoints: latency-svc-b8wpj [747.958756ms]
Mar  3 13:36:40.792: INFO: Got endpoints: latency-svc-dr6vt [749.635707ms]
Mar  3 13:36:40.846: INFO: Got endpoints: latency-svc-5stmj [753.713477ms]
Mar  3 13:36:40.892: INFO: Got endpoints: latency-svc-z2mh2 [750.181567ms]
Mar  3 13:36:40.949: INFO: Got endpoints: latency-svc-gbc8k [750.00894ms]
Mar  3 13:36:40.949: INFO: Latencies: [26.292653ms 28.256896ms 44.50482ms 44.856933ms 70.099699ms 78.553088ms 83.199376ms 88.474706ms 98.780036ms 112.067567ms 117.456384ms 122.289556ms 134.897408ms 135.531864ms 141.275085ms 142.278743ms 146.700276ms 148.374974ms 151.968022ms 155.413403ms 157.751367ms 158.608036ms 160.936515ms 161.260841ms 162.981051ms 165.053844ms 166.934581ms 167.479448ms 167.597215ms 171.059957ms 172.014579ms 175.058273ms 176.219188ms 179.584439ms 183.028529ms 186.106569ms 186.392325ms 195.300163ms 200.06626ms 245.892214ms 294.782869ms 336.285255ms 383.531665ms 418.25896ms 471.218234ms 506.098771ms 543.978781ms 587.100991ms 636.586147ms 668.864621ms 697.32699ms 698.412792ms 698.572937ms 699.222392ms 700.749837ms 701.876385ms 702.236872ms 703.689877ms 720.120645ms 725.235821ms 733.045105ms 736.050953ms 739.506892ms 741.023788ms 741.031473ms 741.5823ms 741.990118ms 742.782495ms 742.907124ms 743.2475ms 743.369945ms 743.468911ms 743.693287ms 743.704084ms 744.382648ms 744.512976ms 745.191524ms 745.911411ms 746.2265ms 746.286964ms 746.366945ms 746.377695ms 746.730871ms 746.83643ms 746.895111ms 747.014924ms 747.123704ms 747.252932ms 747.740718ms 747.784326ms 747.879156ms 747.879866ms 747.958756ms 747.980694ms 747.992747ms 748.19047ms 748.190951ms 748.228919ms 748.264257ms 748.283286ms 748.293891ms 748.344893ms 748.512097ms 748.532234ms 748.534443ms 748.663037ms 748.799489ms 748.851844ms 748.878117ms 748.909519ms 748.909897ms 749.106979ms 749.116376ms 749.469779ms 749.484512ms 749.635707ms 749.651321ms 749.706551ms 749.808853ms 749.83008ms 749.864534ms 749.874734ms 749.905466ms 749.956146ms 749.980803ms 750.00894ms 750.025022ms 750.026675ms 750.050354ms 750.070984ms 750.11536ms 750.181567ms 750.185037ms 750.245757ms 750.375714ms 750.406306ms 750.463593ms 750.603034ms 750.69088ms 750.798263ms 750.907676ms 751.005857ms 751.039248ms 751.071441ms 751.073373ms 751.13915ms 751.254286ms 751.263662ms 751.404214ms 751.412827ms 751.597497ms 751.7247ms 751.805146ms 751.869331ms 751.873253ms 751.943428ms 751.945122ms 751.966259ms 752.269079ms 752.325639ms 752.34469ms 752.373655ms 752.456464ms 752.75768ms 752.822781ms 752.897884ms 753.02687ms 753.103844ms 753.109824ms 753.148354ms 753.297967ms 753.361321ms 753.607633ms 753.713477ms 753.94368ms 754.10513ms 754.126729ms 754.450702ms 754.581043ms 754.795108ms 754.967454ms 755.080434ms 755.121613ms 755.150509ms 755.165917ms 755.793497ms 755.914419ms 756.933706ms 758.763668ms 760.496959ms 760.669951ms 763.367394ms 765.510688ms 796.39082ms 797.83736ms 801.448633ms 803.711144ms 804.379536ms 805.76349ms 852.549202ms]
Mar  3 13:36:40.949: INFO: 50 %ile: 748.293891ms
Mar  3 13:36:40.949: INFO: 90 %ile: 754.967454ms
Mar  3 13:36:40.949: INFO: 99 %ile: 805.76349ms
Mar  3 13:36:40.949: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:36:40.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-1110" for this suite.
Mar  3 13:37:10.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:37:11.168: INFO: namespace svc-latency-1110 deletion completed in 30.213183679s

• [SLOW TEST:40.014 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:37:11.168: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  3 13:37:11.234: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e16eb996-ba73-4ade-8438-160d434cdfc5" in namespace "projected-8854" to be "success or failure"
Mar  3 13:37:11.239: INFO: Pod "downwardapi-volume-e16eb996-ba73-4ade-8438-160d434cdfc5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.476712ms
Mar  3 13:37:13.244: INFO: Pod "downwardapi-volume-e16eb996-ba73-4ade-8438-160d434cdfc5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009794953s
STEP: Saw pod success
Mar  3 13:37:13.244: INFO: Pod "downwardapi-volume-e16eb996-ba73-4ade-8438-160d434cdfc5" satisfied condition "success or failure"
Mar  3 13:37:13.253: INFO: Trying to get logs from node 10.0.2.119 pod downwardapi-volume-e16eb996-ba73-4ade-8438-160d434cdfc5 container client-container: <nil>
STEP: delete the pod
Mar  3 13:37:13.286: INFO: Waiting for pod downwardapi-volume-e16eb996-ba73-4ade-8438-160d434cdfc5 to disappear
Mar  3 13:37:13.291: INFO: Pod downwardapi-volume-e16eb996-ba73-4ade-8438-160d434cdfc5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:37:13.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8854" for this suite.
Mar  3 13:37:19.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:37:19.526: INFO: namespace projected-8854 deletion completed in 6.229201479s

• [SLOW TEST:8.358 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:37:19.526: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-615
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-615
I0303 13:37:19.627181      23 runners.go:184] Created replication controller with name: externalname-service, namespace: services-615, replica count: 2
Mar  3 13:37:22.677: INFO: Creating new exec pod
I0303 13:37:22.677490      23 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  3 13:37:25.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=services-615 execpod5qht6 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Mar  3 13:37:25.899: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Mar  3 13:37:25.899: INFO: stdout: ""
Mar  3 13:37:25.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=services-615 execpod5qht6 -- /bin/sh -x -c nc -zv -t -w 2 172.27.252.86 80'
Mar  3 13:37:26.114: INFO: stderr: "+ nc -zv -t -w 2 172.27.252.86 80\nConnection to 172.27.252.86 80 port [tcp/http] succeeded!\n"
Mar  3 13:37:26.114: INFO: stdout: ""
Mar  3 13:37:26.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=services-615 execpod5qht6 -- /bin/sh -x -c nc -zv -t -w 2 10.0.2.119 32724'
Mar  3 13:37:26.309: INFO: stderr: "+ nc -zv -t -w 2 10.0.2.119 32724\nConnection to 10.0.2.119 32724 port [tcp/32724] succeeded!\n"
Mar  3 13:37:26.309: INFO: stdout: ""
Mar  3 13:37:26.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=services-615 execpod5qht6 -- /bin/sh -x -c nc -zv -t -w 2 10.0.2.74 32724'
Mar  3 13:37:26.511: INFO: stderr: "+ nc -zv -t -w 2 10.0.2.74 32724\nConnection to 10.0.2.74 32724 port [tcp/32724] succeeded!\n"
Mar  3 13:37:26.511: INFO: stdout: ""
Mar  3 13:37:26.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=services-615 execpod5qht6 -- /bin/sh -x -c nc -zv -t -w 2 150.109.125.235 32724'
Mar  3 13:37:26.712: INFO: stderr: "+ nc -zv -t -w 2 150.109.125.235 32724\nConnection to 150.109.125.235 32724 port [tcp/32724] succeeded!\n"
Mar  3 13:37:26.712: INFO: stdout: ""
Mar  3 13:37:26.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=services-615 execpod5qht6 -- /bin/sh -x -c nc -zv -t -w 2 129.226.52.233 32724'
Mar  3 13:37:26.906: INFO: stderr: "+ nc -zv -t -w 2 129.226.52.233 32724\nConnection to 129.226.52.233 32724 port [tcp/32724] succeeded!\n"
Mar  3 13:37:26.906: INFO: stdout: ""
Mar  3 13:37:26.906: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:37:26.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-615" for this suite.
Mar  3 13:37:32.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:37:33.209: INFO: namespace services-615 deletion completed in 6.231311237s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.683 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:37:33.209: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Mar  3 13:37:33.320: INFO: Waiting up to 5m0s for pod "var-expansion-7e3c8add-b73c-4c9d-8c39-5e10c7b3c7f5" in namespace "var-expansion-5346" to be "success or failure"
Mar  3 13:37:33.328: INFO: Pod "var-expansion-7e3c8add-b73c-4c9d-8c39-5e10c7b3c7f5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.299103ms
Mar  3 13:37:35.334: INFO: Pod "var-expansion-7e3c8add-b73c-4c9d-8c39-5e10c7b3c7f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013407705s
STEP: Saw pod success
Mar  3 13:37:35.334: INFO: Pod "var-expansion-7e3c8add-b73c-4c9d-8c39-5e10c7b3c7f5" satisfied condition "success or failure"
Mar  3 13:37:35.338: INFO: Trying to get logs from node 10.0.2.119 pod var-expansion-7e3c8add-b73c-4c9d-8c39-5e10c7b3c7f5 container dapi-container: <nil>
STEP: delete the pod
Mar  3 13:37:35.368: INFO: Waiting for pod var-expansion-7e3c8add-b73c-4c9d-8c39-5e10c7b3c7f5 to disappear
Mar  3 13:37:35.373: INFO: Pod var-expansion-7e3c8add-b73c-4c9d-8c39-5e10c7b3c7f5 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:37:35.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5346" for this suite.
Mar  3 13:37:41.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:37:41.599: INFO: namespace var-expansion-5346 deletion completed in 6.221210172s

• [SLOW TEST:8.390 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:37:41.599: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  3 13:37:41.670: INFO: Waiting up to 5m0s for pod "downwardapi-volume-10c06e1f-9909-4dd5-8300-b322e4ea4dd8" in namespace "downward-api-1077" to be "success or failure"
Mar  3 13:37:41.674: INFO: Pod "downwardapi-volume-10c06e1f-9909-4dd5-8300-b322e4ea4dd8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032188ms
Mar  3 13:37:43.686: INFO: Pod "downwardapi-volume-10c06e1f-9909-4dd5-8300-b322e4ea4dd8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01568023s
STEP: Saw pod success
Mar  3 13:37:43.686: INFO: Pod "downwardapi-volume-10c06e1f-9909-4dd5-8300-b322e4ea4dd8" satisfied condition "success or failure"
Mar  3 13:37:43.694: INFO: Trying to get logs from node 10.0.2.119 pod downwardapi-volume-10c06e1f-9909-4dd5-8300-b322e4ea4dd8 container client-container: <nil>
STEP: delete the pod
Mar  3 13:37:43.725: INFO: Waiting for pod downwardapi-volume-10c06e1f-9909-4dd5-8300-b322e4ea4dd8 to disappear
Mar  3 13:37:43.729: INFO: Pod downwardapi-volume-10c06e1f-9909-4dd5-8300-b322e4ea4dd8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:37:43.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1077" for this suite.
Mar  3 13:37:49.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:37:50.076: INFO: namespace downward-api-1077 deletion completed in 6.332586691s

• [SLOW TEST:8.477 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:37:50.077: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-673cc697-ebb2-478f-93be-ed6a125f1720
STEP: Creating a pod to test consume configMaps
Mar  3 13:37:50.156: INFO: Waiting up to 5m0s for pod "pod-configmaps-4d5c3651-d310-48c0-af61-626326a3158a" in namespace "configmap-6101" to be "success or failure"
Mar  3 13:37:50.161: INFO: Pod "pod-configmaps-4d5c3651-d310-48c0-af61-626326a3158a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.964256ms
Mar  3 13:37:52.166: INFO: Pod "pod-configmaps-4d5c3651-d310-48c0-af61-626326a3158a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010003813s
STEP: Saw pod success
Mar  3 13:37:52.166: INFO: Pod "pod-configmaps-4d5c3651-d310-48c0-af61-626326a3158a" satisfied condition "success or failure"
Mar  3 13:37:52.171: INFO: Trying to get logs from node 10.0.2.119 pod pod-configmaps-4d5c3651-d310-48c0-af61-626326a3158a container configmap-volume-test: <nil>
STEP: delete the pod
Mar  3 13:37:52.211: INFO: Waiting for pod pod-configmaps-4d5c3651-d310-48c0-af61-626326a3158a to disappear
Mar  3 13:37:52.215: INFO: Pod pod-configmaps-4d5c3651-d310-48c0-af61-626326a3158a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:37:52.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6101" for this suite.
Mar  3 13:37:58.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:37:58.446: INFO: namespace configmap-6101 deletion completed in 6.226297258s

• [SLOW TEST:8.370 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:37:58.446: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Mar  3 13:37:58.503: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  3 13:37:58.523: INFO: Waiting for terminating namespaces to be deleted...
Mar  3 13:37:58.527: INFO: 
Logging pods the kubelet thinks is on node 10.0.2.119 before test
Mar  3 13:37:58.540: INFO: tke-cni-agent-nqwxr from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 13:37:58.540: INFO: 	Container tke-cni-agent ready: true, restart count 0
Mar  3 13:37:58.540: INFO: ip-masq-agent-67jk9 from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 13:37:58.540: INFO: 	Container ip-masq-agent ready: true, restart count 0
Mar  3 13:37:58.540: INFO: sonobuoy-systemd-logs-daemon-set-046f08d908064245-vrhb2 from sonobuoy started at 2020-03-03 12:02:34 +0000 UTC (2 container statuses recorded)
Mar  3 13:37:58.540: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar  3 13:37:58.540: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  3 13:37:58.540: INFO: tke-bridge-agent-qb5s8 from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 13:37:58.540: INFO: 	Container tke-bridge-agent ready: true, restart count 0
Mar  3 13:37:58.540: INFO: coredns-79444468c6-mzdqt from kube-system started at 2020-03-03 13:18:16 +0000 UTC (1 container statuses recorded)
Mar  3 13:37:58.540: INFO: 	Container coredns ready: true, restart count 0
Mar  3 13:37:58.540: INFO: 
Logging pods the kubelet thinks is on node 10.0.2.74 before test
Mar  3 13:37:58.551: INFO: ip-masq-agent-vfrbd from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 13:37:58.551: INFO: 	Container ip-masq-agent ready: true, restart count 0
Mar  3 13:37:58.551: INFO: sonobuoy-systemd-logs-daemon-set-046f08d908064245-mvl4g from sonobuoy started at 2020-03-03 12:02:34 +0000 UTC (2 container statuses recorded)
Mar  3 13:37:58.551: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar  3 13:37:58.551: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  3 13:37:58.551: INFO: l7-lb-controller-66b9d774dc-8k885 from kube-system started at 2020-03-03 13:17:43 +0000 UTC (1 container statuses recorded)
Mar  3 13:37:58.551: INFO: 	Container l7-lb-controller ready: true, restart count 0
Mar  3 13:37:58.551: INFO: tke-cni-agent-8jgsc from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 13:37:58.551: INFO: 	Container tke-cni-agent ready: true, restart count 0
Mar  3 13:37:58.551: INFO: sonobuoy from sonobuoy started at 2020-03-03 12:02:28 +0000 UTC (1 container statuses recorded)
Mar  3 13:37:58.551: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  3 13:37:58.551: INFO: sonobuoy-e2e-job-d53d4d2134fd4748 from sonobuoy started at 2020-03-03 12:02:34 +0000 UTC (2 container statuses recorded)
Mar  3 13:37:58.551: INFO: 	Container e2e ready: true, restart count 0
Mar  3 13:37:58.551: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  3 13:37:58.551: INFO: tke-bridge-agent-lrfvg from kube-system started at 2020-03-03 11:52:55 +0000 UTC (1 container statuses recorded)
Mar  3 13:37:58.551: INFO: 	Container tke-bridge-agent ready: true, restart count 0
Mar  3 13:37:58.551: INFO: coredns-79444468c6-b7cdk from kube-system started at 2020-03-03 12:08:15 +0000 UTC (1 container statuses recorded)
Mar  3 13:37:58.551: INFO: 	Container coredns ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-925aa859-7656-4f21-bc1a-cbef71c3d7c1 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-925aa859-7656-4f21-bc1a-cbef71c3d7c1 off the node 10.0.2.119
STEP: verifying the node doesn't have the label kubernetes.io/e2e-925aa859-7656-4f21-bc1a-cbef71c3d7c1
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:38:06.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4678" for this suite.
Mar  3 13:38:28.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:38:29.096: INFO: namespace sched-pred-4678 deletion completed in 22.392163694s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:30.650 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:38:29.097: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-1003
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1003 to expose endpoints map[]
Mar  3 13:38:29.164: INFO: Get endpoints failed (4.492986ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Mar  3 13:38:30.169: INFO: successfully validated that service endpoint-test2 in namespace services-1003 exposes endpoints map[] (1.009648416s elapsed)
STEP: Creating pod pod1 in namespace services-1003
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1003 to expose endpoints map[pod1:[80]]
Mar  3 13:38:31.210: INFO: successfully validated that service endpoint-test2 in namespace services-1003 exposes endpoints map[pod1:[80]] (1.026220484s elapsed)
STEP: Creating pod pod2 in namespace services-1003
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1003 to expose endpoints map[pod1:[80] pod2:[80]]
Mar  3 13:38:33.266: INFO: successfully validated that service endpoint-test2 in namespace services-1003 exposes endpoints map[pod1:[80] pod2:[80]] (2.049166019s elapsed)
STEP: Deleting pod pod1 in namespace services-1003
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1003 to expose endpoints map[pod2:[80]]
Mar  3 13:38:34.304: INFO: successfully validated that service endpoint-test2 in namespace services-1003 exposes endpoints map[pod2:[80]] (1.029412248s elapsed)
STEP: Deleting pod pod2 in namespace services-1003
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1003 to expose endpoints map[]
Mar  3 13:38:35.334: INFO: successfully validated that service endpoint-test2 in namespace services-1003 exposes endpoints map[] (1.018313821s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:38:35.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1003" for this suite.
Mar  3 13:38:47.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:38:47.576: INFO: namespace services-1003 deletion completed in 12.195788902s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:18.480 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:38:47.577: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Mar  3 13:38:53.695: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0303 13:38:53.695767      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:38:53.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4197" for this suite.
Mar  3 13:39:01.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:39:01.971: INFO: namespace gc-4197 deletion completed in 8.271225577s

• [SLOW TEST:14.395 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:39:01.972: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Mar  3 13:39:02.108: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:39:06.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-752" for this suite.
Mar  3 13:39:18.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:39:18.466: INFO: namespace init-container-752 deletion completed in 12.355601229s

• [SLOW TEST:16.494 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:39:18.466: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-6654
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-6654
STEP: Deleting pre-stop pod
Mar  3 13:39:27.582: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:39:27.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-6654" for this suite.
Mar  3 13:40:11.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:40:11.808: INFO: namespace prestop-6654 deletion completed in 44.205108499s

• [SLOW TEST:53.342 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:40:11.808: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-8971/secret-test-5fd56502-e9f4-4c2d-8986-8912e0988158
STEP: Creating a pod to test consume secrets
Mar  3 13:40:11.877: INFO: Waiting up to 5m0s for pod "pod-configmaps-3e3f4d8a-df36-4cd9-8ea4-c0080c0e45d5" in namespace "secrets-8971" to be "success or failure"
Mar  3 13:40:11.881: INFO: Pod "pod-configmaps-3e3f4d8a-df36-4cd9-8ea4-c0080c0e45d5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.205113ms
Mar  3 13:40:13.890: INFO: Pod "pod-configmaps-3e3f4d8a-df36-4cd9-8ea4-c0080c0e45d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013134949s
STEP: Saw pod success
Mar  3 13:40:13.890: INFO: Pod "pod-configmaps-3e3f4d8a-df36-4cd9-8ea4-c0080c0e45d5" satisfied condition "success or failure"
Mar  3 13:40:13.895: INFO: Trying to get logs from node 10.0.2.119 pod pod-configmaps-3e3f4d8a-df36-4cd9-8ea4-c0080c0e45d5 container env-test: <nil>
STEP: delete the pod
Mar  3 13:40:13.928: INFO: Waiting for pod pod-configmaps-3e3f4d8a-df36-4cd9-8ea4-c0080c0e45d5 to disappear
Mar  3 13:40:13.933: INFO: Pod pod-configmaps-3e3f4d8a-df36-4cd9-8ea4-c0080c0e45d5 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:40:13.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8971" for this suite.
Mar  3 13:40:19.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:40:20.162: INFO: namespace secrets-8971 deletion completed in 6.21942009s

• [SLOW TEST:8.354 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:40:20.163: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 13:40:20.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 version'
Mar  3 13:40:20.308: INFO: stderr: ""
Mar  3 13:40:20.308: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.3\", GitCommit:\"b3cbbae08ec52a7fc73d334838e18d17e8512749\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:23:11Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16+\", GitVersion:\"v1.16.3-tke.2\", GitCommit:\"9e165660c7ad9639e1be7c82a4bd83ba24824400\", GitTreeState:\"clean\", BuildDate:\"2020-01-07T07:34:19Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:40:20.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9680" for this suite.
Mar  3 13:40:26.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:40:26.499: INFO: namespace kubectl-9680 deletion completed in 6.184812804s

• [SLOW TEST:6.336 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:40:26.499: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-1ff26670-2fcb-47a6-9f6c-094d5bcebfbb
STEP: Creating a pod to test consume secrets
Mar  3 13:40:26.570: INFO: Waiting up to 5m0s for pod "pod-secrets-cf59ec18-2e0a-4801-aa6a-a55b01c30e11" in namespace "secrets-7955" to be "success or failure"
Mar  3 13:40:26.574: INFO: Pod "pod-secrets-cf59ec18-2e0a-4801-aa6a-a55b01c30e11": Phase="Pending", Reason="", readiness=false. Elapsed: 3.801045ms
Mar  3 13:40:28.580: INFO: Pod "pod-secrets-cf59ec18-2e0a-4801-aa6a-a55b01c30e11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010028008s
STEP: Saw pod success
Mar  3 13:40:28.580: INFO: Pod "pod-secrets-cf59ec18-2e0a-4801-aa6a-a55b01c30e11" satisfied condition "success or failure"
Mar  3 13:40:28.584: INFO: Trying to get logs from node 10.0.2.119 pod pod-secrets-cf59ec18-2e0a-4801-aa6a-a55b01c30e11 container secret-volume-test: <nil>
STEP: delete the pod
Mar  3 13:40:28.673: INFO: Waiting for pod pod-secrets-cf59ec18-2e0a-4801-aa6a-a55b01c30e11 to disappear
Mar  3 13:40:28.680: INFO: Pod pod-secrets-cf59ec18-2e0a-4801-aa6a-a55b01c30e11 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:40:28.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7955" for this suite.
Mar  3 13:40:34.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:40:34.950: INFO: namespace secrets-7955 deletion completed in 6.265351796s

• [SLOW TEST:8.451 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:40:34.950: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar  3 13:40:35.147: INFO: Number of nodes with available pods: 0
Mar  3 13:40:35.147: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 13:40:36.163: INFO: Number of nodes with available pods: 0
Mar  3 13:40:36.163: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 13:40:37.160: INFO: Number of nodes with available pods: 2
Mar  3 13:40:37.161: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar  3 13:40:37.192: INFO: Number of nodes with available pods: 2
Mar  3 13:40:37.192: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1514, will wait for the garbage collector to delete the pods
Mar  3 13:40:38.296: INFO: Deleting DaemonSet.extensions daemon-set took: 26.23653ms
Mar  3 13:40:38.796: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.183158ms
Mar  3 13:42:15.004: INFO: Number of nodes with available pods: 0
Mar  3 13:42:15.004: INFO: Number of running nodes: 0, number of available pods: 0
Mar  3 13:42:15.009: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1514/daemonsets","resourceVersion":"1244413737"},"items":null}

Mar  3 13:42:15.014: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1514/pods","resourceVersion":"1244413737"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:42:15.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1514" for this suite.
Mar  3 13:42:23.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:42:23.339: INFO: namespace daemonsets-1514 deletion completed in 8.29454245s

• [SLOW TEST:108.389 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:42:23.339: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar  3 13:42:23.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-7178'
Mar  3 13:42:23.866: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  3 13:42:23.866: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Mar  3 13:42:23.880: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-lzv5z]
Mar  3 13:42:23.880: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-lzv5z" in namespace "kubectl-7178" to be "running and ready"
Mar  3 13:42:23.884: INFO: Pod "e2e-test-httpd-rc-lzv5z": Phase="Pending", Reason="", readiness=false. Elapsed: 4.246436ms
Mar  3 13:42:25.923: INFO: Pod "e2e-test-httpd-rc-lzv5z": Phase="Running", Reason="", readiness=true. Elapsed: 2.043612333s
Mar  3 13:42:25.923: INFO: Pod "e2e-test-httpd-rc-lzv5z" satisfied condition "running and ready"
Mar  3 13:42:25.923: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-lzv5z]
Mar  3 13:42:25.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 logs rc/e2e-test-httpd-rc --namespace=kubectl-7178'
Mar  3 13:42:26.042: INFO: stderr: ""
Mar  3 13:42:26.042: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.27.0.60. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.27.0.60. Set the 'ServerName' directive globally to suppress this message\n[Tue Mar 03 13:42:24.778605 2020] [mpm_event:notice] [pid 1:tid 139870637792104] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Tue Mar 03 13:42:24.778653 2020] [core:notice] [pid 1:tid 139870637792104] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Mar  3 13:42:26.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 delete rc e2e-test-httpd-rc --namespace=kubectl-7178'
Mar  3 13:42:26.139: INFO: stderr: ""
Mar  3 13:42:26.139: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:42:26.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7178" for this suite.
Mar  3 13:42:32.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:42:32.366: INFO: namespace kubectl-7178 deletion completed in 6.220014009s

• [SLOW TEST:9.026 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:42:32.366: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:42:38.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4508" for this suite.
Mar  3 13:42:44.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:42:44.866: INFO: namespace namespaces-4508 deletion completed in 6.276609764s
STEP: Destroying namespace "nsdeletetest-7577" for this suite.
Mar  3 13:42:44.870: INFO: Namespace nsdeletetest-7577 was already deleted
STEP: Destroying namespace "nsdeletetest-1583" for this suite.
Mar  3 13:42:50.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:42:51.114: INFO: namespace nsdeletetest-1583 deletion completed in 6.243561035s

• [SLOW TEST:18.748 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:42:51.114: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-a3890dbe-5abe-480e-8285-4ed484083434
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-a3890dbe-5abe-480e-8285-4ed484083434
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:42:55.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6273" for this suite.
Mar  3 13:43:07.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:43:07.546: INFO: namespace configmap-6273 deletion completed in 12.279383891s

• [SLOW TEST:16.432 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:43:07.546: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Mar  3 13:43:10.250: INFO: Successfully updated pod "annotationupdate4612449f-4e58-4000-a3dc-4f22b5690525"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:43:14.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3942" for this suite.
Mar  3 13:43:26.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:43:26.522: INFO: namespace downward-api-3942 deletion completed in 12.22276063s

• [SLOW TEST:18.976 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:43:26.522: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5385.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-5385.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5385.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5385.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-5385.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5385.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  3 13:43:28.657: INFO: DNS probes using dns-5385/dns-test-388417c2-e7c7-402d-9128-29875b80f6c3 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:43:28.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5385" for this suite.
Mar  3 13:43:34.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:43:34.907: INFO: namespace dns-5385 deletion completed in 6.214463605s

• [SLOW TEST:8.385 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:43:34.907: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-4980
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-4980
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4980
Mar  3 13:43:34.976: INFO: Found 0 stateful pods, waiting for 1
Mar  3 13:43:44.984: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar  3 13:43:44.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=statefulset-4980 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  3 13:43:45.440: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  3 13:43:45.440: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  3 13:43:45.440: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  3 13:43:45.445: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar  3 13:43:55.451: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  3 13:43:55.451: INFO: Waiting for statefulset status.replicas updated to 0
Mar  3 13:43:55.471: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998634s
Mar  3 13:43:56.477: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995438538s
Mar  3 13:43:57.486: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.989337638s
Mar  3 13:43:58.492: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.979695927s
Mar  3 13:43:59.497: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.974563006s
Mar  3 13:44:00.503: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.969061963s
Mar  3 13:44:01.512: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.963343698s
Mar  3 13:44:02.518: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.953765071s
Mar  3 13:44:03.524: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.947832858s
Mar  3 13:44:04.556: INFO: Verifying statefulset ss doesn't scale past 1 for another 941.930755ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4980
Mar  3 13:44:05.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=statefulset-4980 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  3 13:44:05.765: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar  3 13:44:05.765: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  3 13:44:05.765: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  3 13:44:05.770: INFO: Found 1 stateful pods, waiting for 3
Mar  3 13:44:15.778: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  3 13:44:15.778: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  3 13:44:15.778: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Mar  3 13:44:15.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=statefulset-4980 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  3 13:44:16.016: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  3 13:44:16.016: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  3 13:44:16.016: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  3 13:44:16.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=statefulset-4980 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  3 13:44:16.267: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  3 13:44:16.267: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  3 13:44:16.267: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  3 13:44:16.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=statefulset-4980 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  3 13:44:16.504: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  3 13:44:16.504: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  3 13:44:16.504: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  3 13:44:16.504: INFO: Waiting for statefulset status.replicas updated to 0
Mar  3 13:44:16.508: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Mar  3 13:44:26.519: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  3 13:44:26.519: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar  3 13:44:26.519: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar  3 13:44:26.539: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998823s
Mar  3 13:44:27.544: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995530145s
Mar  3 13:44:28.552: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990201953s
Mar  3 13:44:29.569: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.982495787s
Mar  3 13:44:30.574: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.965837716s
Mar  3 13:44:31.586: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.960634711s
Mar  3 13:44:32.593: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.9487654s
Mar  3 13:44:33.600: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.940956202s
Mar  3 13:44:34.607: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.933937439s
Mar  3 13:44:35.612: INFO: Verifying statefulset ss doesn't scale past 3 for another 927.853043ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4980
Mar  3 13:44:36.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=statefulset-4980 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  3 13:44:36.816: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar  3 13:44:36.816: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  3 13:44:36.816: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  3 13:44:36.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=statefulset-4980 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  3 13:44:37.020: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar  3 13:44:37.020: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  3 13:44:37.020: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  3 13:44:37.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 exec --namespace=statefulset-4980 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  3 13:44:37.228: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar  3 13:44:37.228: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  3 13:44:37.228: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  3 13:44:37.228: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Mar  3 13:45:07.273: INFO: Deleting all statefulset in ns statefulset-4980
Mar  3 13:45:07.278: INFO: Scaling statefulset ss to 0
Mar  3 13:45:07.291: INFO: Waiting for statefulset status.replicas updated to 0
Mar  3 13:45:07.298: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:45:07.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4980" for this suite.
Mar  3 13:45:13.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:45:13.583: INFO: namespace statefulset-4980 deletion completed in 6.252927815s

• [SLOW TEST:98.676 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:45:13.583: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:45:15.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9826" for this suite.
Mar  3 13:45:59.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:45:59.902: INFO: namespace kubelet-test-9826 deletion completed in 44.219353696s

• [SLOW TEST:46.319 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:45:59.903: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  3 13:45:59.968: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4bfa0cb1-2c7b-42a1-bd7d-4f327a3651ba" in namespace "downward-api-9044" to be "success or failure"
Mar  3 13:45:59.972: INFO: Pod "downwardapi-volume-4bfa0cb1-2c7b-42a1-bd7d-4f327a3651ba": Phase="Pending", Reason="", readiness=false. Elapsed: 4.158856ms
Mar  3 13:46:01.983: INFO: Pod "downwardapi-volume-4bfa0cb1-2c7b-42a1-bd7d-4f327a3651ba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015466638s
STEP: Saw pod success
Mar  3 13:46:01.983: INFO: Pod "downwardapi-volume-4bfa0cb1-2c7b-42a1-bd7d-4f327a3651ba" satisfied condition "success or failure"
Mar  3 13:46:01.988: INFO: Trying to get logs from node 10.0.2.119 pod downwardapi-volume-4bfa0cb1-2c7b-42a1-bd7d-4f327a3651ba container client-container: <nil>
STEP: delete the pod
Mar  3 13:46:02.056: INFO: Waiting for pod downwardapi-volume-4bfa0cb1-2c7b-42a1-bd7d-4f327a3651ba to disappear
Mar  3 13:46:02.061: INFO: Pod downwardapi-volume-4bfa0cb1-2c7b-42a1-bd7d-4f327a3651ba no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:46:02.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9044" for this suite.
Mar  3 13:46:08.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:46:08.333: INFO: namespace downward-api-9044 deletion completed in 6.264859216s

• [SLOW TEST:8.431 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:46:08.334: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:46:10.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9755" for this suite.
Mar  3 13:46:18.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:46:18.653: INFO: namespace containers-9755 deletion completed in 8.221740917s

• [SLOW TEST:10.319 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:46:18.653: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Mar  3 13:46:58.844: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:46:58.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0303 13:46:58.844946      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-6855" for this suite.
Mar  3 13:47:06.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:47:07.167: INFO: namespace gc-6855 deletion completed in 8.316523382s

• [SLOW TEST:48.514 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:47:07.167: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-a086eee4-481e-49b7-8b81-b24a857f2316 in namespace container-probe-6739
Mar  3 13:47:09.240: INFO: Started pod liveness-a086eee4-481e-49b7-8b81-b24a857f2316 in namespace container-probe-6739
STEP: checking the pod's current state and verifying that restartCount is present
Mar  3 13:47:09.244: INFO: Initial restart count of pod liveness-a086eee4-481e-49b7-8b81-b24a857f2316 is 0
Mar  3 13:47:25.330: INFO: Restart count of pod container-probe-6739/liveness-a086eee4-481e-49b7-8b81-b24a857f2316 is now 1 (16.086512108s elapsed)
Mar  3 13:47:45.390: INFO: Restart count of pod container-probe-6739/liveness-a086eee4-481e-49b7-8b81-b24a857f2316 is now 2 (36.145881788s elapsed)
Mar  3 13:48:05.468: INFO: Restart count of pod container-probe-6739/liveness-a086eee4-481e-49b7-8b81-b24a857f2316 is now 3 (56.224050005s elapsed)
Mar  3 13:48:25.554: INFO: Restart count of pod container-probe-6739/liveness-a086eee4-481e-49b7-8b81-b24a857f2316 is now 4 (1m16.310300503s elapsed)
Mar  3 13:49:38.026: INFO: Restart count of pod container-probe-6739/liveness-a086eee4-481e-49b7-8b81-b24a857f2316 is now 5 (2m28.781681765s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:49:38.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6739" for this suite.
Mar  3 13:49:44.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:49:44.329: INFO: namespace container-probe-6739 deletion completed in 6.283401432s

• [SLOW TEST:157.163 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:49:44.330: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  3 13:49:44.776: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  3 13:49:47.805: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:50:00.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6621" for this suite.
Mar  3 13:50:06.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:50:06.287: INFO: namespace webhook-6621 deletion completed in 6.261995057s
STEP: Destroying namespace "webhook-6621-markers" for this suite.
Mar  3 13:50:12.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:50:12.511: INFO: namespace webhook-6621-markers deletion completed in 6.223440794s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.217 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:50:12.547: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Mar  3 13:50:12.599: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:50:33.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4518" for this suite.
Mar  3 13:50:40.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:50:40.252: INFO: namespace crd-publish-openapi-4518 deletion completed in 6.250685625s

• [SLOW TEST:27.706 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:50:40.253: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Mar  3 13:50:40.326: INFO: Waiting up to 5m0s for pod "pod-27674d03-2575-42dc-b01b-8022f7825e73" in namespace "emptydir-4186" to be "success or failure"
Mar  3 13:50:40.330: INFO: Pod "pod-27674d03-2575-42dc-b01b-8022f7825e73": Phase="Pending", Reason="", readiness=false. Elapsed: 4.214286ms
Mar  3 13:50:42.357: INFO: Pod "pod-27674d03-2575-42dc-b01b-8022f7825e73": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031161354s
STEP: Saw pod success
Mar  3 13:50:42.357: INFO: Pod "pod-27674d03-2575-42dc-b01b-8022f7825e73" satisfied condition "success or failure"
Mar  3 13:50:42.366: INFO: Trying to get logs from node 10.0.2.119 pod pod-27674d03-2575-42dc-b01b-8022f7825e73 container test-container: <nil>
STEP: delete the pod
Mar  3 13:50:42.407: INFO: Waiting for pod pod-27674d03-2575-42dc-b01b-8022f7825e73 to disappear
Mar  3 13:50:42.412: INFO: Pod pod-27674d03-2575-42dc-b01b-8022f7825e73 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:50:42.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4186" for this suite.
Mar  3 13:50:48.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:50:48.619: INFO: namespace emptydir-4186 deletion completed in 6.201495418s

• [SLOW TEST:8.366 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:50:48.619: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Mar  3 13:50:51.302: INFO: Successfully updated pod "labelsupdate22913ec7-d577-486d-8fa2-ad5a4277a615"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:50:55.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4182" for this suite.
Mar  3 13:51:07.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:51:07.573: INFO: namespace projected-4182 deletion completed in 12.223762071s

• [SLOW TEST:18.954 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:51:07.573: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-9037
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-9037
Mar  3 13:51:07.669: INFO: Found 0 stateful pods, waiting for 1
Mar  3 13:51:17.674: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Mar  3 13:51:17.705: INFO: Deleting all statefulset in ns statefulset-9037
Mar  3 13:51:17.711: INFO: Scaling statefulset ss to 0
Mar  3 13:51:27.746: INFO: Waiting for statefulset status.replicas updated to 0
Mar  3 13:51:27.750: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:51:27.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9037" for this suite.
Mar  3 13:51:33.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:51:34.059: INFO: namespace statefulset-9037 deletion completed in 6.279486581s

• [SLOW TEST:26.486 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:51:34.060: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar  3 13:51:38.232: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  3 13:51:38.236: INFO: Pod pod-with-poststart-http-hook still exists
Mar  3 13:51:40.236: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  3 13:51:40.242: INFO: Pod pod-with-poststart-http-hook still exists
Mar  3 13:51:42.236: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  3 13:51:42.244: INFO: Pod pod-with-poststart-http-hook still exists
Mar  3 13:51:44.236: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  3 13:51:44.241: INFO: Pod pod-with-poststart-http-hook still exists
Mar  3 13:51:46.236: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  3 13:51:46.241: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:51:46.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4478" for this suite.
Mar  3 13:51:58.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:51:58.578: INFO: namespace container-lifecycle-hook-4478 deletion completed in 12.331119873s

• [SLOW TEST:24.518 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:51:58.578: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar  3 13:51:58.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-6998'
Mar  3 13:51:58.733: INFO: stderr: ""
Mar  3 13:51:58.733: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Mar  3 13:51:58.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-187709168 delete pods e2e-test-httpd-pod --namespace=kubectl-6998'
Mar  3 13:52:14.953: INFO: stderr: ""
Mar  3 13:52:14.953: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:52:14.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6998" for this suite.
Mar  3 13:52:20.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:52:21.150: INFO: namespace kubectl-6998 deletion completed in 6.190808819s

• [SLOW TEST:22.573 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:52:21.151: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar  3 13:52:21.258: INFO: Number of nodes with available pods: 0
Mar  3 13:52:21.258: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 13:52:22.268: INFO: Number of nodes with available pods: 0
Mar  3 13:52:22.268: INFO: Node 10.0.2.119 is running more than one daemon pod
Mar  3 13:52:23.274: INFO: Number of nodes with available pods: 2
Mar  3 13:52:23.274: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Mar  3 13:52:23.315: INFO: Number of nodes with available pods: 1
Mar  3 13:52:23.315: INFO: Node 10.0.2.74 is running more than one daemon pod
Mar  3 13:52:24.350: INFO: Number of nodes with available pods: 1
Mar  3 13:52:24.350: INFO: Node 10.0.2.74 is running more than one daemon pod
Mar  3 13:52:25.335: INFO: Number of nodes with available pods: 1
Mar  3 13:52:25.335: INFO: Node 10.0.2.74 is running more than one daemon pod
Mar  3 13:52:26.332: INFO: Number of nodes with available pods: 1
Mar  3 13:52:26.332: INFO: Node 10.0.2.74 is running more than one daemon pod
Mar  3 13:52:27.326: INFO: Number of nodes with available pods: 1
Mar  3 13:52:27.326: INFO: Node 10.0.2.74 is running more than one daemon pod
Mar  3 13:52:28.347: INFO: Number of nodes with available pods: 1
Mar  3 13:52:28.347: INFO: Node 10.0.2.74 is running more than one daemon pod
Mar  3 13:52:29.333: INFO: Number of nodes with available pods: 1
Mar  3 13:52:29.333: INFO: Node 10.0.2.74 is running more than one daemon pod
Mar  3 13:52:30.339: INFO: Number of nodes with available pods: 1
Mar  3 13:52:30.339: INFO: Node 10.0.2.74 is running more than one daemon pod
Mar  3 13:52:31.327: INFO: Number of nodes with available pods: 1
Mar  3 13:52:31.327: INFO: Node 10.0.2.74 is running more than one daemon pod
Mar  3 13:52:32.328: INFO: Number of nodes with available pods: 1
Mar  3 13:52:32.328: INFO: Node 10.0.2.74 is running more than one daemon pod
Mar  3 13:52:33.327: INFO: Number of nodes with available pods: 1
Mar  3 13:52:33.327: INFO: Node 10.0.2.74 is running more than one daemon pod
Mar  3 13:52:34.329: INFO: Number of nodes with available pods: 1
Mar  3 13:52:34.329: INFO: Node 10.0.2.74 is running more than one daemon pod
Mar  3 13:52:35.328: INFO: Number of nodes with available pods: 1
Mar  3 13:52:35.328: INFO: Node 10.0.2.74 is running more than one daemon pod
Mar  3 13:52:36.329: INFO: Number of nodes with available pods: 1
Mar  3 13:52:36.329: INFO: Node 10.0.2.74 is running more than one daemon pod
Mar  3 13:52:37.330: INFO: Number of nodes with available pods: 2
Mar  3 13:52:37.330: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5454, will wait for the garbage collector to delete the pods
Mar  3 13:52:37.420: INFO: Deleting DaemonSet.extensions daemon-set took: 17.68699ms
Mar  3 13:52:37.920: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.273723ms
Mar  3 13:52:45.325: INFO: Number of nodes with available pods: 0
Mar  3 13:52:45.325: INFO: Number of running nodes: 0, number of available pods: 0
Mar  3 13:52:45.338: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5454/daemonsets","resourceVersion":"1244541112"},"items":null}

Mar  3 13:52:45.366: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5454/pods","resourceVersion":"1244541117"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:52:45.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5454" for this suite.
Mar  3 13:52:51.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:52:51.587: INFO: namespace daemonsets-5454 deletion completed in 6.192182454s

• [SLOW TEST:30.437 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:52:51.588: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 13:52:51.665: INFO: (0) /api/v1/nodes/10.0.2.119/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.712528ms)
Mar  3 13:52:51.681: INFO: (1) /api/v1/nodes/10.0.2.119/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 15.369896ms)
Mar  3 13:52:51.687: INFO: (2) /api/v1/nodes/10.0.2.119/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.781224ms)
Mar  3 13:52:51.694: INFO: (3) /api/v1/nodes/10.0.2.119/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.703238ms)
Mar  3 13:52:51.702: INFO: (4) /api/v1/nodes/10.0.2.119/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.962149ms)
Mar  3 13:52:51.711: INFO: (5) /api/v1/nodes/10.0.2.119/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.267426ms)
Mar  3 13:52:51.717: INFO: (6) /api/v1/nodes/10.0.2.119/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.630369ms)
Mar  3 13:52:51.728: INFO: (7) /api/v1/nodes/10.0.2.119/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.157987ms)
Mar  3 13:52:51.738: INFO: (8) /api/v1/nodes/10.0.2.119/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.774826ms)
Mar  3 13:52:51.744: INFO: (9) /api/v1/nodes/10.0.2.119/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.779572ms)
Mar  3 13:52:51.751: INFO: (10) /api/v1/nodes/10.0.2.119/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.301478ms)
Mar  3 13:52:51.760: INFO: (11) /api/v1/nodes/10.0.2.119/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.74994ms)
Mar  3 13:52:51.768: INFO: (12) /api/v1/nodes/10.0.2.119/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.119604ms)
Mar  3 13:52:51.775: INFO: (13) /api/v1/nodes/10.0.2.119/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.63392ms)
Mar  3 13:52:51.788: INFO: (14) /api/v1/nodes/10.0.2.119/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 12.859316ms)
Mar  3 13:52:51.794: INFO: (15) /api/v1/nodes/10.0.2.119/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.087843ms)
Mar  3 13:52:51.800: INFO: (16) /api/v1/nodes/10.0.2.119/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.776555ms)
Mar  3 13:52:51.808: INFO: (17) /api/v1/nodes/10.0.2.119/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.102515ms)
Mar  3 13:52:51.814: INFO: (18) /api/v1/nodes/10.0.2.119/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.905431ms)
Mar  3 13:52:51.825: INFO: (19) /api/v1/nodes/10.0.2.119/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.855079ms)
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:52:51.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9032" for this suite.
Mar  3 13:52:57.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:52:58.045: INFO: namespace proxy-9032 deletion completed in 6.212991704s

• [SLOW TEST:6.458 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:52:58.045: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  3 13:52:58.533: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  3 13:53:01.562: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:53:01.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-352" for this suite.
Mar  3 13:53:13.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:53:13.958: INFO: namespace webhook-352 deletion completed in 12.320138824s
STEP: Destroying namespace "webhook-352-markers" for this suite.
Mar  3 13:53:19.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:53:20.168: INFO: namespace webhook-352-markers deletion completed in 6.209652559s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.150 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:53:20.196: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 13:53:22.347: INFO: Waiting up to 5m0s for pod "client-envvars-87d75432-c4b9-4495-81dc-1ca288b3f231" in namespace "pods-1258" to be "success or failure"
Mar  3 13:53:22.351: INFO: Pod "client-envvars-87d75432-c4b9-4495-81dc-1ca288b3f231": Phase="Pending", Reason="", readiness=false. Elapsed: 3.870124ms
Mar  3 13:53:24.356: INFO: Pod "client-envvars-87d75432-c4b9-4495-81dc-1ca288b3f231": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00904736s
STEP: Saw pod success
Mar  3 13:53:24.356: INFO: Pod "client-envvars-87d75432-c4b9-4495-81dc-1ca288b3f231" satisfied condition "success or failure"
Mar  3 13:53:24.360: INFO: Trying to get logs from node 10.0.2.74 pod client-envvars-87d75432-c4b9-4495-81dc-1ca288b3f231 container env3cont: <nil>
STEP: delete the pod
Mar  3 13:53:24.392: INFO: Waiting for pod client-envvars-87d75432-c4b9-4495-81dc-1ca288b3f231 to disappear
Mar  3 13:53:24.396: INFO: Pod client-envvars-87d75432-c4b9-4495-81dc-1ca288b3f231 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:53:24.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1258" for this suite.
Mar  3 13:53:36.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:53:36.636: INFO: namespace pods-1258 deletion completed in 12.235187333s

• [SLOW TEST:16.439 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:53:36.636: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-796ddfbe-8260-4cc6-84ec-35768f583b1a in namespace container-probe-7961
Mar  3 13:53:38.714: INFO: Started pod test-webserver-796ddfbe-8260-4cc6-84ec-35768f583b1a in namespace container-probe-7961
STEP: checking the pod's current state and verifying that restartCount is present
Mar  3 13:53:38.718: INFO: Initial restart count of pod test-webserver-796ddfbe-8260-4cc6-84ec-35768f583b1a is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:57:39.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7961" for this suite.
Mar  3 13:57:45.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:57:45.857: INFO: namespace container-probe-7961 deletion completed in 6.318923706s

• [SLOW TEST:249.221 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:57:45.858: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:58:02.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6966" for this suite.
Mar  3 13:58:08.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:58:08.261: INFO: namespace resourcequota-6966 deletion completed in 6.202372124s

• [SLOW TEST:22.403 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:58:08.261: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  3 13:58:08.324: INFO: Waiting up to 5m0s for pod "downwardapi-volume-09b7698b-706a-4193-8490-1e14e2304656" in namespace "projected-3907" to be "success or failure"
Mar  3 13:58:08.328: INFO: Pod "downwardapi-volume-09b7698b-706a-4193-8490-1e14e2304656": Phase="Pending", Reason="", readiness=false. Elapsed: 4.22618ms
Mar  3 13:58:10.333: INFO: Pod "downwardapi-volume-09b7698b-706a-4193-8490-1e14e2304656": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009138312s
STEP: Saw pod success
Mar  3 13:58:10.333: INFO: Pod "downwardapi-volume-09b7698b-706a-4193-8490-1e14e2304656" satisfied condition "success or failure"
Mar  3 13:58:10.337: INFO: Trying to get logs from node 10.0.2.119 pod downwardapi-volume-09b7698b-706a-4193-8490-1e14e2304656 container client-container: <nil>
STEP: delete the pod
Mar  3 13:58:10.373: INFO: Waiting for pod downwardapi-volume-09b7698b-706a-4193-8490-1e14e2304656 to disappear
Mar  3 13:58:10.377: INFO: Pod downwardapi-volume-09b7698b-706a-4193-8490-1e14e2304656 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:58:10.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3907" for this suite.
Mar  3 13:58:16.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:58:16.675: INFO: namespace projected-3907 deletion completed in 6.292704865s

• [SLOW TEST:8.414 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:58:16.675: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Mar  3 13:58:19.279: INFO: Successfully updated pod "adopt-release-h5ms6"
STEP: Checking that the Job readopts the Pod
Mar  3 13:58:19.279: INFO: Waiting up to 15m0s for pod "adopt-release-h5ms6" in namespace "job-7227" to be "adopted"
Mar  3 13:58:19.283: INFO: Pod "adopt-release-h5ms6": Phase="Running", Reason="", readiness=true. Elapsed: 4.221983ms
Mar  3 13:58:21.289: INFO: Pod "adopt-release-h5ms6": Phase="Running", Reason="", readiness=true. Elapsed: 2.009352816s
Mar  3 13:58:21.289: INFO: Pod "adopt-release-h5ms6" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Mar  3 13:58:21.806: INFO: Successfully updated pod "adopt-release-h5ms6"
STEP: Checking that the Job releases the Pod
Mar  3 13:58:21.806: INFO: Waiting up to 15m0s for pod "adopt-release-h5ms6" in namespace "job-7227" to be "released"
Mar  3 13:58:21.810: INFO: Pod "adopt-release-h5ms6": Phase="Running", Reason="", readiness=true. Elapsed: 4.049081ms
Mar  3 13:58:23.816: INFO: Pod "adopt-release-h5ms6": Phase="Running", Reason="", readiness=true. Elapsed: 2.009555585s
Mar  3 13:58:23.816: INFO: Pod "adopt-release-h5ms6" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:58:23.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7227" for this suite.
Mar  3 13:59:07.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:59:08.048: INFO: namespace job-7227 deletion completed in 44.227019461s

• [SLOW TEST:51.373 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:59:08.048: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-ab2c7003-73be-47a0-9c5a-326591d74a7e
STEP: Creating a pod to test consume configMaps
Mar  3 13:59:08.155: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c786a585-44ba-414a-a0d1-febb8fbb8df6" in namespace "projected-8645" to be "success or failure"
Mar  3 13:59:08.159: INFO: Pod "pod-projected-configmaps-c786a585-44ba-414a-a0d1-febb8fbb8df6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.236132ms
Mar  3 13:59:10.165: INFO: Pod "pod-projected-configmaps-c786a585-44ba-414a-a0d1-febb8fbb8df6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00978892s
STEP: Saw pod success
Mar  3 13:59:10.165: INFO: Pod "pod-projected-configmaps-c786a585-44ba-414a-a0d1-febb8fbb8df6" satisfied condition "success or failure"
Mar  3 13:59:10.169: INFO: Trying to get logs from node 10.0.2.119 pod pod-projected-configmaps-c786a585-44ba-414a-a0d1-febb8fbb8df6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  3 13:59:10.197: INFO: Waiting for pod pod-projected-configmaps-c786a585-44ba-414a-a0d1-febb8fbb8df6 to disappear
Mar  3 13:59:10.201: INFO: Pod pod-projected-configmaps-c786a585-44ba-414a-a0d1-febb8fbb8df6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:59:10.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8645" for this suite.
Mar  3 13:59:16.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:59:16.447: INFO: namespace projected-8645 deletion completed in 6.241546119s

• [SLOW TEST:8.399 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  3 13:59:16.448: INFO: >>> kubeConfig: /tmp/kubeconfig-187709168
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  3 13:59:16.535: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"3b35327e-eef6-4e77-92de-0c5eeb5a1916", Controller:(*bool)(0xc008d31662), BlockOwnerDeletion:(*bool)(0xc008d31663)}}
Mar  3 13:59:16.553: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"4037fc7f-3a93-4d4e-8d26-cfbf5354d0d5", Controller:(*bool)(0xc00830a0b2), BlockOwnerDeletion:(*bool)(0xc00830a0b3)}}
Mar  3 13:59:16.562: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"375d0587-75a4-4e47-8d26-e8e0396ca53f", Controller:(*bool)(0xc008d31802), BlockOwnerDeletion:(*bool)(0xc008d31803)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  3 13:59:21.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5652" for this suite.
Mar  3 13:59:27.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  3 13:59:27.829: INFO: namespace gc-5652 deletion completed in 6.244894457s

• [SLOW TEST:11.381 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSMar  3 13:59:27.829: INFO: Running AfterSuite actions on all nodes
Mar  3 13:59:27.829: INFO: Running AfterSuite actions on node 1
Mar  3 13:59:27.829: INFO: Skipping dumping logs from cluster

Ran 276 of 4732 Specs in 6964.556 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4456 Skipped
PASS

Ginkgo ran 1 suite in 1h56m5.985628063s
Test Suite Passed
