  I0505 16:07:02.194428      22 e2e.go:117] Starting e2e run "36ac1179-7441-4802-bd3c-1c2016f45a78" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1714925221 - will randomize all specs

Will run 388 of 7407 specs
------------------------------
[ReportBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e_test.go:157
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:77
  May  5 16:07:02.325: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:07:02.326: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
  May  5 16:07:02.352: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  May  5 16:07:02.353: INFO: e2e test version: v1.29.4
  May  5 16:07:02.354: INFO: kube-apiserver version: v1.29.4
  May  5 16:07:02.354: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:07:02.356: INFO: Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.032 seconds]
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:446
  STEP: Creating a kubernetes client @ 05/05/24 16:07:02.474
  May  5 16:07:02.474: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename sched-pred @ 05/05/24 16:07:02.475
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:07:02.49
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:07:02.493
  May  5 16:07:02.497: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  May  5 16:07:02.502: INFO: Waiting for terminating namespaces to be deleted...
  May  5 16:07:02.507: INFO: 
  Logging pods the apiserver thinks is on node worker00 before test
  May  5 16:07:02.536: INFO: coredns-5b87cbd9d7-8hz87 from kube-system started at 2024-05-05 16:00:44 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.536: INFO: 	Container coredns ready: true, restart count 0
  May  5 16:07:02.536: INFO: coredns-5b87cbd9d7-xh2kv from kube-system started at 2024-05-05 16:00:44 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.536: INFO: 	Container coredns ready: true, restart count 0
  May  5 16:07:02.536: INFO: etcd-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.536: INFO: 	Container etcd ready: true, restart count 0
  May  5 16:07:02.536: INFO: gobetween-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.536: INFO: 	Container gobetween ready: true, restart count 0
  May  5 16:07:02.536: INFO: kube-apiserver-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.536: INFO: 	Container kube-apiserver ready: true, restart count 0
  May  5 16:07:02.536: INFO: kube-controller-manager-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.536: INFO: 	Container kube-controller-manager ready: true, restart count 0
  May  5 16:07:02.536: INFO: kube-proxy-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.536: INFO: 	Container kube-proxy ready: true, restart count 0
  May  5 16:07:02.536: INFO: kube-scheduler-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.536: INFO: 	Container kube-scheduler ready: true, restart count 0
  May  5 16:07:02.536: INFO: kubernetes-dashboard-api-86d45cdc48-l8gbt from kube-system started at 2024-05-05 16:04:44 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.536: INFO: 	Container kubernetes-dashboard-api ready: true, restart count 0
  May  5 16:07:02.536: INFO: kubernetes-dashboard-auth-5d859bc497-8c2jr from kube-system started at 2024-05-05 16:04:44 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.537: INFO: 	Container kubernetes-dashboard-auth ready: true, restart count 0
  May  5 16:07:02.537: INFO: kubernetes-dashboard-kong-766ffb8f6-7pg4h from kube-system started at 2024-05-05 16:04:44 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.537: INFO: 	Container proxy ready: true, restart count 0
  May  5 16:07:02.537: INFO: kubernetes-dashboard-metrics-scraper-56c9f5cc54-v6kph from kube-system started at 2024-05-05 16:04:44 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.537: INFO: 	Container kubernetes-dashboard-metrics-scraper ready: true, restart count 0
  May  5 16:07:02.537: INFO: kubernetes-dashboard-web-74dcc49f5-784mj from kube-system started at 2024-05-05 16:04:44 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.537: INFO: 	Container kubernetes-dashboard-web ready: true, restart count 0
  May  5 16:07:02.537: INFO: calico-kube-controllers-758c99c4b5-dlgfr from networking started at 2024-05-05 16:00:44 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.537: INFO: 	Container calico-kube-controllers ready: true, restart count 0
  May  5 16:07:02.537: INFO: calico-node-qbc8c from networking started at 2024-05-05 16:00:27 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.537: INFO: 	Container calico-node ready: true, restart count 0
  May  5 16:07:02.537: INFO: calico-typha-5cfbc84557-kj2xz from networking started at 2024-05-05 16:00:44 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.537: INFO: 	Container calico-typha ready: true, restart count 0
  May  5 16:07:02.537: INFO: metallb-controller-67f4cfb984-gbqv7 from networking started at 2024-05-05 16:00:44 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.537: INFO: 	Container controller ready: true, restart count 0
  May  5 16:07:02.537: INFO: metallb-speaker-cx4l2 from networking started at 2024-05-05 16:00:44 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.537: INFO: 	Container speaker ready: true, restart count 0
  May  5 16:07:02.537: INFO: sonobuoy from sonobuoy started at 2024-05-05 16:06:18 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.537: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  May  5 16:07:02.537: INFO: sonobuoy-e2e-job-919a92fc1d484e90 from sonobuoy started at 2024-05-05 16:06:24 +0000 UTC (2 container statuses recorded)
  May  5 16:07:02.537: INFO: 	Container e2e ready: true, restart count 0
  May  5 16:07:02.537: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May  5 16:07:02.537: INFO: sonobuoy-systemd-logs-daemon-set-75c9f5cbb2184229-8sxzt from sonobuoy started at 2024-05-05 16:06:24 +0000 UTC (2 container statuses recorded)
  May  5 16:07:02.537: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May  5 16:07:02.537: INFO: 	Container systemd-logs ready: true, restart count 0
  May  5 16:07:02.537: INFO: ceph-csi-cephfs-nodeplugin-6sg4j from storage started at 2024-05-05 16:00:27 +0000 UTC (3 container statuses recorded)
  May  5 16:07:02.537: INFO: 	Container csi-cephfsplugin ready: true, restart count 0
  May  5 16:07:02.537: INFO: 	Container driver-registrar ready: true, restart count 0
  May  5 16:07:02.537: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:07:02.537: INFO: ceph-csi-rbd-nodeplugin-8mb94 from storage started at 2024-05-05 16:00:27 +0000 UTC (3 container statuses recorded)
  May  5 16:07:02.537: INFO: 	Container csi-rbdplugin ready: true, restart count 0
  May  5 16:07:02.537: INFO: 	Container driver-registrar ready: true, restart count 0
  May  5 16:07:02.537: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:07:02.537: INFO: ceph-mon-worker00-797bf6469d-qjl6t from storage started at 2024-05-05 16:00:28 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.537: INFO: 	Container ceph-mon ready: true, restart count 0
  May  5 16:07:02.537: INFO: snapshot-controller-587656f7cd-7xn6c from storage started at 2024-05-05 16:00:44 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.537: INFO: 	Container snapshot-controller ready: true, restart count 0
  May  5 16:07:02.537: INFO: snapshot-controller-587656f7cd-zzcw4 from storage started at 2024-05-05 16:00:44 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.537: INFO: 	Container snapshot-controller ready: true, restart count 0
  May  5 16:07:02.537: INFO: snapshot-validation-webhook-64b8d8cb7b-sqjt9 from storage started at 2024-05-05 16:00:44 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.537: INFO: 	Container snapshot-validation-webhook ready: true, restart count 0
  May  5 16:07:02.537: INFO: 
  Logging pods the apiserver thinks is on node worker01 before test
  May  5 16:07:02.546: INFO: gobetween-worker01 from kube-system started at 2024-05-05 15:59:42 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.546: INFO: 	Container gobetween ready: true, restart count 0
  May  5 16:07:02.546: INFO: kube-proxy-worker01 from kube-system started at 2024-05-05 15:59:42 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.546: INFO: 	Container kube-proxy ready: true, restart count 0
  May  5 16:07:02.546: INFO: calico-node-7g4c9 from networking started at 2024-05-05 16:00:29 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.546: INFO: 	Container calico-node ready: true, restart count 0
  May  5 16:07:02.546: INFO: metallb-speaker-22x22 from networking started at 2024-05-05 16:00:48 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.546: INFO: 	Container speaker ready: true, restart count 0
  May  5 16:07:02.546: INFO: sonobuoy-systemd-logs-daemon-set-75c9f5cbb2184229-mw8sz from sonobuoy started at 2024-05-05 16:06:25 +0000 UTC (2 container statuses recorded)
  May  5 16:07:02.546: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May  5 16:07:02.546: INFO: 	Container systemd-logs ready: true, restart count 0
  May  5 16:07:02.546: INFO: ceph-csi-cephfs-nodeplugin-xsgjl from storage started at 2024-05-05 16:00:29 +0000 UTC (3 container statuses recorded)
  May  5 16:07:02.546: INFO: 	Container csi-cephfsplugin ready: true, restart count 0
  May  5 16:07:02.546: INFO: 	Container driver-registrar ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:07:02.547: INFO: ceph-csi-cephfs-provisioner-6dc49995f7-lqt4k from storage started at 2024-05-05 16:00:29 +0000 UTC (5 container statuses recorded)
  May  5 16:07:02.547: INFO: 	Container csi-cephfsplugin ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:07:02.547: INFO: ceph-csi-cephfs-provisioner-6dc49995f7-svr4r from storage started at 2024-05-05 16:00:29 +0000 UTC (5 container statuses recorded)
  May  5 16:07:02.547: INFO: 	Container csi-cephfsplugin ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:07:02.547: INFO: ceph-csi-cephfs-provisioner-6dc49995f7-tfb66 from storage started at 2024-05-05 16:00:29 +0000 UTC (5 container statuses recorded)
  May  5 16:07:02.547: INFO: 	Container csi-cephfsplugin ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:07:02.547: INFO: ceph-csi-rbd-nodeplugin-cmg7z from storage started at 2024-05-05 16:00:29 +0000 UTC (3 container statuses recorded)
  May  5 16:07:02.547: INFO: 	Container csi-rbdplugin ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container driver-registrar ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:07:02.547: INFO: ceph-csi-rbd-provisioner-55f5bd6544-8f77n from storage started at 2024-05-05 16:00:29 +0000 UTC (7 container statuses recorded)
  May  5 16:07:02.547: INFO: 	Container csi-attacher ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-rbdplugin ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-rbdplugin-controller ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:07:02.547: INFO: ceph-csi-rbd-provisioner-55f5bd6544-bgrv6 from storage started at 2024-05-05 16:00:29 +0000 UTC (7 container statuses recorded)
  May  5 16:07:02.547: INFO: 	Container csi-attacher ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-rbdplugin ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-rbdplugin-controller ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:07:02.547: INFO: ceph-csi-rbd-provisioner-55f5bd6544-v9llp from storage started at 2024-05-05 16:00:29 +0000 UTC (7 container statuses recorded)
  May  5 16:07:02.547: INFO: 	Container csi-attacher ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-rbdplugin ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-rbdplugin-controller ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 16:07:02.547: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:07:02.547: INFO: ceph-mds-worker01-798b64d68-wr2nm from storage started at 2024-05-05 16:00:29 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.547: INFO: 	Container ceph-mds ready: true, restart count 0
  May  5 16:07:02.547: INFO: ceph-mgr-worker01-7c4c56cf76-hn7lr from storage started at 2024-05-05 16:00:29 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.547: INFO: 	Container ceph-mgr ready: true, restart count 0
  May  5 16:07:02.547: INFO: ceph-osd-worker01-75d7885b87-5cqv9 from storage started at 2024-05-05 16:00:29 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.547: INFO: 	Container ceph-osd ready: true, restart count 0
  May  5 16:07:02.547: INFO: ceph-rgw-worker01-5bd8c8bf8b-k4vwv from storage started at 2024-05-05 16:00:29 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.547: INFO: 	Container ceph-rgw ready: true, restart count 0
  May  5 16:07:02.547: INFO: ceph-setup-wh6dw from storage started at 2024-05-05 16:00:28 +0000 UTC (1 container statuses recorded)
  May  5 16:07:02.547: INFO: 	Container ceph ready: false, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 05/05/24 16:07:02.547
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.17cca3676398c8ae], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match Pod's node affinity/selector. preemption: 0/2 nodes are available: 2 Preemption is not helpful for scheduling.] @ 05/05/24 16:07:02.576
  May  5 16:07:03.577: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-7512" for this suite. @ 05/05/24 16:07:03.581
• [1.117 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:109
  STEP: Creating a kubernetes client @ 05/05/24 16:07:03.592
  May  5 16:07:03.592: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubelet-test @ 05/05/24 16:07:03.594
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:07:03.616
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:07:03.619
  May  5 16:07:07.642: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-5079" for this suite. @ 05/05/24 16:07:07.644
• [4.056 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:209
  STEP: Creating a kubernetes client @ 05/05/24 16:07:07.648
  May  5 16:07:07.648: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 16:07:07.649
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:07:07.658
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:07:07.66
  STEP: Creating a pod to test downward API volume plugin @ 05/05/24 16:07:07.662
  STEP: Saw pod success @ 05/05/24 16:07:17.706
  May  5 16:07:17.710: INFO: Trying to get logs from node worker00 pod downwardapi-volume-525f7b7b-3792-4744-ae8c-8228bdb0e9b7 container client-container: <nil>
  STEP: delete the pod @ 05/05/24 16:07:17.736
  May  5 16:07:17.758: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6766" for this suite. @ 05/05/24 16:07:17.764
• [10.122 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 05/05/24 16:07:17.771
  May  5 16:07:17.771: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename secrets @ 05/05/24 16:07:17.773
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:07:17.798
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:07:17.803
  STEP: Creating secret with name secret-test-map-6cc6c542-fa6b-4d0d-8d04-d354e2fb7d6f @ 05/05/24 16:07:17.807
  STEP: Creating a pod to test consume secrets @ 05/05/24 16:07:17.814
  STEP: Saw pod success @ 05/05/24 16:07:21.841
  May  5 16:07:21.843: INFO: Trying to get logs from node worker00 pod pod-secrets-fae652c6-9bad-4366-a78d-dc68bdb2fc0c container secret-volume-test: <nil>
  STEP: delete the pod @ 05/05/24 16:07:21.847
  May  5 16:07:21.858: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1869" for this suite. @ 05/05/24 16:07:21.861
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:349
  STEP: Creating a kubernetes client @ 05/05/24 16:07:21.866
  May  5 16:07:21.866: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename security-context-test @ 05/05/24 16:07:21.866
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:07:21.878
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:07:21.879
  May  5 16:07:23.905: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-1756" for this suite. @ 05/05/24 16:07:23.908
• [2.049 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:104
  STEP: Creating a kubernetes client @ 05/05/24 16:07:23.914
  May  5 16:07:23.914: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename replication-controller @ 05/05/24 16:07:23.916
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:07:23.927
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:07:23.929
  STEP: Given a ReplicationController is created @ 05/05/24 16:07:23.932
  STEP: When the matched label of one of its pods change @ 05/05/24 16:07:23.938
  May  5 16:07:23.940: INFO: Pod name pod-release: Found 0 pods out of 1
  May  5 16:07:28.950: INFO: Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 05/05/24 16:07:28.956
  May  5 16:07:29.964: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-1016" for this suite. @ 05/05/24 16:07:29.966
• [6.056 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:132
  STEP: Creating a kubernetes client @ 05/05/24 16:07:29.972
  May  5 16:07:29.972: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename replicaset @ 05/05/24 16:07:29.973
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:07:29.99
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:07:29.996
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 05/05/24 16:07:29.999
  STEP: When a replicaset with a matching selector is created @ 05/05/24 16:07:32.015
  STEP: Then the orphan pod is adopted @ 05/05/24 16:07:32.03
  STEP: When the matched label of one of its pods change @ 05/05/24 16:07:33.046
  May  5 16:07:33.053: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 05/05/24 16:07:33.077
  May  5 16:07:33.095: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4623" for this suite. @ 05/05/24 16:07:33.107
• [3.170 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:344
  STEP: Creating a kubernetes client @ 05/05/24 16:07:33.142
  May  5 16:07:33.143: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubectl @ 05/05/24 16:07:33.148
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:07:33.171
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:07:33.175
  STEP: creating a replication controller @ 05/05/24 16:07:33.181
  May  5 16:07:33.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9239 create -f -'
  May  5 16:07:33.352: INFO: stderr: ""
  May  5 16:07:33.352: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/05/24 16:07:33.352
  May  5 16:07:33.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9239 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May  5 16:07:33.445: INFO: stderr: ""
  May  5 16:07:33.445: INFO: stdout: "update-demo-nautilus-67m5k update-demo-nautilus-t4vtt "
  May  5 16:07:33.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9239 get pods update-demo-nautilus-67m5k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May  5 16:07:33.504: INFO: stderr: ""
  May  5 16:07:33.504: INFO: stdout: ""
  May  5 16:07:33.504: INFO: update-demo-nautilus-67m5k is created but not running
  May  5 16:07:38.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9239 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May  5 16:07:38.601: INFO: stderr: ""
  May  5 16:07:38.602: INFO: stdout: "update-demo-nautilus-67m5k update-demo-nautilus-t4vtt "
  May  5 16:07:38.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9239 get pods update-demo-nautilus-67m5k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May  5 16:07:38.703: INFO: stderr: ""
  May  5 16:07:38.703: INFO: stdout: ""
  May  5 16:07:38.703: INFO: update-demo-nautilus-67m5k is created but not running
  May  5 16:07:43.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9239 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May  5 16:07:43.758: INFO: stderr: ""
  May  5 16:07:43.758: INFO: stdout: "update-demo-nautilus-67m5k update-demo-nautilus-t4vtt "
  May  5 16:07:43.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9239 get pods update-demo-nautilus-67m5k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May  5 16:07:43.806: INFO: stderr: ""
  May  5 16:07:43.806: INFO: stdout: "true"
  May  5 16:07:43.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9239 get pods update-demo-nautilus-67m5k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  May  5 16:07:43.855: INFO: stderr: ""
  May  5 16:07:43.855: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May  5 16:07:43.855: INFO: validating pod update-demo-nautilus-67m5k
  May  5 16:07:43.859: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May  5 16:07:43.859: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May  5 16:07:43.859: INFO: update-demo-nautilus-67m5k is verified up and running
  May  5 16:07:43.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9239 get pods update-demo-nautilus-t4vtt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May  5 16:07:43.914: INFO: stderr: ""
  May  5 16:07:43.915: INFO: stdout: "true"
  May  5 16:07:43.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9239 get pods update-demo-nautilus-t4vtt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  May  5 16:07:43.971: INFO: stderr: ""
  May  5 16:07:43.971: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May  5 16:07:43.971: INFO: validating pod update-demo-nautilus-t4vtt
  May  5 16:07:43.976: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May  5 16:07:43.976: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May  5 16:07:43.976: INFO: update-demo-nautilus-t4vtt is verified up and running
  STEP: using delete to clean up resources @ 05/05/24 16:07:43.976
  May  5 16:07:43.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9239 delete --grace-period=0 --force -f -'
  May  5 16:07:44.031: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May  5 16:07:44.031: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  May  5 16:07:44.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9239 get rc,svc -l name=update-demo --no-headers'
  May  5 16:07:44.092: INFO: stderr: "No resources found in kubectl-9239 namespace.\n"
  May  5 16:07:44.092: INFO: stdout: ""
  May  5 16:07:44.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9239 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  May  5 16:07:44.144: INFO: stderr: ""
  May  5 16:07:44.144: INFO: stdout: ""
  May  5 16:07:44.144: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9239" for this suite. @ 05/05/24 16:07:44.147
• [11.008 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:397
  STEP: Creating a kubernetes client @ 05/05/24 16:07:44.151
  May  5 16:07:44.151: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename resourcequota @ 05/05/24 16:07:44.152
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:07:44.161
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:07:44.164
  STEP: Counting existing ResourceQuota @ 05/05/24 16:07:44.166
  STEP: Creating a ResourceQuota @ 05/05/24 16:07:49.169
  STEP: Ensuring resource quota status is calculated @ 05/05/24 16:07:49.182
  STEP: Creating a ReplicationController @ 05/05/24 16:07:51.187
  STEP: Ensuring resource quota status captures replication controller creation @ 05/05/24 16:07:51.211
  STEP: Deleting a ReplicationController @ 05/05/24 16:07:53.216
  STEP: Ensuring resource quota status released usage @ 05/05/24 16:07:53.221
  May  5 16:07:55.226: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4787" for this suite. @ 05/05/24 16:07:55.23
• [11.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:324
  STEP: Creating a kubernetes client @ 05/05/24 16:07:55.234
  May  5 16:07:55.234: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename cronjob @ 05/05/24 16:07:55.235
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:07:55.244
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:07:55.248
  STEP: Creating a cronjob @ 05/05/24 16:07:55.25
  STEP: creating @ 05/05/24 16:07:55.25
  STEP: getting @ 05/05/24 16:07:55.254
  STEP: listing @ 05/05/24 16:07:55.256
  STEP: watching @ 05/05/24 16:07:55.258
  May  5 16:07:55.258: INFO: starting watch
  STEP: cluster-wide listing @ 05/05/24 16:07:55.259
  STEP: cluster-wide watching @ 05/05/24 16:07:55.261
  May  5 16:07:55.261: INFO: starting watch
  STEP: patching @ 05/05/24 16:07:55.262
  STEP: updating @ 05/05/24 16:07:55.268
  May  5 16:07:55.273: INFO: waiting for watch events with expected annotations
  May  5 16:07:55.273: INFO: saw patched and updated annotations
  STEP: patching /status @ 05/05/24 16:07:55.273
  STEP: updating /status @ 05/05/24 16:07:55.278
  STEP: get /status @ 05/05/24 16:07:55.283
  STEP: deleting @ 05/05/24 16:07:55.285
  STEP: deleting a collection @ 05/05/24 16:07:55.292
  May  5 16:07:55.298: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-3300" for this suite. @ 05/05/24 16:07:55.301
• [0.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:350
  STEP: Creating a kubernetes client @ 05/05/24 16:07:55.307
  May  5 16:07:55.307: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename field-validation @ 05/05/24 16:07:55.309
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:07:55.318
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:07:55.322
  May  5 16:07:55.324: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  W0505 16:07:55.325408      22 field_validation.go:423] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc0009960f0 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  W0505 16:07:57.868188      22 warnings.go:70] unknown field "alpha"
  W0505 16:07:57.868247      22 warnings.go:70] unknown field "beta"
  W0505 16:07:57.868261      22 warnings.go:70] unknown field "delta"
  W0505 16:07:57.868273      22 warnings.go:70] unknown field "epsilon"
  W0505 16:07:57.868285      22 warnings.go:70] unknown field "gamma"
  May  5 16:07:58.407: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-1250" for this suite. @ 05/05/24 16:07:58.412
• [3.116 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:237
  STEP: Creating a kubernetes client @ 05/05/24 16:07:58.424
  May  5 16:07:58.424: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename downward-api @ 05/05/24 16:07:58.425
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:07:58.45
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:07:58.46
  STEP: Creating a pod to test downward API volume plugin @ 05/05/24 16:07:58.468
  STEP: Saw pod success @ 05/05/24 16:08:08.537
  May  5 16:08:08.540: INFO: Trying to get logs from node worker01 pod downwardapi-volume-c5a2f740-62aa-4eaf-b65b-cf170a31a9b4 container client-container: <nil>
  STEP: delete the pod @ 05/05/24 16:08:08.559
  May  5 16:08:08.574: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9402" for this suite. @ 05/05/24 16:08:08.578
• [10.159 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:155
  STEP: Creating a kubernetes client @ 05/05/24 16:08:08.585
  May  5 16:08:08.585: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename secrets @ 05/05/24 16:08:08.586
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:08:08.601
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:08:08.603
  STEP: creating a secret @ 05/05/24 16:08:08.606
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 05/05/24 16:08:08.61
  STEP: patching the secret @ 05/05/24 16:08:08.615
  STEP: deleting the secret using a LabelSelector @ 05/05/24 16:08:08.622
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 05/05/24 16:08:08.629
  May  5 16:08:08.632: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5554" for this suite. @ 05/05/24 16:08:08.635
• [0.054 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:164
  STEP: Creating a kubernetes client @ 05/05/24 16:08:08.639
  May  5 16:08:08.639: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 16:08:08.64
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:08:08.65
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:08:08.655
  STEP: Creating the pod @ 05/05/24 16:08:08.657
  May  5 16:08:11.212: INFO: Successfully updated pod "annotationupdatee98cf94e-3178-411d-ae42-ca9cbd609d84"
  May  5 16:08:13.225: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6092" for this suite. @ 05/05/24 16:08:13.228
• [4.591 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:95
  STEP: Creating a kubernetes client @ 05/05/24 16:08:13.232
  May  5 16:08:13.232: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename var-expansion @ 05/05/24 16:08:13.235
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:08:13.256
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:08:13.266
  STEP: Creating a pod to test substitution in container's args @ 05/05/24 16:08:13.272
  STEP: Saw pod success @ 05/05/24 16:08:17.292
  May  5 16:08:17.294: INFO: Trying to get logs from node worker01 pod var-expansion-04a24be5-4e2a-4509-8c73-ead621c228ad container dapi-container: <nil>
  STEP: delete the pod @ 05/05/24 16:08:17.299
  May  5 16:08:17.316: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7289" for this suite. @ 05/05/24 16:08:17.32
• [4.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 05/05/24 16:08:17.324
  May  5 16:08:17.324: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename daemonsets @ 05/05/24 16:08:17.326
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:08:17.348
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:08:17.352
  STEP: Creating a simple DaemonSet "daemon-set" @ 05/05/24 16:08:17.369
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/05/24 16:08:17.377
  May  5 16:08:17.384: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 16:08:17.384: INFO: Node worker00 is running 0 daemon pod, expected 1
  May  5 16:08:18.385: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 16:08:18.385: INFO: Node worker00 is running 0 daemon pod, expected 1
  May  5 16:08:19.383: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May  5 16:08:19.383: INFO: Node worker00 is running 0 daemon pod, expected 1
  May  5 16:08:20.387: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May  5 16:08:20.387: INFO: Node worker00 is running 0 daemon pod, expected 1
  May  5 16:08:21.385: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May  5 16:08:21.385: INFO: Node worker00 is running 0 daemon pod, expected 1
  May  5 16:08:22.385: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May  5 16:08:22.385: INFO: Node worker00 is running 0 daemon pod, expected 1
  May  5 16:08:23.383: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May  5 16:08:23.383: INFO: Node worker00 is running 0 daemon pod, expected 1
  May  5 16:08:24.388: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May  5 16:08:24.388: INFO: Node worker00 is running 0 daemon pod, expected 1
  May  5 16:08:25.383: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May  5 16:08:25.383: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 05/05/24 16:08:25.387
  May  5 16:08:25.427: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May  5 16:08:25.427: INFO: Node worker00 is running 0 daemon pod, expected 1
  May  5 16:08:26.411: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May  5 16:08:26.411: INFO: Node worker00 is running 0 daemon pod, expected 1
  May  5 16:08:27.408: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May  5 16:08:27.408: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 05/05/24 16:08:27.408
  STEP: Deleting DaemonSet "daemon-set" @ 05/05/24 16:08:27.412
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3391, will wait for the garbage collector to delete the pods @ 05/05/24 16:08:27.412
  May  5 16:08:27.471: INFO: Deleting DaemonSet.extensions daemon-set took: 4.697674ms
  May  5 16:08:27.575: INFO: Terminating DaemonSet.extensions daemon-set pods took: 103.857033ms
  May  5 16:08:29.877: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 16:08:29.877: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  May  5 16:08:29.880: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"3565"},"items":null}

  May  5 16:08:29.883: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"3565"},"items":null}

  May  5 16:08:29.895: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3391" for this suite. @ 05/05/24 16:08:29.898
• [12.582 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:198
  STEP: Creating a kubernetes client @ 05/05/24 16:08:29.906
  May  5 16:08:29.906: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename container-probe @ 05/05/24 16:08:29.907
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:08:29.928
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:08:29.937
  STEP: Creating pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607 @ 05/05/24 16:08:29.941
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/05/24 16:08:31.961
  May  5 16:08:31.963: INFO: Initial restart count of pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f is 0
  May  5 16:08:31.966: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:08:33.971: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:08:35.976: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:08:37.979: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:08:39.983: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:08:41.991: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:08:44.000: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:08:46.009: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:08:48.025: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:08:50.029: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:08:52.035: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:08:52.035: INFO: Restart count of pod container-probe-2607/liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f is now 1 (20.071480769s elapsed)
  May  5 16:08:54.041: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:08:56.049: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:08:58.056: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:00.061: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:02.064: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:04.067: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:06.073: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:08.076: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:10.083: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:12.091: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:12.091: INFO: Restart count of pod container-probe-2607/liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f is now 2 (40.127777522s elapsed)
  May  5 16:09:14.100: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:16.108: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:18.114: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:20.117: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:22.125: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:24.129: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:26.134: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:28.139: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:30.145: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:32.150: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:32.150: INFO: Restart count of pod container-probe-2607/liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f is now 3 (1m0.186686911s elapsed)
  May  5 16:09:34.156: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:36.163: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:38.168: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:40.172: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:42.177: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:44.183: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:46.186: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:48.191: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:50.198: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:52.204: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:52.204: INFO: Restart count of pod container-probe-2607/liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f is now 4 (1m20.240543296s elapsed)
  May  5 16:09:54.212: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:56.217: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:09:58.221: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:00.225: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:02.234: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:04.239: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:06.243: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:08.252: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:10.259: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:12.262: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:14.267: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:16.270: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:18.273: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:20.281: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:22.283: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:24.287: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:26.289: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:28.295: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:30.304: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:32.309: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:34.314: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:36.322: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:38.327: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:40.336: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:42.340: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:44.347: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:46.355: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:48.362: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:50.370: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:52.378: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:54.380: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:56.385: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:10:58.391: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:11:00.398: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:11:02.406: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:11:04.410: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:11:06.420: INFO: Get pod liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f in namespace container-probe-2607
  May  5 16:11:06.420: INFO: Restart count of pod container-probe-2607/liveness-f4c5ca65-4753-4cf8-90d8-b5dffe6f270f is now 5 (2m34.457021477s elapsed)
  STEP: deleting the pod @ 05/05/24 16:11:06.421
  May  5 16:11:06.433: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2607" for this suite. @ 05/05/24 16:11:06.439
• [156.539 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:572
  STEP: Creating a kubernetes client @ 05/05/24 16:11:06.446
  May  5 16:11:06.446: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename webhook @ 05/05/24 16:11:06.447
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:11:06.46
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:11:06.464
  STEP: Setting up server cert @ 05/05/24 16:11:06.482
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/05/24 16:11:06.647
  STEP: Deploying the webhook pod @ 05/05/24 16:11:06.652
  STEP: Wait for the deployment to be ready @ 05/05/24 16:11:06.661
  May  5 16:11:06.670: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/05/24 16:11:08.681
  STEP: Verifying the service has paired with the endpoint @ 05/05/24 16:11:08.706
  May  5 16:11:09.706: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 05/05/24 16:11:09.77
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/05/24 16:11:09.803
  STEP: Deleting the collection of validation webhooks @ 05/05/24 16:11:09.822
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/05/24 16:11:09.853
  May  5 16:11:09.900: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1625" for this suite. @ 05/05/24 16:11:09.902
  STEP: Destroying namespace "webhook-markers-692" for this suite. @ 05/05/24 16:11:09.914
• [3.480 seconds]
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:236
  STEP: Creating a kubernetes client @ 05/05/24 16:11:09.926
  May  5 16:11:09.926: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/05/24 16:11:09.928
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:11:09.941
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:11:09.945
  May  5 16:11:09.948: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 05/05/24 16:11:11.272
  May  5 16:11:11.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-9279 --namespace=crd-publish-openapi-9279 create -f -'
  May  5 16:11:11.360: INFO: stderr: ""
  May  5 16:11:11.360: INFO: stdout: "e2e-test-crd-publish-openapi-3918-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  May  5 16:11:11.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-9279 --namespace=crd-publish-openapi-9279 delete e2e-test-crd-publish-openapi-3918-crds test-cr'
  May  5 16:11:11.451: INFO: stderr: ""
  May  5 16:11:11.451: INFO: stdout: "e2e-test-crd-publish-openapi-3918-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  May  5 16:11:11.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-9279 --namespace=crd-publish-openapi-9279 apply -f -'
  May  5 16:11:11.590: INFO: stderr: ""
  May  5 16:11:11.590: INFO: stdout: "e2e-test-crd-publish-openapi-3918-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  May  5 16:11:11.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-9279 --namespace=crd-publish-openapi-9279 delete e2e-test-crd-publish-openapi-3918-crds test-cr'
  May  5 16:11:11.712: INFO: stderr: ""
  May  5 16:11:11.712: INFO: stdout: "e2e-test-crd-publish-openapi-3918-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 05/05/24 16:11:11.712
  May  5 16:11:11.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-9279 explain e2e-test-crd-publish-openapi-3918-crds'
  May  5 16:11:11.797: INFO: stderr: ""
  May  5 16:11:11.797: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-3918-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  May  5 16:11:13.163: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9279" for this suite. @ 05/05/24 16:11:13.173
• [3.254 seconds]
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:219
  STEP: Creating a kubernetes client @ 05/05/24 16:11:13.182
  May  5 16:11:13.182: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename downward-api @ 05/05/24 16:11:13.186
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:11:13.209
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:11:13.213
  STEP: Creating a pod to test downward api env vars @ 05/05/24 16:11:13.217
  STEP: Saw pod success @ 05/05/24 16:11:17.24
  May  5 16:11:17.242: INFO: Trying to get logs from node worker00 pod downward-api-06d05f36-97f9-4212-8f79-83df73c465ac container dapi-container: <nil>
  STEP: delete the pod @ 05/05/24 16:11:17.25
  May  5 16:11:17.266: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3251" for this suite. @ 05/05/24 16:11:17.27
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 05/05/24 16:11:17.276
  May  5 16:11:17.276: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename dns @ 05/05/24 16:11:17.278
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:11:17.292
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:11:17.296
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8780.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8780.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 05/05/24 16:11:17.299
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8780.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8780.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 05/05/24 16:11:17.299
  STEP: creating a pod to probe /etc/hosts @ 05/05/24 16:11:17.299
  STEP: submitting the pod to kubernetes @ 05/05/24 16:11:17.299
  STEP: retrieving the pod @ 05/05/24 16:11:33.357
  STEP: looking for the results for each expected name from probers @ 05/05/24 16:11:33.361
  May  5 16:11:33.375: INFO: DNS probes using dns-8780/dns-test-2ae0c0cf-73ac-458a-8818-c72b71b1e3c7 succeeded

  STEP: deleting the pod @ 05/05/24 16:11:33.375
  May  5 16:11:33.386: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-8780" for this suite. @ 05/05/24 16:11:33.391
• [16.119 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:669
  STEP: Creating a kubernetes client @ 05/05/24 16:11:33.396
  May  5 16:11:33.396: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename pv @ 05/05/24 16:11:33.397
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:11:33.411
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:11:33.414
  STEP: Creating initial PV and PVC @ 05/05/24 16:11:33.417
  May  5 16:11:33.417: INFO: Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-577" @ 05/05/24 16:11:33.427
  STEP: Listing PVCs in namespace "pv-577" @ 05/05/24 16:11:33.431
  STEP: Reading "pvc-ljfwl" Status @ 05/05/24 16:11:33.436
  STEP: Reading "pv-577-5pq88" Status @ 05/05/24 16:11:33.438
  STEP: Patching "pvc-ljfwl" Status @ 05/05/24 16:11:33.442
  STEP: Patching "pv-577-5pq88" Status @ 05/05/24 16:11:33.445
  STEP: Updating "pvc-ljfwl" Status @ 05/05/24 16:11:33.451
  STEP: Updating "pv-577-5pq88" Status @ 05/05/24 16:11:33.457
  May  5 16:11:33.484: INFO: AfterEach: deleting 1 PVCs and 1 PVs...
  May  5 16:11:33.484: INFO: Deleting PersistentVolumeClaim "pvc-ljfwl"
  May  5 16:11:33.488: INFO: Deleting PersistentVolume "pv-577-5pq88"
  May  5 16:11:33.495: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-577" for this suite. @ 05/05/24 16:11:33.501
• [0.109 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:98
  STEP: Creating a kubernetes client @ 05/05/24 16:11:33.507
  May  5 16:11:33.507: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename aggregator @ 05/05/24 16:11:33.51
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:11:33.52
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:11:33.525
  May  5 16:11:33.529: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Registering the sample API server. @ 05/05/24 16:11:33.53
  May  5 16:11:33.647: INFO: Found ClusterRoles; assuming RBAC is enabled.
  May  5 16:11:33.662: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
  May  5 16:11:35.705: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  May  5 16:11:37.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  May  5 16:11:39.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  May  5 16:11:41.713: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  May  5 16:11:43.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  May  5 16:11:45.712: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  May  5 16:11:47.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  May  5 16:11:49.708: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  May  5 16:11:51.716: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  May  5 16:11:53.715: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  May  5 16:11:55.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  May  5 16:11:57.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 33, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  May  5 16:11:59.826: INFO: Waited 113.138467ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 05/05/24 16:11:59.872
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 05/05/24 16:11:59.874
  STEP: List APIServices @ 05/05/24 16:11:59.881
  May  5 16:11:59.890: INFO: Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 05/05/24 16:11:59.89
  May  5 16:11:59.901: INFO: APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 05/05/24 16:11:59.901
  May  5 16:11:59.908: INFO: updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2024, time.May, 5, 16, 11, 59, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 05/05/24 16:11:59.908
  May  5 16:11:59.912: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2024-05-05 16:11:59 +0000 UTC Passed all checks passed}
  May  5 16:11:59.912: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  May  5 16:11:59.912: INFO: Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 05/05/24 16:11:59.912
  May  5 16:11:59.920: INFO: Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-864411579" @ 05/05/24 16:11:59.92
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 05/05/24 16:11:59.933
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 05/05/24 16:11:59.94
  STEP: Patch APIService Status @ 05/05/24 16:11:59.943
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 05/05/24 16:11:59.951
  May  5 16:11:59.955: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2024-05-05 16:11:59 +0000 UTC Passed all checks passed}
  May  5 16:11:59.955: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  May  5 16:11:59.955: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  May  5 16:11:59.955: INFO: Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 05/05/24 16:11:59.955
  STEP: Confirm that the generated APIService has been deleted @ 05/05/24 16:11:59.963
  May  5 16:11:59.963: INFO: Requesting list of APIServices to confirm quantity
  May  5 16:11:59.967: INFO: Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  May  5 16:11:59.967: INFO: APIService v1alpha1.wardle.example.com has been deleted.
  May  5 16:12:00.058: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-4015" for this suite. @ 05/05/24 16:12:00.062
• [26.562 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:170
  STEP: Creating a kubernetes client @ 05/05/24 16:12:00.069
  May  5 16:12:00.069: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename configmap @ 05/05/24 16:12:00.07
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:12:00.083
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:12:00.086
  STEP: creating a ConfigMap @ 05/05/24 16:12:00.089
  STEP: fetching the ConfigMap @ 05/05/24 16:12:00.094
  STEP: patching the ConfigMap @ 05/05/24 16:12:00.098
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 05/05/24 16:12:00.102
  STEP: deleting the ConfigMap by collection with a label selector @ 05/05/24 16:12:00.106
  STEP: listing all ConfigMaps in test namespace @ 05/05/24 16:12:00.11
  May  5 16:12:00.115: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4447" for this suite. @ 05/05/24 16:12:00.12
• [0.055 seconds]
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:241
  STEP: Creating a kubernetes client @ 05/05/24 16:12:00.124
  May  5 16:12:00.124: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename configmap @ 05/05/24 16:12:00.126
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:12:00.139
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:12:00.142
  STEP: Creating configMap with name cm-test-opt-del-bd412b12-d065-41e1-82d8-c380016628de @ 05/05/24 16:12:00.148
  STEP: Creating configMap with name cm-test-opt-upd-4275a8b2-faa9-400b-a35c-eddfc71e81a8 @ 05/05/24 16:12:00.154
  STEP: Creating the pod @ 05/05/24 16:12:00.16
  STEP: Deleting configmap cm-test-opt-del-bd412b12-d065-41e1-82d8-c380016628de @ 05/05/24 16:12:02.207
  STEP: Updating configmap cm-test-opt-upd-4275a8b2-faa9-400b-a35c-eddfc71e81a8 @ 05/05/24 16:12:02.21
  STEP: Creating configMap with name cm-test-opt-create-5764b04b-f2b7-4415-917c-d1d6a8b05954 @ 05/05/24 16:12:02.215
  STEP: waiting to observe update in volume @ 05/05/24 16:12:02.219
  May  5 16:12:04.245: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1289" for this suite. @ 05/05/24 16:12:04.25
• [4.131 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:305
  STEP: Creating a kubernetes client @ 05/05/24 16:12:04.256
  May  5 16:12:04.256: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename namespaces @ 05/05/24 16:12:04.258
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:12:04.277
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:12:04.284
  STEP: Read namespace status @ 05/05/24 16:12:04.286
  May  5 16:12:04.292: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 05/05/24 16:12:04.292
  May  5 16:12:04.301: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 05/05/24 16:12:04.301
  May  5 16:12:04.311: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  May  5 16:12:04.311: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-3072" for this suite. @ 05/05/24 16:12:04.315
• [0.066 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:147
  STEP: Creating a kubernetes client @ 05/05/24 16:12:04.323
  May  5 16:12:04.323: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubelet-test @ 05/05/24 16:12:04.324
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:12:04.344
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:12:04.351
  STEP: Waiting for pod completion @ 05/05/24 16:12:04.368
  May  5 16:12:08.394: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6669" for this suite. @ 05/05/24 16:12:08.407
• [4.138 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:183
  STEP: Creating a kubernetes client @ 05/05/24 16:12:08.464
  May  5 16:12:08.464: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename container-probe @ 05/05/24 16:12:08.467
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:12:08.481
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:12:08.487
  STEP: Creating pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516 @ 05/05/24 16:12:08.492
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/05/24 16:12:10.507
  May  5 16:12:10.513: INFO: Initial restart count of pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 is 0
  May  5 16:12:10.516: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:12.525: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:14.532: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:16.537: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:18.542: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:20.547: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:22.553: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:24.558: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:26.563: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:28.571: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:30.577: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:32.583: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:34.587: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:36.591: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:38.596: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:40.603: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:42.608: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:44.611: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:46.613: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:48.619: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:50.623: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:52.630: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:54.638: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:56.644: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:12:58.647: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:00.652: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:02.658: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:04.664: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:06.673: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:08.676: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:10.683: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:12.690: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:14.694: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:16.700: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:18.703: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:20.713: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:22.723: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:24.731: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:26.736: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:28.744: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:30.750: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:32.755: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:34.762: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:36.766: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:38.771: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:40.775: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:42.781: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:44.788: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:46.794: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:48.797: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:50.801: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:52.811: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:54.818: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:56.822: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:13:58.826: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:00.836: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:02.842: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:04.846: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:06.851: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:08.855: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:10.860: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:12.866: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:14.869: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:16.875: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:18.882: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:20.888: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:22.894: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:24.897: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:26.905: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:28.914: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:30.918: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:32.926: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:34.935: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:36.939: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:38.946: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:40.952: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:42.956: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:44.961: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:46.967: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:48.974: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:50.978: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:52.985: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:54.993: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:56.997: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:14:59.005: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:01.020: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:03.024: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:05.027: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:07.034: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:09.043: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:11.046: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:13.054: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:15.059: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:17.065: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:19.068: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:21.073: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:23.077: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:25.081: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:27.087: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:29.095: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:31.105: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:33.114: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:35.119: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:37.124: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:39.128: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:41.134: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:43.138: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:45.142: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:47.145: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:49.149: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:51.152: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:53.156: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:55.158: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:57.162: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:15:59.169: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:16:01.174: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:16:03.181: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:16:05.187: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:16:07.194: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  May  5 16:16:09.199: INFO: Get pod liveness-fcbc7c87-f512-4793-941a-32121c2e2302 in namespace container-probe-5516
  STEP: deleting the pod @ 05/05/24 16:16:11.2
  May  5 16:16:11.232: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-5516" for this suite. @ 05/05/24 16:16:11.239
• [242.784 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 05/05/24 16:16:11.249
  May  5 16:16:11.249: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename disruption @ 05/05/24 16:16:11.25
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:16:11.275
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:16:11.282
  STEP: Creating a kubernetes client @ 05/05/24 16:16:11.289
  May  5 16:16:11.289: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename disruption-2 @ 05/05/24 16:16:11.294
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:16:11.319
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:16:11.325
  STEP: Waiting for the pdb to be processed @ 05/05/24 16:16:11.335
  STEP: Waiting for the pdb to be processed @ 05/05/24 16:16:11.354
  STEP: Waiting for the pdb to be processed @ 05/05/24 16:16:13.364
  STEP: listing a collection of PDBs across all namespaces @ 05/05/24 16:16:15.368
  STEP: listing a collection of PDBs in namespace disruption-8715 @ 05/05/24 16:16:15.371
  STEP: deleting a collection of PDBs @ 05/05/24 16:16:15.373
  STEP: Waiting for the PDB collection to be deleted @ 05/05/24 16:16:15.385
  May  5 16:16:15.392: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-106" for this suite. @ 05/05/24 16:16:15.396
  May  5 16:16:15.403: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-8715" for this suite. @ 05/05/24 16:16:15.407
• [4.165 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 05/05/24 16:16:15.414
  May  5 16:16:15.414: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename dns @ 05/05/24 16:16:15.417
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:16:15.439
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:16:15.444
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 05/05/24 16:16:15.448
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 05/05/24 16:16:15.448
  STEP: creating a pod to probe DNS @ 05/05/24 16:16:15.448
  STEP: submitting the pod to kubernetes @ 05/05/24 16:16:15.448
  STEP: retrieving the pod @ 05/05/24 16:16:17.474
  STEP: looking for the results for each expected name from probers @ 05/05/24 16:16:17.476
  May  5 16:16:17.497: INFO: DNS probes using dns-2559/dns-test-dbff71ed-cc70-4635-a77f-de98b4ef4f40 succeeded

  STEP: deleting the pod @ 05/05/24 16:16:17.497
  May  5 16:16:17.523: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2559" for this suite. @ 05/05/24 16:16:17.527
• [2.119 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 05/05/24 16:16:17.534
  May  5 16:16:17.534: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename sysctl @ 05/05/24 16:16:17.536
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:16:17.565
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:16:17.57
  STEP: Creating a pod with one valid and two invalid sysctls @ 05/05/24 16:16:17.574
  May  5 16:16:17.581: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-6398" for this suite. @ 05/05/24 16:16:17.587
• [0.062 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:810
  STEP: Creating a kubernetes client @ 05/05/24 16:16:17.596
  May  5 16:16:17.596: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename svcaccounts @ 05/05/24 16:16:17.597
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:16:17.62
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:16:17.625
  STEP: Creating ServiceAccount "e2e-sa-j5q8r"  @ 05/05/24 16:16:17.629
  May  5 16:16:17.636: INFO: AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-j5q8r"  @ 05/05/24 16:16:17.636
  May  5 16:16:17.647: INFO: AutomountServiceAccountToken: true
  May  5 16:16:17.647: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2103" for this suite. @ 05/05/24 16:16:17.654
• [0.070 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:55
  STEP: Creating a kubernetes client @ 05/05/24 16:16:17.666
  May  5 16:16:17.666: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 16:16:17.668
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:16:17.692
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:16:17.7
  STEP: Creating a pod to test downward API volume plugin @ 05/05/24 16:16:17.707
  STEP: Saw pod success @ 05/05/24 16:16:21.742
  May  5 16:16:21.748: INFO: Trying to get logs from node worker01 pod downwardapi-volume-98286e9e-a623-4bfd-96b6-56ab13bacf8b container client-container: <nil>
  STEP: delete the pod @ 05/05/24 16:16:21.774
  May  5 16:16:21.798: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4729" for this suite. @ 05/05/24 16:16:21.806
• [4.153 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:199
  STEP: Creating a kubernetes client @ 05/05/24 16:16:21.822
  May  5 16:16:21.822: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename webhook @ 05/05/24 16:16:21.823
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:16:21.842
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:16:21.846
  STEP: Setting up server cert @ 05/05/24 16:16:21.875
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/05/24 16:16:22.214
  STEP: Deploying the webhook pod @ 05/05/24 16:16:22.223
  STEP: Wait for the deployment to be ready @ 05/05/24 16:16:22.24
  May  5 16:16:22.253: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/05/24 16:16:24.28
  STEP: Verifying the service has paired with the endpoint @ 05/05/24 16:16:24.287
  May  5 16:16:25.293: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 05/05/24 16:16:25.301
  STEP: create a pod that should be denied by the webhook @ 05/05/24 16:16:25.328
  STEP: create a pod that causes the webhook to hang @ 05/05/24 16:16:25.339
  STEP: create a configmap that should be denied by the webhook @ 05/05/24 16:16:35.349
  STEP: create a configmap that should be admitted by the webhook @ 05/05/24 16:16:35.373
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 05/05/24 16:16:35.383
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 05/05/24 16:16:35.392
  STEP: create a namespace that bypass the webhook @ 05/05/24 16:16:35.395
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 05/05/24 16:16:35.405
  May  5 16:16:35.467: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5942" for this suite. @ 05/05/24 16:16:35.478
  STEP: Destroying namespace "webhook-markers-7893" for this suite. @ 05/05/24 16:16:35.49
  STEP: Destroying namespace "exempted-namespace-1449" for this suite. @ 05/05/24 16:16:35.498
• [13.685 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:153
  STEP: Creating a kubernetes client @ 05/05/24 16:16:35.507
  May  5 16:16:35.507: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/05/24 16:16:35.508
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:16:35.519
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:16:35.522
  May  5 16:16:35.526: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 05/05/24 16:16:36.87
  May  5 16:16:36.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-4236 --namespace=crd-publish-openapi-4236 create -f -'
  May  5 16:16:38.961: INFO: stderr: ""
  May  5 16:16:38.961: INFO: stdout: "e2e-test-crd-publish-openapi-9188-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  May  5 16:16:38.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-4236 --namespace=crd-publish-openapi-4236 delete e2e-test-crd-publish-openapi-9188-crds test-cr'
  May  5 16:16:39.048: INFO: stderr: ""
  May  5 16:16:39.048: INFO: stdout: "e2e-test-crd-publish-openapi-9188-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  May  5 16:16:39.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-4236 --namespace=crd-publish-openapi-4236 apply -f -'
  May  5 16:16:39.110: INFO: stderr: ""
  May  5 16:16:39.111: INFO: stdout: "e2e-test-crd-publish-openapi-9188-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  May  5 16:16:39.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-4236 --namespace=crd-publish-openapi-4236 delete e2e-test-crd-publish-openapi-9188-crds test-cr'
  May  5 16:16:39.169: INFO: stderr: ""
  May  5 16:16:39.169: INFO: stdout: "e2e-test-crd-publish-openapi-9188-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 05/05/24 16:16:39.169
  May  5 16:16:39.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-4236 explain e2e-test-crd-publish-openapi-9188-crds'
  May  5 16:16:39.229: INFO: stderr: ""
  May  5 16:16:39.229: INFO: stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-9188-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  May  5 16:16:40.509: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4236" for this suite. @ 05/05/24 16:16:40.564
• [5.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:289
  STEP: Creating a kubernetes client @ 05/05/24 16:16:40.59
  May  5 16:16:40.590: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename field-validation @ 05/05/24 16:16:40.591
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:16:40.607
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:16:40.609
  May  5 16:16:40.612: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:16:43.690: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-4912" for this suite. @ 05/05/24 16:16:43.693
• [3.118 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 05/05/24 16:16:43.709
  May  5 16:16:43.709: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename pods @ 05/05/24 16:16:43.709
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:16:43.719
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:16:43.724
  May  5 16:16:43.727: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: creating the pod @ 05/05/24 16:16:43.728
  STEP: submitting the pod to kubernetes @ 05/05/24 16:16:43.728
  May  5 16:16:45.752: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1674" for this suite. @ 05/05/24 16:16:45.755
• [2.050 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 05/05/24 16:16:45.758
  May  5 16:16:45.758: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename disruption @ 05/05/24 16:16:45.76
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:16:45.769
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:16:45.772
  STEP: Waiting for the pdb to be processed @ 05/05/24 16:16:45.777
  STEP: Waiting for all pods to be running @ 05/05/24 16:16:47.827
  May  5 16:16:47.836: INFO: running pods: 0 < 3
  May  5 16:16:49.834: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-6490" for this suite. @ 05/05/24 16:16:49.837
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:51
  STEP: Creating a kubernetes client @ 05/05/24 16:16:49.852
  May  5 16:16:49.852: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubelet-test @ 05/05/24 16:16:49.854
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:16:49.871
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:16:49.875
  May  5 16:16:51.903: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-9407" for this suite. @ 05/05/24 16:16:51.905
• [2.067 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 05/05/24 16:16:51.921
  May  5 16:16:51.921: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename proxy @ 05/05/24 16:16:51.922
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:16:51.933
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:16:51.938
  May  5 16:16:51.943: INFO: Creating pod...
  May  5 16:16:53.960: INFO: Creating service...
  May  5 16:16:53.983: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-8779/pods/agnhost/proxy?method=DELETE
  May  5 16:16:53.995: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  May  5 16:16:53.995: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-8779/pods/agnhost/proxy?method=OPTIONS
  May  5 16:16:54.002: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  May  5 16:16:54.002: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-8779/pods/agnhost/proxy?method=PATCH
  May  5 16:16:54.009: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  May  5 16:16:54.009: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-8779/pods/agnhost/proxy?method=POST
  May  5 16:16:54.015: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  May  5 16:16:54.015: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-8779/pods/agnhost/proxy?method=PUT
  May  5 16:16:54.023: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  May  5 16:16:54.023: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-8779/services/e2e-proxy-test-service/proxy?method=DELETE
  May  5 16:16:54.032: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  May  5 16:16:54.032: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-8779/services/e2e-proxy-test-service/proxy?method=OPTIONS
  May  5 16:16:54.040: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  May  5 16:16:54.040: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-8779/services/e2e-proxy-test-service/proxy?method=PATCH
  May  5 16:16:54.047: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  May  5 16:16:54.047: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-8779/services/e2e-proxy-test-service/proxy?method=POST
  May  5 16:16:54.054: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  May  5 16:16:54.054: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-8779/services/e2e-proxy-test-service/proxy?method=PUT
  May  5 16:16:54.060: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  May  5 16:16:54.060: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-8779/pods/agnhost/proxy?method=GET
  May  5 16:16:54.063: INFO: http.Client request:GET StatusCode:301
  May  5 16:16:54.063: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-8779/services/e2e-proxy-test-service/proxy?method=GET
  May  5 16:16:54.066: INFO: http.Client request:GET StatusCode:301
  May  5 16:16:54.066: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-8779/pods/agnhost/proxy?method=HEAD
  May  5 16:16:54.069: INFO: http.Client request:HEAD StatusCode:301
  May  5 16:16:54.069: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-8779/services/e2e-proxy-test-service/proxy?method=HEAD
  May  5 16:16:54.074: INFO: http.Client request:HEAD StatusCode:301
  May  5 16:16:54.074: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-8779" for this suite. @ 05/05/24 16:16:54.079
• [2.169 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:514
  STEP: Creating a kubernetes client @ 05/05/24 16:16:54.09
  May  5 16:16:54.090: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename apf @ 05/05/24 16:16:54.091
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:16:54.11
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:16:54.114
  STEP: getting /apis @ 05/05/24 16:16:54.117
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 05/05/24 16:16:54.122
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 05/05/24 16:16:54.124
  STEP: creating @ 05/05/24 16:16:54.126
  STEP: getting @ 05/05/24 16:16:54.141
  STEP: listing @ 05/05/24 16:16:54.145
  STEP: watching @ 05/05/24 16:16:54.153
  May  5 16:16:54.153: INFO: starting watch
  STEP: patching @ 05/05/24 16:16:54.154
  STEP: updating @ 05/05/24 16:16:54.16
  May  5 16:16:54.170: INFO: waiting for watch events with expected annotations
  STEP: getting /status @ 05/05/24 16:16:54.17
  STEP: patching /status @ 05/05/24 16:16:54.174
  STEP: updating /status @ 05/05/24 16:16:54.18
  STEP: deleting @ 05/05/24 16:16:54.191
  STEP: deleting a collection @ 05/05/24 16:16:54.204
  May  5 16:16:54.227: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-3230" for this suite. @ 05/05/24 16:16:54.232
• [0.149 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 05/05/24 16:16:54.242
  May  5 16:16:54.242: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename pod-network-test @ 05/05/24 16:16:54.244
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:16:54.267
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:16:54.271
  STEP: Performing setup for networking test in namespace pod-network-test-666 @ 05/05/24 16:16:54.275
  STEP: creating a selector @ 05/05/24 16:16:54.275
  STEP: Creating the service pods in kubernetes @ 05/05/24 16:16:54.275
  May  5 16:16:54.275: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 05/05/24 16:17:06.352
  May  5 16:17:08.394: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  May  5 16:17:08.394: INFO: Going to poll 10.200.131.155 on port 8083 at least 0 times, with a maximum of 34 tries before failing
  May  5 16:17:08.398: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.200.131.155:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-666 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 16:17:08.398: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:17:08.399: INFO: ExecWithOptions: Clientset creation
  May  5 16:17:08.399: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/pod-network-test-666/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.200.131.155%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  May  5 16:17:08.470: INFO: Found all 1 expected endpoints: [netserver-0]
  May  5 16:17:08.470: INFO: Going to poll 10.200.5.28 on port 8083 at least 0 times, with a maximum of 34 tries before failing
  May  5 16:17:08.473: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.200.5.28:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-666 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 16:17:08.473: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:17:08.474: INFO: ExecWithOptions: Clientset creation
  May  5 16:17:08.474: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/pod-network-test-666/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.200.5.28%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  May  5 16:17:08.539: INFO: Found all 1 expected endpoints: [netserver-1]
  May  5 16:17:08.540: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-666" for this suite. @ 05/05/24 16:17:08.544
• [14.312 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 05/05/24 16:17:08.555
  May  5 16:17:08.555: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename init-container @ 05/05/24 16:17:08.559
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:17:08.583
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:17:08.591
  STEP: creating the pod @ 05/05/24 16:17:08.595
  May  5 16:17:08.595: INFO: PodSpec: initContainers in spec.initContainers
  May  5 16:17:12.383: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-1586" for this suite. @ 05/05/24 16:17:12.389
• [3.849 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:100
  STEP: Creating a kubernetes client @ 05/05/24 16:17:12.406
  May  5 16:17:12.406: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 16:17:12.408
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:17:12.417
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:17:12.421
  STEP: Creating configMap with name projected-configmap-test-volume-map-273a8619-38bd-4c34-b306-8a7aa22eb051 @ 05/05/24 16:17:12.423
  STEP: Creating a pod to test consume configMaps @ 05/05/24 16:17:12.426
  STEP: Saw pod success @ 05/05/24 16:17:16.446
  May  5 16:17:16.448: INFO: Trying to get logs from node worker01 pod pod-projected-configmaps-631f3efa-3f7d-416e-9141-d0fe75598325 container agnhost-container: <nil>
  STEP: delete the pod @ 05/05/24 16:17:16.453
  May  5 16:17:16.476: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3087" for this suite. @ 05/05/24 16:17:16.479
• [4.077 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 05/05/24 16:17:16.483
  May  5 16:17:16.483: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename tables @ 05/05/24 16:17:16.484
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:17:16.493
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:17:16.496
  May  5 16:17:16.500: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-2146" for this suite. @ 05/05/24 16:17:16.503
• [0.024 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1533
  STEP: Creating a kubernetes client @ 05/05/24 16:17:16.509
  May  5 16:17:16.509: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename services @ 05/05/24 16:17:16.51
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:17:16.561
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:17:16.565
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-8220 @ 05/05/24 16:17:16.568
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 05/05/24 16:17:16.582
  STEP: creating service externalsvc in namespace services-8220 @ 05/05/24 16:17:16.582
  STEP: creating replication controller externalsvc in namespace services-8220 @ 05/05/24 16:17:16.602
  I0505 16:17:16.615358      22 runners.go:197] Created replication controller with name: externalsvc, namespace: services-8220, replica count: 2
  I0505 16:17:19.666827      22 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 05/05/24 16:17:19.672
  May  5 16:17:19.688: INFO: Creating new exec pod
  May  5 16:17:21.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-8220 exec execpodh479c -- /bin/sh -x -c nslookup nodeport-service.services-8220.svc.cluster.local'
  May  5 16:17:21.900: INFO: stderr: "+ nslookup nodeport-service.services-8220.svc.cluster.local\n"
  May  5 16:17:21.900: INFO: stdout: "Server:\t\t10.32.0.10\nAddress:\t10.32.0.10#53\n\nnodeport-service.services-8220.svc.cluster.local\tcanonical name = externalsvc.services-8220.svc.cluster.local.\nName:\texternalsvc.services-8220.svc.cluster.local\nAddress: 10.32.0.123\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-8220, will wait for the garbage collector to delete the pods @ 05/05/24 16:17:21.901
  May  5 16:17:21.966: INFO: Deleting ReplicationController externalsvc took: 9.717808ms
  May  5 16:17:22.067: INFO: Terminating ReplicationController externalsvc pods took: 100.927279ms
  May  5 16:17:25.393: INFO: Cleaning up the NodePort to ExternalName test service
  May  5 16:17:25.417: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8220" for this suite. @ 05/05/24 16:17:25.436
• [8.935 seconds]
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:209
  STEP: Creating a kubernetes client @ 05/05/24 16:17:25.444
  May  5 16:17:25.444: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename downward-api @ 05/05/24 16:17:25.445
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:17:25.457
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:17:25.461
  STEP: Creating a pod to test downward API volume plugin @ 05/05/24 16:17:25.465
  STEP: Saw pod success @ 05/05/24 16:17:29.487
  May  5 16:17:29.491: INFO: Trying to get logs from node worker00 pod downwardapi-volume-f30ea735-2dd7-4bf8-9927-4c8449d44d87 container client-container: <nil>
  STEP: delete the pod @ 05/05/24 16:17:29.499
  May  5 16:17:29.520: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9037" for this suite. @ 05/05/24 16:17:29.527
• [4.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:183
  STEP: Creating a kubernetes client @ 05/05/24 16:17:29.538
  May  5 16:17:29.538: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubelet-test @ 05/05/24 16:17:29.54
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:17:29.564
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:17:29.573
  May  5 16:17:31.609: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-8256" for this suite. @ 05/05/24 16:17:31.613
• [2.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1280
  STEP: Creating a kubernetes client @ 05/05/24 16:17:31.633
  May  5 16:17:31.633: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename services @ 05/05/24 16:17:31.636
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:17:31.649
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:17:31.652
  STEP: creating service nodeport-test with type=NodePort in namespace services-2558 @ 05/05/24 16:17:31.654
  STEP: creating replication controller nodeport-test in namespace services-2558 @ 05/05/24 16:17:31.662
  I0505 16:17:31.671335      22 runners.go:197] Created replication controller with name: nodeport-test, namespace: services-2558, replica count: 2
  I0505 16:17:34.726356      22 runners.go:197] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May  5 16:17:34.726: INFO: Creating new exec pod
  May  5 16:17:37.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-2558 exec execpods64s5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  May  5 16:17:37.917: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  May  5 16:17:37.917: INFO: stdout: "nodeport-test-v7p7n"
  May  5 16:17:37.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-2558 exec execpods64s5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.124 80'
  May  5 16:17:38.149: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.32.0.124 80\nConnection to 10.32.0.124 80 port [tcp/http] succeeded!\n"
  May  5 16:17:38.149: INFO: stdout: "nodeport-test-v7p7n"
  May  5 16:17:38.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-2558 exec execpods64s5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.58.100 31530'
  May  5 16:17:38.292: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.58.100 31530\nConnection to 192.168.58.100 31530 port [tcp/*] succeeded!\n"
  May  5 16:17:38.292: INFO: stdout: "nodeport-test-lg8pn"
  May  5 16:17:38.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-2558 exec execpods64s5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.58.101 31530'
  May  5 16:17:38.421: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.58.101 31530\nConnection to 192.168.58.101 31530 port [tcp/*] succeeded!\n"
  May  5 16:17:38.421: INFO: stdout: "nodeport-test-v7p7n"
  May  5 16:17:38.421: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2558" for this suite. @ 05/05/24 16:17:38.426
• [6.798 seconds]
------------------------------
S
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:408
  STEP: Creating a kubernetes client @ 05/05/24 16:17:38.433
  May  5 16:17:38.433: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename job @ 05/05/24 16:17:38.435
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:17:38.456
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:17:38.461
  STEP: Creating Indexed job @ 05/05/24 16:17:38.465
  STEP: Ensuring job reaches completions @ 05/05/24 16:17:38.472
  STEP: Ensuring pods with index for job exist @ 05/05/24 16:17:46.481
  May  5 16:17:46.488: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2680" for this suite. @ 05/05/24 16:17:46.493
• [8.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:210
  STEP: Creating a kubernetes client @ 05/05/24 16:17:46.507
  May  5 16:17:46.507: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename webhook @ 05/05/24 16:17:46.508
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:17:46.527
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:17:46.53
  STEP: Setting up server cert @ 05/05/24 16:17:46.545
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/05/24 16:17:46.896
  STEP: Deploying the webhook pod @ 05/05/24 16:17:46.902
  STEP: Wait for the deployment to be ready @ 05/05/24 16:17:46.91
  May  5 16:17:46.917: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  May  5 16:17:48.926: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 5, 16, 17, 46, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 17, 46, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 16, 17, 46, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 17, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: Deploying the webhook service @ 05/05/24 16:17:50.93
  STEP: Verifying the service has paired with the endpoint @ 05/05/24 16:17:50.944
  May  5 16:17:51.949: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 05/05/24 16:17:51.955
  STEP: create a pod @ 05/05/24 16:17:51.981
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 05/05/24 16:17:53.998
  May  5 16:17:53.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=webhook-3397 attach --namespace=webhook-3397 to-be-attached-pod -i -c=container1'
  May  5 16:17:54.093: INFO: rc: 1
  May  5 16:17:54.174: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3397" for this suite. @ 05/05/24 16:17:54.184
  STEP: Destroying namespace "webhook-markers-4027" for this suite. @ 05/05/24 16:17:54.192
• [7.699 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:846
  STEP: Creating a kubernetes client @ 05/05/24 16:17:54.209
  May  5 16:17:54.209: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename services @ 05/05/24 16:17:54.211
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:17:54.232
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:17:54.237
  STEP: creating service multi-endpoint-test in namespace services-1009 @ 05/05/24 16:17:54.24
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1009 to expose endpoints map[] @ 05/05/24 16:17:54.26
  May  5 16:17:54.273: INFO: successfully validated that service multi-endpoint-test in namespace services-1009 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-1009 @ 05/05/24 16:17:54.273
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1009 to expose endpoints map[pod1:[100]] @ 05/05/24 16:17:56.302
  May  5 16:17:56.317: INFO: successfully validated that service multi-endpoint-test in namespace services-1009 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-1009 @ 05/05/24 16:17:56.317
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1009 to expose endpoints map[pod1:[100] pod2:[101]] @ 05/05/24 16:17:58.34
  May  5 16:17:58.349: INFO: successfully validated that service multi-endpoint-test in namespace services-1009 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 05/05/24 16:17:58.349
  May  5 16:17:58.349: INFO: Creating new exec pod
  May  5 16:18:01.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-1009 exec execpodx9mxl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  May  5 16:18:01.507: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  May  5 16:18:01.507: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May  5 16:18:01.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-1009 exec execpodx9mxl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.231 80'
  May  5 16:18:01.628: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.32.0.231 80\nConnection to 10.32.0.231 80 port [tcp/http] succeeded!\n"
  May  5 16:18:01.628: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May  5 16:18:01.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-1009 exec execpodx9mxl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  May  5 16:18:01.751: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  May  5 16:18:01.751: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May  5 16:18:01.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-1009 exec execpodx9mxl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.231 81'
  May  5 16:18:01.865: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.32.0.231 81\nConnection to 10.32.0.231 81 port [tcp/*] succeeded!\n"
  May  5 16:18:01.865: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-1009 @ 05/05/24 16:18:01.865
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1009 to expose endpoints map[pod2:[101]] @ 05/05/24 16:18:01.909
  May  5 16:18:01.931: INFO: successfully validated that service multi-endpoint-test in namespace services-1009 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-1009 @ 05/05/24 16:18:01.931
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1009 to expose endpoints map[] @ 05/05/24 16:18:01.961
  May  5 16:18:02.000: INFO: successfully validated that service multi-endpoint-test in namespace services-1009 exposes endpoints map[]
  May  5 16:18:02.040: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1009" for this suite. @ 05/05/24 16:18:02.05
• [7.858 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3649
  STEP: Creating a kubernetes client @ 05/05/24 16:18:02.067
  May  5 16:18:02.067: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename services @ 05/05/24 16:18:02.068
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:18:02.114
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:18:02.119
  STEP: creating service multiprotocol-test in namespace services-2161 @ 05/05/24 16:18:02.125
  STEP: creating pod pod1 in namespace services-2161 @ 05/05/24 16:18:02.146
  STEP: Creating pod pod1 in namespace services-2161 @ 05/05/24 16:18:02.146
  STEP: waiting up to 3m0s for service multiprotocol-test in namespace services-2161 to expose endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]] @ 05/05/24 16:18:04.197
  May  5 16:18:04.204: INFO: successfully validated that service multiprotocol-test in namespace services-2161 exposes endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 05/05/24 16:18:04.204
  May  5 16:18:04.204: INFO: Creating new exec pod
  May  5 16:18:06.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-2161 exec execpodrxvgb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.90 80'
  May  5 16:18:06.356: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.32.0.90 80\nConnection to 10.32.0.90 80 port [tcp/http] succeeded!\n"
  May  5 16:18:06.357: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May  5 16:18:06.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-2161 exec execpodrxvgb -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.32.0.90 80'
  May  5 16:18:10.475: INFO: stderr: "+ nc -v -u -w 2 10.32.0.90 80\n+ echo hostName\nConnection to 10.32.0.90 80 port [udp/*] succeeded!\n"
  May  5 16:18:10.475: INFO: stdout: "pod1"
  STEP: Checking if the Service forwards traffic to TCP only @ 05/05/24 16:18:10.475
  May  5 16:18:10.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-2161 exec execpodrxvgb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.90 80'
  May  5 16:18:10.605: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.32.0.90 80\nConnection to 10.32.0.90 80 port [tcp/http] succeeded!\n"
  May  5 16:18:10.605: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May  5 16:18:10.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-2161 exec execpodrxvgb -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.32.0.90 80'
  May  5 16:18:14.706: INFO: stderr: "+ nc -v -u -w 2 10.32.0.90 80\n+ echo hostName\nConnection to 10.32.0.90 80 port [udp/*] succeeded!\n"
  May  5 16:18:14.706: INFO: stdout: ""
  May  5 16:18:14.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-2161 exec execpodrxvgb -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.32.0.90 80'
  May  5 16:18:18.823: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.32.0.90 80\nConnection to 10.32.0.90 80 port [udp/*] succeeded!\n"
  May  5 16:18:18.823: INFO: stdout: ""
  STEP: Checking if the Service forwards traffic to UDP only @ 05/05/24 16:18:18.824
  May  5 16:18:18.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-2161 exec execpodrxvgb -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.32.0.90 80'
  May  5 16:18:23.021: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.32.0.90 80\nConnection to 10.32.0.90 80 port [udp/*] succeeded!\n"
  May  5 16:18:23.021: INFO: stdout: "pod1"
  May  5 16:18:23.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-2161 exec execpodrxvgb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.90 80'
  May  5 16:18:25.147: INFO: rc: 1
  May  5 16:18:25.147: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-2161 exec execpodrxvgb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.90 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.32.0.90 80
  nc: connect to 10.32.0.90 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  May  5 16:18:25.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-2161 exec execpodrxvgb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.90 80'
  May  5 16:18:27.278: INFO: rc: 1
  May  5 16:18:27.278: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-2161 exec execpodrxvgb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.90 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.32.0.90 80
  nc: connect to 10.32.0.90 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  May  5 16:18:27.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-2161 exec execpodrxvgb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.90 80'
  May  5 16:18:29.431: INFO: rc: 1
  May  5 16:18:29.431: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-2161 exec execpodrxvgb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.90 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.32.0.90 80
  nc: connect to 10.32.0.90 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  May  5 16:18:29.432: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2161" for this suite. @ 05/05/24 16:18:29.437
• [27.376 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:135
  STEP: Creating a kubernetes client @ 05/05/24 16:18:29.444
  May  5 16:18:29.444: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename security-context @ 05/05/24 16:18:29.445
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:18:29.464
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:18:29.468
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 05/05/24 16:18:29.474
  STEP: Saw pod success @ 05/05/24 16:18:33.498
  May  5 16:18:33.501: INFO: Trying to get logs from node worker00 pod security-context-38e73def-f966-4ca7-9427-a6266c033f1b container test-container: <nil>
  STEP: delete the pod @ 05/05/24 16:18:33.507
  May  5 16:18:33.522: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-950" for this suite. @ 05/05/24 16:18:33.526
• [4.091 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:110
  STEP: Creating a kubernetes client @ 05/05/24 16:18:33.535
  May  5 16:18:33.535: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 16:18:33.537
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:18:33.556
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:18:33.561
  STEP: Creating configMap with name projected-configmap-test-volume-map-b6af96e8-96ab-472f-b0fe-f58694cc36ed @ 05/05/24 16:18:33.565
  STEP: Creating a pod to test consume configMaps @ 05/05/24 16:18:33.572
  STEP: Saw pod success @ 05/05/24 16:18:37.6
  May  5 16:18:37.602: INFO: Trying to get logs from node worker00 pod pod-projected-configmaps-32c1e699-5d70-4425-8b26-60ebd3f76416 container agnhost-container: <nil>
  STEP: delete the pod @ 05/05/24 16:18:37.606
  May  5 16:18:37.624: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9844" for this suite. @ 05/05/24 16:18:37.627
• [4.100 seconds]
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
k8s.io/kubernetes/test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 05/05/24 16:18:37.635
  May  5 16:18:37.635: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename conformance-tests @ 05/05/24 16:18:37.638
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:18:37.654
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:18:37.66
  STEP: Getting node addresses @ 05/05/24 16:18:37.665
  May  5 16:18:37.665: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  May  5 16:18:37.673: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-9010" for this suite. @ 05/05/24 16:18:37.678
• [0.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 05/05/24 16:18:37.69
  May  5 16:18:37.690: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename pods @ 05/05/24 16:18:37.693
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:18:37.709
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:18:37.715
  STEP: creating a Pod with a static label @ 05/05/24 16:18:37.758
  STEP: watching for Pod to be ready @ 05/05/24 16:18:37.774
  May  5 16:18:37.776: INFO: observed Pod pod-test in namespace pods-2354 in phase Pending with labels: map[test-pod-static:true] & conditions []
  May  5 16:18:37.784: INFO: observed Pod pod-test in namespace pods-2354 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 16:18:37 +0000 UTC  }]
  May  5 16:18:37.804: INFO: observed Pod pod-test in namespace pods-2354 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-05-05 16:18:39 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 16:18:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-05 16:18:39 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-05 16:18:39 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 16:18:37 +0000 UTC  }]
  May  5 16:18:38.227: INFO: observed Pod pod-test in namespace pods-2354 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-05-05 16:18:39 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 16:18:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-05 16:18:39 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-05 16:18:39 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 16:18:37 +0000 UTC  }]
  May  5 16:18:38.771: INFO: Found Pod pod-test in namespace pods-2354 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 16:18:40 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 16:18:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 16:18:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 16:18:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 16:18:37 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 05/05/24 16:18:38.774
  STEP: getting the Pod and ensuring that it's patched @ 05/05/24 16:18:38.789
  STEP: replacing the Pod's status Ready condition to False @ 05/05/24 16:18:38.795
  STEP: check the Pod again to ensure its Ready conditions are False @ 05/05/24 16:18:38.814
  STEP: deleting the Pod via a Collection with a LabelSelector @ 05/05/24 16:18:38.814
  STEP: watching for the Pod to be deleted @ 05/05/24 16:18:38.826
  May  5 16:18:38.830: INFO: observed event type MODIFIED
  May  5 16:18:40.586: INFO: observed event type MODIFIED
  May  5 16:18:40.904: INFO: observed event type MODIFIED
  May  5 16:18:41.015: INFO: observed event type MODIFIED
  May  5 16:18:41.784: INFO: observed event type MODIFIED
  May  5 16:18:41.799: INFO: observed event type MODIFIED
  May  5 16:18:41.809: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2354" for this suite. @ 05/05/24 16:18:41.811
• [4.127 seconds]
------------------------------
SSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 05/05/24 16:18:41.817
  May  5 16:18:41.817: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename container-runtime @ 05/05/24 16:18:41.818
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:18:41.833
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:18:41.839
  STEP: create the container @ 05/05/24 16:18:41.845
  W0505 16:18:41.855009      22 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 05/05/24 16:18:41.855
  STEP: get the container status @ 05/05/24 16:18:43.869
  STEP: the container should be terminated @ 05/05/24 16:18:43.872
  STEP: the termination message should be set @ 05/05/24 16:18:43.872
  May  5 16:18:43.872: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 05/05/24 16:18:43.872
  May  5 16:18:43.891: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-2557" for this suite. @ 05/05/24 16:18:43.897
• [2.088 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:253
  STEP: Creating a kubernetes client @ 05/05/24 16:18:43.906
  May  5 16:18:43.906: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename limitrange @ 05/05/24 16:18:43.909
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:18:43.931
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:18:43.937
  STEP: Creating LimitRange "e2e-limitrange-xstlm" in namespace "limitrange-7076" @ 05/05/24 16:18:43.939
  STEP: Creating another limitRange in another namespace @ 05/05/24 16:18:43.945
  May  5 16:18:43.961: INFO: Namespace "e2e-limitrange-xstlm-6230" created
  May  5 16:18:43.961: INFO: Creating LimitRange "e2e-limitrange-xstlm" in namespace "e2e-limitrange-xstlm-6230"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-xstlm" @ 05/05/24 16:18:43.966
  May  5 16:18:43.970: INFO: Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-xstlm" in "limitrange-7076" namespace @ 05/05/24 16:18:43.97
  May  5 16:18:43.979: INFO: LimitRange "e2e-limitrange-xstlm" has been patched
  STEP: Delete LimitRange "e2e-limitrange-xstlm" by Collection with labelSelector: "e2e-limitrange-xstlm=patched" @ 05/05/24 16:18:43.979
  STEP: Confirm that the limitRange "e2e-limitrange-xstlm" has been deleted @ 05/05/24 16:18:43.986
  May  5 16:18:43.987: INFO: Requesting list of LimitRange to confirm quantity
  May  5 16:18:43.991: INFO: Found 0 LimitRange with label "e2e-limitrange-xstlm=patched"
  May  5 16:18:43.991: INFO: LimitRange "e2e-limitrange-xstlm" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-xstlm" @ 05/05/24 16:18:43.991
  May  5 16:18:43.996: INFO: Found 1 limitRange
  May  5 16:18:43.996: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-7076" for this suite. @ 05/05/24 16:18:44
  STEP: Destroying namespace "e2e-limitrange-xstlm-6230" for this suite. @ 05/05/24 16:18:44.007
• [0.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:194
  STEP: Creating a kubernetes client @ 05/05/24 16:18:44.015
  May  5 16:18:44.015: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/05/24 16:18:44.018
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:18:44.034
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:18:44.039
  May  5 16:18:44.045: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 05/05/24 16:18:45.296
  May  5 16:18:45.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-9296 --namespace=crd-publish-openapi-9296 create -f -'
  May  5 16:18:47.374: INFO: stderr: ""
  May  5 16:18:47.374: INFO: stdout: "e2e-test-crd-publish-openapi-6761-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  May  5 16:18:47.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-9296 --namespace=crd-publish-openapi-9296 delete e2e-test-crd-publish-openapi-6761-crds test-cr'
  May  5 16:18:47.457: INFO: stderr: ""
  May  5 16:18:47.457: INFO: stdout: "e2e-test-crd-publish-openapi-6761-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  May  5 16:18:47.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-9296 --namespace=crd-publish-openapi-9296 apply -f -'
  May  5 16:18:47.539: INFO: stderr: ""
  May  5 16:18:47.539: INFO: stdout: "e2e-test-crd-publish-openapi-6761-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  May  5 16:18:47.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-9296 --namespace=crd-publish-openapi-9296 delete e2e-test-crd-publish-openapi-6761-crds test-cr'
  May  5 16:18:47.617: INFO: stderr: ""
  May  5 16:18:47.617: INFO: stdout: "e2e-test-crd-publish-openapi-6761-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 05/05/24 16:18:47.617
  May  5 16:18:47.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-9296 explain e2e-test-crd-publish-openapi-6761-crds'
  May  5 16:18:47.700: INFO: stderr: ""
  May  5 16:18:47.700: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-6761-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  May  5 16:18:48.945: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9296" for this suite. @ 05/05/24 16:18:48.954
• [4.947 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1863
  STEP: Creating a kubernetes client @ 05/05/24 16:18:48.962
  May  5 16:18:48.963: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubectl @ 05/05/24 16:18:48.964
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:18:48.987
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:18:48.996
  STEP: Starting the proxy @ 05/05/24 16:18:49.005
  May  5 16:18:49.005: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9173 proxy --unix-socket=/tmp/kubectl-proxy-unix3366735810/test'
  STEP: retrieving proxy /api/ output @ 05/05/24 16:18:49.22
  May  5 16:18:49.227: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9173" for this suite. @ 05/05/24 16:18:49.242
• [0.291 seconds]
------------------------------
SSSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 05/05/24 16:18:49.254
  May  5 16:18:49.254: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename events @ 05/05/24 16:18:49.266
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:18:49.293
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:18:49.309
  STEP: Create set of events @ 05/05/24 16:18:49.325
  May  5 16:18:49.339: INFO: created test-event-1
  May  5 16:18:49.353: INFO: created test-event-2
  May  5 16:18:49.360: INFO: created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 05/05/24 16:18:49.36
  STEP: delete collection of events @ 05/05/24 16:18:49.368
  May  5 16:18:49.368: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 05/05/24 16:18:49.42
  May  5 16:18:49.421: INFO: requesting list of events to confirm quantity
  May  5 16:18:49.428: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-4172" for this suite. @ 05/05/24 16:18:49.435
• [0.188 seconds]
------------------------------
SS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingress.go:558
  STEP: Creating a kubernetes client @ 05/05/24 16:18:49.443
  May  5 16:18:49.443: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename ingress @ 05/05/24 16:18:49.444
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:18:49.464
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:18:49.468
  STEP: getting /apis @ 05/05/24 16:18:49.473
  STEP: getting /apis/networking.k8s.io @ 05/05/24 16:18:49.48
  STEP: getting /apis/networking.k8s.iov1 @ 05/05/24 16:18:49.481
  STEP: creating @ 05/05/24 16:18:49.482
  STEP: getting @ 05/05/24 16:18:49.501
  STEP: listing @ 05/05/24 16:18:49.502
  STEP: watching @ 05/05/24 16:18:49.505
  May  5 16:18:49.505: INFO: starting watch
  STEP: cluster-wide listing @ 05/05/24 16:18:49.506
  STEP: cluster-wide watching @ 05/05/24 16:18:49.509
  May  5 16:18:49.509: INFO: starting watch
  STEP: patching @ 05/05/24 16:18:49.511
  STEP: updating @ 05/05/24 16:18:49.518
  May  5 16:18:49.524: INFO: waiting for watch events with expected annotations
  May  5 16:18:49.524: INFO: saw patched and updated annotations
  STEP: patching /status @ 05/05/24 16:18:49.524
  STEP: updating /status @ 05/05/24 16:18:49.529
  STEP: get /status @ 05/05/24 16:18:49.534
  STEP: deleting @ 05/05/24 16:18:49.536
  STEP: deleting a collection @ 05/05/24 16:18:49.543
  May  5 16:18:49.552: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-6694" for this suite. @ 05/05/24 16:18:49.555
• [0.118 seconds]
------------------------------
SS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 05/05/24 16:18:49.561
  May  5 16:18:49.561: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename pods @ 05/05/24 16:18:49.561
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:18:49.571
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:18:49.574
  STEP: Saw pod success @ 05/05/24 16:18:55.636
  May  5 16:18:55.641: INFO: Trying to get logs from node worker00 pod client-envvars-01d78126-6b25-4f01-bb51-732200f7fa2b container env3cont: <nil>
  STEP: delete the pod @ 05/05/24 16:18:55.657
  May  5 16:18:55.667: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5334" for this suite. @ 05/05/24 16:18:55.67
• [6.114 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 05/05/24 16:18:55.675
  May  5 16:18:55.675: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename deployment @ 05/05/24 16:18:55.676
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:18:55.69
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:18:55.693
  May  5 16:18:55.702: INFO: Pod name cleanup-pod: Found 0 pods out of 1
  May  5 16:19:00.711: INFO: Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/05/24 16:19:00.711
  May  5 16:19:00.711: INFO: Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 05/05/24 16:19:00.738
  May  5 16:19:00.757: INFO: Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3382",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7c1ad3c0-598b-4d1e-895b-e4fc1e1dc164",
      ResourceVersion: (string) (len=4) "7865",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850522740,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850522740,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 0,
      Replicas: (int32) 0,
      UpdatedReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) <nil>,
      CollisionCount: (*int32)(<nil>)
    }
  }


  May  5 16:19:00.777: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
  May  5 16:19:00.777: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
  May  5 16:19:00.778: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3382",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d4252937-9f33-47d7-ad77-bff4ec95cbb6",
      ResourceVersion: (string) (len=4) "7866",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850522735,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "7c1ad3c0-598b-4d1e-895b-e4fc1e1dc164",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850522735,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=483) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000050  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000060  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000070  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000080  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000090  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              000000a0  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000b0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000c0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000d0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000e0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000f0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000100  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000110  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000120  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000130  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000140  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000160  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000170  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000180  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000190  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000001a0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001b0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001c0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001d0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001e0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850522736,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850522740,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=103) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000020  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              00000030  22 75 69 64 5c 22 3a 5c  22 37 63 31 61 64 33 63  |"uid\":\"7c1ad3c|
              00000040  30 2d 35 39 38 62 2d 34  64 31 65 2d 38 39 35 62  |0-598b-4d1e-895b|
              00000050  2d 65 34 66 63 31 65 31  64 63 31 36 34 5c 22 7d  |-e4fc1e1dc164\"}|
              00000060  22 3a 7b 7d 7d 7d 7d                              |":{}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May  5 16:19:00.827: INFO: Pod "test-cleanup-controller-v89nt" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=29) "test-cleanup-controller-v89nt",
      GenerateName: (string) (len=24) "test-cleanup-controller-",
      Namespace: (string) (len=15) "deployment-3382",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "40638d25-2a18-4682-9d5d-d43b9aa2ee50",
      ResourceVersion: (string) (len=4) "7847",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850522735,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "bcb6dbbf248f238beb323264bf24d19297346514413302f71a330a0a4cd3d17d",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=17) "10.200.131.166/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=17) "10.200.131.166/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=23) "test-cleanup-controller",
          UID: (types.UID) (len=36) "d4252937-9f33-47d7-ad77-bff4ec95cbb6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850522735,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=500) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 2c 22 66  |},"f:pod":{}},"f|
              00000050  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000060  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000070  75 69 64 5c 22 3a 5c 22  64 34 32 35 32 39 33 37  |uid\":\"d4252937|
              00000080  2d 39 66 33 33 2d 34 37  64 37 2d 61 64 37 37 2d  |-9f33-47d7-ad77-|
              00000090  62 66 66 34 65 63 39 35  63 62 62 36 5c 22 7d 22  |bff4ec95cbb6\"}"|
              000000a0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000b0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000c0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              000000d0  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              000000e0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              000000f0  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000100  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000110  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000120  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000130  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000140  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000150  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000160  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              00000170  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              00000180  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              00000190  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001a0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001b0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001c0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              000001d0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              000001e0  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              000001f0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850522736,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850522736,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 30 30 2e 31 33 31  2e 31 36 36 5c 22 7d 22  |.200.131.166\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-n6gdc",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-n6gdc",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)(<nil>),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker00",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850522736,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850522735,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850522736,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850522736,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850522735,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.100",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.100"
        }
      },
      PodIP: (string) (len=14) "10.200.131.166",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "10.200.131.166"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850522735,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850522736,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://d52410a2e34608905b77b04750ee009763218e5489a2caf91bf59a818532120d",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 16:19:00.850: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3382" for this suite. @ 05/05/24 16:19:00.894
• [5.268 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:161
  STEP: Creating a kubernetes client @ 05/05/24 16:19:00.946
  May  5 16:19:00.946: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename cronjob @ 05/05/24 16:19:00.951
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:19:00.996
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:19:01.016
  STEP: Creating a ReplaceConcurrent cronjob @ 05/05/24 16:19:01.03
  STEP: Ensuring a job is scheduled @ 05/05/24 16:19:01.046
  STEP: Ensuring exactly one is scheduled @ 05/05/24 16:20:01.052
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 05/05/24 16:20:01.06
  STEP: Ensuring the job is replaced with a new one @ 05/05/24 16:20:01.064
  STEP: Removing cronjob @ 05/05/24 16:21:01.068
  May  5 16:21:01.072: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-6814" for this suite. @ 05/05/24 16:21:01.075
• [120.138 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 05/05/24 16:21:01.089
  May  5 16:21:01.089: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename discovery @ 05/05/24 16:21:01.092
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:21:01.119
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:21:01.125
  STEP: Setting up server cert @ 05/05/24 16:21:01.131
  May  5 16:21:01.343: INFO: Checking APIGroup: apiregistration.k8s.io
  May  5 16:21:01.344: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  May  5 16:21:01.344: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
  May  5 16:21:01.344: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  May  5 16:21:01.344: INFO: Checking APIGroup: apps
  May  5 16:21:01.346: INFO: PreferredVersion.GroupVersion: apps/v1
  May  5 16:21:01.346: INFO: Versions found [{apps/v1 v1}]
  May  5 16:21:01.346: INFO: apps/v1 matches apps/v1
  May  5 16:21:01.346: INFO: Checking APIGroup: events.k8s.io
  May  5 16:21:01.348: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
  May  5 16:21:01.348: INFO: Versions found [{events.k8s.io/v1 v1}]
  May  5 16:21:01.348: INFO: events.k8s.io/v1 matches events.k8s.io/v1
  May  5 16:21:01.348: INFO: Checking APIGroup: authentication.k8s.io
  May  5 16:21:01.351: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
  May  5 16:21:01.351: INFO: Versions found [{authentication.k8s.io/v1 v1} {authentication.k8s.io/v1beta1 v1beta1} {authentication.k8s.io/v1alpha1 v1alpha1}]
  May  5 16:21:01.351: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
  May  5 16:21:01.351: INFO: Checking APIGroup: authorization.k8s.io
  May  5 16:21:01.354: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
  May  5 16:21:01.354: INFO: Versions found [{authorization.k8s.io/v1 v1}]
  May  5 16:21:01.354: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
  May  5 16:21:01.354: INFO: Checking APIGroup: autoscaling
  May  5 16:21:01.355: INFO: PreferredVersion.GroupVersion: autoscaling/v2
  May  5 16:21:01.355: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  May  5 16:21:01.355: INFO: autoscaling/v2 matches autoscaling/v2
  May  5 16:21:01.355: INFO: Checking APIGroup: batch
  May  5 16:21:01.358: INFO: PreferredVersion.GroupVersion: batch/v1
  May  5 16:21:01.358: INFO: Versions found [{batch/v1 v1}]
  May  5 16:21:01.358: INFO: batch/v1 matches batch/v1
  May  5 16:21:01.358: INFO: Checking APIGroup: certificates.k8s.io
  May  5 16:21:01.359: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
  May  5 16:21:01.359: INFO: Versions found [{certificates.k8s.io/v1 v1}]
  May  5 16:21:01.359: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
  May  5 16:21:01.359: INFO: Checking APIGroup: networking.k8s.io
  May  5 16:21:01.361: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
  May  5 16:21:01.361: INFO: Versions found [{networking.k8s.io/v1 v1} {networking.k8s.io/v1alpha1 v1alpha1}]
  May  5 16:21:01.361: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
  May  5 16:21:01.361: INFO: Checking APIGroup: policy
  May  5 16:21:01.362: INFO: PreferredVersion.GroupVersion: policy/v1
  May  5 16:21:01.363: INFO: Versions found [{policy/v1 v1}]
  May  5 16:21:01.363: INFO: policy/v1 matches policy/v1
  May  5 16:21:01.363: INFO: Checking APIGroup: rbac.authorization.k8s.io
  May  5 16:21:01.364: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  May  5 16:21:01.364: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
  May  5 16:21:01.364: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  May  5 16:21:01.364: INFO: Checking APIGroup: storage.k8s.io
  May  5 16:21:01.366: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
  May  5 16:21:01.366: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1alpha1 v1alpha1}]
  May  5 16:21:01.366: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
  May  5 16:21:01.366: INFO: Checking APIGroup: admissionregistration.k8s.io
  May  5 16:21:01.368: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  May  5 16:21:01.368: INFO: Versions found [{admissionregistration.k8s.io/v1 v1} {admissionregistration.k8s.io/v1beta1 v1beta1} {admissionregistration.k8s.io/v1alpha1 v1alpha1}]
  May  5 16:21:01.368: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  May  5 16:21:01.368: INFO: Checking APIGroup: apiextensions.k8s.io
  May  5 16:21:01.371: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  May  5 16:21:01.371: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
  May  5 16:21:01.371: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  May  5 16:21:01.371: INFO: Checking APIGroup: scheduling.k8s.io
  May  5 16:21:01.372: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  May  5 16:21:01.372: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
  May  5 16:21:01.372: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  May  5 16:21:01.372: INFO: Checking APIGroup: coordination.k8s.io
  May  5 16:21:01.374: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
  May  5 16:21:01.374: INFO: Versions found [{coordination.k8s.io/v1 v1}]
  May  5 16:21:01.374: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
  May  5 16:21:01.374: INFO: Checking APIGroup: node.k8s.io
  May  5 16:21:01.376: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
  May  5 16:21:01.376: INFO: Versions found [{node.k8s.io/v1 v1}]
  May  5 16:21:01.376: INFO: node.k8s.io/v1 matches node.k8s.io/v1
  May  5 16:21:01.376: INFO: Checking APIGroup: discovery.k8s.io
  May  5 16:21:01.378: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
  May  5 16:21:01.378: INFO: Versions found [{discovery.k8s.io/v1 v1}]
  May  5 16:21:01.378: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
  May  5 16:21:01.378: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
  May  5 16:21:01.380: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  May  5 16:21:01.380: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1 v1} {flowcontrol.apiserver.k8s.io/v1beta3 v1beta3}]
  May  5 16:21:01.380: INFO: flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  May  5 16:21:01.380: INFO: Checking APIGroup: internal.apiserver.k8s.io
  May  5 16:21:01.381: INFO: PreferredVersion.GroupVersion: internal.apiserver.k8s.io/v1alpha1
  May  5 16:21:01.381: INFO: Versions found [{internal.apiserver.k8s.io/v1alpha1 v1alpha1}]
  May  5 16:21:01.381: INFO: internal.apiserver.k8s.io/v1alpha1 matches internal.apiserver.k8s.io/v1alpha1
  May  5 16:21:01.381: INFO: Checking APIGroup: resource.k8s.io
  May  5 16:21:01.383: INFO: PreferredVersion.GroupVersion: resource.k8s.io/v1alpha2
  May  5 16:21:01.383: INFO: Versions found [{resource.k8s.io/v1alpha2 v1alpha2}]
  May  5 16:21:01.383: INFO: resource.k8s.io/v1alpha2 matches resource.k8s.io/v1alpha2
  May  5 16:21:01.383: INFO: Checking APIGroup: crd.projectcalico.org
  May  5 16:21:01.386: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
  May  5 16:21:01.386: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
  May  5 16:21:01.386: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
  May  5 16:21:01.386: INFO: Checking APIGroup: snapshot.storage.k8s.io
  May  5 16:21:01.388: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
  May  5 16:21:01.388: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1}]
  May  5 16:21:01.388: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
  May  5 16:21:01.388: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-4475" for this suite. @ 05/05/24 16:21:01.392
• [0.324 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 05/05/24 16:21:01.412
  May  5 16:21:01.412: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename dns @ 05/05/24 16:21:01.413
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:21:01.437
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:21:01.443
  STEP: Creating a test headless service @ 05/05/24 16:21:01.447
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9974.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9974.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9974.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9974.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9974.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9974.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9974.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9974.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9974.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9974.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 78.0.32.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.32.0.78_udp@PTR;check="$$(dig +tcp +noall +answer +search 78.0.32.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.32.0.78_tcp@PTR;sleep 1; done
   @ 05/05/24 16:21:01.471
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9974.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9974.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9974.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9974.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9974.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9974.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9974.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9974.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9974.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9974.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 78.0.32.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.32.0.78_udp@PTR;check="$$(dig +tcp +noall +answer +search 78.0.32.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.32.0.78_tcp@PTR;sleep 1; done
   @ 05/05/24 16:21:01.472
  STEP: creating a pod to probe DNS @ 05/05/24 16:21:01.472
  STEP: submitting the pod to kubernetes @ 05/05/24 16:21:01.472
  STEP: retrieving the pod @ 05/05/24 16:21:03.526
  STEP: looking for the results for each expected name from probers @ 05/05/24 16:21:03.531
  May  5 16:21:03.542: INFO: Unable to read wheezy_udp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:03.555: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:03.564: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:03.574: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:03.615: INFO: Unable to read jessie_udp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:03.628: INFO: Unable to read jessie_tcp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:03.639: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:03.649: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:03.690: INFO: Lookups using dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013 failed for: [wheezy_udp@dns-test-service.dns-9974.svc.cluster.local wheezy_tcp@dns-test-service.dns-9974.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local jessie_udp@dns-test-service.dns-9974.svc.cluster.local jessie_tcp@dns-test-service.dns-9974.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local]

  May  5 16:21:03.736: INFO: Pod client logs for webserver: 
  May  5 16:21:03.753: INFO: Pod client logs for querier: 
  May  5 16:21:03.765: INFO: Pod client logs for jessie-querier: 
  May  5 16:21:08.536: INFO: Unable to read wheezy_udp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:08.540: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:08.544: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:08.552: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:08.597: INFO: Unable to read jessie_udp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:08.605: INFO: Unable to read jessie_tcp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:08.612: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:08.622: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:08.651: INFO: Lookups using dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013 failed for: [wheezy_udp@dns-test-service.dns-9974.svc.cluster.local wheezy_tcp@dns-test-service.dns-9974.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local jessie_udp@dns-test-service.dns-9974.svc.cluster.local jessie_tcp@dns-test-service.dns-9974.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local]

  May  5 16:21:08.663: INFO: Pod client logs for webserver: 
  May  5 16:21:08.674: INFO: Pod client logs for querier: 
  May  5 16:21:08.689: INFO: Pod client logs for jessie-querier: 
  May  5 16:21:13.536: INFO: Unable to read wheezy_udp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:13.540: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:13.543: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:13.548: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:13.572: INFO: Unable to read jessie_udp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:13.578: INFO: Unable to read jessie_tcp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:13.584: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:13.589: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:13.605: INFO: Lookups using dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013 failed for: [wheezy_udp@dns-test-service.dns-9974.svc.cluster.local wheezy_tcp@dns-test-service.dns-9974.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local jessie_udp@dns-test-service.dns-9974.svc.cluster.local jessie_tcp@dns-test-service.dns-9974.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local]

  May  5 16:21:13.617: INFO: Pod client logs for webserver: 
  May  5 16:21:13.628: INFO: Pod client logs for querier: 
  May  5 16:21:13.641: INFO: Pod client logs for jessie-querier: 
  May  5 16:21:18.535: INFO: Unable to read wheezy_udp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:18.539: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:18.544: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:18.550: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:18.584: INFO: Unable to read jessie_udp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:18.590: INFO: Unable to read jessie_tcp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:18.598: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:18.605: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:18.625: INFO: Lookups using dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013 failed for: [wheezy_udp@dns-test-service.dns-9974.svc.cluster.local wheezy_tcp@dns-test-service.dns-9974.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local jessie_udp@dns-test-service.dns-9974.svc.cluster.local jessie_tcp@dns-test-service.dns-9974.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local]

  May  5 16:21:18.635: INFO: Pod client logs for webserver: 
  May  5 16:21:18.644: INFO: Pod client logs for querier: 
  May  5 16:21:18.656: INFO: Pod client logs for jessie-querier: 
  May  5 16:21:23.539: INFO: Unable to read wheezy_udp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:23.544: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:23.548: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:23.552: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:23.574: INFO: Unable to read jessie_udp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:23.579: INFO: Unable to read jessie_tcp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:23.585: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:23.591: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:23.614: INFO: Lookups using dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013 failed for: [wheezy_udp@dns-test-service.dns-9974.svc.cluster.local wheezy_tcp@dns-test-service.dns-9974.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local jessie_udp@dns-test-service.dns-9974.svc.cluster.local jessie_tcp@dns-test-service.dns-9974.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local]

  May  5 16:21:23.630: INFO: Pod client logs for webserver: 
  May  5 16:21:23.639: INFO: Pod client logs for querier: 
  May  5 16:21:23.648: INFO: Pod client logs for jessie-querier: 
  May  5 16:21:28.540: INFO: Unable to read wheezy_udp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:28.548: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:28.554: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:28.561: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:28.602: INFO: Unable to read jessie_udp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:28.611: INFO: Unable to read jessie_tcp@dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:28.621: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:28.632: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local from pod dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013: the server could not find the requested resource (get pods dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013)
  May  5 16:21:28.659: INFO: Lookups using dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013 failed for: [wheezy_udp@dns-test-service.dns-9974.svc.cluster.local wheezy_tcp@dns-test-service.dns-9974.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local jessie_udp@dns-test-service.dns-9974.svc.cluster.local jessie_tcp@dns-test-service.dns-9974.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9974.svc.cluster.local]

  May  5 16:21:28.669: INFO: Pod client logs for webserver: 
  May  5 16:21:28.680: INFO: Pod client logs for querier: 
  May  5 16:21:28.691: INFO: Pod client logs for jessie-querier: 
  May  5 16:21:33.587: INFO: DNS probes using dns-9974/dns-test-c49ba7e2-a8ea-45ca-8af1-a6c74dd03013 succeeded

  STEP: deleting the pod @ 05/05/24 16:21:33.587
  STEP: deleting the test service @ 05/05/24 16:21:33.623
  STEP: deleting the test headless service @ 05/05/24 16:21:33.684
  May  5 16:21:33.712: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-9974" for this suite. @ 05/05/24 16:21:33.718
• [32.326 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 05/05/24 16:21:33.74
  May  5 16:21:33.740: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename daemonsets @ 05/05/24 16:21:33.746
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:21:33.771
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:21:33.777
  STEP: Creating simple DaemonSet "daemon-set" @ 05/05/24 16:21:33.798
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/05/24 16:21:33.809
  May  5 16:21:33.823: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 16:21:33.823: INFO: Node worker00 is running 0 daemon pod, expected 1
  May  5 16:21:34.843: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 16:21:34.843: INFO: Node worker00 is running 0 daemon pod, expected 1
  May  5 16:21:35.821: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May  5 16:21:35.821: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 05/05/24 16:21:35.826
  May  5 16:21:35.867: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May  5 16:21:35.867: INFO: Node worker01 is running 0 daemon pod, expected 1
  May  5 16:21:36.861: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May  5 16:21:36.861: INFO: Node worker01 is running 0 daemon pod, expected 1
  May  5 16:21:37.872: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May  5 16:21:37.872: INFO: Node worker01 is running 0 daemon pod, expected 1
  May  5 16:21:38.872: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May  5 16:21:38.872: INFO: Node worker01 is running 0 daemon pod, expected 1
  May  5 16:21:39.863: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May  5 16:21:39.863: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 05/05/24 16:21:39.866
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5812, will wait for the garbage collector to delete the pods @ 05/05/24 16:21:39.866
  May  5 16:21:39.925: INFO: Deleting DaemonSet.extensions daemon-set took: 4.50296ms
  May  5 16:21:40.027: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.520528ms
  May  5 16:21:42.830: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 16:21:42.830: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  May  5 16:21:42.833: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"8726"},"items":null}

  May  5 16:21:42.835: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"8726"},"items":null}

  May  5 16:21:42.844: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-5812" for this suite. @ 05/05/24 16:21:42.848
• [9.114 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 05/05/24 16:21:42.854
  May  5 16:21:42.854: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename proxy @ 05/05/24 16:21:42.856
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:21:42.875
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:21:42.88
  STEP: starting an echo server on multiple ports @ 05/05/24 16:21:42.895
  STEP: creating replication controller proxy-service-kvhd6 in namespace proxy-6487 @ 05/05/24 16:21:42.896
  I0505 16:21:42.919095      22 runners.go:197] Created replication controller with name: proxy-service-kvhd6, namespace: proxy-6487, replica count: 1
  I0505 16:21:43.971208      22 runners.go:197] proxy-service-kvhd6 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0505 16:21:44.971810      22 runners.go:197] proxy-service-kvhd6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  I0505 16:21:45.974434      22 runners.go:197] proxy-service-kvhd6 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May  5 16:21:45.979: INFO: setup took 3.095099821s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 05/05/24 16:21:45.979
  May  5 16:21:45.987: INFO: (0) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname2/proxy/: bar (200; 5.651827ms)
  May  5 16:21:45.987: INFO: (0) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 6.998202ms)
  May  5 16:21:45.991: INFO: (0) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname1/proxy/: foo (200; 9.255983ms)
  May  5 16:21:45.992: INFO: (0) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/rewriteme">test</a> (200; 11.124903ms)
  May  5 16:21:45.992: INFO: (0) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname1/proxy/: foo (200; 11.288991ms)
  May  5 16:21:45.992: INFO: (0) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 10.703471ms)
  May  5 16:21:45.992: INFO: (0) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">test<... (200; 10.871229ms)
  May  5 16:21:45.992: INFO: (0) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 10.985863ms)
  May  5 16:21:45.992: INFO: (0) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname2/proxy/: bar (200; 11.195513ms)
  May  5 16:21:45.992: INFO: (0) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 11.378976ms)
  May  5 16:21:45.997: INFO: (0) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">... (200; 15.34951ms)
  May  5 16:21:45.997: INFO: (0) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname1/proxy/: tls baz (200; 15.572677ms)
  May  5 16:21:45.997: INFO: (0) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:460/proxy/: tls baz (200; 17.205189ms)
  May  5 16:21:46.003: INFO: (0) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:462/proxy/: tls qux (200; 22.543871ms)
  May  5 16:21:46.004: INFO: (0) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname2/proxy/: tls qux (200; 22.387742ms)
  May  5 16:21:46.005: INFO: (0) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/tlsrewritem... (200; 24.073014ms)
  May  5 16:21:46.017: INFO: (1) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 10.70605ms)
  May  5 16:21:46.017: INFO: (1) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname1/proxy/: tls baz (200; 10.878721ms)
  May  5 16:21:46.017: INFO: (1) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 10.782879ms)
  May  5 16:21:46.017: INFO: (1) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname1/proxy/: foo (200; 10.98956ms)
  May  5 16:21:46.018: INFO: (1) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 12.036579ms)
  May  5 16:21:46.018: INFO: (1) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname2/proxy/: bar (200; 12.038737ms)
  May  5 16:21:46.018: INFO: (1) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">test<... (200; 12.347434ms)
  May  5 16:21:46.019: INFO: (1) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/rewriteme">test</a> (200; 13.423371ms)
  May  5 16:21:46.021: INFO: (1) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:460/proxy/: tls baz (200; 15.566609ms)
  May  5 16:21:46.022: INFO: (1) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 16.288572ms)
  May  5 16:21:46.025: INFO: (1) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">... (200; 18.930219ms)
  May  5 16:21:46.025: INFO: (1) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname2/proxy/: tls qux (200; 19.413511ms)
  May  5 16:21:46.025: INFO: (1) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname1/proxy/: foo (200; 19.230735ms)
  May  5 16:21:46.025: INFO: (1) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname2/proxy/: bar (200; 18.681326ms)
  May  5 16:21:46.025: INFO: (1) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:462/proxy/: tls qux (200; 18.929929ms)
  May  5 16:21:46.025: INFO: (1) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/tlsrewritem... (200; 18.657853ms)
  May  5 16:21:46.031: INFO: (2) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 5.879296ms)
  May  5 16:21:46.035: INFO: (2) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">... (200; 9.087007ms)
  May  5 16:21:46.035: INFO: (2) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 9.102169ms)
  May  5 16:21:46.036: INFO: (2) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 9.990765ms)
  May  5 16:21:46.036: INFO: (2) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:462/proxy/: tls qux (200; 10.24788ms)
  May  5 16:21:46.040: INFO: (2) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/rewriteme">test</a> (200; 14.959946ms)
  May  5 16:21:46.041: INFO: (2) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">test<... (200; 14.649153ms)
  May  5 16:21:46.041: INFO: (2) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/tlsrewritem... (200; 14.398353ms)
  May  5 16:21:46.044: INFO: (2) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname2/proxy/: bar (200; 18.641853ms)
  May  5 16:21:46.044: INFO: (2) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname2/proxy/: bar (200; 18.466382ms)
  May  5 16:21:46.044: INFO: (2) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname2/proxy/: tls qux (200; 17.850159ms)
  May  5 16:21:46.044: INFO: (2) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:460/proxy/: tls baz (200; 17.788712ms)
  May  5 16:21:46.044: INFO: (2) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname1/proxy/: tls baz (200; 17.829124ms)
  May  5 16:21:46.044: INFO: (2) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname1/proxy/: foo (200; 18.962208ms)
  May  5 16:21:46.044: INFO: (2) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 17.988192ms)
  May  5 16:21:46.045: INFO: (2) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname1/proxy/: foo (200; 18.873906ms)
  May  5 16:21:46.054: INFO: (3) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname1/proxy/: foo (200; 7.169891ms)
  May  5 16:21:46.055: INFO: (3) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 7.905859ms)
  May  5 16:21:46.056: INFO: (3) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">test<... (200; 9.259414ms)
  May  5 16:21:46.057: INFO: (3) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/tlsrewritem... (200; 9.761744ms)
  May  5 16:21:46.062: INFO: (3) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/rewriteme">test</a> (200; 14.743147ms)
  May  5 16:21:46.062: INFO: (3) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 14.760883ms)
  May  5 16:21:46.062: INFO: (3) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname2/proxy/: bar (200; 14.80063ms)
  May  5 16:21:46.062: INFO: (3) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">... (200; 15.363775ms)
  May  5 16:21:46.062: INFO: (3) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname2/proxy/: tls qux (200; 15.528644ms)
  May  5 16:21:46.063: INFO: (3) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 15.485405ms)
  May  5 16:21:46.063: INFO: (3) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname2/proxy/: bar (200; 16.091263ms)
  May  5 16:21:46.063: INFO: (3) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 15.533463ms)
  May  5 16:21:46.063: INFO: (3) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:460/proxy/: tls baz (200; 16.27344ms)
  May  5 16:21:46.069: INFO: (3) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname1/proxy/: foo (200; 21.943078ms)
  May  5 16:21:46.069: INFO: (3) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname1/proxy/: tls baz (200; 22.114984ms)
  May  5 16:21:46.069: INFO: (3) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:462/proxy/: tls qux (200; 22.19637ms)
  May  5 16:21:46.076: INFO: (4) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 6.364661ms)
  May  5 16:21:46.077: INFO: (4) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:462/proxy/: tls qux (200; 7.48662ms)
  May  5 16:21:46.079: INFO: (4) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">... (200; 7.744167ms)
  May  5 16:21:46.081: INFO: (4) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname1/proxy/: tls baz (200; 10.372371ms)
  May  5 16:21:46.086: INFO: (4) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">test<... (200; 12.812104ms)
  May  5 16:21:46.086: INFO: (4) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 14.724249ms)
  May  5 16:21:46.086: INFO: (4) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 15.064626ms)
  May  5 16:21:46.086: INFO: (4) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/rewriteme">test</a> (200; 15.297402ms)
  May  5 16:21:46.088: INFO: (4) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname1/proxy/: foo (200; 18.977106ms)
  May  5 16:21:46.094: INFO: (4) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 19.58701ms)
  May  5 16:21:46.094: INFO: (4) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/tlsrewritem... (200; 19.752469ms)
  May  5 16:21:46.094: INFO: (4) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname1/proxy/: foo (200; 20.07491ms)
  May  5 16:21:46.094: INFO: (4) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname2/proxy/: bar (200; 21.79528ms)
  May  5 16:21:46.095: INFO: (4) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname2/proxy/: bar (200; 24.907876ms)
  May  5 16:21:46.096: INFO: (4) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:460/proxy/: tls baz (200; 21.611717ms)
  May  5 16:21:46.098: INFO: (4) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname2/proxy/: tls qux (200; 24.960421ms)
  May  5 16:21:46.108: INFO: (5) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/rewriteme">test</a> (200; 8.682909ms)
  May  5 16:21:46.108: INFO: (5) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">test<... (200; 9.78258ms)
  May  5 16:21:46.110: INFO: (5) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 11.177365ms)
  May  5 16:21:46.111: INFO: (5) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname2/proxy/: bar (200; 11.998171ms)
  May  5 16:21:46.111: INFO: (5) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">... (200; 12.543725ms)
  May  5 16:21:46.115: INFO: (5) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:462/proxy/: tls qux (200; 15.407119ms)
  May  5 16:21:46.115: INFO: (5) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:460/proxy/: tls baz (200; 15.819524ms)
  May  5 16:21:46.116: INFO: (5) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/tlsrewritem... (200; 16.836672ms)
  May  5 16:21:46.116: INFO: (5) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 16.870166ms)
  May  5 16:21:46.117: INFO: (5) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname2/proxy/: bar (200; 17.239031ms)
  May  5 16:21:46.117: INFO: (5) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 17.60506ms)
  May  5 16:21:46.117: INFO: (5) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname2/proxy/: tls qux (200; 18.499767ms)
  May  5 16:21:46.117: INFO: (5) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname1/proxy/: foo (200; 18.001108ms)
  May  5 16:21:46.117: INFO: (5) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname1/proxy/: foo (200; 18.268473ms)
  May  5 16:21:46.118: INFO: (5) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 17.954486ms)
  May  5 16:21:46.118: INFO: (5) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname1/proxy/: tls baz (200; 18.586633ms)
  May  5 16:21:46.128: INFO: (6) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 9.955369ms)
  May  5 16:21:46.134: INFO: (6) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:462/proxy/: tls qux (200; 15.437284ms)
  May  5 16:21:46.134: INFO: (6) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname1/proxy/: foo (200; 16.147435ms)
  May  5 16:21:46.135: INFO: (6) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">test<... (200; 16.062473ms)
  May  5 16:21:46.135: INFO: (6) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname2/proxy/: bar (200; 16.636185ms)
  May  5 16:21:46.135: INFO: (6) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 16.902171ms)
  May  5 16:21:46.136: INFO: (6) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 17.528742ms)
  May  5 16:21:46.138: INFO: (6) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 19.422029ms)
  May  5 16:21:46.138: INFO: (6) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname2/proxy/: bar (200; 19.525968ms)
  May  5 16:21:46.138: INFO: (6) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname1/proxy/: tls baz (200; 19.537171ms)
  May  5 16:21:46.138: INFO: (6) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname1/proxy/: foo (200; 19.653909ms)
  May  5 16:21:46.138: INFO: (6) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:460/proxy/: tls baz (200; 19.721043ms)
  May  5 16:21:46.138: INFO: (6) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/rewriteme">test</a> (200; 19.678499ms)
  May  5 16:21:46.138: INFO: (6) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/tlsrewritem... (200; 20.097779ms)
  May  5 16:21:46.138: INFO: (6) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">... (200; 19.733336ms)
  May  5 16:21:46.138: INFO: (6) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname2/proxy/: tls qux (200; 19.397524ms)
  May  5 16:21:46.155: INFO: (7) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">test<... (200; 14.984321ms)
  May  5 16:21:46.155: INFO: (7) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:462/proxy/: tls qux (200; 15.380891ms)
  May  5 16:21:46.155: INFO: (7) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:460/proxy/: tls baz (200; 15.193924ms)
  May  5 16:21:46.162: INFO: (7) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/tlsrewritem... (200; 23.410678ms)
  May  5 16:21:46.171: INFO: (7) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/rewriteme">test</a> (200; 32.599367ms)
  May  5 16:21:46.171: INFO: (7) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">... (200; 31.043374ms)
  May  5 16:21:46.171: INFO: (7) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 31.291636ms)
  May  5 16:21:46.172: INFO: (7) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 33.002105ms)
  May  5 16:21:46.172: INFO: (7) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 32.227056ms)
  May  5 16:21:46.172: INFO: (7) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 31.642779ms)
  May  5 16:21:46.172: INFO: (7) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname2/proxy/: bar (200; 31.677026ms)
  May  5 16:21:46.182: INFO: (7) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname1/proxy/: foo (200; 42.751977ms)
  May  5 16:21:46.183: INFO: (7) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname1/proxy/: tls baz (200; 42.516272ms)
  May  5 16:21:46.183: INFO: (7) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname2/proxy/: bar (200; 43.248454ms)
  May  5 16:21:46.183: INFO: (7) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname1/proxy/: foo (200; 44.212987ms)
  May  5 16:21:46.183: INFO: (7) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname2/proxy/: tls qux (200; 43.246546ms)
  May  5 16:21:46.201: INFO: (8) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/rewriteme">test</a> (200; 15.85259ms)
  May  5 16:21:46.220: INFO: (8) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:462/proxy/: tls qux (200; 31.807728ms)
  May  5 16:21:46.229: INFO: (8) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/tlsrewritem... (200; 44.200813ms)
  May  5 16:21:46.238: INFO: (8) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">test<... (200; 48.418858ms)
  May  5 16:21:46.238: INFO: (8) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 53.311492ms)
  May  5 16:21:46.238: INFO: (8) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 48.879048ms)
  May  5 16:21:46.238: INFO: (8) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 48.861606ms)
  May  5 16:21:46.238: INFO: (8) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 49.635548ms)
  May  5 16:21:46.238: INFO: (8) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">... (200; 48.80829ms)
  May  5 16:21:46.238: INFO: (8) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:460/proxy/: tls baz (200; 48.926413ms)
  May  5 16:21:46.239: INFO: (8) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname2/proxy/: bar (200; 50.792812ms)
  May  5 16:21:46.239: INFO: (8) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname1/proxy/: foo (200; 49.438244ms)
  May  5 16:21:46.239: INFO: (8) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname1/proxy/: foo (200; 49.554158ms)
  May  5 16:21:46.239: INFO: (8) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname2/proxy/: bar (200; 49.493446ms)
  May  5 16:21:46.239: INFO: (8) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname1/proxy/: tls baz (200; 50.708484ms)
  May  5 16:21:46.239: INFO: (8) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname2/proxy/: tls qux (200; 49.851897ms)
  May  5 16:21:46.260: INFO: (9) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 19.343645ms)
  May  5 16:21:46.267: INFO: (9) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname1/proxy/: foo (200; 25.506076ms)
  May  5 16:21:46.267: INFO: (9) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 25.750178ms)
  May  5 16:21:46.267: INFO: (9) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">test<... (200; 27.651579ms)
  May  5 16:21:46.267: INFO: (9) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/rewriteme">test</a> (200; 26.578694ms)
  May  5 16:21:46.268: INFO: (9) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:460/proxy/: tls baz (200; 26.301993ms)
  May  5 16:21:46.268: INFO: (9) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 26.194153ms)
  May  5 16:21:46.268: INFO: (9) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">... (200; 26.839912ms)
  May  5 16:21:46.268: INFO: (9) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 26.624218ms)
  May  5 16:21:46.268: INFO: (9) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/tlsrewritem... (200; 26.35841ms)
  May  5 16:21:46.268: INFO: (9) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname2/proxy/: tls qux (200; 26.735932ms)
  May  5 16:21:46.268: INFO: (9) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname1/proxy/: foo (200; 26.559487ms)
  May  5 16:21:46.268: INFO: (9) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:462/proxy/: tls qux (200; 26.7375ms)
  May  5 16:21:46.268: INFO: (9) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname2/proxy/: bar (200; 26.600554ms)
  May  5 16:21:46.268: INFO: (9) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname2/proxy/: bar (200; 27.125585ms)
  May  5 16:21:46.274: INFO: (9) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname1/proxy/: tls baz (200; 32.24094ms)
  May  5 16:21:46.282: INFO: (10) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">... (200; 8.380115ms)
  May  5 16:21:46.282: INFO: (10) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 8.630394ms)
  May  5 16:21:46.282: INFO: (10) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/rewriteme">test</a> (200; 8.36227ms)
  May  5 16:21:46.284: INFO: (10) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/tlsrewritem... (200; 9.906785ms)
  May  5 16:21:46.288: INFO: (10) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname2/proxy/: tls qux (200; 13.652085ms)
  May  5 16:21:46.288: INFO: (10) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 13.757653ms)
  May  5 16:21:46.288: INFO: (10) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 13.899797ms)
  May  5 16:21:46.290: INFO: (10) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">test<... (200; 15.743572ms)
  May  5 16:21:46.294: INFO: (10) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 19.694739ms)
  May  5 16:21:46.296: INFO: (10) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname1/proxy/: foo (200; 22.236204ms)
  May  5 16:21:46.297: INFO: (10) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:462/proxy/: tls qux (200; 22.92071ms)
  May  5 16:21:46.299: INFO: (10) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname2/proxy/: bar (200; 25.41257ms)
  May  5 16:21:46.303: INFO: (10) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname1/proxy/: tls baz (200; 29.2886ms)
  May  5 16:21:46.307: INFO: (10) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname2/proxy/: bar (200; 29.097077ms)
  May  5 16:21:46.315: INFO: (10) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:460/proxy/: tls baz (200; 40.298499ms)
  May  5 16:21:46.320: INFO: (10) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname1/proxy/: foo (200; 42.998224ms)
  May  5 16:21:46.332: INFO: (11) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/rewriteme">test</a> (200; 11.951377ms)
  May  5 16:21:46.332: INFO: (11) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 11.83583ms)
  May  5 16:21:46.338: INFO: (11) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 17.700022ms)
  May  5 16:21:46.343: INFO: (11) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">test<... (200; 22.704857ms)
  May  5 16:21:46.343: INFO: (11) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">... (200; 22.800193ms)
  May  5 16:21:46.344: INFO: (11) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/tlsrewritem... (200; 24.315874ms)
  May  5 16:21:46.355: INFO: (11) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 30.303665ms)
  May  5 16:21:46.356: INFO: (11) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname1/proxy/: foo (200; 34.921083ms)
  May  5 16:21:46.356: INFO: (11) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname2/proxy/: bar (200; 36.111193ms)
  May  5 16:21:46.356: INFO: (11) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname1/proxy/: foo (200; 31.216583ms)
  May  5 16:21:46.356: INFO: (11) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 36.09855ms)
  May  5 16:21:46.358: INFO: (11) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname2/proxy/: bar (200; 37.499905ms)
  May  5 16:21:46.358: INFO: (11) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname2/proxy/: tls qux (200; 37.412447ms)
  May  5 16:21:46.358: INFO: (11) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:462/proxy/: tls qux (200; 33.192724ms)
  May  5 16:21:46.363: INFO: (11) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname1/proxy/: tls baz (200; 41.821958ms)
  May  5 16:21:46.363: INFO: (11) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:460/proxy/: tls baz (200; 38.615205ms)
  May  5 16:21:46.379: INFO: (12) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 15.740234ms)
  May  5 16:21:46.379: INFO: (12) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">... (200; 15.793376ms)
  May  5 16:21:46.379: INFO: (12) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/tlsrewritem... (200; 15.802303ms)
  May  5 16:21:46.379: INFO: (12) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/rewriteme">test</a> (200; 15.998997ms)
  May  5 16:21:46.379: INFO: (12) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 16.172093ms)
  May  5 16:21:46.380: INFO: (12) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 16.063373ms)
  May  5 16:21:46.380: INFO: (12) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">test<... (200; 16.295551ms)
  May  5 16:21:46.380: INFO: (12) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname2/proxy/: bar (200; 16.669889ms)
  May  5 16:21:46.381: INFO: (12) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname2/proxy/: bar (200; 17.405156ms)
  May  5 16:21:46.380: INFO: (12) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname1/proxy/: foo (200; 16.858117ms)
  May  5 16:21:46.380: INFO: (12) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname1/proxy/: tls baz (200; 16.665202ms)
  May  5 16:21:46.380: INFO: (12) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname1/proxy/: foo (200; 16.583973ms)
  May  5 16:21:46.380: INFO: (12) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 16.809603ms)
  May  5 16:21:46.380: INFO: (12) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname2/proxy/: tls qux (200; 17.150479ms)
  May  5 16:21:46.380: INFO: (12) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:460/proxy/: tls baz (200; 17.068524ms)
  May  5 16:21:46.380: INFO: (12) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:462/proxy/: tls qux (200; 17.025973ms)
  May  5 16:21:46.391: INFO: (13) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/rewriteme">test</a> (200; 9.190076ms)
  May  5 16:21:46.391: INFO: (13) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 9.11492ms)
  May  5 16:21:46.391: INFO: (13) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 8.731399ms)
  May  5 16:21:46.391: INFO: (13) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">... (200; 9.546787ms)
  May  5 16:21:46.391: INFO: (13) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 9.300679ms)
  May  5 16:21:46.400: INFO: (13) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 17.349053ms)
  May  5 16:21:46.400: INFO: (13) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:460/proxy/: tls baz (200; 17.57339ms)
  May  5 16:21:46.400: INFO: (13) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname2/proxy/: bar (200; 16.186269ms)
  May  5 16:21:46.400: INFO: (13) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname1/proxy/: tls baz (200; 17.979085ms)
  May  5 16:21:46.400: INFO: (13) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">test<... (200; 17.801437ms)
  May  5 16:21:46.400: INFO: (13) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname2/proxy/: bar (200; 18.132146ms)
  May  5 16:21:46.402: INFO: (13) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname1/proxy/: foo (200; 19.848692ms)
  May  5 16:21:46.402: INFO: (13) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:462/proxy/: tls qux (200; 19.640263ms)
  May  5 16:21:46.402: INFO: (13) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/tlsrewritem... (200; 20.158749ms)
  May  5 16:21:46.402: INFO: (13) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname2/proxy/: tls qux (200; 20.257362ms)
  May  5 16:21:46.403: INFO: (13) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname1/proxy/: foo (200; 20.726669ms)
  May  5 16:21:46.417: INFO: (14) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 12.246882ms)
  May  5 16:21:46.417: INFO: (14) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 12.308923ms)
  May  5 16:21:46.417: INFO: (14) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/rewriteme">test</a> (200; 12.914784ms)
  May  5 16:21:46.417: INFO: (14) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/tlsrewritem... (200; 13.100717ms)
  May  5 16:21:46.417: INFO: (14) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 12.951579ms)
  May  5 16:21:46.417: INFO: (14) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:462/proxy/: tls qux (200; 13.60363ms)
  May  5 16:21:46.417: INFO: (14) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 12.396976ms)
  May  5 16:21:46.415: INFO: (14) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">test<... (200; 10.757503ms)
  May  5 16:21:46.418: INFO: (14) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:460/proxy/: tls baz (200; 13.365414ms)
  May  5 16:21:46.423: INFO: (14) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname1/proxy/: foo (200; 19.084523ms)
  May  5 16:21:46.424: INFO: (14) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">... (200; 20.2519ms)
  May  5 16:21:46.424: INFO: (14) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname2/proxy/: bar (200; 19.873374ms)
  May  5 16:21:46.424: INFO: (14) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname2/proxy/: tls qux (200; 19.20945ms)
  May  5 16:21:46.424: INFO: (14) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname1/proxy/: tls baz (200; 20.084569ms)
  May  5 16:21:46.424: INFO: (14) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname1/proxy/: foo (200; 19.375768ms)
  May  5 16:21:46.424: INFO: (14) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname2/proxy/: bar (200; 20.604235ms)
  May  5 16:21:46.437: INFO: (15) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname2/proxy/: tls qux (200; 11.685772ms)
  May  5 16:21:46.437: INFO: (15) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">... (200; 13.578949ms)
  May  5 16:21:46.437: INFO: (15) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 11.931158ms)
  May  5 16:21:46.437: INFO: (15) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:460/proxy/: tls baz (200; 11.513052ms)
  May  5 16:21:46.437: INFO: (15) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 12.024257ms)
  May  5 16:21:46.437: INFO: (15) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/tlsrewritem... (200; 11.711339ms)
  May  5 16:21:46.437: INFO: (15) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 11.436067ms)
  May  5 16:21:46.437: INFO: (15) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">test<... (200; 11.84289ms)
  May  5 16:21:46.439: INFO: (15) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 13.602604ms)
  May  5 16:21:46.439: INFO: (15) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/rewriteme">test</a> (200; 13.469063ms)
  May  5 16:21:46.443: INFO: (15) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname2/proxy/: bar (200; 17.686898ms)
  May  5 16:21:46.443: INFO: (15) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname1/proxy/: tls baz (200; 17.720851ms)
  May  5 16:21:46.443: INFO: (15) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname1/proxy/: foo (200; 17.519804ms)
  May  5 16:21:46.443: INFO: (15) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname1/proxy/: foo (200; 17.482347ms)
  May  5 16:21:46.444: INFO: (15) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:462/proxy/: tls qux (200; 17.673174ms)
  May  5 16:21:46.447: INFO: (15) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname2/proxy/: bar (200; 21.387399ms)
  May  5 16:21:46.456: INFO: (16) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">... (200; 8.144519ms)
  May  5 16:21:46.457: INFO: (16) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 9.654257ms)
  May  5 16:21:46.457: INFO: (16) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:460/proxy/: tls baz (200; 9.556229ms)
  May  5 16:21:46.457: INFO: (16) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 9.809719ms)
  May  5 16:21:46.457: INFO: (16) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 9.619465ms)
  May  5 16:21:46.460: INFO: (16) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname1/proxy/: foo (200; 12.611247ms)
  May  5 16:21:46.463: INFO: (16) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">test<... (200; 15.521987ms)
  May  5 16:21:46.464: INFO: (16) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:462/proxy/: tls qux (200; 16.311496ms)
  May  5 16:21:46.464: INFO: (16) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname1/proxy/: tls baz (200; 16.357224ms)
  May  5 16:21:46.464: INFO: (16) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/tlsrewritem... (200; 16.938691ms)
  May  5 16:21:46.464: INFO: (16) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname2/proxy/: bar (200; 16.709881ms)
  May  5 16:21:46.464: INFO: (16) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname1/proxy/: foo (200; 16.851701ms)
  May  5 16:21:46.464: INFO: (16) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname2/proxy/: bar (200; 16.726519ms)
  May  5 16:21:46.465: INFO: (16) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/rewriteme">test</a> (200; 16.976179ms)
  May  5 16:21:46.465: INFO: (16) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 16.728823ms)
  May  5 16:21:46.465: INFO: (16) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname2/proxy/: tls qux (200; 16.750832ms)
  May  5 16:21:46.474: INFO: (17) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 7.856354ms)
  May  5 16:21:46.477: INFO: (17) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/rewriteme">test</a> (200; 10.688206ms)
  May  5 16:21:46.477: INFO: (17) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:462/proxy/: tls qux (200; 11.017338ms)
  May  5 16:21:46.477: INFO: (17) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">... (200; 11.001203ms)
  May  5 16:21:46.479: INFO: (17) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">test<... (200; 12.543226ms)
  May  5 16:21:46.480: INFO: (17) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname1/proxy/: tls baz (200; 13.979729ms)
  May  5 16:21:46.481: INFO: (17) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 14.439302ms)
  May  5 16:21:46.481: INFO: (17) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 14.57978ms)
  May  5 16:21:46.482: INFO: (17) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname1/proxy/: foo (200; 16.257662ms)
  May  5 16:21:46.482: INFO: (17) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 16.443909ms)
  May  5 16:21:46.483: INFO: (17) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/tlsrewritem... (200; 16.429259ms)
  May  5 16:21:46.487: INFO: (17) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname2/proxy/: bar (200; 20.707994ms)
  May  5 16:21:46.490: INFO: (17) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname2/proxy/: bar (200; 23.532309ms)
  May  5 16:21:46.490: INFO: (17) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname2/proxy/: tls qux (200; 23.553767ms)
  May  5 16:21:46.490: INFO: (17) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:460/proxy/: tls baz (200; 24.412572ms)
  May  5 16:21:46.494: INFO: (17) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname1/proxy/: foo (200; 28.156985ms)
  May  5 16:21:46.502: INFO: (18) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/rewriteme">test</a> (200; 7.583514ms)
  May  5 16:21:46.502: INFO: (18) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">... (200; 7.663326ms)
  May  5 16:21:46.502: INFO: (18) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/tlsrewritem... (200; 8.112294ms)
  May  5 16:21:46.503: INFO: (18) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">test<... (200; 8.976554ms)
  May  5 16:21:46.504: INFO: (18) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:460/proxy/: tls baz (200; 9.704201ms)
  May  5 16:21:46.509: INFO: (18) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 14.241791ms)
  May  5 16:21:46.509: INFO: (18) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:462/proxy/: tls qux (200; 13.811401ms)
  May  5 16:21:46.509: INFO: (18) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname1/proxy/: foo (200; 13.884523ms)
  May  5 16:21:46.509: INFO: (18) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 14.414155ms)
  May  5 16:21:46.509: INFO: (18) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 13.972564ms)
  May  5 16:21:46.509: INFO: (18) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 14.575408ms)
  May  5 16:21:46.512: INFO: (18) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname2/proxy/: bar (200; 16.748735ms)
  May  5 16:21:46.512: INFO: (18) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname2/proxy/: tls qux (200; 16.711255ms)
  May  5 16:21:46.512: INFO: (18) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname2/proxy/: bar (200; 17.38325ms)
  May  5 16:21:46.512: INFO: (18) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname1/proxy/: foo (200; 17.327172ms)
  May  5 16:21:46.519: INFO: (18) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname1/proxy/: tls baz (200; 24.049856ms)
  May  5 16:21:46.529: INFO: (19) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 10.398985ms)
  May  5 16:21:46.529: INFO: (19) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:443/proxy/tlsrewritem... (200; 10.593145ms)
  May  5 16:21:46.529: INFO: (19) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 9.845182ms)
  May  5 16:21:46.529: INFO: (19) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">test<... (200; 10.182175ms)
  May  5 16:21:46.529: INFO: (19) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:462/proxy/: tls qux (200; 9.965451ms)
  May  5 16:21:46.530: INFO: (19) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k:162/proxy/: bar (200; 9.966882ms)
  May  5 16:21:46.530: INFO: (19) /api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/proxy-service-kvhd6-xdg9k/proxy/rewriteme">test</a> (200; 9.938762ms)
  May  5 16:21:46.530: INFO: (19) /api/v1/namespaces/proxy-6487/pods/https:proxy-service-kvhd6-xdg9k:460/proxy/: tls baz (200; 10.321535ms)
  May  5 16:21:46.531: INFO: (19) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:160/proxy/: foo (200; 11.507312ms)
  May  5 16:21:46.531: INFO: (19) /api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/: <a href="/api/v1/namespaces/proxy-6487/pods/http:proxy-service-kvhd6-xdg9k:1080/proxy/rewriteme">... (200; 11.645243ms)
  May  5 16:21:46.536: INFO: (19) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname2/proxy/: bar (200; 16.226154ms)
  May  5 16:21:46.536: INFO: (19) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname2/proxy/: bar (200; 16.231784ms)
  May  5 16:21:46.538: INFO: (19) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname1/proxy/: tls baz (200; 18.181671ms)
  May  5 16:21:46.539: INFO: (19) /api/v1/namespaces/proxy-6487/services/proxy-service-kvhd6:portname1/proxy/: foo (200; 19.447885ms)
  May  5 16:21:46.540: INFO: (19) /api/v1/namespaces/proxy-6487/services/http:proxy-service-kvhd6:portname1/proxy/: foo (200; 20.640526ms)
  May  5 16:21:46.541: INFO: (19) /api/v1/namespaces/proxy-6487/services/https:proxy-service-kvhd6:tlsportname2/proxy/: tls qux (200; 21.65411ms)
  STEP: deleting ReplicationController proxy-service-kvhd6 in namespace proxy-6487, will wait for the garbage collector to delete the pods @ 05/05/24 16:21:46.542
  May  5 16:21:46.615: INFO: Deleting ReplicationController proxy-service-kvhd6 took: 16.064331ms
  May  5 16:21:46.716: INFO: Terminating ReplicationController proxy-service-kvhd6 pods took: 101.419362ms
  May  5 16:21:49.718: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-6487" for this suite. @ 05/05/24 16:21:49.724
• [6.880 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:550
  STEP: Creating a kubernetes client @ 05/05/24 16:21:49.735
  May  5 16:21:49.735: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename container-probe @ 05/05/24 16:21:49.742
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:21:49.769
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:21:49.776
  STEP: Creating pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960 @ 05/05/24 16:21:49.782
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/05/24 16:21:51.806
  May  5 16:21:51.809: INFO: Initial restart count of pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 is 0
  May  5 16:21:51.813: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:21:53.824: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:21:55.831: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:21:57.835: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:21:59.837: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:01.841: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:03.850: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:05.857: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:07.860: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:09.867: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:11.874: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:13.880: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:15.885: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:17.892: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:19.898: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:21.905: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:23.913: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:25.919: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:27.925: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:29.932: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:31.935: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:33.938: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:35.944: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:37.946: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:39.952: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:41.962: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:43.969: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:45.975: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:47.985: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:49.996: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:52.003: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:54.013: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:56.018: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:58.025: INFO: Get pod test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 in namespace container-probe-960
  May  5 16:22:58.026: INFO: Restart count of pod container-probe-960/test-grpc-7668a42c-cd92-4b6a-a46f-e891f132c650 is now 1 (1m6.216375759s elapsed)
  STEP: deleting the pod @ 05/05/24 16:22:58.026
  May  5 16:22:58.077: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-960" for this suite. @ 05/05/24 16:22:58.1
• [68.390 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 05/05/24 16:22:58.134
  May  5 16:22:58.134: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename crd-watch @ 05/05/24 16:22:58.137
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:22:58.196
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:22:58.207
  May  5 16:22:58.216: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Creating first CR  @ 05/05/24 16:23:00.762
  May  5 16:23:00.770: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-05T16:23:00Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-05T16:23:00Z]] name:name1 resourceVersion:9117 uid:9f81de11-8cd8-4ae5-aa68-9322d87ee28b] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Creating second CR @ 05/05/24 16:23:10.771
  May  5 16:23:10.779: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-05T16:23:10Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-05T16:23:10Z]] name:name2 resourceVersion:9164 uid:488132f8-a0be-4d27-a89e-55d0a1c3992c] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Modifying first CR @ 05/05/24 16:23:20.782
  May  5 16:23:20.786: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-05T16:23:00Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-05T16:23:20Z]] name:name1 resourceVersion:9198 uid:9f81de11-8cd8-4ae5-aa68-9322d87ee28b] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Modifying second CR @ 05/05/24 16:23:30.787
  May  5 16:23:30.795: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-05T16:23:10Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-05T16:23:30Z]] name:name2 resourceVersion:9234 uid:488132f8-a0be-4d27-a89e-55d0a1c3992c] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Deleting first CR @ 05/05/24 16:23:40.798
  May  5 16:23:40.816: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-05T16:23:00Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-05T16:23:20Z]] name:name1 resourceVersion:9270 uid:9f81de11-8cd8-4ae5-aa68-9322d87ee28b] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Deleting second CR @ 05/05/24 16:23:50.822
  May  5 16:23:50.838: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-05T16:23:10Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-05T16:23:30Z]] name:name2 resourceVersion:9304 uid:488132f8-a0be-4d27-a89e-55d0a1c3992c] num:map[num1:9223372036854775807 num2:1000000]]}
  May  5 16:24:01.349: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-7150" for this suite. @ 05/05/24 16:24:01.352
• [63.223 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:1015
  STEP: Creating a kubernetes client @ 05/05/24 16:24:01.357
  May  5 16:24:01.357: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename resourcequota @ 05/05/24 16:24:01.358
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:24:01.375
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:24:01.381
  STEP: Creating resourceQuota "e2e-rq-status-fgph4" @ 05/05/24 16:24:01.39
  May  5 16:24:01.402: INFO: Resource quota "e2e-rq-status-fgph4" reports spec: hard cpu limit of 500m
  May  5 16:24:01.402: INFO: Resource quota "e2e-rq-status-fgph4" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-fgph4" /status @ 05/05/24 16:24:01.402
  STEP: Confirm /status for "e2e-rq-status-fgph4" resourceQuota via watch @ 05/05/24 16:24:01.411
  May  5 16:24:01.413: INFO: observed resourceQuota "e2e-rq-status-fgph4" in namespace "resourcequota-9234" with hard status: v1.ResourceList(nil)
  May  5 16:24:01.413: INFO: Found resourceQuota "e2e-rq-status-fgph4" in namespace "resourcequota-9234" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  May  5 16:24:01.413: INFO: ResourceQuota "e2e-rq-status-fgph4" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 05/05/24 16:24:01.418
  May  5 16:24:01.430: INFO: Resource quota "e2e-rq-status-fgph4" reports spec: hard cpu limit of 1
  May  5 16:24:01.430: INFO: Resource quota "e2e-rq-status-fgph4" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-fgph4" /status @ 05/05/24 16:24:01.43
  STEP: Confirm /status for "e2e-rq-status-fgph4" resourceQuota via watch @ 05/05/24 16:24:01.441
  May  5 16:24:01.444: INFO: observed resourceQuota "e2e-rq-status-fgph4" in namespace "resourcequota-9234" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  May  5 16:24:01.444: INFO: Found resourceQuota "e2e-rq-status-fgph4" in namespace "resourcequota-9234" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  May  5 16:24:01.444: INFO: ResourceQuota "e2e-rq-status-fgph4" /status was patched
  STEP: Get "e2e-rq-status-fgph4" /status @ 05/05/24 16:24:01.444
  May  5 16:24:01.449: INFO: Resourcequota "e2e-rq-status-fgph4" reports status: hard cpu of 1
  May  5 16:24:01.449: INFO: Resourcequota "e2e-rq-status-fgph4" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-fgph4" /status before checking Spec is unchanged @ 05/05/24 16:24:01.452
  May  5 16:24:01.459: INFO: Resourcequota "e2e-rq-status-fgph4" reports status: hard cpu of 2
  May  5 16:24:01.459: INFO: Resourcequota "e2e-rq-status-fgph4" reports status: hard memory of 2Gi
  May  5 16:24:01.462: INFO: Found resourceQuota "e2e-rq-status-fgph4" in namespace "resourcequota-9234" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  May  5 16:24:01.466: INFO: ResourceQuota "e2e-rq-status-fgph4" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fgph4", GenerateName:"", Namespace:"resourcequota-9234", SelfLink:"", UID:"7b18353e-045d-4bde-9b32-b786e0562776", ResourceVersion:"9357", Generation:0, CreationTimestamp:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fgph4"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000cead20), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000cead68), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ceade0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  May  5 16:24:06.469: INFO: ResourceQuota "e2e-rq-status-fgph4" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fgph4", GenerateName:"", Namespace:"resourcequota-9234", SelfLink:"", UID:"7b18353e-045d-4bde-9b32-b786e0562776", ResourceVersion:"9357", Generation:0, CreationTimestamp:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fgph4"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ceb140), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ceb1b8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ceb1e8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  May  5 16:24:11.469: INFO: ResourceQuota "e2e-rq-status-fgph4" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fgph4", GenerateName:"", Namespace:"resourcequota-9234", SelfLink:"", UID:"7b18353e-045d-4bde-9b32-b786e0562776", ResourceVersion:"9357", Generation:0, CreationTimestamp:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fgph4"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ceb3b0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ceb410), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ceb440), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  May  5 16:24:16.468: INFO: ResourceQuota "e2e-rq-status-fgph4" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fgph4", GenerateName:"", Namespace:"resourcequota-9234", SelfLink:"", UID:"7b18353e-045d-4bde-9b32-b786e0562776", ResourceVersion:"9357", Generation:0, CreationTimestamp:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fgph4"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00539d4a0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00539d4d0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00539d500), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  May  5 16:24:21.466: INFO: ResourceQuota "e2e-rq-status-fgph4" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fgph4", GenerateName:"", Namespace:"resourcequota-9234", SelfLink:"", UID:"7b18353e-045d-4bde-9b32-b786e0562776", ResourceVersion:"9357", Generation:0, CreationTimestamp:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fgph4"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ceb788), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ceb7d0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ceb800), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  May  5 16:24:26.468: INFO: ResourceQuota "e2e-rq-status-fgph4" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fgph4", GenerateName:"", Namespace:"resourcequota-9234", SelfLink:"", UID:"7b18353e-045d-4bde-9b32-b786e0562776", ResourceVersion:"9357", Generation:0, CreationTimestamp:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fgph4"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000cebb00), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000cebb30), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000cebba8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  May  5 16:24:31.466: INFO: ResourceQuota "e2e-rq-status-fgph4" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fgph4", GenerateName:"", Namespace:"resourcequota-9234", SelfLink:"", UID:"7b18353e-045d-4bde-9b32-b786e0562776", ResourceVersion:"9357", Generation:0, CreationTimestamp:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fgph4"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000cebde8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000cebe60), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000cebe90), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  May  5 16:24:36.469: INFO: ResourceQuota "e2e-rq-status-fgph4" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fgph4", GenerateName:"", Namespace:"resourcequota-9234", SelfLink:"", UID:"7b18353e-045d-4bde-9b32-b786e0562776", ResourceVersion:"9357", Generation:0, CreationTimestamp:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fgph4"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046c4d50), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046c4d98), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046c4dc8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  May  5 16:24:41.468: INFO: ResourceQuota "e2e-rq-status-fgph4" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fgph4", GenerateName:"", Namespace:"resourcequota-9234", SelfLink:"", UID:"7b18353e-045d-4bde-9b32-b786e0562776", ResourceVersion:"9357", Generation:0, CreationTimestamp:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fgph4"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049c81e0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049c8210), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049c8240), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  May  5 16:24:46.473: INFO: ResourceQuota "e2e-rq-status-fgph4" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fgph4", GenerateName:"", Namespace:"resourcequota-9234", SelfLink:"", UID:"7b18353e-045d-4bde-9b32-b786e0562776", ResourceVersion:"9357", Generation:0, CreationTimestamp:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fgph4"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049c85d0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049c8600), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049c8630), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  May  5 16:24:51.467: INFO: ResourceQuota "e2e-rq-status-fgph4" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fgph4", GenerateName:"", Namespace:"resourcequota-9234", SelfLink:"", UID:"7b18353e-045d-4bde-9b32-b786e0562776", ResourceVersion:"9357", Generation:0, CreationTimestamp:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fgph4"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049c88b8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049c88e8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049c8948), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  May  5 16:24:56.467: INFO: ResourceQuota "e2e-rq-status-fgph4" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fgph4", GenerateName:"", Namespace:"resourcequota-9234", SelfLink:"", UID:"7b18353e-045d-4bde-9b32-b786e0562776", ResourceVersion:"9357", Generation:0, CreationTimestamp:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fgph4"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049c8c18), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049c8c48), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049c8c90), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  May  5 16:25:01.467: INFO: ResourceQuota "e2e-rq-status-fgph4" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fgph4", GenerateName:"", Namespace:"resourcequota-9234", SelfLink:"", UID:"7b18353e-045d-4bde-9b32-b786e0562776", ResourceVersion:"9357", Generation:0, CreationTimestamp:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fgph4"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046c50f8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046c5128), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046c5158), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  May  5 16:25:06.470: INFO: ResourceQuota "e2e-rq-status-fgph4" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fgph4", GenerateName:"", Namespace:"resourcequota-9234", SelfLink:"", UID:"7b18353e-045d-4bde-9b32-b786e0562776", ResourceVersion:"9357", Generation:0, CreationTimestamp:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fgph4"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00539d710), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00539d7a0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00539d7e8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  May  5 16:25:11.466: INFO: ResourceQuota "e2e-rq-status-fgph4" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fgph4", GenerateName:"", Namespace:"resourcequota-9234", SelfLink:"", UID:"7b18353e-045d-4bde-9b32-b786e0562776", ResourceVersion:"9357", Generation:0, CreationTimestamp:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fgph4"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00539d998), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00539d9c8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00539d9f8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  May  5 16:25:16.466: INFO: ResourceQuota "e2e-rq-status-fgph4" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fgph4", GenerateName:"", Namespace:"resourcequota-9234", SelfLink:"", UID:"7b18353e-045d-4bde-9b32-b786e0562776", ResourceVersion:"9357", Generation:0, CreationTimestamp:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fgph4"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00539dc68), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00539dc98), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00539dcc8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  May  5 16:25:21.476: INFO: ResourceQuota "e2e-rq-status-fgph4" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fgph4", GenerateName:"", Namespace:"resourcequota-9234", SelfLink:"", UID:"7b18353e-045d-4bde-9b32-b786e0562776", ResourceVersion:"9357", Generation:0, CreationTimestamp:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fgph4"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00539de78), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00539dea8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00539df20), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  May  5 16:25:26.468: INFO: ResourceQuota "e2e-rq-status-fgph4" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fgph4", GenerateName:"", Namespace:"resourcequota-9234", SelfLink:"", UID:"7b18353e-045d-4bde-9b32-b786e0562776", ResourceVersion:"9357", Generation:0, CreationTimestamp:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fgph4"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049c8ed0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049c8f00), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 24, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049c8f48), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  May  5 16:25:31.468: INFO: ResourceQuota "e2e-rq-status-fgph4" Spec was unchanged and /status reset
  May  5 16:25:31.468: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9234" for this suite. @ 05/05/24 16:25:31.473
• [90.136 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:139
  STEP: Creating a kubernetes client @ 05/05/24 16:25:31.495
  May  5 16:25:31.496: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename configmap @ 05/05/24 16:25:31.498
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:25:31.52
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:25:31.526
  STEP: Creating configMap that has name configmap-test-emptyKey-3ccdf8be-a858-42b4-80d4-60a377599ac5 @ 05/05/24 16:25:31.531
  May  5 16:25:31.540: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3546" for this suite. @ 05/05/24 16:25:31.545
• [0.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:96
  STEP: Creating a kubernetes client @ 05/05/24 16:25:31.554
  May  5 16:25:31.555: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename secrets @ 05/05/24 16:25:31.557
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:25:31.579
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:25:31.585
  STEP: creating secret secrets-8139/secret-test-8d9047bf-a4b2-4f0e-af2a-70b81cc889cf @ 05/05/24 16:25:31.589
  STEP: Creating a pod to test consume secrets @ 05/05/24 16:25:31.597
  STEP: Saw pod success @ 05/05/24 16:25:35.627
  May  5 16:25:35.633: INFO: Trying to get logs from node worker00 pod pod-configmaps-8326910e-70b7-4536-bfd5-7526799e36c3 container env-test: <nil>
  STEP: delete the pod @ 05/05/24 16:25:35.648
  May  5 16:25:35.671: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8139" for this suite. @ 05/05/24 16:25:35.676
• [4.130 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:150
  STEP: Creating a kubernetes client @ 05/05/24 16:25:35.685
  May  5 16:25:35.685: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename emptydir @ 05/05/24 16:25:35.687
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:25:35.707
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:25:35.712
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 05/05/24 16:25:35.717
  STEP: Saw pod success @ 05/05/24 16:25:39.753
  May  5 16:25:39.755: INFO: Trying to get logs from node worker01 pod pod-b9842a58-6381-4cb3-9640-6ab8917d7994 container test-container: <nil>
  STEP: delete the pod @ 05/05/24 16:25:39.774
  May  5 16:25:39.793: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1793" for this suite. @ 05/05/24 16:25:39.797
• [4.117 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:191
  STEP: Creating a kubernetes client @ 05/05/24 16:25:39.804
  May  5 16:25:39.804: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename runtimeclass @ 05/05/24 16:25:39.807
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:25:39.826
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:25:39.832
  STEP: getting /apis @ 05/05/24 16:25:39.837
  STEP: getting /apis/node.k8s.io @ 05/05/24 16:25:39.843
  STEP: getting /apis/node.k8s.io/v1 @ 05/05/24 16:25:39.845
  STEP: creating @ 05/05/24 16:25:39.847
  STEP: watching @ 05/05/24 16:25:39.865
  May  5 16:25:39.865: INFO: starting watch
  STEP: getting @ 05/05/24 16:25:39.872
  STEP: listing @ 05/05/24 16:25:39.876
  STEP: patching @ 05/05/24 16:25:39.88
  STEP: updating @ 05/05/24 16:25:39.885
  May  5 16:25:39.892: INFO: waiting for watch events with expected annotations
  STEP: deleting @ 05/05/24 16:25:39.892
  STEP: deleting a collection @ 05/05/24 16:25:39.906
  May  5 16:25:39.923: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-6628" for this suite. @ 05/05/24 16:25:39.929
• [0.138 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:425
  STEP: Creating a kubernetes client @ 05/05/24 16:25:39.943
  May  5 16:25:39.943: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename replication-controller @ 05/05/24 16:25:39.947
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:25:39.967
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:25:39.974
  STEP: Creating ReplicationController "e2e-rc-qgqbg" @ 05/05/24 16:25:39.981
  May  5 16:25:39.992: INFO: Get Replication Controller "e2e-rc-qgqbg" to confirm replicas
  May  5 16:25:40.994: INFO: Get Replication Controller "e2e-rc-qgqbg" to confirm replicas
  May  5 16:25:40.999: INFO: Found 1 replicas for "e2e-rc-qgqbg" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-qgqbg" @ 05/05/24 16:25:40.999
  STEP: Updating a scale subresource @ 05/05/24 16:25:41.002
  STEP: Verifying replicas where modified for replication controller "e2e-rc-qgqbg" @ 05/05/24 16:25:41.011
  May  5 16:25:41.012: INFO: Get Replication Controller "e2e-rc-qgqbg" to confirm replicas
  May  5 16:25:42.013: INFO: Get Replication Controller "e2e-rc-qgqbg" to confirm replicas
  May  5 16:25:42.020: INFO: Found 2 replicas for "e2e-rc-qgqbg" replication controller
  May  5 16:25:42.020: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-4325" for this suite. @ 05/05/24 16:25:42.027
• [2.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:175
  STEP: Creating a kubernetes client @ 05/05/24 16:25:42.039
  May  5 16:25:42.039: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 16:25:42.042
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:25:42.06
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:25:42.067
  STEP: Creating configMap with name cm-test-opt-del-06d58714-4ae2-4833-bdb9-08fd5acf93a5 @ 05/05/24 16:25:42.078
  STEP: Creating configMap with name cm-test-opt-upd-ec9ec76f-2fee-4185-9188-13b19759fceb @ 05/05/24 16:25:42.085
  STEP: Creating the pod @ 05/05/24 16:25:42.092
  STEP: Deleting configmap cm-test-opt-del-06d58714-4ae2-4833-bdb9-08fd5acf93a5 @ 05/05/24 16:25:44.153
  STEP: Updating configmap cm-test-opt-upd-ec9ec76f-2fee-4185-9188-13b19759fceb @ 05/05/24 16:25:44.157
  STEP: Creating configMap with name cm-test-opt-create-ed1dca86-4efe-419d-b596-ea430390351b @ 05/05/24 16:25:44.162
  STEP: waiting to observe update in volume @ 05/05/24 16:25:44.168
  May  5 16:25:46.220: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7312" for this suite. @ 05/05/24 16:25:46.225
• [4.196 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:228
  STEP: Creating a kubernetes client @ 05/05/24 16:25:46.235
  May  5 16:25:46.235: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename var-expansion @ 05/05/24 16:25:46.237
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:25:46.265
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:25:46.275
  STEP: creating the pod with failed condition @ 05/05/24 16:25:46.29
  STEP: updating the pod @ 05/05/24 16:27:46.318
  May  5 16:27:46.828: INFO: Successfully updated pod "var-expansion-18399a4e-aeae-4687-972e-9adddc853b10"
  STEP: waiting for pod running @ 05/05/24 16:27:46.828
  STEP: deleting the pod gracefully @ 05/05/24 16:27:48.854
  May  5 16:27:48.854: INFO: Deleting pod "var-expansion-18399a4e-aeae-4687-972e-9adddc853b10" in namespace "var-expansion-3883"
  May  5 16:27:48.878: INFO: Wait up to 5m0s for pod "var-expansion-18399a4e-aeae-4687-972e-9adddc853b10" to be fully deleted
  May  5 16:28:20.983: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3883" for this suite. @ 05/05/24 16:28:20.986
• [154.755 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:94
  STEP: Creating a kubernetes client @ 05/05/24 16:28:20.991
  May  5 16:28:20.991: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename configmap @ 05/05/24 16:28:20.992
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:28:21.013
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:28:21.017
  STEP: Creating configMap configmap-3009/configmap-test-19a34a4c-4a2e-4cdc-b4f5-78a8968bc1ba @ 05/05/24 16:28:21.022
  STEP: Creating a pod to test consume configMaps @ 05/05/24 16:28:21.028
  STEP: Saw pod success @ 05/05/24 16:28:25.052
  May  5 16:28:25.054: INFO: Trying to get logs from node worker00 pod pod-configmaps-fc0c4536-d396-44c5-a964-769e8007ab74 container env-test: <nil>
  STEP: delete the pod @ 05/05/24 16:28:25.062
  May  5 16:28:25.086: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3009" for this suite. @ 05/05/24 16:28:25.091
• [4.108 seconds]
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:649
  STEP: Creating a kubernetes client @ 05/05/24 16:28:25.1
  May  5 16:28:25.100: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename svcaccounts @ 05/05/24 16:28:25.102
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:28:25.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:28:25.132
  STEP: creating a ServiceAccount @ 05/05/24 16:28:25.138
  STEP: watching for the ServiceAccount to be added @ 05/05/24 16:28:25.16
  STEP: patching the ServiceAccount @ 05/05/24 16:28:25.163
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 05/05/24 16:28:25.171
  STEP: deleting the ServiceAccount @ 05/05/24 16:28:25.177
  May  5 16:28:25.199: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5395" for this suite. @ 05/05/24 16:28:25.207
• [0.119 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 05/05/24 16:28:25.219
  May  5 16:28:25.219: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename hostport @ 05/05/24 16:28:25.221
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:28:25.24
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:28:25.249
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 05/05/24 16:28:25.258
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.58.101 on the node which pod1 resides and expect scheduled @ 05/05/24 16:28:27.282
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.58.101 but use UDP protocol on the node which pod2 resides @ 05/05/24 16:28:29.307
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 05/05/24 16:28:35.356
  May  5 16:28:35.356: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.58.101 http://127.0.0.1:54323/hostname] Namespace:hostport-9545 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 16:28:35.356: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:28:35.357: INFO: ExecWithOptions: Clientset creation
  May  5 16:28:35.357: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/hostport-9545/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.58.101+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.58.101, port: 54323 @ 05/05/24 16:28:35.434
  May  5 16:28:35.434: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.58.101:54323/hostname] Namespace:hostport-9545 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 16:28:35.434: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:28:35.435: INFO: ExecWithOptions: Clientset creation
  May  5 16:28:35.436: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/hostport-9545/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.58.101%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.58.101, port: 54323 UDP @ 05/05/24 16:28:35.506
  May  5 16:28:35.506: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.58.101 54323] Namespace:hostport-9545 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 16:28:35.506: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:28:35.508: INFO: ExecWithOptions: Clientset creation
  May  5 16:28:35.508: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/hostport-9545/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.58.101+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  May  5 16:28:40.586: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-9545" for this suite. @ 05/05/24 16:28:40.589
• [15.389 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 05/05/24 16:28:40.609
  May  5 16:28:40.609: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename daemonsets @ 05/05/24 16:28:40.61
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:28:40.632
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:28:40.639
  May  5 16:28:40.671: INFO: Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/05/24 16:28:40.678
  May  5 16:28:40.689: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 16:28:40.690: INFO: Node worker00 is running 0 daemon pod, expected 1
  May  5 16:28:41.692: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 16:28:41.692: INFO: Node worker00 is running 0 daemon pod, expected 1
  May  5 16:28:42.691: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May  5 16:28:42.691: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Update daemon pods image. @ 05/05/24 16:28:42.714
  STEP: Check that daemon pods images are updated. @ 05/05/24 16:28:42.739
  May  5 16:28:42.744: INFO: Wrong image for pod: daemon-set-5w7v8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  May  5 16:28:42.744: INFO: Wrong image for pod: daemon-set-jpxrm. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  May  5 16:28:43.748: INFO: Wrong image for pod: daemon-set-jpxrm. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  May  5 16:28:44.750: INFO: Wrong image for pod: daemon-set-jpxrm. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  May  5 16:28:45.743: INFO: Pod daemon-set-2tjl6 is not available
  May  5 16:28:45.743: INFO: Wrong image for pod: daemon-set-jpxrm. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  May  5 16:28:47.745: INFO: Pod daemon-set-99sdv is not available
  STEP: Check that daemon pods are still running on every node of the cluster. @ 05/05/24 16:28:47.748
  May  5 16:28:47.753: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May  5 16:28:47.753: INFO: Node worker01 is running 0 daemon pod, expected 1
  May  5 16:28:48.757: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May  5 16:28:48.757: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 05/05/24 16:28:48.775
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-811, will wait for the garbage collector to delete the pods @ 05/05/24 16:28:48.775
  May  5 16:28:48.876: INFO: Deleting DaemonSet.extensions daemon-set took: 43.501657ms
  May  5 16:28:48.977: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.129135ms
  May  5 16:28:50.980: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 16:28:50.980: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  May  5 16:28:50.984: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"10874"},"items":null}

  May  5 16:28:50.986: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"10874"},"items":null}

  May  5 16:28:50.997: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-811" for this suite. @ 05/05/24 16:28:51.003
• [10.402 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:86
  STEP: Creating a kubernetes client @ 05/05/24 16:28:51.011
  May  5 16:28:51.011: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/05/24 16:28:51.013
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:28:51.033
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:28:51.039
  May  5 16:28:51.044: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:28:57.334: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-9992" for this suite. @ 05/05/24 16:28:57.341
• [6.343 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:300
  STEP: Creating a kubernetes client @ 05/05/24 16:28:57.354
  May  5 16:28:57.354: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename var-expansion @ 05/05/24 16:28:57.355
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:28:57.379
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:28:57.386
  STEP: creating the pod @ 05/05/24 16:28:57.395
  STEP: waiting for pod running @ 05/05/24 16:28:57.415
  STEP: creating a file in subpath @ 05/05/24 16:28:59.436
  May  5 16:28:59.442: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-876 PodName:var-expansion-b81dd3a3-7427-4aba-81a8-6141e4c5ac44 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 16:28:59.442: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:28:59.444: INFO: ExecWithOptions: Clientset creation
  May  5 16:28:59.444: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/var-expansion-876/pods/var-expansion-b81dd3a3-7427-4aba-81a8-6141e4c5ac44/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 05/05/24 16:28:59.585
  May  5 16:28:59.592: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-876 PodName:var-expansion-b81dd3a3-7427-4aba-81a8-6141e4c5ac44 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 16:28:59.592: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:28:59.593: INFO: ExecWithOptions: Clientset creation
  May  5 16:28:59.593: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/var-expansion-876/pods/var-expansion-b81dd3a3-7427-4aba-81a8-6141e4c5ac44/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 05/05/24 16:28:59.717
  May  5 16:29:00.232: INFO: Successfully updated pod "var-expansion-b81dd3a3-7427-4aba-81a8-6141e4c5ac44"
  STEP: waiting for annotated pod running @ 05/05/24 16:29:00.232
  STEP: deleting the pod gracefully @ 05/05/24 16:29:00.237
  May  5 16:29:00.237: INFO: Deleting pod "var-expansion-b81dd3a3-7427-4aba-81a8-6141e4c5ac44" in namespace "var-expansion-876"
  May  5 16:29:00.249: INFO: Wait up to 5m0s for pod "var-expansion-b81dd3a3-7427-4aba-81a8-6141e4c5ac44" to be fully deleted
  May  5 16:29:34.343: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-876" for this suite. @ 05/05/24 16:29:34.346
• [36.995 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:489
  STEP: Creating a kubernetes client @ 05/05/24 16:29:34.35
  May  5 16:29:34.350: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename deployment @ 05/05/24 16:29:34.352
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:29:34.369
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:29:34.375
  STEP: creating a Deployment @ 05/05/24 16:29:34.387
  May  5 16:29:34.387: INFO: Creating simple deployment test-deployment-w9mnc
  May  5 16:29:34.403: INFO: deployment "test-deployment-w9mnc" doesn't have the required revision set
  STEP: Getting /status @ 05/05/24 16:29:36.417
  May  5 16:29:36.420: INFO: Deployment test-deployment-w9mnc has Conditions: [{Available True 2024-05-05 16:29:35 +0000 UTC 2024-05-05 16:29:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2024-05-05 16:29:35 +0000 UTC 2024-05-05 16:29:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-w9mnc-5d576bd769" has successfully progressed.}]
  STEP: updating Deployment Status @ 05/05/24 16:29:36.42
  May  5 16:29:36.429: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 16, 29, 35, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 29, 35, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 16, 29, 35, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 29, 34, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-w9mnc-5d576bd769\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 05/05/24 16:29:36.429
  May  5 16:29:36.433: INFO: Observed &Deployment event: ADDED
  May  5 16:29:36.433: INFO: Observed Deployment test-deployment-w9mnc in namespace deployment-2592 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-05 16:29:34 +0000 UTC 2024-05-05 16:29:34 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-w9mnc-5d576bd769"}
  May  5 16:29:36.434: INFO: Observed &Deployment event: MODIFIED
  May  5 16:29:36.434: INFO: Observed Deployment test-deployment-w9mnc in namespace deployment-2592 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-05 16:29:34 +0000 UTC 2024-05-05 16:29:34 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-w9mnc-5d576bd769"}
  May  5 16:29:36.434: INFO: Observed Deployment test-deployment-w9mnc in namespace deployment-2592 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-05-05 16:29:34 +0000 UTC 2024-05-05 16:29:34 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  May  5 16:29:36.434: INFO: Observed &Deployment event: MODIFIED
  May  5 16:29:36.434: INFO: Observed Deployment test-deployment-w9mnc in namespace deployment-2592 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-05-05 16:29:34 +0000 UTC 2024-05-05 16:29:34 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  May  5 16:29:36.434: INFO: Observed Deployment test-deployment-w9mnc in namespace deployment-2592 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-05 16:29:34 +0000 UTC 2024-05-05 16:29:34 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-w9mnc-5d576bd769" is progressing.}
  May  5 16:29:36.434: INFO: Observed &Deployment event: MODIFIED
  May  5 16:29:36.434: INFO: Observed Deployment test-deployment-w9mnc in namespace deployment-2592 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-05-05 16:29:35 +0000 UTC 2024-05-05 16:29:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  May  5 16:29:36.434: INFO: Observed Deployment test-deployment-w9mnc in namespace deployment-2592 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-05 16:29:35 +0000 UTC 2024-05-05 16:29:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-w9mnc-5d576bd769" has successfully progressed.}
  May  5 16:29:36.435: INFO: Observed &Deployment event: MODIFIED
  May  5 16:29:36.435: INFO: Observed Deployment test-deployment-w9mnc in namespace deployment-2592 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-05-05 16:29:35 +0000 UTC 2024-05-05 16:29:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  May  5 16:29:36.435: INFO: Observed Deployment test-deployment-w9mnc in namespace deployment-2592 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-05 16:29:35 +0000 UTC 2024-05-05 16:29:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-w9mnc-5d576bd769" has successfully progressed.}
  May  5 16:29:36.435: INFO: Found Deployment test-deployment-w9mnc in namespace deployment-2592 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  May  5 16:29:36.435: INFO: Deployment test-deployment-w9mnc has an updated status
  STEP: patching the Statefulset Status @ 05/05/24 16:29:36.435
  May  5 16:29:36.435: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  May  5 16:29:36.447: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 05/05/24 16:29:36.447
  May  5 16:29:36.454: INFO: Observed &Deployment event: ADDED
  May  5 16:29:36.454: INFO: Observed deployment test-deployment-w9mnc in namespace deployment-2592 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-05 16:29:34 +0000 UTC 2024-05-05 16:29:34 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-w9mnc-5d576bd769"}
  May  5 16:29:36.457: INFO: Observed &Deployment event: MODIFIED
  May  5 16:29:36.457: INFO: Observed deployment test-deployment-w9mnc in namespace deployment-2592 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-05 16:29:34 +0000 UTC 2024-05-05 16:29:34 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-w9mnc-5d576bd769"}
  May  5 16:29:36.458: INFO: Observed deployment test-deployment-w9mnc in namespace deployment-2592 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-05-05 16:29:34 +0000 UTC 2024-05-05 16:29:34 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  May  5 16:29:36.458: INFO: Observed &Deployment event: MODIFIED
  May  5 16:29:36.459: INFO: Observed deployment test-deployment-w9mnc in namespace deployment-2592 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-05-05 16:29:34 +0000 UTC 2024-05-05 16:29:34 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  May  5 16:29:36.459: INFO: Observed deployment test-deployment-w9mnc in namespace deployment-2592 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-05 16:29:34 +0000 UTC 2024-05-05 16:29:34 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-w9mnc-5d576bd769" is progressing.}
  May  5 16:29:36.460: INFO: Observed &Deployment event: MODIFIED
  May  5 16:29:36.460: INFO: Observed deployment test-deployment-w9mnc in namespace deployment-2592 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-05-05 16:29:35 +0000 UTC 2024-05-05 16:29:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  May  5 16:29:36.461: INFO: Observed deployment test-deployment-w9mnc in namespace deployment-2592 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-05 16:29:35 +0000 UTC 2024-05-05 16:29:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-w9mnc-5d576bd769" has successfully progressed.}
  May  5 16:29:36.461: INFO: Observed &Deployment event: MODIFIED
  May  5 16:29:36.461: INFO: Observed deployment test-deployment-w9mnc in namespace deployment-2592 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-05-05 16:29:35 +0000 UTC 2024-05-05 16:29:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  May  5 16:29:36.461: INFO: Observed deployment test-deployment-w9mnc in namespace deployment-2592 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-05 16:29:35 +0000 UTC 2024-05-05 16:29:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-w9mnc-5d576bd769" has successfully progressed.}
  May  5 16:29:36.461: INFO: Observed deployment test-deployment-w9mnc in namespace deployment-2592 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  May  5 16:29:36.463: INFO: Observed &Deployment event: MODIFIED
  May  5 16:29:36.463: INFO: Found deployment test-deployment-w9mnc in namespace deployment-2592 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  May  5 16:29:36.463: INFO: Deployment test-deployment-w9mnc has a patched status
  May  5 16:29:36.470: INFO: Deployment "test-deployment-w9mnc":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-w9mnc",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2592",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "adc99be1-ec03-4950-b02e-f5d796afd194",
      ResourceVersion: (string) (len=5) "11176",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850523374,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850523374,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850523376,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850523376,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850523376,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850523376,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=56) "Found new replica set \"test-deployment-w9mnc-5d576bd769\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  May  5 16:29:36.489: INFO: New ReplicaSet "test-deployment-w9mnc-5d576bd769" of Deployment "test-deployment-w9mnc":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-w9mnc-5d576bd769",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2592",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a5830dfe-47d6-4485-9e61-0921278aa9cd",
      ResourceVersion: (string) (len=5) "11171",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850523374,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-w9mnc",
          UID: (types.UID) (len=36) "adc99be1-ec03-4950-b02e-f5d796afd194",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850523374,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 61 64 63  |k:{\"uid\":\"adc|
              00000120  39 39 62 65 31 2d 65 63  30 33 2d 34 39 35 30 2d  |99be1-ec03-4950-|
              00000130  62 30 32 65 2d 66 35 64  37 39 36 61 66 64 31 39  |b02e-f5d796afd19|
              00000140  34 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |4\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850523375,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769",
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May  5 16:29:36.513: INFO: Pod "test-deployment-w9mnc-5d576bd769-xpvgd" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=38) "test-deployment-w9mnc-5d576bd769-xpvgd",
      GenerateName: (string) (len=33) "test-deployment-w9mnc-5d576bd769-",
      Namespace: (string) (len=15) "deployment-2592",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "97a4121f-046e-40da-ad3b-8f0c29ad8ec9",
      ResourceVersion: (string) (len=5) "11170",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850523374,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769",
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "45ea8003b28df2332a5ea858fc6e4a5494eaf27c01e62b702017bbec70e32b76",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=17) "10.200.131.175/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=17) "10.200.131.175/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=32) "test-deployment-w9mnc-5d576bd769",
          UID: (types.UID) (len=36) "a5830dfe-47d6-4485-9e61-0921278aa9cd",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850523374,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850523374,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 61 35 38 33 30 64 66  65 2d 34 37 64 36 2d 34  |"a5830dfe-47d6-4|
              000000a0  34 38 35 2d 39 65 36 31  2d 30 39 32 31 32 37 38  |485-9e61-0921278|
              000000b0  61 61 39 63 64 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |aa9cd\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850523375,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 30 30 2e 31 33 31  2e 31 37 35 5c 22 7d 22  |.200.131.175\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-kln9d",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-kln9d",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker00",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850523375,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850523374,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850523375,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850523375,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850523374,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.100",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.100"
        }
      },
      PodIP: (string) (len=14) "10.200.131.175",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "10.200.131.175"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850523374,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850523375,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://8b387b9e74ce1f69fbc70a3c2d65da09ff86f7f588b20fd523ebaf6a067a5684",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 16:29:36.526: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2592" for this suite. @ 05/05/24 16:29:36.537
• [2.201 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 05/05/24 16:29:36.553
  May  5 16:29:36.553: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename init-container @ 05/05/24 16:29:36.558
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:29:36.595
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:29:36.603
  STEP: creating the pod @ 05/05/24 16:29:36.607
  May  5 16:29:36.607: INFO: PodSpec: initContainers in spec.initContainers
  May  5 16:29:40.159: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-2213" for this suite. @ 05/05/24 16:29:40.162
• [3.614 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:785
  STEP: Creating a kubernetes client @ 05/05/24 16:29:40.168
  May  5 16:29:40.168: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename services @ 05/05/24 16:29:40.17
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:29:40.188
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:29:40.193
  STEP: creating service endpoint-test2 in namespace services-7735 @ 05/05/24 16:29:40.198
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7735 to expose endpoints map[] @ 05/05/24 16:29:40.22
  May  5 16:29:40.235: INFO: successfully validated that service endpoint-test2 in namespace services-7735 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-7735 @ 05/05/24 16:29:40.235
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7735 to expose endpoints map[pod1:[80]] @ 05/05/24 16:29:42.264
  May  5 16:29:42.271: INFO: successfully validated that service endpoint-test2 in namespace services-7735 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 05/05/24 16:29:42.271
  May  5 16:29:42.271: INFO: Creating new exec pod
  May  5 16:29:45.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-7735 exec execpodkt6v7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  May  5 16:29:45.456: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  May  5 16:29:45.456: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May  5 16:29:45.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-7735 exec execpodkt6v7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.199 80'
  May  5 16:29:45.581: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.32.0.199 80\nConnection to 10.32.0.199 80 port [tcp/http] succeeded!\n"
  May  5 16:29:45.581: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-7735 @ 05/05/24 16:29:45.581
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7735 to expose endpoints map[pod1:[80] pod2:[80]] @ 05/05/24 16:29:47.6
  May  5 16:29:47.622: INFO: successfully validated that service endpoint-test2 in namespace services-7735 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 05/05/24 16:29:47.622
  May  5 16:29:48.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-7735 exec execpodkt6v7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  May  5 16:29:48.809: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2+ echo hostName\n 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  May  5 16:29:48.809: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May  5 16:29:48.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-7735 exec execpodkt6v7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.199 80'
  May  5 16:29:49.004: INFO: stderr: "+ nc -v -t -w 2 10.32.0.199 80\n+ echo hostName\nConnection to 10.32.0.199 80 port [tcp/http] succeeded!\n"
  May  5 16:29:49.004: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-7735 @ 05/05/24 16:29:49.004
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7735 to expose endpoints map[pod2:[80]] @ 05/05/24 16:29:49.058
  May  5 16:29:49.090: INFO: successfully validated that service endpoint-test2 in namespace services-7735 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 05/05/24 16:29:49.09
  May  5 16:29:50.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-7735 exec execpodkt6v7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  May  5 16:29:50.286: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  May  5 16:29:50.286: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May  5 16:29:50.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-7735 exec execpodkt6v7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.199 80'
  May  5 16:29:50.440: INFO: stderr: "+ + nc -v -t -w 2 10.32.0.199 80\necho hostName\nConnection to 10.32.0.199 80 port [tcp/http] succeeded!\n"
  May  5 16:29:50.440: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-7735 @ 05/05/24 16:29:50.44
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7735 to expose endpoints map[] @ 05/05/24 16:29:50.471
  May  5 16:29:51.494: INFO: successfully validated that service endpoint-test2 in namespace services-7735 exposes endpoints map[]
  May  5 16:29:51.521: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7735" for this suite. @ 05/05/24 16:29:51.525
• [11.364 seconds]
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 05/05/24 16:29:51.537
  May  5 16:29:51.537: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename pod-network-test @ 05/05/24 16:29:51.538
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:29:51.555
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:29:51.56
  STEP: Performing setup for networking test in namespace pod-network-test-6001 @ 05/05/24 16:29:51.565
  STEP: creating a selector @ 05/05/24 16:29:51.565
  STEP: Creating the service pods in kubernetes @ 05/05/24 16:29:51.565
  May  5 16:29:51.565: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 05/05/24 16:30:13.701
  May  5 16:30:15.771: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  May  5 16:30:15.771: INFO: Going to poll 10.200.131.178 on port 8081 at least 0 times, with a maximum of 34 tries before failing
  May  5 16:30:15.777: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.200.131.178 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6001 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 16:30:15.777: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:30:15.779: INFO: ExecWithOptions: Clientset creation
  May  5 16:30:15.779: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/pod-network-test-6001/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.200.131.178+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  May  5 16:30:16.857: INFO: Found all 1 expected endpoints: [netserver-0]
  May  5 16:30:16.857: INFO: Going to poll 10.200.5.3 on port 8081 at least 0 times, with a maximum of 34 tries before failing
  May  5 16:30:16.866: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.200.5.3 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6001 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 16:30:16.866: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:30:16.867: INFO: ExecWithOptions: Clientset creation
  May  5 16:30:16.867: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/pod-network-test-6001/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.200.5.3+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  May  5 16:30:17.962: INFO: Found all 1 expected endpoints: [netserver-1]
  May  5 16:30:17.962: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-6001" for this suite. @ 05/05/24 16:30:17.968
• [26.459 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:230
  STEP: Creating a kubernetes client @ 05/05/24 16:30:17.995
  May  5 16:30:17.995: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename emptydir @ 05/05/24 16:30:18.002
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:30:18.03
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:30:18.036
  STEP: Creating Pod @ 05/05/24 16:30:18.047
  STEP: Reading file content from the nginx-container @ 05/05/24 16:30:22.087
  May  5 16:30:22.087: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-1107 PodName:pod-sharedvolume-f94a41ab-b2c9-4ff5-9a66-8aeed231444f ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 16:30:22.087: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:30:22.089: INFO: ExecWithOptions: Clientset creation
  May  5 16:30:22.089: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/emptydir-1107/pods/pod-sharedvolume-f94a41ab-b2c9-4ff5-9a66-8aeed231444f/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  May  5 16:30:22.172: INFO: Exec stderr: ""
  May  5 16:30:22.173: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1107" for this suite. @ 05/05/24 16:30:22.177
• [4.192 seconds]
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:531
  STEP: Creating a kubernetes client @ 05/05/24 16:30:22.187
  May  5 16:30:22.187: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename svcaccounts @ 05/05/24 16:30:22.19
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:30:22.218
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:30:22.226
  May  5 16:30:22.250: INFO: created pod
  STEP: Saw pod success @ 05/05/24 16:30:26.266
  May  5 16:30:56.269: INFO: polling logs
  May  5 16:30:56.292: INFO: Pod logs: 
  I0505 16:30:24.501743       1 log.go:245] OK: Got token
  I0505 16:30:24.501950       1 log.go:245] validating with in-cluster discovery
  I0505 16:30:24.505403       1 log.go:245] OK: got issuer https://kubernetes.default.svc.cluster.local
  I0505 16:30:24.505486       1 log.go:245] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-3587:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc000279380), NotBefore:(*jwt.NumericDate)(0xc000279468), IssuedAt:(*jwt.NumericDate)(0xc000279390), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-3587", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"127749d8-0e36-4bea-a0b6-7de434d1dcba"}}}
  I0505 16:30:24.534788       1 log.go:245] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
  I0505 16:30:24.559277       1 log.go:245] OK: Validated signature on JWT
  I0505 16:30:24.559451       1 log.go:245] OK: Got valid claims from token!
  I0505 16:30:24.561125       1 log.go:245] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-3587:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0002791b0), NotBefore:(*jwt.NumericDate)(0xc0002791d8), IssuedAt:(*jwt.NumericDate)(0xc0002791b8), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-3587", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"127749d8-0e36-4bea-a0b6-7de434d1dcba"}}}

  May  5 16:30:56.292: INFO: completed pod
  May  5 16:30:56.298: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-3587" for this suite. @ 05/05/24 16:30:56.301
• [34.119 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 05/05/24 16:30:56.31
  May  5 16:30:56.310: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename init-container @ 05/05/24 16:30:56.311
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:30:56.334
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:30:56.34
  STEP: creating the pod @ 05/05/24 16:30:56.344
  May  5 16:30:56.344: INFO: PodSpec: initContainers in spec.initContainers
  May  5 16:31:41.301: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-bf45fec2-3e5f-48bc-86ee-60c79eac294c", GenerateName:"", Namespace:"init-container-3215", SelfLink:"", UID:"846bcc8c-ecd2-4bef-a619-1fa7e7925467", ResourceVersion:"11976", Generation:0, CreationTimestamp:time.Date(2024, time.May, 5, 16, 30, 56, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"344810759"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"f4118bec71832ba7d251b601203ac5268762dec2691d2c2da25b126f10c0d866", "cni.projectcalico.org/podIP":"10.200.131.179/32", "cni.projectcalico.org/podIPs":"10.200.131.179/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 30, 56, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c0c378), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 30, 56, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c0c3f0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 5, 16, 31, 41, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c0c420), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-8btdj", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc000e126a0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-8btdj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-8btdj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-8btdj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004960bc0), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"worker00", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0002c1810), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004960c40)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004960c60)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004960c68), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc004960c6c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc001384ff0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 5, 16, 30, 57, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 5, 16, 30, 56, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 5, 16, 30, 56, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 5, 16, 30, 56, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 5, 16, 30, 56, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.58.100", HostIPs:[]v1.HostIP{v1.HostIP{IP:"192.168.58.100"}}, PodIP:"10.200.131.179", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.200.131.179"}}, StartTime:time.Date(2024, time.May, 5, 16, 30, 56, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0002c1960)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0002c1a40)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9", ContainerID:"containerd://ce337d0f7cca8f5ac8a280402a827d8690b41ed6f5ed6dedcc660892bb13861e", Started:(*bool)(0xc004960d2f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000e12700), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc004960d35), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000e126e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc004960d04), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  May  5 16:31:41.302: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-3215" for this suite. @ 05/05/24 16:31:41.307
• [45.002 seconds]
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:76
  STEP: Creating a kubernetes client @ 05/05/24 16:31:41.312
  May  5 16:31:41.312: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename var-expansion @ 05/05/24 16:31:41.314
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:31:41.325
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:31:41.327
  STEP: Creating a pod to test substitution in container's command @ 05/05/24 16:31:41.331
  STEP: Saw pod success @ 05/05/24 16:31:45.346
  May  5 16:31:45.349: INFO: Trying to get logs from node worker01 pod var-expansion-9c30024d-2517-4fd6-befb-f780563183ed container dapi-container: <nil>
  STEP: delete the pod @ 05/05/24 16:31:45.357
  May  5 16:31:45.369: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8439" for this suite. @ 05/05/24 16:31:45.372
• [4.065 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:887
  STEP: Creating a kubernetes client @ 05/05/24 16:31:45.377
  May  5 16:31:45.377: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubectl @ 05/05/24 16:31:45.377
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:31:45.387
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:31:45.391
  STEP: validating api versions @ 05/05/24 16:31:45.393
  May  5 16:31:45.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-4464 api-versions'
  May  5 16:31:45.445: INFO: stderr: ""
  May  5 16:31:45.445: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1alpha1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta3\ninternal.apiserver.k8s.io/v1alpha1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1alpha1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nresource.k8s.io/v1alpha2\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1alpha1\nv1\n"
  May  5 16:31:45.445: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4464" for this suite. @ 05/05/24 16:31:45.448
• [0.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 05/05/24 16:31:45.454
  May  5 16:31:45.454: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename emptydir-wrapper @ 05/05/24 16:31:45.455
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:31:45.467
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:31:45.47
  STEP: Creating 50 configmaps @ 05/05/24 16:31:45.473
  STEP: Creating RC which spawns configmap-volume pods @ 05/05/24 16:31:45.71
  May  5 16:31:45.874: INFO: Pod name wrapped-volume-race-43564c56-e3d4-4f25-bfd9-a6fb11b99c96: Found 3 pods out of 5
  May  5 16:31:50.886: INFO: Pod name wrapped-volume-race-43564c56-e3d4-4f25-bfd9-a6fb11b99c96: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 05/05/24 16:31:50.886
  STEP: Creating RC which spawns configmap-volume pods @ 05/05/24 16:31:50.905
  May  5 16:31:50.931: INFO: Pod name wrapped-volume-race-17cb6382-a5e5-4e8d-8b17-e9048f5e0404: Found 0 pods out of 5
  May  5 16:31:55.936: INFO: Pod name wrapped-volume-race-17cb6382-a5e5-4e8d-8b17-e9048f5e0404: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 05/05/24 16:31:55.936
  STEP: Creating RC which spawns configmap-volume pods @ 05/05/24 16:31:55.949
  May  5 16:31:55.970: INFO: Pod name wrapped-volume-race-6aafac91-7306-4a8b-83d1-db85a0a86f9c: Found 0 pods out of 5
  May  5 16:32:00.986: INFO: Pod name wrapped-volume-race-6aafac91-7306-4a8b-83d1-db85a0a86f9c: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 05/05/24 16:32:00.986
  STEP: deleting ReplicationController wrapped-volume-race-6aafac91-7306-4a8b-83d1-db85a0a86f9c in namespace emptydir-wrapper-7223, will wait for the garbage collector to delete the pods @ 05/05/24 16:32:01.013
  May  5 16:32:01.078: INFO: Deleting ReplicationController wrapped-volume-race-6aafac91-7306-4a8b-83d1-db85a0a86f9c took: 10.384212ms
  May  5 16:32:01.181: INFO: Terminating ReplicationController wrapped-volume-race-6aafac91-7306-4a8b-83d1-db85a0a86f9c pods took: 102.988842ms
  STEP: deleting ReplicationController wrapped-volume-race-17cb6382-a5e5-4e8d-8b17-e9048f5e0404 in namespace emptydir-wrapper-7223, will wait for the garbage collector to delete the pods @ 05/05/24 16:32:02.683
  May  5 16:32:02.745: INFO: Deleting ReplicationController wrapped-volume-race-17cb6382-a5e5-4e8d-8b17-e9048f5e0404 took: 8.600776ms
  May  5 16:32:02.847: INFO: Terminating ReplicationController wrapped-volume-race-17cb6382-a5e5-4e8d-8b17-e9048f5e0404 pods took: 101.167129ms
  STEP: deleting ReplicationController wrapped-volume-race-43564c56-e3d4-4f25-bfd9-a6fb11b99c96 in namespace emptydir-wrapper-7223, will wait for the garbage collector to delete the pods @ 05/05/24 16:32:04.648
  May  5 16:32:04.709: INFO: Deleting ReplicationController wrapped-volume-race-43564c56-e3d4-4f25-bfd9-a6fb11b99c96 took: 7.156166ms
  May  5 16:32:04.810: INFO: Terminating ReplicationController wrapped-volume-race-43564c56-e3d4-4f25-bfd9-a6fb11b99c96 pods took: 100.581229ms
  STEP: Cleaning up the configMaps @ 05/05/24 16:32:06.311
  May  5 16:32:06.509: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-7223" for this suite. @ 05/05/24 16:32:06.512
• [21.063 seconds]
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:263
  STEP: Creating a kubernetes client @ 05/05/24 16:32:06.518
  May  5 16:32:06.519: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename downward-api @ 05/05/24 16:32:06.519
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:32:06.531
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:32:06.534
  STEP: Creating a pod to test downward API volume plugin @ 05/05/24 16:32:06.537
  STEP: Saw pod success @ 05/05/24 16:32:10.557
  May  5 16:32:10.560: INFO: Trying to get logs from node worker01 pod downwardapi-volume-0fcebf23-5624-4194-baee-6a17df62747c container client-container: <nil>
  STEP: delete the pod @ 05/05/24 16:32:10.569
  May  5 16:32:10.597: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5644" for this suite. @ 05/05/24 16:32:10.603
• [4.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 05/05/24 16:32:10.612
  May  5 16:32:10.613: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename cronjob @ 05/05/24 16:32:10.614
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:32:10.627
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:32:10.631
  STEP: Creating a ForbidConcurrent cronjob @ 05/05/24 16:32:10.634
  STEP: Ensuring a job is scheduled @ 05/05/24 16:32:10.641
  STEP: Ensuring exactly one is scheduled @ 05/05/24 16:33:00.645
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 05/05/24 16:33:00.647
  STEP: Ensuring no more jobs are scheduled @ 05/05/24 16:33:00.653
  STEP: Removing cronjob @ 05/05/24 16:38:00.666
  May  5 16:38:00.674: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-5703" for this suite. @ 05/05/24 16:38:00.68
• [350.081 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 05/05/24 16:38:00.693
  May  5 16:38:00.693: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 16:38:00.693
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:38:00.709
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:38:00.717
  STEP: Creating projection with secret that has name projected-secret-test-map-443e1ec5-ff03-4a90-aea4-ba5a27ddbbc8 @ 05/05/24 16:38:00.722
  STEP: Creating a pod to test consume secrets @ 05/05/24 16:38:00.733
  STEP: Saw pod success @ 05/05/24 16:38:04.77
  May  5 16:38:04.774: INFO: Trying to get logs from node worker01 pod pod-projected-secrets-0bdc3992-0aea-4e46-bf8d-1494e2a16eac container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/05/24 16:38:04.8
  May  5 16:38:04.849: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8891" for this suite. @ 05/05/24 16:38:04.857
• [4.174 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 05/05/24 16:38:04.872
  May  5 16:38:04.872: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename sched-preemption @ 05/05/24 16:38:04.874
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:38:04.903
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:38:04.909
  May  5 16:38:04.936: INFO: Waiting up to 1m0s for all nodes to be ready
  May  5 16:39:04.941: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 05/05/24 16:39:04.944
  May  5 16:39:04.944: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename sched-preemption-path @ 05/05/24 16:39:04.945
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:39:04.974
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:39:04.977
  STEP: Finding an available node @ 05/05/24 16:39:04.98
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 05/05/24 16:39:04.98
  STEP: Explicitly delete pod here to free the resource it takes. @ 05/05/24 16:39:06.995
  May  5 16:39:07.023: INFO: found a healthy node: worker00
  May  5 16:39:13.102: INFO: pods created so far: [1 1 1]
  May  5 16:39:13.102: INFO: length of pods created so far: 3
  May  5 16:39:15.128: INFO: pods created so far: [2 2 1]
  May  5 16:39:22.180: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-7838" for this suite. @ 05/05/24 16:39:22.183
  May  5 16:39:22.188: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-6935" for this suite. @ 05/05/24 16:39:22.191
• [77.328 seconds]
------------------------------
SS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:488
  STEP: Creating a kubernetes client @ 05/05/24 16:39:22.199
  May  5 16:39:22.199: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename security-context-test @ 05/05/24 16:39:22.201
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:39:22.217
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:39:22.223
  May  5 16:39:26.251: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-9819" for this suite. @ 05/05/24 16:39:26.256
• [4.072 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:714
  STEP: Creating a kubernetes client @ 05/05/24 16:39:26.272
  May  5 16:39:26.272: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename gc @ 05/05/24 16:39:26.275
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:39:26.287
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:39:26.291
  STEP: create the rc1 @ 05/05/24 16:39:26.297
  STEP: create the rc2 @ 05/05/24 16:39:26.303
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 05/05/24 16:39:32.355
  STEP: delete the rc simpletest-rc-to-be-deleted @ 05/05/24 16:39:35.835
  STEP: wait for the rc to be deleted @ 05/05/24 16:39:35.904
  May  5 16:39:41.015: INFO: 70 pods remaining
  May  5 16:39:41.015: INFO: 70 pods has nil DeletionTimestamp
  May  5 16:39:41.015: INFO: 
  STEP: Gathering metrics @ 05/05/24 16:39:45.941
  May  5 16:39:47.084: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  May  5 16:39:47.085: INFO: Deleting pod "simpletest-rc-to-be-deleted-2qf52" in namespace "gc-8147"
  May  5 16:39:47.202: INFO: Deleting pod "simpletest-rc-to-be-deleted-48tsf" in namespace "gc-8147"
  May  5 16:39:47.295: INFO: Deleting pod "simpletest-rc-to-be-deleted-4xq9v" in namespace "gc-8147"
  May  5 16:39:47.497: INFO: Deleting pod "simpletest-rc-to-be-deleted-52974" in namespace "gc-8147"
  May  5 16:39:47.631: INFO: Deleting pod "simpletest-rc-to-be-deleted-58wvc" in namespace "gc-8147"
  May  5 16:39:47.717: INFO: Deleting pod "simpletest-rc-to-be-deleted-5vgl4" in namespace "gc-8147"
  May  5 16:39:47.852: INFO: Deleting pod "simpletest-rc-to-be-deleted-62gh2" in namespace "gc-8147"
  May  5 16:39:47.928: INFO: Deleting pod "simpletest-rc-to-be-deleted-6dlml" in namespace "gc-8147"
  May  5 16:39:48.035: INFO: Deleting pod "simpletest-rc-to-be-deleted-6lrhg" in namespace "gc-8147"
  May  5 16:39:48.166: INFO: Deleting pod "simpletest-rc-to-be-deleted-6tzvc" in namespace "gc-8147"
  May  5 16:39:48.314: INFO: Deleting pod "simpletest-rc-to-be-deleted-7wgbz" in namespace "gc-8147"
  May  5 16:39:48.460: INFO: Deleting pod "simpletest-rc-to-be-deleted-88rh2" in namespace "gc-8147"
  May  5 16:39:48.542: INFO: Deleting pod "simpletest-rc-to-be-deleted-89qgv" in namespace "gc-8147"
  May  5 16:39:48.599: INFO: Deleting pod "simpletest-rc-to-be-deleted-8dqt2" in namespace "gc-8147"
  May  5 16:39:48.667: INFO: Deleting pod "simpletest-rc-to-be-deleted-8jp82" in namespace "gc-8147"
  May  5 16:39:48.705: INFO: Deleting pod "simpletest-rc-to-be-deleted-8rtxh" in namespace "gc-8147"
  May  5 16:39:48.770: INFO: Deleting pod "simpletest-rc-to-be-deleted-9bd6j" in namespace "gc-8147"
  May  5 16:39:48.821: INFO: Deleting pod "simpletest-rc-to-be-deleted-9lfql" in namespace "gc-8147"
  May  5 16:39:48.877: INFO: Deleting pod "simpletest-rc-to-be-deleted-9qs8j" in namespace "gc-8147"
  May  5 16:39:48.945: INFO: Deleting pod "simpletest-rc-to-be-deleted-9rt5x" in namespace "gc-8147"
  May  5 16:39:49.044: INFO: Deleting pod "simpletest-rc-to-be-deleted-9xcj6" in namespace "gc-8147"
  May  5 16:39:49.128: INFO: Deleting pod "simpletest-rc-to-be-deleted-b8nlk" in namespace "gc-8147"
  May  5 16:39:49.197: INFO: Deleting pod "simpletest-rc-to-be-deleted-b9tph" in namespace "gc-8147"
  May  5 16:39:49.275: INFO: Deleting pod "simpletest-rc-to-be-deleted-bzfvl" in namespace "gc-8147"
  May  5 16:39:49.350: INFO: Deleting pod "simpletest-rc-to-be-deleted-cmldv" in namespace "gc-8147"
  May  5 16:39:49.456: INFO: Deleting pod "simpletest-rc-to-be-deleted-cpbfc" in namespace "gc-8147"
  May  5 16:39:49.844: INFO: Deleting pod "simpletest-rc-to-be-deleted-d2whs" in namespace "gc-8147"
  May  5 16:39:50.028: INFO: Deleting pod "simpletest-rc-to-be-deleted-ddxrj" in namespace "gc-8147"
  May  5 16:39:50.192: INFO: Deleting pod "simpletest-rc-to-be-deleted-df4sq" in namespace "gc-8147"
  May  5 16:39:50.382: INFO: Deleting pod "simpletest-rc-to-be-deleted-dgdhb" in namespace "gc-8147"
  May  5 16:39:50.464: INFO: Deleting pod "simpletest-rc-to-be-deleted-dvddk" in namespace "gc-8147"
  May  5 16:39:50.634: INFO: Deleting pod "simpletest-rc-to-be-deleted-f76nf" in namespace "gc-8147"
  May  5 16:39:50.760: INFO: Deleting pod "simpletest-rc-to-be-deleted-flpmf" in namespace "gc-8147"
  May  5 16:39:50.839: INFO: Deleting pod "simpletest-rc-to-be-deleted-fv2jx" in namespace "gc-8147"
  May  5 16:39:50.969: INFO: Deleting pod "simpletest-rc-to-be-deleted-fvh5w" in namespace "gc-8147"
  May  5 16:39:51.134: INFO: Deleting pod "simpletest-rc-to-be-deleted-g6x8t" in namespace "gc-8147"
  May  5 16:39:51.209: INFO: Deleting pod "simpletest-rc-to-be-deleted-gj47f" in namespace "gc-8147"
  May  5 16:39:51.317: INFO: Deleting pod "simpletest-rc-to-be-deleted-gn68k" in namespace "gc-8147"
  May  5 16:39:51.535: INFO: Deleting pod "simpletest-rc-to-be-deleted-gpcgg" in namespace "gc-8147"
  May  5 16:39:51.654: INFO: Deleting pod "simpletest-rc-to-be-deleted-h5jsx" in namespace "gc-8147"
  May  5 16:39:51.754: INFO: Deleting pod "simpletest-rc-to-be-deleted-hbtl8" in namespace "gc-8147"
  May  5 16:39:51.936: INFO: Deleting pod "simpletest-rc-to-be-deleted-hnl9q" in namespace "gc-8147"
  May  5 16:39:52.070: INFO: Deleting pod "simpletest-rc-to-be-deleted-j2jtj" in namespace "gc-8147"
  May  5 16:39:52.255: INFO: Deleting pod "simpletest-rc-to-be-deleted-j54r4" in namespace "gc-8147"
  May  5 16:39:52.328: INFO: Deleting pod "simpletest-rc-to-be-deleted-j76k4" in namespace "gc-8147"
  May  5 16:39:52.408: INFO: Deleting pod "simpletest-rc-to-be-deleted-j86g8" in namespace "gc-8147"
  May  5 16:39:52.474: INFO: Deleting pod "simpletest-rc-to-be-deleted-jbsl5" in namespace "gc-8147"
  May  5 16:39:52.575: INFO: Deleting pod "simpletest-rc-to-be-deleted-jhcmd" in namespace "gc-8147"
  May  5 16:39:52.629: INFO: Deleting pod "simpletest-rc-to-be-deleted-jvnk9" in namespace "gc-8147"
  May  5 16:39:52.674: INFO: Deleting pod "simpletest-rc-to-be-deleted-jzjgs" in namespace "gc-8147"
  May  5 16:39:52.724: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8147" for this suite. @ 05/05/24 16:39:52.746
• [26.504 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:214
  STEP: Creating a kubernetes client @ 05/05/24 16:39:52.779
  May  5 16:39:52.779: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename container-probe @ 05/05/24 16:39:52.792
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:39:52.874
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:39:52.889
  STEP: Creating pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194 @ 05/05/24 16:39:52.906
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/05/24 16:40:03.233
  May  5 16:40:03.241: INFO: Initial restart count of pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 is 0
  May  5 16:40:03.247: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:05.252: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:07.256: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:09.259: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:11.262: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:13.266: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:15.276: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:17.282: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:19.289: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:21.304: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:23.310: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:25.317: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:27.322: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:29.326: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:31.329: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:33.336: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:35.348: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:37.356: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:39.361: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:41.368: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:43.372: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:45.376: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:47.384: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:49.392: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:51.399: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:53.404: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:55.410: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:57.420: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:40:59.423: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:01.429: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:03.435: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:05.439: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:07.444: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:09.446: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:11.453: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:13.456: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:15.464: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:17.469: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:19.471: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:21.476: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:23.481: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:25.489: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:27.506: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:29.514: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:31.519: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:33.529: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:35.533: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:37.543: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:39.548: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:41.557: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:43.566: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:45.572: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:47.584: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:49.590: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:51.599: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:53.606: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:55.611: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:57.617: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:41:59.621: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:01.627: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:03.634: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:05.641: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:07.647: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:09.652: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:11.658: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:13.661: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:15.665: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:17.672: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:19.677: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:21.686: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:23.696: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:25.703: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:27.709: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:29.720: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:31.726: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:33.731: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:35.740: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:37.750: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:39.756: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:41.760: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:43.767: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:45.770: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:47.778: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:49.786: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:51.789: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:53.799: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:55.803: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:57.807: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:42:59.812: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:01.816: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:03.823: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:05.829: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:07.836: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:09.843: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:11.849: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:13.855: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:15.865: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:17.876: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:19.884: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:21.889: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:23.896: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:25.904: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:27.909: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:29.915: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:31.919: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:33.928: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:35.936: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:37.943: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:39.949: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:41.953: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:43.957: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:45.965: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:47.978: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:49.984: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:51.989: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:53.993: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:56.000: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:43:58.004: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:44:00.011: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  May  5 16:44:02.014: INFO: Get pod test-webserver-9c151259-d461-4e80-a909-500b6f695c19 in namespace container-probe-6194
  STEP: deleting the pod @ 05/05/24 16:44:04.016
  May  5 16:44:04.037: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6194" for this suite. @ 05/05/24 16:44:04.048
• [251.282 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 05/05/24 16:44:04.061
  May  5 16:44:04.061: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 05/05/24 16:44:04.063
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:44:04.083
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:44:04.089
  STEP: Setting up the test @ 05/05/24 16:44:04.096
  STEP: Creating hostNetwork=false pod @ 05/05/24 16:44:04.096
  STEP: Creating hostNetwork=true pod @ 05/05/24 16:44:06.12
  STEP: Running the test @ 05/05/24 16:44:08.16
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 05/05/24 16:44:08.16
  May  5 16:44:08.160: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1018 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 16:44:08.160: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:44:08.161: INFO: ExecWithOptions: Clientset creation
  May  5 16:44:08.161: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1018/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  May  5 16:44:08.248: INFO: Exec stderr: ""
  May  5 16:44:08.248: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1018 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 16:44:08.248: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:44:08.249: INFO: ExecWithOptions: Clientset creation
  May  5 16:44:08.249: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1018/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  May  5 16:44:08.317: INFO: Exec stderr: ""
  May  5 16:44:08.317: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1018 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 16:44:08.317: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:44:08.317: INFO: ExecWithOptions: Clientset creation
  May  5 16:44:08.317: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1018/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  May  5 16:44:08.366: INFO: Exec stderr: ""
  May  5 16:44:08.366: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1018 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 16:44:08.366: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:44:08.367: INFO: ExecWithOptions: Clientset creation
  May  5 16:44:08.367: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1018/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  May  5 16:44:08.435: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 05/05/24 16:44:08.435
  May  5 16:44:08.435: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1018 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 16:44:08.435: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:44:08.436: INFO: ExecWithOptions: Clientset creation
  May  5 16:44:08.436: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1018/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  May  5 16:44:08.507: INFO: Exec stderr: ""
  May  5 16:44:08.507: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1018 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 16:44:08.507: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:44:08.508: INFO: ExecWithOptions: Clientset creation
  May  5 16:44:08.508: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1018/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  May  5 16:44:08.581: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 05/05/24 16:44:08.581
  May  5 16:44:08.581: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1018 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 16:44:08.581: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:44:08.582: INFO: ExecWithOptions: Clientset creation
  May  5 16:44:08.582: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1018/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  May  5 16:44:08.648: INFO: Exec stderr: ""
  May  5 16:44:08.648: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1018 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 16:44:08.648: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:44:08.649: INFO: ExecWithOptions: Clientset creation
  May  5 16:44:08.649: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1018/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  May  5 16:44:08.714: INFO: Exec stderr: ""
  May  5 16:44:08.714: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1018 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 16:44:08.714: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:44:08.714: INFO: ExecWithOptions: Clientset creation
  May  5 16:44:08.714: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1018/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  May  5 16:44:08.771: INFO: Exec stderr: ""
  May  5 16:44:08.771: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1018 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 16:44:08.771: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:44:08.772: INFO: ExecWithOptions: Clientset creation
  May  5 16:44:08.772: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1018/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  May  5 16:44:08.831: INFO: Exec stderr: ""
  May  5 16:44:08.832: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-1018" for this suite. @ 05/05/24 16:44:08.837
• [4.795 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:818
  STEP: Creating a kubernetes client @ 05/05/24 16:44:08.856
  May  5 16:44:08.857: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename gc @ 05/05/24 16:44:08.859
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:44:08.879
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:44:08.884
  May  5 16:44:08.935: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"7d8e8956-b909-4ed5-9316-024392a6b668", Controller:(*bool)(0xc00229dfea), BlockOwnerDeletion:(*bool)(0xc00229dfeb)}}
  May  5 16:44:08.952: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"34509b1b-de6a-434a-85b0-23c197880624", Controller:(*bool)(0xc002bcc20e), BlockOwnerDeletion:(*bool)(0xc002bcc20f)}}
  May  5 16:44:08.968: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"369e3e29-9b8a-4f7c-b785-9a3178c2ea86", Controller:(*bool)(0xc005e9a63e), BlockOwnerDeletion:(*bool)(0xc005e9a63f)}}
  May  5 16:44:13.989: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1295" for this suite. @ 05/05/24 16:44:14
• [5.160 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:134
  STEP: Creating a kubernetes client @ 05/05/24 16:44:14.024
  May  5 16:44:14.024: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubelet-test @ 05/05/24 16:44:14.029
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:44:14.061
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:44:14.068
  May  5 16:44:14.129: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-2708" for this suite. @ 05/05/24 16:44:14.134
• [0.126 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:46
  STEP: Creating a kubernetes client @ 05/05/24 16:44:14.155
  May  5 16:44:14.155: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename configmap @ 05/05/24 16:44:14.156
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:44:14.173
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:44:14.179
  STEP: Creating configMap configmap-3030/configmap-test-4b300f68-b276-4654-aab6-b19703b384fb @ 05/05/24 16:44:14.184
  STEP: Creating a pod to test consume configMaps @ 05/05/24 16:44:14.191
  STEP: Saw pod success @ 05/05/24 16:44:18.224
  May  5 16:44:18.228: INFO: Trying to get logs from node worker01 pod pod-configmaps-0b2d1d20-7379-4279-b6c7-83c11b08b70f container env-test: <nil>
  STEP: delete the pod @ 05/05/24 16:44:18.251
  May  5 16:44:18.272: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3030" for this suite. @ 05/05/24 16:44:18.276
• [4.126 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 05/05/24 16:44:18.281
  May  5 16:44:18.281: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename pods @ 05/05/24 16:44:18.284
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:44:18.299
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:44:18.304
  STEP: creating the pod @ 05/05/24 16:44:18.307
  STEP: submitting the pod to kubernetes @ 05/05/24 16:44:18.307
  STEP: verifying QOS class is set on the pod @ 05/05/24 16:44:18.314
  May  5 16:44:18.320: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2263" for this suite. @ 05/05/24 16:44:18.326
• [0.053 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 05/05/24 16:44:18.338
  May  5 16:44:18.338: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename pods @ 05/05/24 16:44:18.34
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:44:18.356
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:44:18.36
  STEP: Create a pod @ 05/05/24 16:44:18.362
  STEP: patching /status @ 05/05/24 16:44:20.378
  May  5 16:44:20.399: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
  May  5 16:44:20.399: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2997" for this suite. @ 05/05/24 16:44:20.406
• [2.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1798
  STEP: Creating a kubernetes client @ 05/05/24 16:44:20.411
  May  5 16:44:20.411: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubectl @ 05/05/24 16:44:20.411
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:44:20.425
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:44:20.429
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/05/24 16:44:20.432
  May  5 16:44:20.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-62 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  May  5 16:44:20.634: INFO: stderr: ""
  May  5 16:44:20.634: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 05/05/24 16:44:20.634
  STEP: verifying the pod e2e-test-httpd-pod was created @ 05/05/24 16:44:25.686
  May  5 16:44:25.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-62 get pod e2e-test-httpd-pod -o json'
  May  5 16:44:25.785: INFO: stderr: ""
  May  5 16:44:25.785: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"20a9741396b084ed8cd5911d4894c24c4d3beb40edad87e31642ff222ac8fb96\",\n            \"cni.projectcalico.org/podIP\": \"10.200.5.17/32\",\n            \"cni.projectcalico.org/podIPs\": \"10.200.5.17/32\"\n        },\n        \"creationTimestamp\": \"2024-05-05T16:44:20Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-62\",\n        \"resourceVersion\": \"17904\",\n        \"uid\": \"16effd4c-6c95-4f0d-9856-8467dd847d8a\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-4kfrl\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"worker01\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-4kfrl\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-05T16:44:22Z\",\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-05T16:44:21Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-05T16:44:22Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-05T16:44:22Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-05T16:44:20Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://1cb34e20193509e10731e005824a8a82c73a94fd22fdd346b6e27f6dd92cba10\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2024-05-05T16:44:22Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.58.101\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"192.168.58.101\"\n            }\n        ],\n        \"phase\": \"Running\",\n        \"podIP\": \"10.200.5.17\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.200.5.17\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2024-05-05T16:44:21Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 05/05/24 16:44:25.785
  May  5 16:44:25.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-62 replace -f -'
  May  5 16:44:25.987: INFO: stderr: ""
  May  5 16:44:25.987: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.36.1-1 @ 05/05/24 16:44:25.987
  May  5 16:44:25.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-62 delete pods e2e-test-httpd-pod'
  May  5 16:44:27.428: INFO: stderr: ""
  May  5 16:44:27.428: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  May  5 16:44:27.428: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-62" for this suite. @ 05/05/24 16:44:27.431
• [7.025 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:285
  STEP: Creating a kubernetes client @ 05/05/24 16:44:27.436
  May  5 16:44:27.436: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename webhook @ 05/05/24 16:44:27.437
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:44:27.449
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:44:27.452
  STEP: Setting up server cert @ 05/05/24 16:44:27.469
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/05/24 16:44:27.641
  STEP: Deploying the webhook pod @ 05/05/24 16:44:27.646
  STEP: Wait for the deployment to be ready @ 05/05/24 16:44:27.653
  May  5 16:44:27.656: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 05/05/24 16:44:29.668
  STEP: Verifying the service has paired with the endpoint @ 05/05/24 16:44:29.678
  May  5 16:44:30.678: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  May  5 16:44:30.687: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5246-crds.webhook.example.com via the AdmissionRegistration API @ 05/05/24 16:44:31.205
  STEP: Creating a custom resource that should be mutated by the webhook @ 05/05/24 16:44:31.238
  May  5 16:44:33.881: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1110" for this suite. @ 05/05/24 16:44:33.887
  STEP: Destroying namespace "webhook-markers-1858" for this suite. @ 05/05/24 16:44:33.905
• [6.481 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:86
  STEP: Creating a kubernetes client @ 05/05/24 16:44:33.917
  May  5 16:44:33.917: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename replication-controller @ 05/05/24 16:44:33.918
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:44:33.935
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:44:33.939
  May  5 16:44:33.942: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 05/05/24 16:44:34.956
  STEP: Checking rc "condition-test" has the desired failure condition set @ 05/05/24 16:44:34.962
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 05/05/24 16:44:35.97
  May  5 16:44:35.976: INFO: Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 05/05/24 16:44:35.976
  May  5 16:44:35.985: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-171" for this suite. @ 05/05/24 16:44:35.99
• [2.081 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1053
  STEP: Creating a kubernetes client @ 05/05/24 16:44:35.998
  May  5 16:44:35.998: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubectl @ 05/05/24 16:44:35.999
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:44:36.013
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:44:36.019
  STEP: create deployment with httpd image @ 05/05/24 16:44:36.023
  May  5 16:44:36.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-3040 create -f -'
  May  5 16:44:36.151: INFO: stderr: ""
  May  5 16:44:36.151: INFO: stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 05/05/24 16:44:36.151
  May  5 16:44:36.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-3040 diff -f -'
  May  5 16:44:36.362: INFO: rc: 1
  May  5 16:44:36.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-3040 delete -f -'
  May  5 16:44:36.451: INFO: stderr: ""
  May  5 16:44:36.451: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  May  5 16:44:36.451: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3040" for this suite. @ 05/05/24 16:44:36.457
• [0.468 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:277
  STEP: Creating a kubernetes client @ 05/05/24 16:44:36.467
  May  5 16:44:36.467: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename svcaccounts @ 05/05/24 16:44:36.468
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:44:36.497
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:44:36.505
  STEP: Creating a pod to test service account token:  @ 05/05/24 16:44:36.509
  STEP: Saw pod success @ 05/05/24 16:44:40.548
  May  5 16:44:40.550: INFO: Trying to get logs from node worker01 pod test-pod-59c4b1b4-1f45-4d8a-9090-67b50084a4ca container agnhost-container: <nil>
  STEP: delete the pod @ 05/05/24 16:44:40.555
  May  5 16:44:40.570: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-3300" for this suite. @ 05/05/24 16:44:40.572
• [4.109 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:92
  STEP: Creating a kubernetes client @ 05/05/24 16:44:40.576
  May  5 16:44:40.576: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename downward-api @ 05/05/24 16:44:40.577
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:44:40.588
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:44:40.591
  STEP: Creating a pod to test downward api env vars @ 05/05/24 16:44:40.593
  STEP: Saw pod success @ 05/05/24 16:44:44.614
  May  5 16:44:44.619: INFO: Trying to get logs from node worker00 pod downward-api-32646ac2-67e3-4591-beb4-6157debb112a container dapi-container: <nil>
  STEP: delete the pod @ 05/05/24 16:44:44.627
  May  5 16:44:44.647: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4810" for this suite. @ 05/05/24 16:44:44.65
• [4.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3565
  STEP: Creating a kubernetes client @ 05/05/24 16:44:44.657
  May  5 16:44:44.657: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename services @ 05/05/24 16:44:44.658
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:44:44.67
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:44:44.673
  STEP: creating a collection of services @ 05/05/24 16:44:44.677
  May  5 16:44:44.677: INFO: Creating e2e-svc-a-lnc46
  May  5 16:44:44.684: INFO: Creating e2e-svc-b-64wfg
  May  5 16:44:44.696: INFO: Creating e2e-svc-c-j9tgr
  STEP: deleting service collection @ 05/05/24 16:44:44.708
  May  5 16:44:44.733: INFO: Collection of services has been deleted
  May  5 16:44:44.733: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9255" for this suite. @ 05/05/24 16:44:44.736
• [0.083 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:269
  STEP: Creating a kubernetes client @ 05/05/24 16:44:44.743
  May  5 16:44:44.744: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename downward-api @ 05/05/24 16:44:44.745
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:44:44.759
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:44:44.761
  STEP: Creating a pod to test downward api env vars @ 05/05/24 16:44:44.763
  STEP: Saw pod success @ 05/05/24 16:44:48.781
  May  5 16:44:48.785: INFO: Trying to get logs from node worker00 pod downward-api-e6291072-9163-413d-aee2-e5c37d7e9852 container dapi-container: <nil>
  STEP: delete the pod @ 05/05/24 16:44:48.8
  May  5 16:44:48.814: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8310" for this suite. @ 05/05/24 16:44:48.818
• [4.081 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:55
  STEP: Creating a kubernetes client @ 05/05/24 16:44:48.824
  May  5 16:44:48.824: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename downward-api @ 05/05/24 16:44:48.825
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:44:48.834
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:44:48.84
  STEP: Creating a pod to test downward API volume plugin @ 05/05/24 16:44:48.848
  STEP: Saw pod success @ 05/05/24 16:44:52.885
  May  5 16:44:52.891: INFO: Trying to get logs from node worker00 pod downwardapi-volume-ae38f2d7-1d16-4b37-81c6-a3ce313273f9 container client-container: <nil>
  STEP: delete the pod @ 05/05/24 16:44:52.905
  May  5 16:44:52.942: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9401" for this suite. @ 05/05/24 16:44:52.951
• [4.136 seconds]
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:170
  STEP: Creating a kubernetes client @ 05/05/24 16:44:52.96
  May  5 16:44:52.960: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename emptydir @ 05/05/24 16:44:52.964
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:44:52.99
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:44:52.994
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 05/05/24 16:44:52.997
  STEP: Saw pod success @ 05/05/24 16:44:57.021
  May  5 16:44:57.025: INFO: Trying to get logs from node worker01 pod pod-77ab50ec-c581-457a-95df-a4d25c3d290c container test-container: <nil>
  STEP: delete the pod @ 05/05/24 16:44:57.031
  May  5 16:44:57.041: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5202" for this suite. @ 05/05/24 16:44:57.043
• [4.090 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:113
  STEP: Creating a kubernetes client @ 05/05/24 16:44:57.05
  May  5 16:44:57.050: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename replication-controller @ 05/05/24 16:44:57.05
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:44:57.066
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:44:57.07
  STEP: creating a ReplicationController @ 05/05/24 16:44:57.081
  STEP: waiting for RC to be added @ 05/05/24 16:44:57.09
  STEP: waiting for available Replicas @ 05/05/24 16:44:57.09
  STEP: patching ReplicationController @ 05/05/24 16:44:58.608
  STEP: waiting for RC to be modified @ 05/05/24 16:44:58.614
  STEP: patching ReplicationController status @ 05/05/24 16:44:58.614
  STEP: waiting for RC to be modified @ 05/05/24 16:44:58.618
  STEP: waiting for available Replicas @ 05/05/24 16:44:58.619
  STEP: fetching ReplicationController status @ 05/05/24 16:44:58.623
  STEP: patching ReplicationController scale @ 05/05/24 16:44:58.626
  STEP: waiting for RC to be modified @ 05/05/24 16:44:58.63
  STEP: waiting for ReplicationController's scale to be the max amount @ 05/05/24 16:44:58.63
  STEP: fetching ReplicationController; ensuring that it's patched @ 05/05/24 16:44:59.978
  STEP: updating ReplicationController status @ 05/05/24 16:44:59.985
  STEP: waiting for RC to be modified @ 05/05/24 16:44:59.995
  STEP: listing all ReplicationControllers @ 05/05/24 16:44:59.995
  STEP: checking that ReplicationController has expected values @ 05/05/24 16:45:00.001
  STEP: deleting ReplicationControllers by collection @ 05/05/24 16:45:00.001
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 05/05/24 16:45:00.012
  May  5 16:45:00.094: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0505 16:45:00.094846      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-716" for this suite. @ 05/05/24 16:45:00.105
• [3.062 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:48
  STEP: Creating a kubernetes client @ 05/05/24 16:45:00.112
  May  5 16:45:00.112: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename configmap @ 05/05/24 16:45:00.115
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:45:00.132
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:45:00.142
  STEP: Creating configMap with name configmap-test-volume-6f4af7cc-5c19-48da-94d6-5e7c2fedee56 @ 05/05/24 16:45:00.148
  STEP: Creating a pod to test consume configMaps @ 05/05/24 16:45:00.155
  E0505 16:45:01.095370      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:02.095243      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:03.096250      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:04.096796      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:45:04.194
  May  5 16:45:04.196: INFO: Trying to get logs from node worker01 pod pod-configmaps-f8d61e39-f149-4cd9-9178-b91d382f6e86 container agnhost-container: <nil>
  STEP: delete the pod @ 05/05/24 16:45:04.202
  May  5 16:45:04.224: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2772" for this suite. @ 05/05/24 16:45:04.227
• [4.119 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 05/05/24 16:45:04.23
  May  5 16:45:04.230: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename taint-multiple-pods @ 05/05/24 16:45:04.231
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:45:04.241
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:45:04.244
  May  5 16:45:04.246: INFO: Waiting up to 1m0s for all nodes to be ready
  E0505 16:45:05.097598      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:06.101313      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:07.100521      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:08.100876      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:09.101376      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:10.101501      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:11.102847      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:12.103296      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:13.103296      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:14.103616      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:15.106021      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:16.107084      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:17.107713      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:18.108864      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:19.110004      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:20.111307      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:21.111367      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:22.111742      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:23.113451      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:24.114936      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:25.117591      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:26.117560      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:27.119622      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:28.119936      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:29.120451      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:30.122764      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:31.123004      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:32.123312      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:33.124169      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:34.125196      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:35.125474      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:36.126525      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:37.126815      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:38.127734      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:39.128610      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:40.130482      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:41.130490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:42.131516      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:43.132018      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:44.132676      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:45.132891      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:46.133099      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:47.134659      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:48.139354      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:49.139850      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:50.140520      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:51.140898      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:52.141013      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:53.141323      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:54.144860      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:55.148628      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:56.149151      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:57.149382      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:58.150911      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:45:59.150940      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:00.151089      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:01.151230      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:02.151967      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:03.152458      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:04.153006      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:46:04.248: INFO: Waiting for terminating namespaces to be deleted...
  May  5 16:46:04.254: INFO: Starting informer...
  STEP: Starting pods... @ 05/05/24 16:46:04.254
  May  5 16:46:04.491: INFO: Pod1 is running on worker00. Tainting Node
  E0505 16:46:05.153805      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:06.154568      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:46:06.716: INFO: Pod2 is running on worker00. Tainting Node
  STEP: Trying to apply a taint on the Node @ 05/05/24 16:46:06.716
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/05/24 16:46:06.748
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 05/05/24 16:46:06.755
  E0505 16:46:07.155956      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:08.156717      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:09.159759      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:10.163393      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:11.163867      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:12.164639      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:46:12.824: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
  E0505 16:46:13.164352      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:14.165320      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:15.167964      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:16.168503      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:17.169510      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:18.169895      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:19.169871      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:20.170233      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:21.170447      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:22.172480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:23.175592      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:24.179803      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:25.180586      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:26.181297      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:27.181680      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:28.182138      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:29.182979      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:30.184572      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:31.185046      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:32.185898      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:46:32.924: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/05/24 16:46:32.937
  May  5 16:46:32.943: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-3771" for this suite. @ 05/05/24 16:46:32.947
• [88.740 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:330
  STEP: Creating a kubernetes client @ 05/05/24 16:46:32.987
  May  5 16:46:32.988: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename resourcequota @ 05/05/24 16:46:32.995
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:46:33.036
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:46:33.045
  E0505 16:46:33.187318      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:34.188298      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:35.189516      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:36.189493      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:37.189697      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:38.190648      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:39.191878      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:40.192112      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:41.192865      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:42.192929      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:43.201978      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:44.202929      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:45.203756      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:46.203941      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:47.204215      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:48.204416      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:49.205487      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 05/05/24 16:46:50.052
  E0505 16:46:50.205897      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:51.207463      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:52.208049      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:53.209964      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:54.210793      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/05/24 16:46:55.056
  STEP: Ensuring resource quota status is calculated @ 05/05/24 16:46:55.062
  E0505 16:46:55.211727      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:56.212531      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 05/05/24 16:46:57.067
  STEP: Ensuring resource quota status captures configMap creation @ 05/05/24 16:46:57.089
  E0505 16:46:57.213019      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:46:58.213642      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 05/05/24 16:46:59.096
  STEP: Ensuring resource quota status released usage @ 05/05/24 16:46:59.104
  E0505 16:46:59.213864      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:00.215068      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:47:01.107: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7808" for this suite. @ 05/05/24 16:47:01.111
• [28.135 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:261
  STEP: Creating a kubernetes client @ 05/05/24 16:47:01.122
  May  5 16:47:01.123: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename webhook @ 05/05/24 16:47:01.123
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:47:01.141
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:47:01.147
  STEP: Setting up server cert @ 05/05/24 16:47:01.172
  E0505 16:47:01.215523      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/05/24 16:47:01.398
  STEP: Deploying the webhook pod @ 05/05/24 16:47:01.404
  STEP: Wait for the deployment to be ready @ 05/05/24 16:47:01.418
  May  5 16:47:01.426: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0505 16:47:02.216378      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:03.216422      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/05/24 16:47:03.437
  STEP: Verifying the service has paired with the endpoint @ 05/05/24 16:47:03.447
  E0505 16:47:04.216566      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:47:04.450: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 05/05/24 16:47:04.456
  STEP: create a pod that should be updated by the webhook @ 05/05/24 16:47:04.477
  May  5 16:47:04.561: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-105" for this suite. @ 05/05/24 16:47:04.574
  STEP: Destroying namespace "webhook-markers-8667" for this suite. @ 05/05/24 16:47:04.585
• [3.475 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:90
  STEP: Creating a kubernetes client @ 05/05/24 16:47:04.601
  May  5 16:47:04.601: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 16:47:04.604
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:47:04.627
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:47:04.631
  STEP: Creating configMap with name projected-configmap-test-volume-map-d5eece7c-2f98-424c-9cf4-b8fbcb9505c6 @ 05/05/24 16:47:04.637
  STEP: Creating a pod to test consume configMaps @ 05/05/24 16:47:04.644
  E0505 16:47:05.217643      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:06.218084      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:07.218889      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:08.219038      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:47:08.671
  May  5 16:47:08.673: INFO: Trying to get logs from node worker00 pod pod-projected-configmaps-19e29299-f80d-49cb-a003-0fad90f4ea3e container agnhost-container: <nil>
  STEP: delete the pod @ 05/05/24 16:47:08.679
  May  5 16:47:08.703: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2789" for this suite. @ 05/05/24 16:47:08.708
• [4.119 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 05/05/24 16:47:08.72
  May  5 16:47:08.720: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 16:47:08.723
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:47:08.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:47:08.751
  STEP: Creating secret with name projected-secret-test-14fe2cdd-d76f-4a13-8295-f4ac1608eb56 @ 05/05/24 16:47:08.758
  STEP: Creating a pod to test consume secrets @ 05/05/24 16:47:08.765
  E0505 16:47:09.220059      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:10.221401      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:11.222587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:12.223035      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:47:12.835
  May  5 16:47:12.842: INFO: Trying to get logs from node worker00 pod pod-projected-secrets-5dcaf2d4-23bb-4b51-8599-c1d6d1b3fa4d container secret-volume-test: <nil>
  STEP: delete the pod @ 05/05/24 16:47:12.85
  May  5 16:47:12.872: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1373" for this suite. @ 05/05/24 16:47:12.879
• [4.168 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:962
  STEP: Creating a kubernetes client @ 05/05/24 16:47:12.891
  May  5 16:47:12.891: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename statefulset @ 05/05/24 16:47:12.893
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:47:12.923
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:47:12.928
  STEP: Creating service test in namespace statefulset-876 @ 05/05/24 16:47:12.932
  May  5 16:47:12.984: INFO: Found 0 stateful pods, waiting for 1
  E0505 16:47:13.223918      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:14.224375      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:15.224651      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:16.224725      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:17.224870      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:18.225877      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:19.226194      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:20.226173      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:21.226329      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:22.227053      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:47:22.981: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 05/05/24 16:47:22.993
  W0505 16:47:23.031334      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  May  5 16:47:23.042: INFO: Found 1 stateful pods, waiting for 2
  E0505 16:47:23.227376      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:24.227721      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:25.228485      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:26.228878      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:27.229461      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:28.230540      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:29.235385      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:30.236594      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:31.236757      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:32.241978      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:47:33.041: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  May  5 16:47:33.041: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 05/05/24 16:47:33.051
  STEP: Delete all of the StatefulSets @ 05/05/24 16:47:33.054
  STEP: Verify that StatefulSets have been deleted @ 05/05/24 16:47:33.074
  May  5 16:47:33.077: INFO: Deleting all statefulset in ns statefulset-876
  May  5 16:47:33.094: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-876" for this suite. @ 05/05/24 16:47:33.102
• [20.249 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csistoragecapacity.go:50
  STEP: Creating a kubernetes client @ 05/05/24 16:47:33.149
  May  5 16:47:33.149: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename csistoragecapacity @ 05/05/24 16:47:33.151
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:47:33.177
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:47:33.183
  STEP: getting /apis @ 05/05/24 16:47:33.195
  STEP: getting /apis/storage.k8s.io @ 05/05/24 16:47:33.208
  STEP: getting /apis/storage.k8s.io/v1 @ 05/05/24 16:47:33.211
  STEP: creating @ 05/05/24 16:47:33.217
  E0505 16:47:33.242700      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: watching @ 05/05/24 16:47:33.259
  May  5 16:47:33.259: INFO: starting watch
  STEP: getting @ 05/05/24 16:47:33.272
  STEP: listing in namespace @ 05/05/24 16:47:33.279
  STEP: listing across namespaces @ 05/05/24 16:47:33.285
  STEP: patching @ 05/05/24 16:47:33.291
  STEP: updating @ 05/05/24 16:47:33.303
  May  5 16:47:33.316: INFO: waiting for watch events with expected annotations in namespace
  May  5 16:47:33.316: INFO: waiting for watch events with expected annotations across namespace
  STEP: deleting @ 05/05/24 16:47:33.316
  STEP: deleting a collection @ 05/05/24 16:47:33.335
  May  5 16:47:33.358: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-843" for this suite. @ 05/05/24 16:47:33.368
• [0.232 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:453
  STEP: Creating a kubernetes client @ 05/05/24 16:47:33.382
  May  5 16:47:33.383: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename resourcequota @ 05/05/24 16:47:33.384
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:47:33.434
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:47:33.442
  STEP: Counting existing ResourceQuota @ 05/05/24 16:47:33.449
  E0505 16:47:34.243395      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:35.245452      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:36.246038      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:37.246223      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:38.246643      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/05/24 16:47:38.451
  STEP: Ensuring resource quota status is calculated @ 05/05/24 16:47:38.46
  E0505 16:47:39.247414      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:40.247554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicaSet @ 05/05/24 16:47:40.466
  STEP: Ensuring resource quota status captures replicaset creation @ 05/05/24 16:47:40.483
  E0505 16:47:41.249667      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:42.252437      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicaSet @ 05/05/24 16:47:42.486
  STEP: Ensuring resource quota status released usage @ 05/05/24 16:47:42.489
  E0505 16:47:43.277792      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:44.278626      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:47:44.495: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1631" for this suite. @ 05/05/24 16:47:44.498
• [11.124 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 05/05/24 16:47:44.506
  May  5 16:47:44.506: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename events @ 05/05/24 16:47:44.509
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:47:44.528
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:47:44.531
  STEP: Create set of events @ 05/05/24 16:47:44.533
  STEP: get a list of Events with a label in the current namespace @ 05/05/24 16:47:44.548
  STEP: delete a list of events @ 05/05/24 16:47:44.553
  May  5 16:47:44.553: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 05/05/24 16:47:44.567
  May  5 16:47:44.572: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-698" for this suite. @ 05/05/24 16:47:44.578
• [0.080 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:190
  STEP: Creating a kubernetes client @ 05/05/24 16:47:44.586
  May  5 16:47:44.587: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename emptydir @ 05/05/24 16:47:44.59
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:47:44.606
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:47:44.61
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 05/05/24 16:47:44.616
  E0505 16:47:45.279806      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:46.280675      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:47:46.638
  May  5 16:47:46.643: INFO: Trying to get logs from node worker00 pod pod-78c8e670-f997-449f-921b-d472bf8f9742 container test-container: <nil>
  STEP: delete the pod @ 05/05/24 16:47:46.647
  May  5 16:47:46.658: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5584" for this suite. @ 05/05/24 16:47:46.661
• [2.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 05/05/24 16:47:46.667
  May  5 16:47:46.667: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename subpath @ 05/05/24 16:47:46.67
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:47:46.689
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:47:46.692
  STEP: Setting up data @ 05/05/24 16:47:46.695
  STEP: Creating pod pod-subpath-test-configmap-4q2d @ 05/05/24 16:47:46.703
  STEP: Creating a pod to test atomic-volume-subpath @ 05/05/24 16:47:46.703
  E0505 16:47:47.280663      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:48.281403      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:49.282283      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:50.282593      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:51.286716      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:52.288118      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:53.290057      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:54.290142      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:55.290428      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:56.290696      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:57.293316      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:58.293768      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:47:59.295566      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:00.296838      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:01.296661      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:02.297627      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:03.297848      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:04.301773      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:05.308258      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:06.308351      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:07.309554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:08.310550      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:48:08.781
  May  5 16:48:08.784: INFO: Trying to get logs from node worker00 pod pod-subpath-test-configmap-4q2d container test-container-subpath-configmap-4q2d: <nil>
  STEP: delete the pod @ 05/05/24 16:48:08.792
  STEP: Deleting pod pod-subpath-test-configmap-4q2d @ 05/05/24 16:48:08.815
  May  5 16:48:08.815: INFO: Deleting pod "pod-subpath-test-configmap-4q2d" in namespace "subpath-7812"
  May  5 16:48:08.821: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-7812" for this suite. @ 05/05/24 16:48:08.826
• [22.163 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 05/05/24 16:48:08.83
  May  5 16:48:08.830: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename containers @ 05/05/24 16:48:08.831
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:48:08.844
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:48:08.849
  STEP: Creating a pod to test override command @ 05/05/24 16:48:08.854
  E0505 16:48:09.310599      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:10.311087      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:11.312448      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:12.312614      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:48:12.88
  May  5 16:48:12.884: INFO: Trying to get logs from node worker00 pod client-containers-1877671b-0fe8-419f-aabb-abf0b46ecd8b container agnhost-container: <nil>
  STEP: delete the pod @ 05/05/24 16:48:12.891
  May  5 16:48:12.912: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-6741" for this suite. @ 05/05/24 16:48:12.916
• [4.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:250
  STEP: Creating a kubernetes client @ 05/05/24 16:48:12.921
  May  5 16:48:12.922: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename webhook @ 05/05/24 16:48:12.924
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:48:12.937
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:48:12.94
  STEP: Setting up server cert @ 05/05/24 16:48:12.954
  E0505 16:48:13.312962      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/05/24 16:48:13.36
  STEP: Deploying the webhook pod @ 05/05/24 16:48:13.379
  STEP: Wait for the deployment to be ready @ 05/05/24 16:48:13.394
  May  5 16:48:13.402: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0505 16:48:14.314792      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:15.314946      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/05/24 16:48:15.411
  STEP: Verifying the service has paired with the endpoint @ 05/05/24 16:48:15.429
  E0505 16:48:16.315488      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:48:16.430: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 05/05/24 16:48:16.438
  STEP: create a configmap that should be updated by the webhook @ 05/05/24 16:48:16.462
  May  5 16:48:16.583: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7703" for this suite. @ 05/05/24 16:48:16.589
  STEP: Destroying namespace "webhook-markers-6520" for this suite. @ 05/05/24 16:48:16.6
• [3.693 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:273
  STEP: Creating a kubernetes client @ 05/05/24 16:48:16.615
  May  5 16:48:16.615: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename webhook @ 05/05/24 16:48:16.617
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:48:16.632
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:48:16.635
  STEP: Setting up server cert @ 05/05/24 16:48:16.652
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/05/24 16:48:17.278
  STEP: Deploying the webhook pod @ 05/05/24 16:48:17.292
  STEP: Wait for the deployment to be ready @ 05/05/24 16:48:17.303
  May  5 16:48:17.308: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0505 16:48:17.315978      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:18.316407      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:19.317920      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/05/24 16:48:19.323
  STEP: Verifying the service has paired with the endpoint @ 05/05/24 16:48:19.341
  E0505 16:48:20.319561      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:48:20.342: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 05/05/24 16:48:20.351
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 05/05/24 16:48:20.372
  STEP: Creating a dummy validating-webhook-configuration object @ 05/05/24 16:48:20.385
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 05/05/24 16:48:20.396
  STEP: Creating a dummy mutating-webhook-configuration object @ 05/05/24 16:48:20.403
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 05/05/24 16:48:20.411
  May  5 16:48:20.467: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-746" for this suite. @ 05/05/24 16:48:20.481
  STEP: Destroying namespace "webhook-markers-8104" for this suite. @ 05/05/24 16:48:20.487
• [3.879 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 05/05/24 16:48:20.495
  May  5 16:48:20.495: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 16:48:20.498
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:48:20.51
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:48:20.517
  STEP: Creating projection with secret that has name projected-secret-test-94987423-34bc-4828-9a62-4c7112d404d4 @ 05/05/24 16:48:20.521
  STEP: Creating a pod to test consume secrets @ 05/05/24 16:48:20.525
  E0505 16:48:21.322072      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:22.322104      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:23.322832      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:24.323854      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:48:24.551
  May  5 16:48:24.554: INFO: Trying to get logs from node worker00 pod pod-projected-secrets-fa717886-380d-4b0b-a497-fde350e248ac container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/05/24 16:48:24.56
  May  5 16:48:24.582: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-741" for this suite. @ 05/05/24 16:48:24.587
• [4.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:107
  STEP: Creating a kubernetes client @ 05/05/24 16:48:24.596
  May  5 16:48:24.596: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename container-probe @ 05/05/24 16:48:24.597
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:48:24.611
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:48:24.616
  E0505 16:48:25.323852      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:26.324520      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:27.328734      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:28.329165      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:29.329242      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:30.330541      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:31.331003      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:32.333469      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:33.333694      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:34.335117      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:35.336056      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:36.339849      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:37.340196      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:38.340725      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:39.341068      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:40.343841      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:41.344090      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:42.345426      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:43.346387      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:44.346531      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:45.347341      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:46.347300      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:47.348418      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:48.348591      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:49.348789      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:50.349817      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:51.349998      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:52.350574      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:53.350787      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:54.352219      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:55.352457      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:56.352774      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:57.353201      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:58.353797      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:48:59.353906      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:00.354034      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:01.355035      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:02.358524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:03.359132      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:04.360121      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:05.362347      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:06.363637      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:07.365265      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:08.368077      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:09.368074      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:10.368630      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:11.369984      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:12.370008      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:13.370654      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:14.374804      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:15.375526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:16.379554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:17.383265      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:18.385490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:19.386281      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:20.391293      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:21.392337      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:22.392991      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:23.394412      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:24.398352      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:49:24.641: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7522" for this suite. @ 05/05/24 16:49:24.647
• [60.060 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:70
  STEP: Creating a kubernetes client @ 05/05/24 16:49:24.656
  May  5 16:49:24.656: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 16:49:24.657
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:49:24.685
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:49:24.691
  STEP: Creating a pod to test downward API volume plugin @ 05/05/24 16:49:24.695
  E0505 16:49:25.399030      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:26.399445      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:27.399361      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:28.399678      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:49:28.721
  May  5 16:49:28.725: INFO: Trying to get logs from node worker00 pod downwardapi-volume-3ed2bd73-7088-4253-afd8-811e88972894 container client-container: <nil>
  STEP: delete the pod @ 05/05/24 16:49:28.733
  May  5 16:49:28.756: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1189" for this suite. @ 05/05/24 16:49:28.761
• [4.112 seconds]
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:321
  STEP: Creating a kubernetes client @ 05/05/24 16:49:28.768
  May  5 16:49:28.768: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename statefulset @ 05/05/24 16:49:28.77
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:49:28.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:49:28.788
  STEP: Creating service test in namespace statefulset-6095 @ 05/05/24 16:49:28.802
  STEP: Creating a new StatefulSet @ 05/05/24 16:49:28.81
  May  5 16:49:28.824: INFO: Found 0 stateful pods, waiting for 3
  E0505 16:49:29.400707      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:30.402320      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:31.406144      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:32.406669      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:33.407748      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:34.408117      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:35.408761      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:36.409787      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:37.410668      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:38.411617      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:49:38.825: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  May  5 16:49:38.825: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  May  5 16:49:38.825: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  May  5 16:49:38.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=statefulset-6095 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May  5 16:49:39.049: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May  5 16:49:39.049: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May  5 16:49:39.049: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0505 16:49:39.412759      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:40.413497      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:41.414054      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:42.414709      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:43.415939      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:44.416594      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:45.419407      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:46.419451      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:47.420462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:48.420770      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 05/05/24 16:49:49.061
  May  5 16:49:49.087: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 05/05/24 16:49:49.087
  E0505 16:49:49.420791      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:50.421889      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:51.422397      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:52.423368      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:53.423061      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:54.424509      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:55.426128      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:56.431829      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:57.435368      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:49:58.435537      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 05/05/24 16:49:59.096
  May  5 16:49:59.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=statefulset-6095 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May  5 16:49:59.266: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May  5 16:49:59.266: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May  5 16:49:59.266: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0505 16:49:59.437900      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:00.438489      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:01.438765      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:02.439861      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:03.440008      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:04.440599      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:05.440663      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:06.442464      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:07.442662      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:08.443412      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:09.444055      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:10.444856      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:11.445664      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:12.445728      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:13.445676      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:14.446680      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:15.451499      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:16.452057      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:17.452478      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:18.454276      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:50:19.279: INFO: Waiting for StatefulSet statefulset-6095/ss2 to complete update
  May  5 16:50:19.279: INFO: Waiting for Pod statefulset-6095/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0505 16:50:19.455767      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:20.456633      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:21.456865      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:22.457094      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:23.458419      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:24.458815      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:25.459611      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:26.461291      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:27.461359      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:28.464431      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 05/05/24 16:50:29.281
  May  5 16:50:29.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=statefulset-6095 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May  5 16:50:29.401: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May  5 16:50:29.401: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May  5 16:50:29.401: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0505 16:50:29.465429      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:30.465763      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:31.467496      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:32.468940      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:33.469545      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:34.469932      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:35.470851      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:36.471508      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:37.472957      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:38.473680      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:50:39.435: INFO: Updating stateful set ss2
  E0505 16:50:39.473921      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:40.474628      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:41.475584      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:42.476569      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:43.477530      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:44.478430      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:45.479113      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:46.480131      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:47.481274      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:48.481675      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 05/05/24 16:50:49.446
  May  5 16:50:49.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=statefulset-6095 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0505 16:50:49.482743      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:50:49.648: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May  5 16:50:49.648: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May  5 16:50:49.648: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0505 16:50:50.483561      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:51.494764      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:52.495153      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:53.495552      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:54.498692      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:55.499651      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:56.500635      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:57.500941      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:58.501695      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:50:59.502466      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:50:59.660: INFO: Deleting all statefulset in ns statefulset-6095
  May  5 16:50:59.664: INFO: Scaling statefulset ss2 to 0
  E0505 16:51:00.504849      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:01.506673      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:02.506995      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:03.507352      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:04.507941      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:05.510428      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:06.510544      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:07.513776      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:08.517780      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:09.518836      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:51:09.695: INFO: Waiting for statefulset status.replicas updated to 0
  May  5 16:51:09.698: INFO: Deleting statefulset ss2
  May  5 16:51:09.727: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-6095" for this suite. @ 05/05/24 16:51:09.73
• [100.979 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2236
  STEP: Creating a kubernetes client @ 05/05/24 16:51:09.747
  May  5 16:51:09.747: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename services @ 05/05/24 16:51:09.748
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:51:09.779
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:51:09.787
  STEP: creating service in namespace services-9804 @ 05/05/24 16:51:09.793
  STEP: creating service affinity-nodeport-transition in namespace services-9804 @ 05/05/24 16:51:09.793
  STEP: creating replication controller affinity-nodeport-transition in namespace services-9804 @ 05/05/24 16:51:09.818
  I0505 16:51:09.843821      22 runners.go:197] Created replication controller with name: affinity-nodeport-transition, namespace: services-9804, replica count: 3
  E0505 16:51:10.519129      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:11.521118      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:12.521633      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0505 16:51:12.900480      22 runners.go:197] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May  5 16:51:12.911: INFO: Creating new exec pod
  E0505 16:51:13.522529      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:14.522794      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:15.522957      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:51:15.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-9804 exec execpod-affinityts9bm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  May  5 16:51:16.067: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  May  5 16:51:16.067: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May  5 16:51:16.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-9804 exec execpod-affinityts9bm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.50 80'
  May  5 16:51:16.174: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.32.0.50 80\nConnection to 10.32.0.50 80 port [tcp/http] succeeded!\n"
  May  5 16:51:16.174: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May  5 16:51:16.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-9804 exec execpod-affinityts9bm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.58.100 32736'
  May  5 16:51:16.291: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.58.100 32736\nConnection to 192.168.58.100 32736 port [tcp/*] succeeded!\n"
  May  5 16:51:16.291: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May  5 16:51:16.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-9804 exec execpod-affinityts9bm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.58.101 32736'
  May  5 16:51:16.390: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.58.101 32736\nConnection to 192.168.58.101 32736 port [tcp/*] succeeded!\n"
  May  5 16:51:16.390: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May  5 16:51:16.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-9804 exec execpod-affinityts9bm -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.58.100:32736/ ; done'
  E0505 16:51:16.523822      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:51:16.632: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n"
  May  5 16:51:16.632: INFO: stdout: "\naffinity-nodeport-transition-brjsb\naffinity-nodeport-transition-vwk6s\naffinity-nodeport-transition-f7wdj\naffinity-nodeport-transition-vwk6s\naffinity-nodeport-transition-f7wdj\naffinity-nodeport-transition-brjsb\naffinity-nodeport-transition-f7wdj\naffinity-nodeport-transition-brjsb\naffinity-nodeport-transition-vwk6s\naffinity-nodeport-transition-brjsb\naffinity-nodeport-transition-f7wdj\naffinity-nodeport-transition-vwk6s\naffinity-nodeport-transition-f7wdj\naffinity-nodeport-transition-brjsb\naffinity-nodeport-transition-vwk6s\naffinity-nodeport-transition-brjsb"
  May  5 16:51:16.632: INFO: Received response from host: affinity-nodeport-transition-brjsb
  May  5 16:51:16.632: INFO: Received response from host: affinity-nodeport-transition-vwk6s
  May  5 16:51:16.632: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.632: INFO: Received response from host: affinity-nodeport-transition-vwk6s
  May  5 16:51:16.632: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.632: INFO: Received response from host: affinity-nodeport-transition-brjsb
  May  5 16:51:16.632: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.632: INFO: Received response from host: affinity-nodeport-transition-brjsb
  May  5 16:51:16.632: INFO: Received response from host: affinity-nodeport-transition-vwk6s
  May  5 16:51:16.632: INFO: Received response from host: affinity-nodeport-transition-brjsb
  May  5 16:51:16.632: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.632: INFO: Received response from host: affinity-nodeport-transition-vwk6s
  May  5 16:51:16.632: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.632: INFO: Received response from host: affinity-nodeport-transition-brjsb
  May  5 16:51:16.632: INFO: Received response from host: affinity-nodeport-transition-vwk6s
  May  5 16:51:16.632: INFO: Received response from host: affinity-nodeport-transition-brjsb
  May  5 16:51:16.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-9804 exec execpod-affinityts9bm -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.58.100:32736/ ; done'
  May  5 16:51:16.866: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:32736/\n"
  May  5 16:51:16.866: INFO: stdout: "\naffinity-nodeport-transition-f7wdj\naffinity-nodeport-transition-f7wdj\naffinity-nodeport-transition-f7wdj\naffinity-nodeport-transition-f7wdj\naffinity-nodeport-transition-f7wdj\naffinity-nodeport-transition-f7wdj\naffinity-nodeport-transition-f7wdj\naffinity-nodeport-transition-f7wdj\naffinity-nodeport-transition-f7wdj\naffinity-nodeport-transition-f7wdj\naffinity-nodeport-transition-f7wdj\naffinity-nodeport-transition-f7wdj\naffinity-nodeport-transition-f7wdj\naffinity-nodeport-transition-f7wdj\naffinity-nodeport-transition-f7wdj\naffinity-nodeport-transition-f7wdj"
  May  5 16:51:16.866: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.866: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.866: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.866: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.866: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.866: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.866: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.866: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.866: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.866: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.866: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.866: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.866: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.866: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.866: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.866: INFO: Received response from host: affinity-nodeport-transition-f7wdj
  May  5 16:51:16.867: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-9804, will wait for the garbage collector to delete the pods @ 05/05/24 16:51:16.896
  May  5 16:51:16.958: INFO: Deleting ReplicationController affinity-nodeport-transition took: 6.43523ms
  May  5 16:51:17.058: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.466102ms
  E0505 16:51:17.524667      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:18.526107      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:19.526594      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:51:20.388: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9804" for this suite. @ 05/05/24 16:51:20.391
• [10.652 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 05/05/24 16:51:20.399
  May  5 16:51:20.399: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename proxy @ 05/05/24 16:51:20.401
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:51:20.415
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:51:20.421
  May  5 16:51:20.424: INFO: Creating pod...
  E0505 16:51:20.527513      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:21.527695      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:51:22.441: INFO: Creating service...
  May  5 16:51:22.455: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-3598/pods/agnhost/proxy/some/path/with/DELETE
  May  5 16:51:22.475: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  May  5 16:51:22.475: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-3598/pods/agnhost/proxy/some/path/with/GET
  May  5 16:51:22.482: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  May  5 16:51:22.482: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-3598/pods/agnhost/proxy/some/path/with/HEAD
  May  5 16:51:22.485: INFO: http.Client request:HEAD | StatusCode:200
  May  5 16:51:22.485: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-3598/pods/agnhost/proxy/some/path/with/OPTIONS
  May  5 16:51:22.491: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  May  5 16:51:22.491: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-3598/pods/agnhost/proxy/some/path/with/PATCH
  May  5 16:51:22.495: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  May  5 16:51:22.495: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-3598/pods/agnhost/proxy/some/path/with/POST
  May  5 16:51:22.499: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  May  5 16:51:22.499: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-3598/pods/agnhost/proxy/some/path/with/PUT
  May  5 16:51:22.502: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  May  5 16:51:22.502: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-3598/services/test-service/proxy/some/path/with/DELETE
  May  5 16:51:22.508: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  May  5 16:51:22.508: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-3598/services/test-service/proxy/some/path/with/GET
  May  5 16:51:22.511: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  May  5 16:51:22.511: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-3598/services/test-service/proxy/some/path/with/HEAD
  May  5 16:51:22.514: INFO: http.Client request:HEAD | StatusCode:200
  May  5 16:51:22.514: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-3598/services/test-service/proxy/some/path/with/OPTIONS
  May  5 16:51:22.517: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  May  5 16:51:22.517: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-3598/services/test-service/proxy/some/path/with/PATCH
  May  5 16:51:22.521: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  May  5 16:51:22.521: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-3598/services/test-service/proxy/some/path/with/POST
  May  5 16:51:22.526: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  May  5 16:51:22.526: INFO: Starting http.Client for https://10.32.0.1:443/api/v1/namespaces/proxy-3598/services/test-service/proxy/some/path/with/PUT
  E0505 16:51:22.528452      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:51:22.530: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  May  5 16:51:22.531: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-3598" for this suite. @ 05/05/24 16:51:22.534
• [2.140 seconds]
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:163
  STEP: Creating a kubernetes client @ 05/05/24 16:51:22.54
  May  5 16:51:22.540: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename svcaccounts @ 05/05/24 16:51:22.541
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:51:22.56
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:51:22.563
  May  5 16:51:22.581: INFO: created pod pod-service-account-defaultsa
  May  5 16:51:22.581: INFO: pod pod-service-account-defaultsa service account token volume mount: true
  May  5 16:51:22.589: INFO: created pod pod-service-account-mountsa
  May  5 16:51:22.589: INFO: pod pod-service-account-mountsa service account token volume mount: true
  May  5 16:51:22.602: INFO: created pod pod-service-account-nomountsa
  May  5 16:51:22.602: INFO: pod pod-service-account-nomountsa service account token volume mount: false
  May  5 16:51:22.618: INFO: created pod pod-service-account-defaultsa-mountspec
  May  5 16:51:22.618: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  May  5 16:51:22.635: INFO: created pod pod-service-account-mountsa-mountspec
  May  5 16:51:22.635: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
  May  5 16:51:22.651: INFO: created pod pod-service-account-nomountsa-mountspec
  May  5 16:51:22.651: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  May  5 16:51:22.669: INFO: created pod pod-service-account-defaultsa-nomountspec
  May  5 16:51:22.669: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  May  5 16:51:22.679: INFO: created pod pod-service-account-mountsa-nomountspec
  May  5 16:51:22.679: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  May  5 16:51:22.691: INFO: created pod pod-service-account-nomountsa-nomountspec
  May  5 16:51:22.691: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  May  5 16:51:22.691: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8965" for this suite. @ 05/05/24 16:51:22.699
• [0.174 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:356
  STEP: Creating a kubernetes client @ 05/05/24 16:51:22.715
  May  5 16:51:22.716: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename endpointslice @ 05/05/24 16:51:22.718
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:51:22.739
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:51:22.744
  STEP: getting /apis @ 05/05/24 16:51:22.749
  STEP: getting /apis/discovery.k8s.io @ 05/05/24 16:51:22.755
  STEP: getting /apis/discovery.k8s.iov1 @ 05/05/24 16:51:22.757
  STEP: creating @ 05/05/24 16:51:22.76
  STEP: getting @ 05/05/24 16:51:22.78
  STEP: listing @ 05/05/24 16:51:22.785
  STEP: watching @ 05/05/24 16:51:22.789
  May  5 16:51:22.789: INFO: starting watch
  STEP: cluster-wide listing @ 05/05/24 16:51:22.79
  STEP: cluster-wide watching @ 05/05/24 16:51:22.793
  May  5 16:51:22.793: INFO: starting watch
  STEP: patching @ 05/05/24 16:51:22.794
  STEP: updating @ 05/05/24 16:51:22.799
  May  5 16:51:22.813: INFO: waiting for watch events with expected annotations
  May  5 16:51:22.813: INFO: saw patched and updated annotations
  STEP: deleting @ 05/05/24 16:51:22.813
  STEP: deleting a collection @ 05/05/24 16:51:22.832
  May  5 16:51:22.853: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-4991" for this suite. @ 05/05/24 16:51:22.862
• [0.155 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1084
  STEP: Creating a kubernetes client @ 05/05/24 16:51:22.871
  May  5 16:51:22.871: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubectl @ 05/05/24 16:51:22.876
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:51:22.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:51:22.896
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/05/24 16:51:22.898
  May  5 16:51:22.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-1667 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  May  5 16:51:23.023: INFO: stderr: ""
  May  5 16:51:23.023: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 05/05/24 16:51:23.023
  May  5 16:51:23.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-1667 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.36.1-1"}]}} --dry-run=server'
  May  5 16:51:23.135: INFO: stderr: ""
  May  5 16:51:23.135: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/05/24 16:51:23.135
  May  5 16:51:23.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-1667 delete pods e2e-test-httpd-pod'
  E0505 16:51:23.529105      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:24.529299      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:51:24.981: INFO: stderr: ""
  May  5 16:51:24.981: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  May  5 16:51:24.981: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1667" for this suite. @ 05/05/24 16:51:24.985
• [2.120 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:110
  STEP: Creating a kubernetes client @ 05/05/24 16:51:24.991
  May  5 16:51:24.991: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename configmap @ 05/05/24 16:51:24.993
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:51:25.004
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:51:25.008
  STEP: Creating configMap with name configmap-test-volume-map-6fef33cb-2c4a-410c-99c8-5a7b7e20b543 @ 05/05/24 16:51:25.011
  STEP: Creating a pod to test consume configMaps @ 05/05/24 16:51:25.014
  E0505 16:51:25.531228      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:26.531204      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:27.532560      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:28.533386      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:51:29.031
  May  5 16:51:29.035: INFO: Trying to get logs from node worker01 pod pod-configmaps-e5fdd490-e293-45bf-b005-9dfff161c048 container agnhost-container: <nil>
  STEP: delete the pod @ 05/05/24 16:51:29.065
  May  5 16:51:29.083: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-933" for this suite. @ 05/05/24 16:51:29.089
• [4.109 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:403
  STEP: Creating a kubernetes client @ 05/05/24 16:51:29.101
  May  5 16:51:29.101: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename webhook @ 05/05/24 16:51:29.106
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:51:29.181
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:51:29.188
  STEP: Setting up server cert @ 05/05/24 16:51:29.218
  E0505 16:51:29.534759      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/05/24 16:51:29.999
  STEP: Deploying the webhook pod @ 05/05/24 16:51:30.006
  STEP: Wait for the deployment to be ready @ 05/05/24 16:51:30.03
  May  5 16:51:30.050: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0505 16:51:30.536456      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:31.536697      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:51:32.063: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 5, 16, 51, 30, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 51, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 16, 51, 30, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 16, 51, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0505 16:51:32.537378      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:33.537597      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/05/24 16:51:34.068
  STEP: Verifying the service has paired with the endpoint @ 05/05/24 16:51:34.074
  E0505 16:51:34.539467      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:51:35.075: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 05/05/24 16:51:35.082
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/05/24 16:51:35.108
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 05/05/24 16:51:35.117
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/05/24 16:51:35.127
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 05/05/24 16:51:35.137
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/05/24 16:51:35.142
  May  5 16:51:35.198: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1689" for this suite. @ 05/05/24 16:51:35.204
  STEP: Destroying namespace "webhook-markers-4419" for this suite. @ 05/05/24 16:51:35.22
• [6.133 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1373
  STEP: Creating a kubernetes client @ 05/05/24 16:51:35.24
  May  5 16:51:35.240: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubectl @ 05/05/24 16:51:35.247
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:51:35.27
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:51:35.272
  STEP: validating cluster-info @ 05/05/24 16:51:35.277
  May  5 16:51:35.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-7503 cluster-info'
  May  5 16:51:35.374: INFO: stderr: ""
  May  5 16:51:35.374: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.32.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  May  5 16:51:35.375: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7503" for this suite. @ 05/05/24 16:51:35.382
• [0.153 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:223
  STEP: Creating a kubernetes client @ 05/05/24 16:51:35.392
  May  5 16:51:35.392: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename downward-api @ 05/05/24 16:51:35.394
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:51:35.412
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:51:35.415
  STEP: Creating a pod to test downward API volume plugin @ 05/05/24 16:51:35.418
  E0505 16:51:35.541138      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:36.542641      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:37.542760      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:38.543357      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:51:39.449
  May  5 16:51:39.453: INFO: Trying to get logs from node worker00 pod downwardapi-volume-f25326dc-1d55-48c8-a635-5e0f98dd54a8 container client-container: <nil>
  STEP: delete the pod @ 05/05/24 16:51:39.463
  May  5 16:51:39.479: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-276" for this suite. @ 05/05/24 16:51:39.487
• [4.101 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 05/05/24 16:51:39.494
  May  5 16:51:39.494: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename events @ 05/05/24 16:51:39.496
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:51:39.51
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:51:39.515
  STEP: creating a test event @ 05/05/24 16:51:39.519
  STEP: listing all events in all namespaces @ 05/05/24 16:51:39.524
  STEP: patching the test event @ 05/05/24 16:51:39.539
  E0505 16:51:39.543517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: fetching the test event @ 05/05/24 16:51:39.547
  STEP: updating the test event @ 05/05/24 16:51:39.551
  STEP: getting the test event @ 05/05/24 16:51:39.56
  STEP: deleting the test event @ 05/05/24 16:51:39.564
  STEP: listing all events in all namespaces @ 05/05/24 16:51:39.571
  May  5 16:51:39.590: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-8289" for this suite. @ 05/05/24 16:51:39.594
• [0.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:399
  STEP: Creating a kubernetes client @ 05/05/24 16:51:39.601
  May  5 16:51:39.601: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubectl @ 05/05/24 16:51:39.603
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:51:39.632
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:51:39.637
  STEP: creating all guestbook components @ 05/05/24 16:51:39.642
  May  5 16:51:39.642: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  May  5 16:51:39.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-3231 create -f -'
  May  5 16:51:39.809: INFO: stderr: ""
  May  5 16:51:39.809: INFO: stdout: "service/agnhost-replica created\n"
  May  5 16:51:39.809: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  May  5 16:51:39.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-3231 create -f -'
  May  5 16:51:40.023: INFO: stderr: ""
  May  5 16:51:40.023: INFO: stdout: "service/agnhost-primary created\n"
  May  5 16:51:40.023: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  May  5 16:51:40.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-3231 create -f -'
  May  5 16:51:40.201: INFO: stderr: ""
  May  5 16:51:40.201: INFO: stdout: "service/frontend created\n"
  May  5 16:51:40.201: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  May  5 16:51:40.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-3231 create -f -'
  May  5 16:51:40.440: INFO: stderr: ""
  May  5 16:51:40.440: INFO: stdout: "deployment.apps/frontend created\n"
  May  5 16:51:40.440: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  May  5 16:51:40.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-3231 create -f -'
  E0505 16:51:40.544796      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:51:40.744: INFO: stderr: ""
  May  5 16:51:40.744: INFO: stdout: "deployment.apps/agnhost-primary created\n"
  May  5 16:51:40.744: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  May  5 16:51:40.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-3231 create -f -'
  May  5 16:51:41.040: INFO: stderr: ""
  May  5 16:51:41.040: INFO: stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 05/05/24 16:51:41.04
  May  5 16:51:41.040: INFO: Waiting for all frontend pods to be Running.
  E0505 16:51:41.544799      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:42.545591      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:43.546019      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:44.546472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:45.550296      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:51:46.091: INFO: Waiting for frontend to serve content.
  May  5 16:51:46.107: INFO: Trying to add a new entry to the guestbook.
  May  5 16:51:46.128: INFO: Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 05/05/24 16:51:46.137
  May  5 16:51:46.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-3231 delete --grace-period=0 --force -f -'
  May  5 16:51:46.246: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May  5 16:51:46.246: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 05/05/24 16:51:46.246
  May  5 16:51:46.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-3231 delete --grace-period=0 --force -f -'
  May  5 16:51:46.348: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May  5 16:51:46.348: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 05/05/24 16:51:46.349
  May  5 16:51:46.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-3231 delete --grace-period=0 --force -f -'
  May  5 16:51:46.428: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May  5 16:51:46.429: INFO: stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 05/05/24 16:51:46.429
  May  5 16:51:46.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-3231 delete --grace-period=0 --force -f -'
  May  5 16:51:46.496: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May  5 16:51:46.496: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 05/05/24 16:51:46.496
  May  5 16:51:46.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-3231 delete --grace-period=0 --force -f -'
  E0505 16:51:46.550000      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:51:46.608: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May  5 16:51:46.608: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 05/05/24 16:51:46.608
  May  5 16:51:46.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-3231 delete --grace-period=0 --force -f -'
  May  5 16:51:46.742: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May  5 16:51:46.742: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  May  5 16:51:46.742: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3231" for this suite. @ 05/05/24 16:51:46.748
• [7.170 seconds]
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 05/05/24 16:51:46.771
  May  5 16:51:46.771: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 16:51:46.771
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:51:46.791
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:51:46.796
  STEP: Creating secret with name s-test-opt-del-4c738bbd-02f5-4660-a913-259a70ec367f @ 05/05/24 16:51:46.806
  STEP: Creating secret with name s-test-opt-upd-b5e3b6c2-22e9-4ce3-9933-01e2fb63a194 @ 05/05/24 16:51:46.812
  STEP: Creating the pod @ 05/05/24 16:51:46.821
  E0505 16:51:47.550417      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:48.552960      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-4c738bbd-02f5-4660-a913-259a70ec367f @ 05/05/24 16:51:48.889
  STEP: Updating secret s-test-opt-upd-b5e3b6c2-22e9-4ce3-9933-01e2fb63a194 @ 05/05/24 16:51:48.895
  STEP: Creating secret with name s-test-opt-create-e6f197e1-2b12-45ae-9631-cf21e269f028 @ 05/05/24 16:51:48.901
  STEP: waiting to observe update in volume @ 05/05/24 16:51:48.907
  E0505 16:51:49.553325      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:50.556806      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:51:50.936: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4467" for this suite. @ 05/05/24 16:51:50.94
• [4.186 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:78
  STEP: Creating a kubernetes client @ 05/05/24 16:51:50.957
  May  5 16:51:50.957: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename resourcequota @ 05/05/24 16:51:50.961
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:51:50.982
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:51:50.985
  STEP: Counting existing ResourceQuota @ 05/05/24 16:51:50.989
  E0505 16:51:51.558461      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:52.558563      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:53.559752      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:54.560649      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:55.563718      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/05/24 16:51:55.993
  STEP: Ensuring resource quota status is calculated @ 05/05/24 16:51:56.001
  E0505 16:51:56.565637      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:57.566652      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:51:58.005: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3861" for this suite. @ 05/05/24 16:51:58.011
• [7.069 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:58
  STEP: Creating a kubernetes client @ 05/05/24 16:51:58.027
  May  5 16:51:58.027: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename configmap @ 05/05/24 16:51:58.033
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:51:58.058
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:51:58.062
  STEP: Creating configMap with name configmap-test-volume-2ae280f2-db34-4980-90c5-26461f14525b @ 05/05/24 16:51:58.065
  STEP: Creating a pod to test consume configMaps @ 05/05/24 16:51:58.069
  E0505 16:51:58.567589      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:51:59.567730      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:00.568573      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:01.569699      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:52:02.098
  May  5 16:52:02.100: INFO: Trying to get logs from node worker00 pod pod-configmaps-ee50ef91-522a-40c0-a981-c4d6452b28cc container agnhost-container: <nil>
  STEP: delete the pod @ 05/05/24 16:52:02.105
  May  5 16:52:02.134: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-950" for this suite. @ 05/05/24 16:52:02.137
• [4.115 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 05/05/24 16:52:02.142
  May  5 16:52:02.142: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename deployment @ 05/05/24 16:52:02.143
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:52:02.153
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:52:02.159
  STEP: creating a Deployment @ 05/05/24 16:52:02.166
  STEP: waiting for Deployment to be created @ 05/05/24 16:52:02.171
  STEP: waiting for all Replicas to be Ready @ 05/05/24 16:52:02.173
  May  5 16:52:02.175: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May  5 16:52:02.175: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May  5 16:52:02.182: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May  5 16:52:02.182: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May  5 16:52:02.201: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May  5 16:52:02.201: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May  5 16:52:02.228: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May  5 16:52:02.228: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E0505 16:52:02.586362      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:52:03.289: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  May  5 16:52:03.289: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  May  5 16:52:03.549: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 05/05/24 16:52:03.549
  May  5 16:52:03.560: INFO: observed event type ADDED
  STEP: waiting for Replicas to scale @ 05/05/24 16:52:03.561
  May  5 16:52:03.567: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 0
  May  5 16:52:03.567: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 0
  May  5 16:52:03.567: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 0
  May  5 16:52:03.567: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 0
  May  5 16:52:03.568: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 0
  May  5 16:52:03.568: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 0
  May  5 16:52:03.568: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 0
  May  5 16:52:03.568: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 0
  May  5 16:52:03.568: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 1
  May  5 16:52:03.568: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 1
  May  5 16:52:03.568: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 2
  May  5 16:52:03.568: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 2
  May  5 16:52:03.570: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 2
  May  5 16:52:03.570: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 2
  May  5 16:52:03.587: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 2
  May  5 16:52:03.587: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 2
  E0505 16:52:03.587991      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:52:03.609: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 2
  May  5 16:52:03.609: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 2
  May  5 16:52:03.622: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 1
  May  5 16:52:03.622: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 1
  May  5 16:52:04.566: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 2
  May  5 16:52:04.566: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 2
  May  5 16:52:04.583: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 1
  STEP: listing Deployments @ 05/05/24 16:52:04.583
  E0505 16:52:04.588958      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:52:04.589: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 05/05/24 16:52:04.59
  May  5 16:52:04.607: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 05/05/24 16:52:04.607
  May  5 16:52:04.619: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  May  5 16:52:04.628: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  May  5 16:52:04.665: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  May  5 16:52:04.696: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  May  5 16:52:04.703: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0505 16:52:05.589418      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:52:05.599: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  May  5 16:52:05.632: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  May  5 16:52:05.666: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  May  5 16:52:05.670: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0505 16:52:06.589524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:52:07.332: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 05/05/24 16:52:07.366
  STEP: fetching the DeploymentStatus @ 05/05/24 16:52:07.381
  May  5 16:52:07.393: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 1
  May  5 16:52:07.394: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 1
  May  5 16:52:07.394: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 1
  May  5 16:52:07.394: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 1
  May  5 16:52:07.394: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 1
  May  5 16:52:07.394: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 2
  May  5 16:52:07.395: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 2
  May  5 16:52:07.395: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 2
  May  5 16:52:07.395: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 2
  May  5 16:52:07.396: INFO: observed Deployment test-deployment in namespace deployment-2739 with ReadyReplicas 3
  STEP: deleting the Deployment @ 05/05/24 16:52:07.396
  May  5 16:52:07.408: INFO: observed event type MODIFIED
  May  5 16:52:07.408: INFO: observed event type MODIFIED
  May  5 16:52:07.408: INFO: observed event type MODIFIED
  May  5 16:52:07.408: INFO: observed event type MODIFIED
  May  5 16:52:07.409: INFO: observed event type MODIFIED
  May  5 16:52:07.409: INFO: observed event type MODIFIED
  May  5 16:52:07.409: INFO: observed event type MODIFIED
  May  5 16:52:07.409: INFO: observed event type MODIFIED
  May  5 16:52:07.409: INFO: observed event type MODIFIED
  May  5 16:52:07.410: INFO: observed event type MODIFIED
  May  5 16:52:07.410: INFO: observed event type MODIFIED
  May  5 16:52:07.410: INFO: observed event type MODIFIED
  May  5 16:52:07.410: INFO: observed event type MODIFIED
  May  5 16:52:07.420: INFO: Log out all the ReplicaSets if there is no deployment created
  May  5 16:52:07.435: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2739" for this suite. @ 05/05/24 16:52:07.441
• [5.316 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:237
  STEP: Creating a kubernetes client @ 05/05/24 16:52:07.459
  May  5 16:52:07.459: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 16:52:07.463
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:52:07.482
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:52:07.486
  STEP: Creating a pod to test downward API volume plugin @ 05/05/24 16:52:07.488
  E0505 16:52:07.590059      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:08.590715      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:09.591532      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:10.591746      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:52:11.515
  May  5 16:52:11.517: INFO: Trying to get logs from node worker00 pod downwardapi-volume-a11fff1f-dd97-47c7-8288-f922ce2247bf container client-container: <nil>
  STEP: delete the pod @ 05/05/24 16:52:11.522
  May  5 16:52:11.541: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-608" for this suite. @ 05/05/24 16:52:11.545
• [4.091 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 05/05/24 16:52:11.551
  May  5 16:52:11.551: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename csiinlinevolumes @ 05/05/24 16:52:11.553
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:52:11.563
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:52:11.567
  STEP: creating @ 05/05/24 16:52:11.569
  STEP: getting @ 05/05/24 16:52:11.59
  E0505 16:52:11.592003      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: listing in namespace @ 05/05/24 16:52:11.592
  STEP: patching @ 05/05/24 16:52:11.597
  STEP: deleting @ 05/05/24 16:52:11.61
  May  5 16:52:11.623: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-4613" for this suite. @ 05/05/24 16:52:11.626
• [0.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 05/05/24 16:52:11.633
  May  5 16:52:11.633: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename dns @ 05/05/24 16:52:11.634
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:52:11.643
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:52:11.646
  STEP: Creating a test headless service @ 05/05/24 16:52:11.648
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-750.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-750.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-750.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-750.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-750.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-750.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-750.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-750.svc.cluster.local;sleep 1; done
   @ 05/05/24 16:52:11.65
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-750.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-750.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-750.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-750.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-750.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-750.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-750.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-750.svc.cluster.local;sleep 1; done
   @ 05/05/24 16:52:11.65
  STEP: creating a pod to probe DNS @ 05/05/24 16:52:11.651
  STEP: submitting the pod to kubernetes @ 05/05/24 16:52:11.651
  E0505 16:52:12.593659      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:13.593368      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/05/24 16:52:13.678
  STEP: looking for the results for each expected name from probers @ 05/05/24 16:52:13.68
  May  5 16:52:13.694: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:13.698: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:13.704: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:13.714: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:13.739: INFO: Unable to read jessie_udp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:13.764: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:13.764: INFO: Lookups using dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92 failed for: [wheezy_udp@dns-test-service-2.dns-750.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-750.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-750.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-750.svc.cluster.local jessie_udp@dns-test-service-2.dns-750.svc.cluster.local jessie_tcp@dns-test-service-2.dns-750.svc.cluster.local]

  May  5 16:52:13.776: INFO: Pod client logs for webserver: 
  May  5 16:52:13.783: INFO: Pod client logs for querier: 
  May  5 16:52:13.789: INFO: Pod client logs for jessie-querier: 
  E0505 16:52:14.594846      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:15.595020      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:16.595318      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:17.595564      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:18.596036      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:52:18.698: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:18.705: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:18.729: INFO: Unable to read jessie_udp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:18.736: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:18.736: INFO: Lookups using dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92 failed for: [wheezy_udp@dns-test-service-2.dns-750.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-750.svc.cluster.local jessie_udp@dns-test-service-2.dns-750.svc.cluster.local jessie_tcp@dns-test-service-2.dns-750.svc.cluster.local]

  May  5 16:52:18.745: INFO: Pod client logs for webserver: 
  May  5 16:52:18.757: INFO: Pod client logs for querier: 
  May  5 16:52:18.767: INFO: Pod client logs for jessie-querier: 
  E0505 16:52:19.596285      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:20.596531      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:21.597516      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:22.598418      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:23.599129      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:52:23.701: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:23.707: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:23.718: INFO: Unable to read jessie_udp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:23.724: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:23.724: INFO: Lookups using dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92 failed for: [wheezy_udp@dns-test-service-2.dns-750.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-750.svc.cluster.local jessie_udp@dns-test-service-2.dns-750.svc.cluster.local jessie_tcp@dns-test-service-2.dns-750.svc.cluster.local]

  May  5 16:52:23.730: INFO: Pod client logs for webserver: 
  May  5 16:52:23.736: INFO: Pod client logs for querier: 
  May  5 16:52:23.743: INFO: Pod client logs for jessie-querier: 
  E0505 16:52:24.599328      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:25.600570      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:26.601663      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:27.601928      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:28.602412      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:52:28.696: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:28.702: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:28.716: INFO: Unable to read jessie_udp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:28.724: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:28.724: INFO: Lookups using dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92 failed for: [wheezy_udp@dns-test-service-2.dns-750.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-750.svc.cluster.local jessie_udp@dns-test-service-2.dns-750.svc.cluster.local jessie_tcp@dns-test-service-2.dns-750.svc.cluster.local]

  May  5 16:52:28.735: INFO: Pod client logs for webserver: 
  May  5 16:52:28.745: INFO: Pod client logs for querier: 
  May  5 16:52:28.756: INFO: Pod client logs for jessie-querier: 
  E0505 16:52:29.604266      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:30.605165      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:31.605868      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:32.606023      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:33.607131      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:52:33.701: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:33.706: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:33.724: INFO: Unable to read jessie_udp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:33.732: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:33.732: INFO: Lookups using dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92 failed for: [wheezy_udp@dns-test-service-2.dns-750.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-750.svc.cluster.local jessie_udp@dns-test-service-2.dns-750.svc.cluster.local jessie_tcp@dns-test-service-2.dns-750.svc.cluster.local]

  May  5 16:52:33.741: INFO: Pod client logs for webserver: 
  May  5 16:52:33.749: INFO: Pod client logs for querier: 
  May  5 16:52:33.757: INFO: Pod client logs for jessie-querier: 
  E0505 16:52:34.611014      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:35.619850      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:36.620814      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:37.620994      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:38.622376      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:52:38.706: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:38.713: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:38.734: INFO: Unable to read jessie_udp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:38.741: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-750.svc.cluster.local from pod dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92: the server could not find the requested resource (get pods dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92)
  May  5 16:52:38.741: INFO: Lookups using dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92 failed for: [wheezy_udp@dns-test-service-2.dns-750.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-750.svc.cluster.local jessie_udp@dns-test-service-2.dns-750.svc.cluster.local jessie_tcp@dns-test-service-2.dns-750.svc.cluster.local]

  May  5 16:52:38.750: INFO: Pod client logs for webserver: 
  May  5 16:52:38.758: INFO: Pod client logs for querier: 
  May  5 16:52:38.766: INFO: Pod client logs for jessie-querier: 
  E0505 16:52:39.622910      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:40.623472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:41.624522      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:42.625497      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:43.626483      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:52:43.722: INFO: DNS probes using dns-750/dns-test-14f1d78c-ac26-45b2-87d6-ac42f4407a92 succeeded

  STEP: deleting the pod @ 05/05/24 16:52:43.722
  STEP: deleting the test headless service @ 05/05/24 16:52:43.744
  May  5 16:52:43.781: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-750" for this suite. @ 05/05/24 16:52:43.79
• [32.177 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:57
  STEP: Creating a kubernetes client @ 05/05/24 16:52:43.811
  May  5 16:52:43.812: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename runtimeclass @ 05/05/24 16:52:43.815
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:52:43.834
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:52:43.838
  May  5 16:52:43.853: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-9850" for this suite. @ 05/05/24 16:52:43.857
• [0.053 seconds]
------------------------------
S
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:132
  STEP: Creating a kubernetes client @ 05/05/24 16:52:43.865
  May  5 16:52:43.865: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename downward-api @ 05/05/24 16:52:43.867
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:52:43.886
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:52:43.891
  STEP: Creating the pod @ 05/05/24 16:52:43.895
  E0505 16:52:44.626757      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:45.627453      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:52:46.433: INFO: Successfully updated pod "labelsupdate8fd60446-9c35-419b-8c6f-89ec3fdf59fb"
  E0505 16:52:46.629131      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:47.632527      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:48.632557      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:49.632663      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:52:50.461: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9991" for this suite. @ 05/05/24 16:52:50.464
• [6.603 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:332
  STEP: Creating a kubernetes client @ 05/05/24 16:52:50.469
  May  5 16:52:50.470: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename webhook @ 05/05/24 16:52:50.471
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:52:50.484
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:52:50.488
  STEP: Setting up server cert @ 05/05/24 16:52:50.505
  E0505 16:52:50.633748      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/05/24 16:52:50.743
  STEP: Deploying the webhook pod @ 05/05/24 16:52:50.747
  STEP: Wait for the deployment to be ready @ 05/05/24 16:52:50.753
  May  5 16:52:50.760: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0505 16:52:51.634682      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:52.636315      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/05/24 16:52:52.775
  STEP: Verifying the service has paired with the endpoint @ 05/05/24 16:52:52.794
  E0505 16:52:53.636682      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:52:53.794: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  May  5 16:52:53.803: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4230-crds.webhook.example.com via the AdmissionRegistration API @ 05/05/24 16:52:54.329
  STEP: Creating a custom resource that should be mutated by the webhook @ 05/05/24 16:52:54.356
  E0505 16:52:54.638823      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:55.639350      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:56.640265      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:52:56.920: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1042" for this suite. @ 05/05/24 16:52:56.923
  STEP: Destroying namespace "webhook-markers-7252" for this suite. @ 05/05/24 16:52:56.936
• [6.473 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3154
  STEP: Creating a kubernetes client @ 05/05/24 16:52:56.942
  May  5 16:52:56.942: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename services @ 05/05/24 16:52:56.944
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:52:56.957
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:52:56.959
  STEP: creating an Endpoint @ 05/05/24 16:52:56.964
  STEP: waiting for available Endpoint @ 05/05/24 16:52:56.969
  STEP: listing all Endpoints @ 05/05/24 16:52:56.971
  STEP: updating the Endpoint @ 05/05/24 16:52:56.974
  STEP: fetching the Endpoint @ 05/05/24 16:52:56.98
  STEP: patching the Endpoint @ 05/05/24 16:52:56.983
  STEP: fetching the Endpoint @ 05/05/24 16:52:57.039
  STEP: deleting the Endpoint by Collection @ 05/05/24 16:52:57.046
  STEP: waiting for Endpoint deletion @ 05/05/24 16:52:57.052
  STEP: fetching the Endpoint @ 05/05/24 16:52:57.054
  May  5 16:52:57.057: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9860" for this suite. @ 05/05/24 16:52:57.062
• [0.125 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 05/05/24 16:52:57.067
  May  5 16:52:57.067: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename deployment @ 05/05/24 16:52:57.069
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:52:57.086
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:52:57.09
  May  5 16:52:57.093: INFO: Creating simple deployment test-new-deployment
  May  5 16:52:57.108: INFO: deployment "test-new-deployment" doesn't have the required revision set
  E0505 16:52:57.640437      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:52:58.641028      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 05/05/24 16:52:59.129
  STEP: updating a scale subresource @ 05/05/24 16:52:59.137
  STEP: verifying the deployment Spec.Replicas was modified @ 05/05/24 16:52:59.154
  STEP: Patch a scale subresource @ 05/05/24 16:52:59.161
  May  5 16:52:59.202: INFO: Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6613",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "22f5df76-5c7a-4049-ab57-b07d956f7e12",
      ResourceVersion: (string) (len=5) "23507",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850524777,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-557759b7c7\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  May  5 16:52:59.215: INFO: New ReplicaSet "test-new-deployment-557759b7c7" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6613",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "72c5fa7c-9249-4eb7-b6b6-31fe3052a460",
      ResourceVersion: (string) (len=5) "23511",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850524777,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "22f5df76-5c7a-4049-ab57-b07d956f7e12",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524779,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 32 32 66 35 64 66  37 36 2d 35 63 37 61 2d  |\"22f5df76-5c7a-|
              00000120  34 30 34 39 2d 61 62 35  37 2d 62 30 37 64 39 35  |4049-ab57-b07d95|
              00000130  36 66 37 65 31 32 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |6f7e12\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524779,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May  5 16:52:59.242: INFO: Pod "test-new-deployment-557759b7c7-7958g" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-7958g",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6613",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4336e5d9-1c2e-4fe4-9058-c1d143a88a2b",
      ResourceVersion: (string) (len=5) "23515",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850524779,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "72c5fa7c-9249-4eb7-b6b6-31fe3052a460",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524779,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 32  63 35 66 61 37 63 2d 39  |d\":\"72c5fa7c-9|
              00000090  32 34 39 2d 34 65 62 37  2d 62 36 62 36 2d 33 31  |249-4eb7-b6b6-31|
              000000a0  66 65 33 30 35 32 61 34  36 30 5c 22 7d 22 3a 7b  |fe3052a460\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524779,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-g7q6k",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-g7q6k",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524779,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524779,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524779,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524779,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524779,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.101",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.101"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850524779,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 16:52:59.248: INFO: Pod "test-new-deployment-557759b7c7-n7pbl" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-n7pbl",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6613",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9d5c5a1f-6073-4fd6-abe5-6767eb5e33f3",
      ResourceVersion: (string) (len=5) "23498",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850524777,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=17) "10.200.131.153/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=17) "10.200.131.153/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "18d77739e0766991cdcd982b48909cdd78c0f5fb2aa5b2c2fbdce5ab076b0fa0"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "72c5fa7c-9249-4eb7-b6b6-31fe3052a460",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 32  63 35 66 61 37 63 2d 39  |d\":\"72c5fa7c-9|
              00000090  32 34 39 2d 34 65 62 37  2d 62 36 62 36 2d 33 31  |249-4eb7-b6b6-31|
              000000a0  66 65 33 30 35 32 61 34  36 30 5c 22 7d 22 3a 7b  |fe3052a460\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 30 30 2e 31 33 31  2e 31 35 33 5c 22 7d 22  |.200.131.153\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vndwj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vndwj",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker00",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850524777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.100",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.100"
        }
      },
      PodIP: (string) (len=14) "10.200.131.153",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "10.200.131.153"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850524777,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850524777,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://9e180ff1808d473bf6bc6e4cd77741ff407a140ade2f55f775d1746326b49eac",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 16:52:59.256: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6613" for this suite. @ 05/05/24 16:52:59.269
• [2.227 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:784
  STEP: Creating a kubernetes client @ 05/05/24 16:52:59.302
  May  5 16:52:59.302: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename job @ 05/05/24 16:52:59.306
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:52:59.345
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:52:59.354
  STEP: Creating a job @ 05/05/24 16:52:59.36
  STEP: Ensure pods equal to parallelism count is attached to the job @ 05/05/24 16:52:59.368
  E0505 16:52:59.642595      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:00.643011      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 05/05/24 16:53:01.371
  STEP: updating /status @ 05/05/24 16:53:01.383
  STEP: get /status @ 05/05/24 16:53:01.389
  May  5 16:53:01.391: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1685" for this suite. @ 05/05/24 16:53:01.394
• [2.100 seconds]
------------------------------
SSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 05/05/24 16:53:01.4
  May  5 16:53:01.400: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename dns @ 05/05/24 16:53:01.4
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:53:01.411
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:53:01.414
  STEP: Creating a test headless service @ 05/05/24 16:53:01.417
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9955.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-9955.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 05/05/24 16:53:01.422
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9955.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-9955.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 05/05/24 16:53:01.422
  STEP: creating a pod to probe DNS @ 05/05/24 16:53:01.422
  STEP: submitting the pod to kubernetes @ 05/05/24 16:53:01.422
  E0505 16:53:01.643720      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:02.644018      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/05/24 16:53:03.441
  STEP: looking for the results for each expected name from probers @ 05/05/24 16:53:03.443
  May  5 16:53:03.454: INFO: DNS probes using dns-9955/dns-test-9c8668d3-950f-4b07-9ef8-9ddf26dd2d56 succeeded

  STEP: deleting the pod @ 05/05/24 16:53:03.454
  STEP: deleting the test headless service @ 05/05/24 16:53:03.471
  May  5 16:53:03.485: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-9955" for this suite. @ 05/05/24 16:53:03.493
• [2.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1493
  STEP: Creating a kubernetes client @ 05/05/24 16:53:03.502
  May  5 16:53:03.502: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename services @ 05/05/24 16:53:03.504
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:53:03.524
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:53:03.53
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-4226 @ 05/05/24 16:53:03.535
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 05/05/24 16:53:03.548
  STEP: creating service externalsvc in namespace services-4226 @ 05/05/24 16:53:03.548
  STEP: creating replication controller externalsvc in namespace services-4226 @ 05/05/24 16:53:03.576
  I0505 16:53:03.591913      22 runners.go:197] Created replication controller with name: externalsvc, namespace: services-4226, replica count: 2
  E0505 16:53:03.645524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:04.646760      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:05.647474      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0505 16:53:06.643507      22 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 05/05/24 16:53:06.646
  E0505 16:53:06.647579      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:53:06.659: INFO: Creating new exec pod
  E0505 16:53:07.648648      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:08.648674      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:53:08.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-4226 exec execpodkct5h -- /bin/sh -x -c nslookup clusterip-service.services-4226.svc.cluster.local'
  May  5 16:53:08.821: INFO: stderr: "+ nslookup clusterip-service.services-4226.svc.cluster.local\n"
  May  5 16:53:08.821: INFO: stdout: "Server:\t\t10.32.0.10\nAddress:\t10.32.0.10#53\n\nclusterip-service.services-4226.svc.cluster.local\tcanonical name = externalsvc.services-4226.svc.cluster.local.\nName:\texternalsvc.services-4226.svc.cluster.local\nAddress: 10.32.0.240\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-4226, will wait for the garbage collector to delete the pods @ 05/05/24 16:53:08.821
  May  5 16:53:08.879: INFO: Deleting ReplicationController externalsvc took: 4.000954ms
  May  5 16:53:08.980: INFO: Terminating ReplicationController externalsvc pods took: 100.494172ms
  E0505 16:53:09.649446      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:10.649763      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:11.650244      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:53:11.897: INFO: Cleaning up the ClusterIP to ExternalName test service
  May  5 16:53:11.905: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4226" for this suite. @ 05/05/24 16:53:11.912
• [8.414 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 05/05/24 16:53:11.917
  May  5 16:53:11.917: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename dns @ 05/05/24 16:53:11.918
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:53:11.93
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:53:11.935
  STEP: Creating a test headless service @ 05/05/24 16:53:11.939
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1351 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1351;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1351 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1351;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1351.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1351.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1351.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1351.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1351.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1351.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1351.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1351.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1351.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1351.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1351.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1351.svc;check="$$(dig +notcp +noall +answer +search 133.0.32.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.32.0.133_udp@PTR;check="$$(dig +tcp +noall +answer +search 133.0.32.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.32.0.133_tcp@PTR;sleep 1; done
   @ 05/05/24 16:53:11.955
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1351 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1351;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1351 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1351;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1351.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1351.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1351.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1351.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1351.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1351.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1351.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1351.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1351.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1351.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1351.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1351.svc;check="$$(dig +notcp +noall +answer +search 133.0.32.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.32.0.133_udp@PTR;check="$$(dig +tcp +noall +answer +search 133.0.32.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.32.0.133_tcp@PTR;sleep 1; done
   @ 05/05/24 16:53:11.955
  STEP: creating a pod to probe DNS @ 05/05/24 16:53:11.955
  STEP: submitting the pod to kubernetes @ 05/05/24 16:53:11.955
  E0505 16:53:12.650587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:13.652022      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/05/24 16:53:14.008
  STEP: looking for the results for each expected name from probers @ 05/05/24 16:53:14.01
  May  5 16:53:14.013: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.015: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.017: INFO: Unable to read wheezy_udp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.019: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.022: INFO: Unable to read wheezy_udp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.026: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.029: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.032: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.035: INFO: Unable to read wheezy_udp@_http._tcp.test-service-2.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.039: INFO: Unable to read wheezy_tcp@_http._tcp.test-service-2.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.044: INFO: Unable to read 10.32.0.133_udp@PTR from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.047: INFO: Unable to read 10.32.0.133_tcp@PTR from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.051: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.056: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.061: INFO: Unable to read jessie_udp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.066: INFO: Unable to read jessie_tcp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.071: INFO: Unable to read jessie_udp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.076: INFO: Unable to read jessie_tcp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.081: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.088: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.093: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.098: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.103: INFO: Unable to read 10.32.0.133_udp@PTR from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.106: INFO: Unable to read 10.32.0.133_tcp@PTR from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:14.106: INFO: Lookups using dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1351 wheezy_tcp@dns-test-service.dns-1351 wheezy_udp@dns-test-service.dns-1351.svc wheezy_tcp@dns-test-service.dns-1351.svc wheezy_udp@_http._tcp.dns-test-service.dns-1351.svc wheezy_tcp@_http._tcp.dns-test-service.dns-1351.svc wheezy_udp@_http._tcp.test-service-2.dns-1351.svc wheezy_tcp@_http._tcp.test-service-2.dns-1351.svc 10.32.0.133_udp@PTR 10.32.0.133_tcp@PTR jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1351 jessie_tcp@dns-test-service.dns-1351 jessie_udp@dns-test-service.dns-1351.svc jessie_tcp@dns-test-service.dns-1351.svc jessie_udp@_http._tcp.dns-test-service.dns-1351.svc jessie_tcp@_http._tcp.dns-test-service.dns-1351.svc jessie_udp@_http._tcp.test-service-2.dns-1351.svc jessie_tcp@_http._tcp.test-service-2.dns-1351.svc 10.32.0.133_udp@PTR 10.32.0.133_tcp@PTR]

  May  5 16:53:14.116: INFO: Pod client logs for webserver: 
  May  5 16:53:14.123: INFO: Pod client logs for querier: 
  May  5 16:53:14.131: INFO: Pod client logs for jessie-querier: 
  E0505 16:53:14.652209      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:15.652751      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:16.653556      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:17.653793      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:18.655025      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:53:19.018: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.023: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.029: INFO: Unable to read wheezy_udp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.032: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.036: INFO: Unable to read wheezy_udp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.039: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.043: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.049: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.052: INFO: Unable to read wheezy_udp@_http._tcp.test-service-2.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.055: INFO: Unable to read wheezy_tcp@_http._tcp.test-service-2.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.058: INFO: Unable to read 10.32.0.133_udp@PTR from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.061: INFO: Unable to read 10.32.0.133_tcp@PTR from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.064: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.067: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.070: INFO: Unable to read jessie_udp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.074: INFO: Unable to read jessie_tcp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.078: INFO: Unable to read jessie_udp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.082: INFO: Unable to read jessie_tcp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.085: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.088: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.091: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.094: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.097: INFO: Unable to read 10.32.0.133_udp@PTR from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.100: INFO: Unable to read 10.32.0.133_tcp@PTR from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:19.100: INFO: Lookups using dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1351 wheezy_tcp@dns-test-service.dns-1351 wheezy_udp@dns-test-service.dns-1351.svc wheezy_tcp@dns-test-service.dns-1351.svc wheezy_udp@_http._tcp.dns-test-service.dns-1351.svc wheezy_tcp@_http._tcp.dns-test-service.dns-1351.svc wheezy_udp@_http._tcp.test-service-2.dns-1351.svc wheezy_tcp@_http._tcp.test-service-2.dns-1351.svc 10.32.0.133_udp@PTR 10.32.0.133_tcp@PTR jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1351 jessie_tcp@dns-test-service.dns-1351 jessie_udp@dns-test-service.dns-1351.svc jessie_tcp@dns-test-service.dns-1351.svc jessie_udp@_http._tcp.dns-test-service.dns-1351.svc jessie_tcp@_http._tcp.dns-test-service.dns-1351.svc jessie_udp@_http._tcp.test-service-2.dns-1351.svc jessie_tcp@_http._tcp.test-service-2.dns-1351.svc 10.32.0.133_udp@PTR 10.32.0.133_tcp@PTR]

  May  5 16:53:19.106: INFO: Pod client logs for webserver: 
  May  5 16:53:19.111: INFO: Pod client logs for querier: 
  May  5 16:53:19.116: INFO: Pod client logs for jessie-querier: 
  E0505 16:53:19.656139      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:20.656541      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:21.656941      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:22.657773      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:23.659183      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:53:24.016: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.020: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.024: INFO: Unable to read wheezy_udp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.028: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.032: INFO: Unable to read wheezy_udp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.035: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.039: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.044: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.048: INFO: Unable to read wheezy_udp@_http._tcp.test-service-2.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.053: INFO: Unable to read wheezy_tcp@_http._tcp.test-service-2.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.058: INFO: Unable to read 10.32.0.133_udp@PTR from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.063: INFO: Unable to read 10.32.0.133_tcp@PTR from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.067: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.072: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.077: INFO: Unable to read jessie_udp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.081: INFO: Unable to read jessie_tcp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.087: INFO: Unable to read jessie_udp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.093: INFO: Unable to read jessie_tcp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.099: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.106: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.111: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.117: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.122: INFO: Unable to read 10.32.0.133_udp@PTR from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.129: INFO: Unable to read 10.32.0.133_tcp@PTR from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:24.129: INFO: Lookups using dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1351 wheezy_tcp@dns-test-service.dns-1351 wheezy_udp@dns-test-service.dns-1351.svc wheezy_tcp@dns-test-service.dns-1351.svc wheezy_udp@_http._tcp.dns-test-service.dns-1351.svc wheezy_tcp@_http._tcp.dns-test-service.dns-1351.svc wheezy_udp@_http._tcp.test-service-2.dns-1351.svc wheezy_tcp@_http._tcp.test-service-2.dns-1351.svc 10.32.0.133_udp@PTR 10.32.0.133_tcp@PTR jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1351 jessie_tcp@dns-test-service.dns-1351 jessie_udp@dns-test-service.dns-1351.svc jessie_tcp@dns-test-service.dns-1351.svc jessie_udp@_http._tcp.dns-test-service.dns-1351.svc jessie_tcp@_http._tcp.dns-test-service.dns-1351.svc jessie_udp@_http._tcp.test-service-2.dns-1351.svc jessie_tcp@_http._tcp.test-service-2.dns-1351.svc 10.32.0.133_udp@PTR 10.32.0.133_tcp@PTR]

  May  5 16:53:24.139: INFO: Pod client logs for webserver: 
  May  5 16:53:24.149: INFO: Pod client logs for querier: 
  May  5 16:53:24.157: INFO: Pod client logs for jessie-querier: 
  E0505 16:53:24.659685      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:25.661027      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:26.661228      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:27.662425      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:28.663807      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:53:29.013: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:29.015: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:29.017: INFO: Unable to read wheezy_udp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:29.019: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:29.021: INFO: Unable to read wheezy_udp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:29.022: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:29.041: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:29.045: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:29.048: INFO: Unable to read jessie_udp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:29.052: INFO: Unable to read jessie_tcp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:29.055: INFO: Unable to read jessie_udp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:29.058: INFO: Unable to read jessie_tcp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:29.077: INFO: Lookups using dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1351 wheezy_tcp@dns-test-service.dns-1351 wheezy_udp@dns-test-service.dns-1351.svc wheezy_tcp@dns-test-service.dns-1351.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1351 jessie_tcp@dns-test-service.dns-1351 jessie_udp@dns-test-service.dns-1351.svc jessie_tcp@dns-test-service.dns-1351.svc]

  May  5 16:53:29.084: INFO: Pod client logs for webserver: 
  May  5 16:53:29.092: INFO: Pod client logs for querier: 
  May  5 16:53:29.099: INFO: Pod client logs for jessie-querier: 
  E0505 16:53:29.664034      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:30.664488      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:31.667385      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:32.667616      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:33.667600      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:53:34.020: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:34.026: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:34.031: INFO: Unable to read wheezy_udp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:34.035: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:34.038: INFO: Unable to read wheezy_udp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:34.041: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:34.054: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:34.056: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:34.058: INFO: Unable to read jessie_udp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:34.059: INFO: Unable to read jessie_tcp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:34.063: INFO: Unable to read jessie_udp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:34.065: INFO: Unable to read jessie_tcp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:34.076: INFO: Lookups using dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1351 wheezy_tcp@dns-test-service.dns-1351 wheezy_udp@dns-test-service.dns-1351.svc wheezy_tcp@dns-test-service.dns-1351.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1351 jessie_tcp@dns-test-service.dns-1351 jessie_udp@dns-test-service.dns-1351.svc jessie_tcp@dns-test-service.dns-1351.svc]

  May  5 16:53:34.079: INFO: Pod client logs for webserver: 
  May  5 16:53:34.082: INFO: Pod client logs for querier: 
  May  5 16:53:34.087: INFO: Pod client logs for jessie-querier: 
  E0505 16:53:34.668025      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:35.669648      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:36.671417      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:37.672322      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:38.673977      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:53:39.015: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:39.018: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:39.021: INFO: Unable to read wheezy_udp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:39.025: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:39.028: INFO: Unable to read wheezy_udp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:39.031: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:39.045: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:39.047: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:39.049: INFO: Unable to read jessie_udp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:39.050: INFO: Unable to read jessie_tcp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:39.052: INFO: Unable to read jessie_udp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:39.055: INFO: Unable to read jessie_tcp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:39.067: INFO: Lookups using dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1351 wheezy_tcp@dns-test-service.dns-1351 wheezy_udp@dns-test-service.dns-1351.svc wheezy_tcp@dns-test-service.dns-1351.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1351 jessie_tcp@dns-test-service.dns-1351 jessie_udp@dns-test-service.dns-1351.svc jessie_tcp@dns-test-service.dns-1351.svc]

  May  5 16:53:39.070: INFO: Pod client logs for webserver: 
  May  5 16:53:39.074: INFO: Pod client logs for querier: 
  May  5 16:53:39.077: INFO: Pod client logs for jessie-querier: 
  E0505 16:53:39.674661      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:40.675970      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:41.677177      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:42.677994      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:43.678733      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:53:44.017: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:44.022: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:44.026: INFO: Unable to read wheezy_udp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:44.029: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:44.031: INFO: Unable to read wheezy_udp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:44.033: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:44.049: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:44.052: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:44.053: INFO: Unable to read jessie_udp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:44.055: INFO: Unable to read jessie_tcp@dns-test-service.dns-1351 from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:44.058: INFO: Unable to read jessie_udp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:44.061: INFO: Unable to read jessie_tcp@dns-test-service.dns-1351.svc from pod dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05: the server could not find the requested resource (get pods dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05)
  May  5 16:53:44.075: INFO: Lookups using dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1351 wheezy_tcp@dns-test-service.dns-1351 wheezy_udp@dns-test-service.dns-1351.svc wheezy_tcp@dns-test-service.dns-1351.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1351 jessie_tcp@dns-test-service.dns-1351 jessie_udp@dns-test-service.dns-1351.svc jessie_tcp@dns-test-service.dns-1351.svc]

  May  5 16:53:44.078: INFO: Pod client logs for webserver: 
  May  5 16:53:44.082: INFO: Pod client logs for querier: 
  May  5 16:53:44.085: INFO: Pod client logs for jessie-querier: 
  E0505 16:53:44.679985      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:45.680879      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:46.681132      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:47.681322      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:48.681569      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:53:49.056: INFO: DNS probes using dns-1351/dns-test-17092fea-58b7-41d6-9fa9-c62cd64d3b05 succeeded

  STEP: deleting the pod @ 05/05/24 16:53:49.056
  STEP: deleting the test service @ 05/05/24 16:53:49.064
  STEP: deleting the test headless service @ 05/05/24 16:53:49.081
  May  5 16:53:49.092: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-1351" for this suite. @ 05/05/24 16:53:49.099
• [37.189 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:177
  STEP: Creating a kubernetes client @ 05/05/24 16:53:49.106
  May  5 16:53:49.106: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename podtemplate @ 05/05/24 16:53:49.107
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:53:49.127
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:53:49.132
  STEP: Create a pod template @ 05/05/24 16:53:49.135
  STEP: Replace a pod template @ 05/05/24 16:53:49.143
  May  5 16:53:49.149: INFO: Found updated podtemplate annotation: "true"

  May  5 16:53:49.149: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-2914" for this suite. @ 05/05/24 16:53:49.153
• [0.052 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:270
  STEP: Creating a kubernetes client @ 05/05/24 16:53:49.158
  May  5 16:53:49.158: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename apf @ 05/05/24 16:53:49.161
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:53:49.174
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:53:49.178
  STEP: getting /apis @ 05/05/24 16:53:49.181
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 05/05/24 16:53:49.187
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 05/05/24 16:53:49.189
  STEP: creating @ 05/05/24 16:53:49.191
  STEP: getting @ 05/05/24 16:53:49.216
  STEP: listing @ 05/05/24 16:53:49.22
  STEP: watching @ 05/05/24 16:53:49.226
  May  5 16:53:49.226: INFO: starting watch
  STEP: patching @ 05/05/24 16:53:49.228
  STEP: updating @ 05/05/24 16:53:49.234
  May  5 16:53:49.243: INFO: waiting for watch events with expected annotations
  May  5 16:53:49.243: INFO: missing expected annotations, waiting: map[string]string(nil)
  STEP: getting /status @ 05/05/24 16:53:49.244
  STEP: patching /status @ 05/05/24 16:53:49.248
  STEP: updating /status @ 05/05/24 16:53:49.254
  STEP: deleting @ 05/05/24 16:53:49.279
  STEP: deleting a collection @ 05/05/24 16:53:49.288
  May  5 16:53:49.304: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-3937" for this suite. @ 05/05/24 16:53:49.308
• [0.157 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:474
  STEP: Creating a kubernetes client @ 05/05/24 16:53:49.315
  May  5 16:53:49.315: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename field-validation @ 05/05/24 16:53:49.317
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:53:49.336
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:53:49.34
  May  5 16:53:49.344: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  E0505 16:53:49.682055      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:50.682052      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:51.682342      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0505 16:53:51.874841      22 warnings.go:70] unknown field "alpha"
  W0505 16:53:51.875002      22 warnings.go:70] unknown field "beta"
  W0505 16:53:51.875008      22 warnings.go:70] unknown field "delta"
  W0505 16:53:51.875012      22 warnings.go:70] unknown field "epsilon"
  W0505 16:53:51.875017      22 warnings.go:70] unknown field "gamma"
  May  5 16:53:52.394: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-440" for this suite. @ 05/05/24 16:53:52.396
• [3.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 05/05/24 16:53:52.401
  May  5 16:53:52.401: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename container-runtime @ 05/05/24 16:53:52.402
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:53:52.41
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:53:52.412
  STEP: create the container @ 05/05/24 16:53:52.414
  W0505 16:53:52.418923      22 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 05/05/24 16:53:52.419
  E0505 16:53:52.682919      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:53.683464      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:54.684970      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/05/24 16:53:55.431
  STEP: the container should be terminated @ 05/05/24 16:53:55.435
  STEP: the termination message should be set @ 05/05/24 16:53:55.435
  May  5 16:53:55.435: INFO: Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 05/05/24 16:53:55.436
  May  5 16:53:55.462: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-9527" for this suite. @ 05/05/24 16:53:55.465
• [3.067 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:69
  STEP: Creating a kubernetes client @ 05/05/24 16:53:55.468
  May  5 16:53:55.468: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename endpointslice @ 05/05/24 16:53:55.469
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:53:55.475
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:53:55.477
  May  5 16:53:55.482: INFO: Endpoints addresses: [192.168.58.100] , ports: [6443]
  May  5 16:53:55.482: INFO: EndpointSlices addresses: [192.168.58.100] , ports: [6443]
  May  5 16:53:55.482: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-360" for this suite. @ 05/05/24 16:53:55.483
• [0.018 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 05/05/24 16:53:55.486
  May  5 16:53:55.486: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename secrets @ 05/05/24 16:53:55.486
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:53:55.491
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:53:55.493
  STEP: Creating secret with name secret-test-map-4c5e90e1-50f9-4419-8a4b-341317b69ca6 @ 05/05/24 16:53:55.494
  STEP: Creating a pod to test consume secrets @ 05/05/24 16:53:55.522
  E0505 16:53:55.685269      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:56.685403      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:57.685590      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:53:58.686527      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:53:59.532
  May  5 16:53:59.534: INFO: Trying to get logs from node worker00 pod pod-secrets-8df17777-d3f6-4492-886f-3b0c6e1b7189 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/05/24 16:53:59.538
  May  5 16:53:59.549: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-517" for this suite. @ 05/05/24 16:53:59.552
• [4.069 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 05/05/24 16:53:59.556
  May  5 16:53:59.556: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename field-validation @ 05/05/24 16:53:59.557
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:53:59.564
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:53:59.567
  STEP: apply creating a deployment @ 05/05/24 16:53:59.569
  May  5 16:53:59.576: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-1868" for this suite. @ 05/05/24 16:53:59.578
• [0.026 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:180
  STEP: Creating a kubernetes client @ 05/05/24 16:53:59.582
  May  5 16:53:59.582: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename emptydir @ 05/05/24 16:53:59.583
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:53:59.591
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:53:59.593
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 05/05/24 16:53:59.596
  E0505 16:53:59.687215      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:00.687643      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:01.690292      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:02.691061      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:54:03.617
  May  5 16:54:03.621: INFO: Trying to get logs from node worker00 pod pod-3bd1df5e-b964-4206-92f7-beb6682f6287 container test-container: <nil>
  STEP: delete the pod @ 05/05/24 16:54:03.629
  May  5 16:54:03.638: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7835" for this suite. @ 05/05/24 16:54:03.64
• [4.062 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:315
  STEP: Creating a kubernetes client @ 05/05/24 16:54:03.644
  May  5 16:54:03.644: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename webhook @ 05/05/24 16:54:03.645
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:54:03.654
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:54:03.656
  STEP: Setting up server cert @ 05/05/24 16:54:03.666
  E0505 16:54:03.693619      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/05/24 16:54:03.853
  STEP: Deploying the webhook pod @ 05/05/24 16:54:03.857
  STEP: Wait for the deployment to be ready @ 05/05/24 16:54:03.862
  May  5 16:54:03.868: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0505 16:54:04.694390      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:05.696245      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/05/24 16:54:05.884
  STEP: Verifying the service has paired with the endpoint @ 05/05/24 16:54:05.903
  E0505 16:54:06.696341      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:54:06.904: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  May  5 16:54:06.910: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4886-crds.webhook.example.com via the AdmissionRegistration API @ 05/05/24 16:54:07.423
  STEP: Creating a custom resource while v1 is storage version @ 05/05/24 16:54:07.433
  E0505 16:54:07.697230      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:08.697336      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 05/05/24 16:54:09.463
  STEP: Patching the custom resource while v2 is storage version @ 05/05/24 16:54:09.468
  E0505 16:54:09.697830      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:54:10.038: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3797" for this suite. @ 05/05/24 16:54:10.044
  STEP: Destroying namespace "webhook-markers-6176" for this suite. @ 05/05/24 16:54:10.05
• [6.414 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:86
  STEP: Creating a kubernetes client @ 05/05/24 16:54:10.059
  May  5 16:54:10.059: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename downward-api @ 05/05/24 16:54:10.06
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:54:10.07
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:54:10.074
  STEP: Creating a pod to test downward API volume plugin @ 05/05/24 16:54:10.075
  E0505 16:54:10.698551      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:11.699008      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:12.699400      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:13.699772      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:54:14.095
  May  5 16:54:14.098: INFO: Trying to get logs from node worker00 pod downwardapi-volume-f8d1910c-c9ab-4052-af43-0d4e26106fc7 container client-container: <nil>
  STEP: delete the pod @ 05/05/24 16:54:14.101
  May  5 16:54:14.110: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3443" for this suite. @ 05/05/24 16:54:14.112
• [4.058 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:505
  STEP: Creating a kubernetes client @ 05/05/24 16:54:14.117
  May  5 16:54:14.117: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename configmap @ 05/05/24 16:54:14.118
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:54:14.127
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:54:14.129
  May  5 16:54:14.143: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8106" for this suite. @ 05/05/24 16:54:14.145
• [0.031 seconds]
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:46
  STEP: Creating a kubernetes client @ 05/05/24 16:54:14.148
  May  5 16:54:14.148: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename downward-api @ 05/05/24 16:54:14.149
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:54:14.155
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:54:14.159
  STEP: Creating a pod to test downward api env vars @ 05/05/24 16:54:14.161
  E0505 16:54:14.700053      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:15.701987      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:16.702493      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:17.704546      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:54:18.192
  May  5 16:54:18.194: INFO: Trying to get logs from node worker00 pod downward-api-bdabac17-0f99-40a5-a923-8296149e0437 container dapi-container: <nil>
  STEP: delete the pod @ 05/05/24 16:54:18.199
  May  5 16:54:18.213: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1990" for this suite. @ 05/05/24 16:54:18.217
• [4.074 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:47
  STEP: Creating a kubernetes client @ 05/05/24 16:54:18.222
  May  5 16:54:18.222: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename var-expansion @ 05/05/24 16:54:18.224
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:54:18.237
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:54:18.241
  STEP: Creating a pod to test env composition @ 05/05/24 16:54:18.245
  E0505 16:54:18.705295      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:19.709587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:20.709628      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:21.710130      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:54:22.264
  May  5 16:54:22.266: INFO: Trying to get logs from node worker00 pod var-expansion-5fc8834e-fdd3-48e0-b3e6-835351cb5bf7 container dapi-container: <nil>
  STEP: delete the pod @ 05/05/24 16:54:22.269
  May  5 16:54:22.285: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5074" for this suite. @ 05/05/24 16:54:22.289
• [4.072 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 05/05/24 16:54:22.295
  May  5 16:54:22.295: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename discovery @ 05/05/24 16:54:22.295
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:54:22.304
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:54:22.308
  STEP: Setting up server cert @ 05/05/24 16:54:22.311
  STEP: Requesting APIResourceList from "/api/v1" @ 05/05/24 16:54:22.503
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 05/05/24 16:54:22.515
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 05/05/24 16:54:22.516
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 05/05/24 16:54:22.517
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 05/05/24 16:54:22.518
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 05/05/24 16:54:22.519
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 05/05/24 16:54:22.519
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 05/05/24 16:54:22.52
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 05/05/24 16:54:22.521
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 05/05/24 16:54:22.522
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 05/05/24 16:54:22.523
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 05/05/24 16:54:22.524
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 05/05/24 16:54:22.525
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 05/05/24 16:54:22.526
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 05/05/24 16:54:22.527
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 05/05/24 16:54:22.527
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 05/05/24 16:54:22.528
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 05/05/24 16:54:22.528
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 05/05/24 16:54:22.529
  May  5 16:54:22.530: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-8322" for this suite. @ 05/05/24 16:54:22.532
• [0.244 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:70
  STEP: Creating a kubernetes client @ 05/05/24 16:54:22.54
  May  5 16:54:22.540: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename downward-api @ 05/05/24 16:54:22.541
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:54:22.554
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:54:22.557
  STEP: Creating a pod to test downward API volume plugin @ 05/05/24 16:54:22.56
  E0505 16:54:22.711126      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:23.712066      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:24.712753      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:25.713452      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:54:26.585
  May  5 16:54:26.589: INFO: Trying to get logs from node worker00 pod downwardapi-volume-b9cc3a2a-6604-4c50-9bb5-8f15ac08822f container client-container: <nil>
  STEP: delete the pod @ 05/05/24 16:54:26.598
  May  5 16:54:26.617: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2089" for this suite. @ 05/05/24 16:54:26.623
• [4.091 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:332
  STEP: Creating a kubernetes client @ 05/05/24 16:54:26.631
  May  5 16:54:26.632: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename statefulset @ 05/05/24 16:54:26.633
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:54:26.648
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:54:26.653
  STEP: Creating service test in namespace statefulset-1105 @ 05/05/24 16:54:26.658
  STEP: Creating a new StatefulSet @ 05/05/24 16:54:26.666
  May  5 16:54:26.683: INFO: Found 0 stateful pods, waiting for 3
  E0505 16:54:26.714808      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:27.717680      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:28.717660      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:29.718271      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:30.718551      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:31.719369      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:32.720631      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:33.721455      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:34.721803      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:35.722829      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:54:36.681: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  May  5 16:54:36.681: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  May  5 16:54:36.681: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 05/05/24 16:54:36.69
  May  5 16:54:36.717: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 05/05/24 16:54:36.717
  E0505 16:54:36.723320      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:37.723797      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:38.724576      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:39.725000      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:40.725324      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:41.725663      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:42.726942      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:43.727636      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:44.727775      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:45.729825      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 05/05/24 16:54:46.723
  STEP: Performing a canary update @ 05/05/24 16:54:46.723
  E0505 16:54:46.739504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:54:46.757: INFO: Updating stateful set ss2
  May  5 16:54:46.768: INFO: Waiting for Pod statefulset-1105/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0505 16:54:47.763833      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:48.765506      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:49.765903      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:50.766622      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:51.767410      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:52.768618      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:53.768898      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:54.769313      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:55.769617      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 05/05/24 16:54:56.767
  E0505 16:54:56.770336      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:54:56.821: INFO: Found 2 stateful pods, waiting for 3
  E0505 16:54:57.770671      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:58.771591      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:54:59.774674      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:00.774643      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:01.777835      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:02.778481      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:03.778506      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:04.778946      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:05.781981      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:06.783533      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:55:06.820: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  May  5 16:55:06.820: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  May  5 16:55:06.820: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 05/05/24 16:55:06.825
  May  5 16:55:06.853: INFO: Updating stateful set ss2
  May  5 16:55:06.860: INFO: Waiting for Pod statefulset-1105/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0505 16:55:07.783599      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:08.784872      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:09.786825      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:10.787689      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:11.788706      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:12.790315      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:13.790388      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:14.791088      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:15.791722      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:16.791896      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:55:16.884: INFO: Updating stateful set ss2
  May  5 16:55:16.889: INFO: Waiting for StatefulSet statefulset-1105/ss2 to complete update
  May  5 16:55:16.889: INFO: Waiting for Pod statefulset-1105/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0505 16:55:17.792591      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:18.793531      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:19.794270      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:20.795445      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:21.796402      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:22.796500      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:23.797385      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:24.798092      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:25.801276      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:26.801530      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:55:26.889: INFO: Deleting all statefulset in ns statefulset-1105
  May  5 16:55:26.892: INFO: Scaling statefulset ss2 to 0
  E0505 16:55:27.802301      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:28.803329      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:29.805354      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:30.806955      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:31.808056      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:32.808493      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:33.809219      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:34.811281      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:35.813548      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:36.815715      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:55:36.906: INFO: Waiting for statefulset status.replicas updated to 0
  May  5 16:55:36.910: INFO: Deleting statefulset ss2
  May  5 16:55:36.934: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1105" for this suite. @ 05/05/24 16:55:36.938
• [70.311 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:334
  STEP: Creating a kubernetes client @ 05/05/24 16:55:36.943
  May  5 16:55:36.943: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename sched-pred @ 05/05/24 16:55:36.945
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:55:36.957
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:55:36.961
  May  5 16:55:36.964: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  May  5 16:55:36.968: INFO: Waiting for terminating namespaces to be deleted...
  May  5 16:55:36.970: INFO: 
  Logging pods the apiserver thinks is on node worker00 before test
  May  5 16:55:36.976: INFO: etcd-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.976: INFO: 	Container etcd ready: true, restart count 0
  May  5 16:55:36.976: INFO: gobetween-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.976: INFO: 	Container gobetween ready: true, restart count 0
  May  5 16:55:36.976: INFO: kube-apiserver-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.976: INFO: 	Container kube-apiserver ready: true, restart count 0
  May  5 16:55:36.976: INFO: kube-controller-manager-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.976: INFO: 	Container kube-controller-manager ready: true, restart count 0
  May  5 16:55:36.976: INFO: kube-proxy-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.976: INFO: 	Container kube-proxy ready: true, restart count 0
  May  5 16:55:36.976: INFO: kube-scheduler-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.976: INFO: 	Container kube-scheduler ready: true, restart count 0
  May  5 16:55:36.976: INFO: calico-node-qbc8c from networking started at 2024-05-05 16:00:27 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.976: INFO: 	Container calico-node ready: true, restart count 0
  May  5 16:55:36.976: INFO: metallb-speaker-bb4zq from networking started at 2024-05-05 16:46:32 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.976: INFO: 	Container speaker ready: true, restart count 0
  May  5 16:55:36.976: INFO: sonobuoy from sonobuoy started at 2024-05-05 16:06:18 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.976: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  May  5 16:55:36.976: INFO: sonobuoy-e2e-job-919a92fc1d484e90 from sonobuoy started at 2024-05-05 16:06:24 +0000 UTC (2 container statuses recorded)
  May  5 16:55:36.976: INFO: 	Container e2e ready: true, restart count 0
  May  5 16:55:36.976: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May  5 16:55:36.976: INFO: sonobuoy-systemd-logs-daemon-set-75c9f5cbb2184229-8sxzt from sonobuoy started at 2024-05-05 16:06:24 +0000 UTC (2 container statuses recorded)
  May  5 16:55:36.976: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May  5 16:55:36.976: INFO: 	Container systemd-logs ready: true, restart count 0
  May  5 16:55:36.976: INFO: ceph-csi-cephfs-nodeplugin-kht47 from storage started at 2024-05-05 16:46:33 +0000 UTC (3 container statuses recorded)
  May  5 16:55:36.976: INFO: 	Container csi-cephfsplugin ready: true, restart count 0
  May  5 16:55:36.976: INFO: 	Container driver-registrar ready: true, restart count 0
  May  5 16:55:36.976: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:55:36.976: INFO: ceph-csi-rbd-nodeplugin-sjzlp from storage started at 2024-05-05 16:46:33 +0000 UTC (3 container statuses recorded)
  May  5 16:55:36.976: INFO: 	Container csi-rbdplugin ready: true, restart count 0
  May  5 16:55:36.976: INFO: 	Container driver-registrar ready: true, restart count 0
  May  5 16:55:36.976: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:55:36.976: INFO: ceph-mon-worker00-797bf6469d-wb64d from storage started at 2024-05-05 16:46:32 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.976: INFO: 	Container ceph-mon ready: true, restart count 0
  May  5 16:55:36.976: INFO: 
  Logging pods the apiserver thinks is on node worker01 before test
  May  5 16:55:36.987: INFO: coredns-5b87cbd9d7-7qqjb from kube-system started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.987: INFO: 	Container coredns ready: true, restart count 0
  May  5 16:55:36.987: INFO: coredns-5b87cbd9d7-sbzwr from kube-system started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.987: INFO: 	Container coredns ready: true, restart count 0
  May  5 16:55:36.987: INFO: gobetween-worker01 from kube-system started at 2024-05-05 15:59:42 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.987: INFO: 	Container gobetween ready: true, restart count 0
  May  5 16:55:36.987: INFO: kube-proxy-worker01 from kube-system started at 2024-05-05 15:59:42 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.987: INFO: 	Container kube-proxy ready: true, restart count 0
  May  5 16:55:36.987: INFO: kubernetes-dashboard-api-86d45cdc48-tqjcd from kube-system started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.987: INFO: 	Container kubernetes-dashboard-api ready: true, restart count 0
  May  5 16:55:36.987: INFO: kubernetes-dashboard-auth-5d859bc497-tv49r from kube-system started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.987: INFO: 	Container kubernetes-dashboard-auth ready: true, restart count 0
  May  5 16:55:36.987: INFO: kubernetes-dashboard-kong-766ffb8f6-bhcg5 from kube-system started at 2024-05-05 16:46:09 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.987: INFO: 	Container proxy ready: true, restart count 0
  May  5 16:55:36.987: INFO: kubernetes-dashboard-metrics-scraper-56c9f5cc54-j5nbq from kube-system started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.987: INFO: 	Container kubernetes-dashboard-metrics-scraper ready: true, restart count 0
  May  5 16:55:36.987: INFO: kubernetes-dashboard-web-74dcc49f5-5zxqx from kube-system started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.987: INFO: 	Container kubernetes-dashboard-web ready: true, restart count 0
  May  5 16:55:36.987: INFO: calico-kube-controllers-758c99c4b5-bblrs from networking started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.987: INFO: 	Container calico-kube-controllers ready: true, restart count 0
  May  5 16:55:36.987: INFO: calico-node-7g4c9 from networking started at 2024-05-05 16:00:29 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.987: INFO: 	Container calico-node ready: true, restart count 0
  May  5 16:55:36.987: INFO: calico-typha-5cfbc84557-5zvkz from networking started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.987: INFO: 	Container calico-typha ready: true, restart count 0
  May  5 16:55:36.987: INFO: metallb-controller-67f4cfb984-rk9hg from networking started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.987: INFO: 	Container controller ready: true, restart count 0
  May  5 16:55:36.987: INFO: metallb-speaker-22x22 from networking started at 2024-05-05 16:00:48 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.987: INFO: 	Container speaker ready: true, restart count 0
  May  5 16:55:36.987: INFO: sonobuoy-systemd-logs-daemon-set-75c9f5cbb2184229-mw8sz from sonobuoy started at 2024-05-05 16:06:25 +0000 UTC (2 container statuses recorded)
  May  5 16:55:36.987: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May  5 16:55:36.987: INFO: 	Container systemd-logs ready: true, restart count 0
  May  5 16:55:36.987: INFO: ceph-csi-cephfs-nodeplugin-xsgjl from storage started at 2024-05-05 16:00:29 +0000 UTC (3 container statuses recorded)
  May  5 16:55:36.987: INFO: 	Container csi-cephfsplugin ready: true, restart count 0
  May  5 16:55:36.988: INFO: 	Container driver-registrar ready: true, restart count 0
  May  5 16:55:36.988: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:55:36.988: INFO: ceph-csi-cephfs-provisioner-6dc49995f7-lqt4k from storage started at 2024-05-05 16:00:29 +0000 UTC (5 container statuses recorded)
  May  5 16:55:36.988: INFO: 	Container csi-cephfsplugin ready: true, restart count 0
  May  5 16:55:36.989: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 16:55:36.989: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 16:55:36.989: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 16:55:36.989: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:55:36.989: INFO: ceph-csi-cephfs-provisioner-6dc49995f7-svr4r from storage started at 2024-05-05 16:00:29 +0000 UTC (5 container statuses recorded)
  May  5 16:55:36.989: INFO: 	Container csi-cephfsplugin ready: true, restart count 0
  May  5 16:55:36.989: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 16:55:36.989: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 16:55:36.989: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 16:55:36.989: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:55:36.989: INFO: ceph-csi-cephfs-provisioner-6dc49995f7-tfb66 from storage started at 2024-05-05 16:00:29 +0000 UTC (5 container statuses recorded)
  May  5 16:55:36.989: INFO: 	Container csi-cephfsplugin ready: true, restart count 0
  May  5 16:55:36.989: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 16:55:36.989: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 16:55:36.989: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 16:55:36.989: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:55:36.989: INFO: ceph-csi-rbd-nodeplugin-cmg7z from storage started at 2024-05-05 16:00:29 +0000 UTC (3 container statuses recorded)
  May  5 16:55:36.990: INFO: 	Container csi-rbdplugin ready: true, restart count 0
  May  5 16:55:36.990: INFO: 	Container driver-registrar ready: true, restart count 0
  May  5 16:55:36.990: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:55:36.990: INFO: ceph-csi-rbd-provisioner-55f5bd6544-8f77n from storage started at 2024-05-05 16:00:29 +0000 UTC (7 container statuses recorded)
  May  5 16:55:36.990: INFO: 	Container csi-attacher ready: true, restart count 0
  May  5 16:55:36.990: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 16:55:36.990: INFO: 	Container csi-rbdplugin ready: true, restart count 0
  May  5 16:55:36.990: INFO: 	Container csi-rbdplugin-controller ready: true, restart count 0
  May  5 16:55:36.990: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 16:55:36.990: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 16:55:36.990: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:55:36.990: INFO: ceph-csi-rbd-provisioner-55f5bd6544-bgrv6 from storage started at 2024-05-05 16:00:29 +0000 UTC (7 container statuses recorded)
  May  5 16:55:36.990: INFO: 	Container csi-attacher ready: true, restart count 0
  May  5 16:55:36.990: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 16:55:36.990: INFO: 	Container csi-rbdplugin ready: true, restart count 0
  May  5 16:55:36.990: INFO: 	Container csi-rbdplugin-controller ready: true, restart count 0
  May  5 16:55:36.990: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 16:55:36.990: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 16:55:36.990: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:55:36.990: INFO: ceph-csi-rbd-provisioner-55f5bd6544-v9llp from storage started at 2024-05-05 16:00:29 +0000 UTC (7 container statuses recorded)
  May  5 16:55:36.990: INFO: 	Container csi-attacher ready: true, restart count 0
  May  5 16:55:36.990: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 16:55:36.990: INFO: 	Container csi-rbdplugin ready: true, restart count 0
  May  5 16:55:36.990: INFO: 	Container csi-rbdplugin-controller ready: true, restart count 0
  May  5 16:55:36.990: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 16:55:36.990: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 16:55:36.990: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:55:36.990: INFO: ceph-mds-worker01-798b64d68-wr2nm from storage started at 2024-05-05 16:00:29 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.990: INFO: 	Container ceph-mds ready: true, restart count 0
  May  5 16:55:36.990: INFO: ceph-mgr-worker01-7c4c56cf76-hn7lr from storage started at 2024-05-05 16:00:29 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.990: INFO: 	Container ceph-mgr ready: true, restart count 0
  May  5 16:55:36.990: INFO: ceph-osd-worker01-75d7885b87-5cqv9 from storage started at 2024-05-05 16:00:29 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.990: INFO: 	Container ceph-osd ready: true, restart count 0
  May  5 16:55:36.990: INFO: ceph-rgw-worker01-5bd8c8bf8b-k4vwv from storage started at 2024-05-05 16:00:29 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.990: INFO: 	Container ceph-rgw ready: true, restart count 0
  May  5 16:55:36.990: INFO: ceph-setup-wh6dw from storage started at 2024-05-05 16:00:28 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.990: INFO: 	Container ceph ready: false, restart count 0
  May  5 16:55:36.990: INFO: snapshot-controller-587656f7cd-7n6bj from storage started at 2024-05-05 16:46:09 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.990: INFO: 	Container snapshot-controller ready: true, restart count 0
  May  5 16:55:36.990: INFO: snapshot-controller-587656f7cd-wf594 from storage started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.990: INFO: 	Container snapshot-controller ready: true, restart count 0
  May  5 16:55:36.990: INFO: snapshot-validation-webhook-64b8d8cb7b-n7m99 from storage started at 2024-05-05 16:46:09 +0000 UTC (1 container statuses recorded)
  May  5 16:55:36.990: INFO: 	Container snapshot-validation-webhook ready: true, restart count 0
  STEP: verifying the node has the label node worker00 @ 05/05/24 16:55:37.021
  STEP: verifying the node has the label node worker01 @ 05/05/24 16:55:37.041
  May  5 16:55:37.063: INFO: Pod coredns-5b87cbd9d7-7qqjb requesting resource cpu=100m on Node worker01
  May  5 16:55:37.063: INFO: Pod coredns-5b87cbd9d7-sbzwr requesting resource cpu=100m on Node worker01
  May  5 16:55:37.063: INFO: Pod etcd-worker00 requesting resource cpu=0m on Node worker00
  May  5 16:55:37.063: INFO: Pod gobetween-worker00 requesting resource cpu=100m on Node worker00
  May  5 16:55:37.063: INFO: Pod gobetween-worker01 requesting resource cpu=100m on Node worker01
  May  5 16:55:37.063: INFO: Pod kube-apiserver-worker00 requesting resource cpu=250m on Node worker00
  May  5 16:55:37.063: INFO: Pod kube-controller-manager-worker00 requesting resource cpu=200m on Node worker00
  May  5 16:55:37.063: INFO: Pod kube-proxy-worker00 requesting resource cpu=200m on Node worker00
  May  5 16:55:37.063: INFO: Pod kube-proxy-worker01 requesting resource cpu=200m on Node worker01
  May  5 16:55:37.063: INFO: Pod kube-scheduler-worker00 requesting resource cpu=100m on Node worker00
  May  5 16:55:37.063: INFO: Pod kubernetes-dashboard-api-86d45cdc48-tqjcd requesting resource cpu=100m on Node worker01
  May  5 16:55:37.063: INFO: Pod kubernetes-dashboard-auth-5d859bc497-tv49r requesting resource cpu=100m on Node worker01
  May  5 16:55:37.063: INFO: Pod kubernetes-dashboard-kong-766ffb8f6-bhcg5 requesting resource cpu=0m on Node worker01
  May  5 16:55:37.063: INFO: Pod kubernetes-dashboard-metrics-scraper-56c9f5cc54-j5nbq requesting resource cpu=100m on Node worker01
  May  5 16:55:37.063: INFO: Pod kubernetes-dashboard-web-74dcc49f5-5zxqx requesting resource cpu=100m on Node worker01
  May  5 16:55:37.063: INFO: Pod calico-kube-controllers-758c99c4b5-bblrs requesting resource cpu=0m on Node worker01
  May  5 16:55:37.063: INFO: Pod calico-node-7g4c9 requesting resource cpu=250m on Node worker01
  May  5 16:55:37.063: INFO: Pod calico-node-qbc8c requesting resource cpu=250m on Node worker00
  May  5 16:55:37.063: INFO: Pod calico-typha-5cfbc84557-5zvkz requesting resource cpu=0m on Node worker01
  May  5 16:55:37.063: INFO: Pod metallb-controller-67f4cfb984-rk9hg requesting resource cpu=100m on Node worker01
  May  5 16:55:37.063: INFO: Pod metallb-speaker-22x22 requesting resource cpu=100m on Node worker01
  May  5 16:55:37.063: INFO: Pod metallb-speaker-bb4zq requesting resource cpu=100m on Node worker00
  May  5 16:55:37.063: INFO: Pod sonobuoy requesting resource cpu=0m on Node worker00
  May  5 16:55:37.063: INFO: Pod sonobuoy-e2e-job-919a92fc1d484e90 requesting resource cpu=0m on Node worker00
  May  5 16:55:37.063: INFO: Pod sonobuoy-systemd-logs-daemon-set-75c9f5cbb2184229-8sxzt requesting resource cpu=0m on Node worker00
  May  5 16:55:37.063: INFO: Pod sonobuoy-systemd-logs-daemon-set-75c9f5cbb2184229-mw8sz requesting resource cpu=0m on Node worker01
  May  5 16:55:37.063: INFO: Pod ceph-csi-cephfs-nodeplugin-kht47 requesting resource cpu=0m on Node worker00
  May  5 16:55:37.063: INFO: Pod ceph-csi-cephfs-nodeplugin-xsgjl requesting resource cpu=0m on Node worker01
  May  5 16:55:37.063: INFO: Pod ceph-csi-cephfs-provisioner-6dc49995f7-lqt4k requesting resource cpu=0m on Node worker01
  May  5 16:55:37.063: INFO: Pod ceph-csi-cephfs-provisioner-6dc49995f7-svr4r requesting resource cpu=0m on Node worker01
  May  5 16:55:37.063: INFO: Pod ceph-csi-cephfs-provisioner-6dc49995f7-tfb66 requesting resource cpu=0m on Node worker01
  May  5 16:55:37.063: INFO: Pod ceph-csi-rbd-nodeplugin-cmg7z requesting resource cpu=0m on Node worker01
  May  5 16:55:37.063: INFO: Pod ceph-csi-rbd-nodeplugin-sjzlp requesting resource cpu=0m on Node worker00
  May  5 16:55:37.063: INFO: Pod ceph-csi-rbd-provisioner-55f5bd6544-8f77n requesting resource cpu=0m on Node worker01
  May  5 16:55:37.063: INFO: Pod ceph-csi-rbd-provisioner-55f5bd6544-bgrv6 requesting resource cpu=0m on Node worker01
  May  5 16:55:37.063: INFO: Pod ceph-csi-rbd-provisioner-55f5bd6544-v9llp requesting resource cpu=0m on Node worker01
  May  5 16:55:37.063: INFO: Pod ceph-mds-worker01-798b64d68-wr2nm requesting resource cpu=0m on Node worker01
  May  5 16:55:37.064: INFO: Pod ceph-mgr-worker01-7c4c56cf76-hn7lr requesting resource cpu=0m on Node worker01
  May  5 16:55:37.064: INFO: Pod ceph-mon-worker00-797bf6469d-wb64d requesting resource cpu=0m on Node worker00
  May  5 16:55:37.064: INFO: Pod ceph-osd-worker01-75d7885b87-5cqv9 requesting resource cpu=0m on Node worker01
  May  5 16:55:37.064: INFO: Pod ceph-rgw-worker01-5bd8c8bf8b-k4vwv requesting resource cpu=0m on Node worker01
  May  5 16:55:37.064: INFO: Pod snapshot-controller-587656f7cd-7n6bj requesting resource cpu=0m on Node worker01
  May  5 16:55:37.064: INFO: Pod snapshot-controller-587656f7cd-wf594 requesting resource cpu=0m on Node worker01
  May  5 16:55:37.064: INFO: Pod snapshot-validation-webhook-64b8d8cb7b-n7m99 requesting resource cpu=0m on Node worker01
  STEP: Starting Pods to consume most of the cluster CPU. @ 05/05/24 16:55:37.064
  May  5 16:55:37.064: INFO: Creating a pod which consumes cpu=1960m on Node worker00
  May  5 16:55:37.078: INFO: Creating a pod which consumes cpu=1855m on Node worker01
  E0505 16:55:37.815841      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:38.816084      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 05/05/24 16:55:39.113
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-3bef6da3-eaf0-448f-b942-538b8f7b91b8.17cca60dfacf61c8], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7258/filler-pod-3bef6da3-eaf0-448f-b942-538b8f7b91b8 to worker00] @ 05/05/24 16:55:39.115
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-3bef6da3-eaf0-448f-b942-538b8f7b91b8.17cca60e22fc364a], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 05/05/24 16:55:39.115
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-3bef6da3-eaf0-448f-b942-538b8f7b91b8.17cca60e2473a6c2], Reason = [Created], Message = [Created container filler-pod-3bef6da3-eaf0-448f-b942-538b8f7b91b8] @ 05/05/24 16:55:39.115
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-3bef6da3-eaf0-448f-b942-538b8f7b91b8.17cca60e2a762c8a], Reason = [Started], Message = [Started container filler-pod-3bef6da3-eaf0-448f-b942-538b8f7b91b8] @ 05/05/24 16:55:39.115
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-9dd860d0-8800-413e-8777-6a7315946372.17cca60dfbe52e2a], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7258/filler-pod-9dd860d0-8800-413e-8777-6a7315946372 to worker01] @ 05/05/24 16:55:39.115
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-9dd860d0-8800-413e-8777-6a7315946372.17cca60e4768f824], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 05/05/24 16:55:39.115
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-9dd860d0-8800-413e-8777-6a7315946372.17cca60e4947fd59], Reason = [Created], Message = [Created container filler-pod-9dd860d0-8800-413e-8777-6a7315946372] @ 05/05/24 16:55:39.115
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-9dd860d0-8800-413e-8777-6a7315946372.17cca60e4f1ab935], Reason = [Started], Message = [Started container filler-pod-9dd860d0-8800-413e-8777-6a7315946372] @ 05/05/24 16:55:39.115
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.17cca60e739e5143], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu. preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod.] @ 05/05/24 16:55:39.125
  E0505 16:55:39.816535      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label node off the node worker00 @ 05/05/24 16:55:40.126
  STEP: verifying the node doesn't have the label node @ 05/05/24 16:55:40.158
  STEP: removing the label node off the node worker01 @ 05/05/24 16:55:40.164
  STEP: verifying the node doesn't have the label node @ 05/05/24 16:55:40.188
  May  5 16:55:40.199: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-7258" for this suite. @ 05/05/24 16:55:40.21
• [3.279 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1455
  STEP: Creating a kubernetes client @ 05/05/24 16:55:40.227
  May  5 16:55:40.227: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename services @ 05/05/24 16:55:40.229
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:55:40.255
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:55:40.263
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-7542 @ 05/05/24 16:55:40.272
  STEP: changing the ExternalName service to type=NodePort @ 05/05/24 16:55:40.286
  STEP: creating replication controller externalname-service in namespace services-7542 @ 05/05/24 16:55:40.317
  I0505 16:55:40.338601      22 runners.go:197] Created replication controller with name: externalname-service, namespace: services-7542, replica count: 2
  E0505 16:55:40.817443      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:41.823214      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:42.823444      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0505 16:55:43.390574      22 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May  5 16:55:43.390: INFO: Creating new exec pod
  E0505 16:55:43.823743      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:44.824134      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:45.824846      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:55:46.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-7542 exec execpodp6cft -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  May  5 16:55:46.767: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  May  5 16:55:46.767: INFO: stdout: "externalname-service-t656f"
  May  5 16:55:46.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-7542 exec execpodp6cft -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.199 80'
  E0505 16:55:46.825135      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:55:46.953: INFO: stderr: "+ nc -v -t -w 2 10.32.0.199 80\n+ echo hostName\nConnection to 10.32.0.199 80 port [tcp/http] succeeded!\n"
  May  5 16:55:46.953: INFO: stdout: ""
  May  5 16:55:47.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-7542 exec execpodp6cft -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.199 80'
  E0505 16:55:47.826479      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:55:47.928: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.32.0.199 80\nConnection to 10.32.0.199 80 port [tcp/http] succeeded!\n"
  May  5 16:55:47.928: INFO: stdout: "externalname-service-x44tt"
  May  5 16:55:47.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-7542 exec execpodp6cft -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.58.100 31441'
  May  5 16:55:48.057: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.58.100 31441\nConnection to 192.168.58.100 31441 port [tcp/*] succeeded!\n"
  May  5 16:55:48.057: INFO: stdout: "externalname-service-t656f"
  May  5 16:55:48.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-7542 exec execpodp6cft -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.58.101 31441'
  May  5 16:55:48.161: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.58.101 31441\nConnection to 192.168.58.101 31441 port [tcp/*] succeeded!\n"
  May  5 16:55:48.161: INFO: stdout: "externalname-service-x44tt"
  May  5 16:55:48.161: INFO: Cleaning up the ExternalName to NodePort test service
  May  5 16:55:48.184: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7542" for this suite. @ 05/05/24 16:55:48.187
• [7.965 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:146
  STEP: Creating a kubernetes client @ 05/05/24 16:55:48.191
  May  5 16:55:48.191: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/05/24 16:55:48.193
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:55:48.211
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:55:48.216
  May  5 16:55:48.219: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 16:55:48.766: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-4893" for this suite. @ 05/05/24 16:55:48.774
• [0.593 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 05/05/24 16:55:48.787
  May  5 16:55:48.787: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubectl-logs @ 05/05/24 16:55:48.791
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:55:48.814
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:55:48.821
  E0505 16:55:48.826587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating an pod @ 05/05/24 16:55:48.83
  May  5 16:55:48.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-logs-5327 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.47 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  May  5 16:55:48.977: INFO: stderr: ""
  May  5 16:55:48.978: INFO: stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 05/05/24 16:55:48.978
  May  5 16:55:48.978: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E0505 16:55:49.827233      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:50.828040      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:55:50.986: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 05/05/24 16:55:50.986
  May  5 16:55:50.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-logs-5327 logs logs-generator logs-generator'
  May  5 16:55:51.045: INFO: stderr: ""
  May  5 16:55:51.045: INFO: stdout: "I0505 16:55:49.619002       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/7cn 554\nI0505 16:55:49.819628       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/9pwb 497\nI0505 16:55:50.019049       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/7lzp 599\nI0505 16:55:50.220096       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/bgl9 392\nI0505 16:55:50.419351       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/fd6m 316\nI0505 16:55:50.619857       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/zp4 441\nI0505 16:55:50.819870       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/fcl 216\nI0505 16:55:51.019317       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/nqp 458\n"
  STEP: limiting log lines @ 05/05/24 16:55:51.045
  May  5 16:55:51.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-logs-5327 logs logs-generator logs-generator --tail=1'
  May  5 16:55:51.088: INFO: stderr: ""
  May  5 16:55:51.089: INFO: stdout: "I0505 16:55:51.019317       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/nqp 458\n"
  May  5 16:55:51.089: INFO: got output "I0505 16:55:51.019317       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/nqp 458\n"
  STEP: limiting log bytes @ 05/05/24 16:55:51.089
  May  5 16:55:51.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-logs-5327 logs logs-generator logs-generator --limit-bytes=1'
  May  5 16:55:51.131: INFO: stderr: ""
  May  5 16:55:51.131: INFO: stdout: "I"
  May  5 16:55:51.131: INFO: got output "I"
  STEP: exposing timestamps @ 05/05/24 16:55:51.131
  May  5 16:55:51.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-logs-5327 logs logs-generator logs-generator --tail=1 --timestamps'
  May  5 16:55:51.177: INFO: stderr: ""
  May  5 16:55:51.177: INFO: stdout: "2024-05-05T16:55:51.020420556Z I0505 16:55:51.019317       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/nqp 458\n"
  May  5 16:55:51.177: INFO: got output "2024-05-05T16:55:51.020420556Z I0505 16:55:51.019317       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/nqp 458\n"
  STEP: restricting to a time range @ 05/05/24 16:55:51.177
  E0505 16:55:51.828366      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:52.828692      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:55:53.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-logs-5327 logs logs-generator logs-generator --since=1s'
  May  5 16:55:53.756: INFO: stderr: ""
  May  5 16:55:53.756: INFO: stdout: "I0505 16:55:52.819682       1 logs_generator.go:76] 16 POST /api/v1/namespaces/kube-system/pods/zcnj 373\nI0505 16:55:53.019531       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/xxvq 391\nI0505 16:55:53.219382       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/cgd 508\nI0505 16:55:53.419790       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/b7c7 417\nI0505 16:55:53.619174       1 logs_generator.go:76] 20 POST /api/v1/namespaces/default/pods/8x2s 597\n"
  May  5 16:55:53.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-logs-5327 logs logs-generator logs-generator --since=24h'
  E0505 16:55:53.829411      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:55:53.906: INFO: stderr: ""
  May  5 16:55:53.906: INFO: stdout: "I0505 16:55:49.619002       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/7cn 554\nI0505 16:55:49.819628       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/9pwb 497\nI0505 16:55:50.019049       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/7lzp 599\nI0505 16:55:50.220096       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/bgl9 392\nI0505 16:55:50.419351       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/fd6m 316\nI0505 16:55:50.619857       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/zp4 441\nI0505 16:55:50.819870       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/fcl 216\nI0505 16:55:51.019317       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/nqp 458\nI0505 16:55:51.219979       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/cfz 400\nI0505 16:55:51.419465       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/ns/pods/w47 573\nI0505 16:55:51.620199       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/ndm 407\nI0505 16:55:51.821940       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/dsq 443\nI0505 16:55:52.019606       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/default/pods/tlnw 412\nI0505 16:55:52.219679       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/jrgq 370\nI0505 16:55:52.419447       1 logs_generator.go:76] 14 POST /api/v1/namespaces/default/pods/444 536\nI0505 16:55:52.620031       1 logs_generator.go:76] 15 POST /api/v1/namespaces/kube-system/pods/dpkk 511\nI0505 16:55:52.819682       1 logs_generator.go:76] 16 POST /api/v1/namespaces/kube-system/pods/zcnj 373\nI0505 16:55:53.019531       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/xxvq 391\nI0505 16:55:53.219382       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/cgd 508\nI0505 16:55:53.419790       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/b7c7 417\nI0505 16:55:53.619174       1 logs_generator.go:76] 20 POST /api/v1/namespaces/default/pods/8x2s 597\nI0505 16:55:53.819856       1 logs_generator.go:76] 21 POST /api/v1/namespaces/default/pods/db5 226\n"
  May  5 16:55:53.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-logs-5327 delete pod logs-generator'
  May  5 16:55:54.516: INFO: stderr: ""
  May  5 16:55:54.516: INFO: stdout: "pod \"logs-generator\" deleted\n"
  May  5 16:55:54.516: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-5327" for this suite. @ 05/05/24 16:55:54.522
• [5.740 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:168
  STEP: Creating a kubernetes client @ 05/05/24 16:55:54.527
  May  5 16:55:54.527: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename container-probe @ 05/05/24 16:55:54.528
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:55:54.543
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:55:54.547
  STEP: Creating pod liveness-4da68e2e-58ac-4259-af54-5a86ceaa4702 in namespace container-probe-8872 @ 05/05/24 16:55:54.55
  E0505 16:55:54.829654      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:55.829984      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/05/24 16:55:56.574
  May  5 16:55:56.580: INFO: Initial restart count of pod liveness-4da68e2e-58ac-4259-af54-5a86ceaa4702 is 0
  May  5 16:55:56.586: INFO: Get pod liveness-4da68e2e-58ac-4259-af54-5a86ceaa4702 in namespace container-probe-8872
  E0505 16:55:56.831405      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:57.831882      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:55:58.592: INFO: Get pod liveness-4da68e2e-58ac-4259-af54-5a86ceaa4702 in namespace container-probe-8872
  E0505 16:55:58.832067      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:55:59.832380      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:56:00.597: INFO: Get pod liveness-4da68e2e-58ac-4259-af54-5a86ceaa4702 in namespace container-probe-8872
  E0505 16:56:00.833991      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:01.835578      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:56:02.602: INFO: Get pod liveness-4da68e2e-58ac-4259-af54-5a86ceaa4702 in namespace container-probe-8872
  E0505 16:56:02.835827      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:03.837456      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:56:04.609: INFO: Get pod liveness-4da68e2e-58ac-4259-af54-5a86ceaa4702 in namespace container-probe-8872
  E0505 16:56:04.838090      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:05.838459      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:56:06.613: INFO: Get pod liveness-4da68e2e-58ac-4259-af54-5a86ceaa4702 in namespace container-probe-8872
  E0505 16:56:06.839325      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:07.839486      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:56:08.616: INFO: Get pod liveness-4da68e2e-58ac-4259-af54-5a86ceaa4702 in namespace container-probe-8872
  E0505 16:56:08.841242      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:09.841863      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:56:10.620: INFO: Get pod liveness-4da68e2e-58ac-4259-af54-5a86ceaa4702 in namespace container-probe-8872
  E0505 16:56:10.842286      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:11.842832      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:56:12.624: INFO: Get pod liveness-4da68e2e-58ac-4259-af54-5a86ceaa4702 in namespace container-probe-8872
  E0505 16:56:12.843738      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:13.844439      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:56:14.631: INFO: Get pod liveness-4da68e2e-58ac-4259-af54-5a86ceaa4702 in namespace container-probe-8872
  E0505 16:56:14.845587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:15.846755      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:56:16.636: INFO: Get pod liveness-4da68e2e-58ac-4259-af54-5a86ceaa4702 in namespace container-probe-8872
  May  5 16:56:16.636: INFO: Restart count of pod container-probe-8872/liveness-4da68e2e-58ac-4259-af54-5a86ceaa4702 is now 1 (20.056071134s elapsed)
  STEP: deleting the pod @ 05/05/24 16:56:16.637
  May  5 16:56:16.662: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8872" for this suite. @ 05/05/24 16:56:16.668
• [22.146 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 05/05/24 16:56:16.674
  May  5 16:56:16.674: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename secrets @ 05/05/24 16:56:16.675
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:56:16.684
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:56:16.686
  STEP: Creating secret with name secret-test-3d717d31-1a39-4137-b936-c8dd259943fe @ 05/05/24 16:56:16.688
  STEP: Creating a pod to test consume secrets @ 05/05/24 16:56:16.691
  E0505 16:56:16.846810      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:17.847274      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:18.847475      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:19.847937      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:56:20.709
  May  5 16:56:20.714: INFO: Trying to get logs from node worker00 pod pod-secrets-0d1a716e-0117-43ed-b3b3-cc58f291cd63 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/05/24 16:56:20.72
  May  5 16:56:20.733: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3001" for this suite. @ 05/05/24 16:56:20.734
• [4.063 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:132
  STEP: Creating a kubernetes client @ 05/05/24 16:56:20.737
  May  5 16:56:20.737: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 16:56:20.738
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:56:20.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:56:20.746
  STEP: Creating the pod @ 05/05/24 16:56:20.748
  E0505 16:56:20.849100      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:21.850949      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:22.853540      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:56:23.293: INFO: Successfully updated pod "labelsupdate718242dd-a5d6-4a8d-81f1-c3d7cdec97b6"
  E0505 16:56:23.853903      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:24.854382      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:25.855663      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:26.855964      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:56:27.313: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9517" for this suite. @ 05/05/24 16:56:27.326
• [6.592 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 05/05/24 16:56:27.33
  May  5 16:56:27.330: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename sysctl @ 05/05/24 16:56:27.332
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:56:27.339
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:56:27.341
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 05/05/24 16:56:27.342
  STEP: Watching for error events or started pod @ 05/05/24 16:56:27.346
  E0505 16:56:27.856384      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:28.857151      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 05/05/24 16:56:29.352
  E0505 16:56:29.857500      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:30.858391      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 05/05/24 16:56:31.359
  STEP: Getting logs from the pod @ 05/05/24 16:56:31.359
  STEP: Checking that the sysctl is actually updated @ 05/05/24 16:56:31.361
  May  5 16:56:31.362: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-8212" for this suite. @ 05/05/24 16:56:31.363
• [4.037 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 05/05/24 16:56:31.367
  May  5 16:56:31.367: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename endpointslicemirroring @ 05/05/24 16:56:31.369
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:56:31.378
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:56:31.38
  STEP: mirroring a new custom Endpoint @ 05/05/24 16:56:31.386
  May  5 16:56:31.393: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
  E0505 16:56:31.863618      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:32.865642      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 05/05/24 16:56:33.398
  STEP: mirroring deletion of a custom Endpoint @ 05/05/24 16:56:33.417
  May  5 16:56:33.423: INFO: Waiting for 0 EndpointSlices to exist, got 1
  E0505 16:56:33.866772      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:34.867868      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:56:35.434: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-6010" for this suite. @ 05/05/24 16:56:35.436
• [4.071 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/storageclass.go:53
  STEP: Creating a kubernetes client @ 05/05/24 16:56:35.44
  May  5 16:56:35.440: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename csi-storageclass @ 05/05/24 16:56:35.441
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:56:35.45
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:56:35.453
  STEP: Creating a StorageClass @ 05/05/24 16:56:35.455
  STEP: Get StorageClass "e2e-9fbzh" @ 05/05/24 16:56:35.459
  STEP: Patching the StorageClass "e2e-9fbzh" @ 05/05/24 16:56:35.461
  STEP: Delete StorageClass "e2e-9fbzh" @ 05/05/24 16:56:35.464
  STEP: Confirm deletion of StorageClass "e2e-9fbzh" @ 05/05/24 16:56:35.466
  STEP: Create a replacement StorageClass @ 05/05/24 16:56:35.468
  STEP: Updating StorageClass "e2e-v2-f6wtz" @ 05/05/24 16:56:35.47
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-f6wtz=updated" @ 05/05/24 16:56:35.473
  STEP: Deleting StorageClass "e2e-v2-f6wtz" via DeleteCollection @ 05/05/24 16:56:35.474
  STEP: Confirm deletion of StorageClass "e2e-v2-f6wtz" @ 05/05/24 16:56:35.477
  May  5 16:56:35.478: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-storageclass-6808" for this suite. @ 05/05/24 16:56:35.479
• [0.042 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 05/05/24 16:56:35.482
  May  5 16:56:35.482: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename secrets @ 05/05/24 16:56:35.483
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:56:35.489
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:56:35.491
  STEP: Creating secret with name secret-test-38bb44de-4241-4327-b62f-d42b286d1dc7 @ 05/05/24 16:56:35.493
  STEP: Creating a pod to test consume secrets @ 05/05/24 16:56:35.496
  E0505 16:56:35.868016      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:36.868760      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:37.868689      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:38.869477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:56:39.505
  May  5 16:56:39.507: INFO: Trying to get logs from node worker00 pod pod-secrets-43a1a4ac-1c45-4259-9603-a73633e6e91a container secret-volume-test: <nil>
  STEP: delete the pod @ 05/05/24 16:56:39.511
  May  5 16:56:39.520: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-237" for this suite. @ 05/05/24 16:56:39.522
• [4.043 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should provide secure master service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:775
  STEP: Creating a kubernetes client @ 05/05/24 16:56:39.526
  May  5 16:56:39.526: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename services @ 05/05/24 16:56:39.527
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:56:39.536
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:56:39.54
  May  5 16:56:39.543: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8172" for this suite. @ 05/05/24 16:56:39.545
• [0.023 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:221
  STEP: Creating a kubernetes client @ 05/05/24 16:56:39.55
  May  5 16:56:39.550: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename webhook @ 05/05/24 16:56:39.551
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:56:39.562
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:56:39.564
  STEP: Setting up server cert @ 05/05/24 16:56:39.58
  E0505 16:56:39.869762      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/05/24 16:56:39.951
  STEP: Deploying the webhook pod @ 05/05/24 16:56:39.966
  STEP: Wait for the deployment to be ready @ 05/05/24 16:56:39.974
  May  5 16:56:39.977: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0505 16:56:40.871547      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:41.872776      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/05/24 16:56:41.983
  STEP: Verifying the service has paired with the endpoint @ 05/05/24 16:56:41.996
  E0505 16:56:42.873242      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:56:42.997: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  May  5 16:56:43.006: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 05/05/24 16:56:43.526
  STEP: Creating a custom resource that should be denied by the webhook @ 05/05/24 16:56:43.551
  E0505 16:56:43.874008      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:44.874933      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 05/05/24 16:56:45.569
  STEP: Updating the custom resource with disallowed data should be denied @ 05/05/24 16:56:45.576
  STEP: Deleting the custom resource should be denied @ 05/05/24 16:56:45.58
  STEP: Remove the offending key and value from the custom resource data @ 05/05/24 16:56:45.582
  STEP: Deleting the updated custom resource should be successful @ 05/05/24 16:56:45.587
  E0505 16:56:45.875621      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:56:46.145: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5748" for this suite. @ 05/05/24 16:56:46.149
  STEP: Destroying namespace "webhook-markers-2637" for this suite. @ 05/05/24 16:56:46.166
• [6.621 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:875
  STEP: Creating a kubernetes client @ 05/05/24 16:56:46.172
  May  5 16:56:46.172: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename daemonsets @ 05/05/24 16:56:46.173
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:56:46.187
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:56:46.191
  STEP: Creating simple DaemonSet "daemon-set" @ 05/05/24 16:56:46.205
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/05/24 16:56:46.208
  May  5 16:56:46.213: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 16:56:46.213: INFO: Node worker00 is running 0 daemon pod, expected 1
  E0505 16:56:46.875976      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:56:47.213: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 16:56:47.213: INFO: Node worker00 is running 0 daemon pod, expected 1
  E0505 16:56:47.876675      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:56:48.217: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May  5 16:56:48.217: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Getting /status @ 05/05/24 16:56:48.224
  May  5 16:56:48.229: INFO: Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 05/05/24 16:56:48.229
  May  5 16:56:48.245: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 05/05/24 16:56:48.245
  May  5 16:56:48.247: INFO: Observed &DaemonSet event: ADDED
  May  5 16:56:48.248: INFO: Observed &DaemonSet event: MODIFIED
  May  5 16:56:48.248: INFO: Observed &DaemonSet event: MODIFIED
  May  5 16:56:48.249: INFO: Observed &DaemonSet event: MODIFIED
  May  5 16:56:48.249: INFO: Found daemon set daemon-set in namespace daemonsets-5037 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  May  5 16:56:48.249: INFO: Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 05/05/24 16:56:48.249
  STEP: watching for the daemon set status to be patched @ 05/05/24 16:56:48.255
  May  5 16:56:48.256: INFO: Observed &DaemonSet event: ADDED
  May  5 16:56:48.256: INFO: Observed &DaemonSet event: MODIFIED
  May  5 16:56:48.256: INFO: Observed &DaemonSet event: MODIFIED
  May  5 16:56:48.257: INFO: Observed &DaemonSet event: MODIFIED
  May  5 16:56:48.257: INFO: Observed daemon set daemon-set in namespace daemonsets-5037 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  May  5 16:56:48.257: INFO: Observed &DaemonSet event: MODIFIED
  May  5 16:56:48.257: INFO: Found daemon set daemon-set in namespace daemonsets-5037 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  May  5 16:56:48.257: INFO: Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 05/05/24 16:56:48.259
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5037, will wait for the garbage collector to delete the pods @ 05/05/24 16:56:48.259
  May  5 16:56:48.315: INFO: Deleting DaemonSet.extensions daemon-set took: 2.72348ms
  May  5 16:56:48.415: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.258479ms
  E0505 16:56:48.879389      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:49.879692      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:56:50.818: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 16:56:50.818: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  May  5 16:56:50.821: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"26013"},"items":null}

  May  5 16:56:50.826: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"26013"},"items":null}

  May  5 16:56:50.833: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-5037" for this suite. @ 05/05/24 16:56:50.834
• [4.665 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:400
  STEP: Creating a kubernetes client @ 05/05/24 16:56:50.837
  May  5 16:56:50.837: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename namespaces @ 05/05/24 16:56:50.838
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:56:50.847
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:56:50.849
  STEP: Creating namespace "e2e-ns-xtzg4" @ 05/05/24 16:56:50.851
  May  5 16:56:50.861: INFO: Namespace "e2e-ns-xtzg4-2360" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-xtzg4-2360" @ 05/05/24 16:56:50.861
  May  5 16:56:50.864: INFO: Namespace "e2e-ns-xtzg4-2360" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-xtzg4-2360" @ 05/05/24 16:56:50.864
  May  5 16:56:50.868: INFO: Namespace "e2e-ns-xtzg4-2360" has []v1.FinalizerName{"kubernetes"}
  May  5 16:56:50.868: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1997" for this suite. @ 05/05/24 16:56:50.873
  STEP: Destroying namespace "e2e-ns-xtzg4-2360" for this suite. @ 05/05/24 16:56:50.878
  E0505 16:56:50.880697      22 retrywatcher.go:129] "Watch failed" err="context canceled"
• [0.045 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:136
  STEP: Creating a kubernetes client @ 05/05/24 16:56:50.883
  May  5 16:56:50.883: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/05/24 16:56:50.883
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:56:50.893
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:56:50.896
  STEP: create the container to handle the HTTPGet hook request. @ 05/05/24 16:56:50.9
  E0505 16:56:51.881796      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:52.882162      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/05/24 16:56:52.919
  E0505 16:56:53.882488      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:54.882564      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 05/05/24 16:56:54.944
  STEP: delete the pod with lifecycle hook @ 05/05/24 16:56:54.956
  E0505 16:56:55.883410      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:56.884059      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:56:56.973: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-105" for this suite. @ 05/05/24 16:56:56.974
• [6.095 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:469
  STEP: Creating a kubernetes client @ 05/05/24 16:56:56.977
  May  5 16:56:56.977: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename sched-pred @ 05/05/24 16:56:56.978
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:56:56.985
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:56:56.987
  May  5 16:56:56.989: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  May  5 16:56:56.993: INFO: Waiting for terminating namespaces to be deleted...
  May  5 16:56:56.996: INFO: 
  Logging pods the apiserver thinks is on node worker00 before test
  May  5 16:56:57.003: INFO: etcd-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.004: INFO: 	Container etcd ready: true, restart count 0
  May  5 16:56:57.004: INFO: gobetween-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.004: INFO: 	Container gobetween ready: true, restart count 0
  May  5 16:56:57.004: INFO: kube-apiserver-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.004: INFO: 	Container kube-apiserver ready: true, restart count 0
  May  5 16:56:57.004: INFO: kube-controller-manager-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.004: INFO: 	Container kube-controller-manager ready: true, restart count 0
  May  5 16:56:57.004: INFO: kube-proxy-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.004: INFO: 	Container kube-proxy ready: true, restart count 0
  May  5 16:56:57.004: INFO: kube-scheduler-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.004: INFO: 	Container kube-scheduler ready: true, restart count 0
  May  5 16:56:57.004: INFO: calico-node-qbc8c from networking started at 2024-05-05 16:00:27 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.004: INFO: 	Container calico-node ready: true, restart count 0
  May  5 16:56:57.004: INFO: metallb-speaker-bb4zq from networking started at 2024-05-05 16:46:32 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.004: INFO: 	Container speaker ready: true, restart count 0
  May  5 16:56:57.004: INFO: sonobuoy from sonobuoy started at 2024-05-05 16:06:18 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.004: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  May  5 16:56:57.004: INFO: sonobuoy-e2e-job-919a92fc1d484e90 from sonobuoy started at 2024-05-05 16:06:24 +0000 UTC (2 container statuses recorded)
  May  5 16:56:57.004: INFO: 	Container e2e ready: true, restart count 0
  May  5 16:56:57.004: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May  5 16:56:57.004: INFO: sonobuoy-systemd-logs-daemon-set-75c9f5cbb2184229-8sxzt from sonobuoy started at 2024-05-05 16:06:24 +0000 UTC (2 container statuses recorded)
  May  5 16:56:57.004: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May  5 16:56:57.004: INFO: 	Container systemd-logs ready: true, restart count 0
  May  5 16:56:57.004: INFO: ceph-csi-cephfs-nodeplugin-kht47 from storage started at 2024-05-05 16:46:33 +0000 UTC (3 container statuses recorded)
  May  5 16:56:57.004: INFO: 	Container csi-cephfsplugin ready: true, restart count 0
  May  5 16:56:57.004: INFO: 	Container driver-registrar ready: true, restart count 0
  May  5 16:56:57.004: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:56:57.004: INFO: ceph-csi-rbd-nodeplugin-sjzlp from storage started at 2024-05-05 16:46:33 +0000 UTC (3 container statuses recorded)
  May  5 16:56:57.004: INFO: 	Container csi-rbdplugin ready: true, restart count 0
  May  5 16:56:57.004: INFO: 	Container driver-registrar ready: true, restart count 0
  May  5 16:56:57.004: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:56:57.004: INFO: ceph-mon-worker00-797bf6469d-wb64d from storage started at 2024-05-05 16:46:32 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.004: INFO: 	Container ceph-mon ready: true, restart count 0
  May  5 16:56:57.004: INFO: 
  Logging pods the apiserver thinks is on node worker01 before test
  May  5 16:56:57.016: INFO: pod-handle-http-request from container-lifecycle-hook-105 started at 2024-05-05 16:56:51 +0000 UTC (2 container statuses recorded)
  May  5 16:56:57.016: INFO: 	Container container-handle-http-request ready: true, restart count 0
  May  5 16:56:57.016: INFO: 	Container container-handle-https-request ready: true, restart count 0
  May  5 16:56:57.016: INFO: coredns-5b87cbd9d7-7qqjb from kube-system started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.016: INFO: 	Container coredns ready: true, restart count 0
  May  5 16:56:57.016: INFO: coredns-5b87cbd9d7-sbzwr from kube-system started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.016: INFO: 	Container coredns ready: true, restart count 0
  May  5 16:56:57.016: INFO: gobetween-worker01 from kube-system started at 2024-05-05 15:59:42 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.016: INFO: 	Container gobetween ready: true, restart count 0
  May  5 16:56:57.016: INFO: kube-proxy-worker01 from kube-system started at 2024-05-05 15:59:42 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.016: INFO: 	Container kube-proxy ready: true, restart count 0
  May  5 16:56:57.016: INFO: kubernetes-dashboard-api-86d45cdc48-tqjcd from kube-system started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.016: INFO: 	Container kubernetes-dashboard-api ready: true, restart count 0
  May  5 16:56:57.016: INFO: kubernetes-dashboard-auth-5d859bc497-tv49r from kube-system started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.016: INFO: 	Container kubernetes-dashboard-auth ready: true, restart count 0
  May  5 16:56:57.016: INFO: kubernetes-dashboard-kong-766ffb8f6-bhcg5 from kube-system started at 2024-05-05 16:46:09 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.016: INFO: 	Container proxy ready: true, restart count 0
  May  5 16:56:57.016: INFO: kubernetes-dashboard-metrics-scraper-56c9f5cc54-j5nbq from kube-system started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.016: INFO: 	Container kubernetes-dashboard-metrics-scraper ready: true, restart count 0
  May  5 16:56:57.016: INFO: kubernetes-dashboard-web-74dcc49f5-5zxqx from kube-system started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.016: INFO: 	Container kubernetes-dashboard-web ready: true, restart count 0
  May  5 16:56:57.016: INFO: calico-kube-controllers-758c99c4b5-bblrs from networking started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.016: INFO: 	Container calico-kube-controllers ready: true, restart count 0
  May  5 16:56:57.017: INFO: calico-node-7g4c9 from networking started at 2024-05-05 16:00:29 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.017: INFO: 	Container calico-node ready: true, restart count 0
  May  5 16:56:57.017: INFO: calico-typha-5cfbc84557-5zvkz from networking started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.017: INFO: 	Container calico-typha ready: true, restart count 0
  May  5 16:56:57.017: INFO: metallb-controller-67f4cfb984-rk9hg from networking started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.017: INFO: 	Container controller ready: true, restart count 0
  May  5 16:56:57.017: INFO: metallb-speaker-22x22 from networking started at 2024-05-05 16:00:48 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.017: INFO: 	Container speaker ready: true, restart count 0
  May  5 16:56:57.017: INFO: sonobuoy-systemd-logs-daemon-set-75c9f5cbb2184229-mw8sz from sonobuoy started at 2024-05-05 16:06:25 +0000 UTC (2 container statuses recorded)
  May  5 16:56:57.017: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container systemd-logs ready: true, restart count 0
  May  5 16:56:57.017: INFO: ceph-csi-cephfs-nodeplugin-xsgjl from storage started at 2024-05-05 16:00:29 +0000 UTC (3 container statuses recorded)
  May  5 16:56:57.017: INFO: 	Container csi-cephfsplugin ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container driver-registrar ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:56:57.017: INFO: ceph-csi-cephfs-provisioner-6dc49995f7-lqt4k from storage started at 2024-05-05 16:00:29 +0000 UTC (5 container statuses recorded)
  May  5 16:56:57.017: INFO: 	Container csi-cephfsplugin ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:56:57.017: INFO: ceph-csi-cephfs-provisioner-6dc49995f7-svr4r from storage started at 2024-05-05 16:00:29 +0000 UTC (5 container statuses recorded)
  May  5 16:56:57.017: INFO: 	Container csi-cephfsplugin ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:56:57.017: INFO: ceph-csi-cephfs-provisioner-6dc49995f7-tfb66 from storage started at 2024-05-05 16:00:29 +0000 UTC (5 container statuses recorded)
  May  5 16:56:57.017: INFO: 	Container csi-cephfsplugin ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:56:57.017: INFO: ceph-csi-rbd-nodeplugin-cmg7z from storage started at 2024-05-05 16:00:29 +0000 UTC (3 container statuses recorded)
  May  5 16:56:57.017: INFO: 	Container csi-rbdplugin ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container driver-registrar ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:56:57.017: INFO: ceph-csi-rbd-provisioner-55f5bd6544-8f77n from storage started at 2024-05-05 16:00:29 +0000 UTC (7 container statuses recorded)
  May  5 16:56:57.017: INFO: 	Container csi-attacher ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container csi-rbdplugin ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container csi-rbdplugin-controller ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:56:57.017: INFO: ceph-csi-rbd-provisioner-55f5bd6544-bgrv6 from storage started at 2024-05-05 16:00:29 +0000 UTC (7 container statuses recorded)
  May  5 16:56:57.017: INFO: 	Container csi-attacher ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container csi-rbdplugin ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container csi-rbdplugin-controller ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 16:56:57.017: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:56:57.017: INFO: ceph-csi-rbd-provisioner-55f5bd6544-v9llp from storage started at 2024-05-05 16:00:29 +0000 UTC (7 container statuses recorded)
  May  5 16:56:57.018: INFO: 	Container csi-attacher ready: true, restart count 0
  May  5 16:56:57.018: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 16:56:57.018: INFO: 	Container csi-rbdplugin ready: true, restart count 0
  May  5 16:56:57.018: INFO: 	Container csi-rbdplugin-controller ready: true, restart count 0
  May  5 16:56:57.018: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 16:56:57.018: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 16:56:57.018: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 16:56:57.018: INFO: ceph-mds-worker01-798b64d68-wr2nm from storage started at 2024-05-05 16:00:29 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.018: INFO: 	Container ceph-mds ready: true, restart count 0
  May  5 16:56:57.018: INFO: ceph-mgr-worker01-7c4c56cf76-hn7lr from storage started at 2024-05-05 16:00:29 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.018: INFO: 	Container ceph-mgr ready: true, restart count 0
  May  5 16:56:57.018: INFO: ceph-osd-worker01-75d7885b87-5cqv9 from storage started at 2024-05-05 16:00:29 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.018: INFO: 	Container ceph-osd ready: true, restart count 0
  May  5 16:56:57.018: INFO: ceph-rgw-worker01-5bd8c8bf8b-k4vwv from storage started at 2024-05-05 16:00:29 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.018: INFO: 	Container ceph-rgw ready: true, restart count 0
  May  5 16:56:57.018: INFO: ceph-setup-wh6dw from storage started at 2024-05-05 16:00:28 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.018: INFO: 	Container ceph ready: false, restart count 0
  May  5 16:56:57.018: INFO: snapshot-controller-587656f7cd-7n6bj from storage started at 2024-05-05 16:46:09 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.018: INFO: 	Container snapshot-controller ready: true, restart count 0
  May  5 16:56:57.018: INFO: snapshot-controller-587656f7cd-wf594 from storage started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.018: INFO: 	Container snapshot-controller ready: true, restart count 0
  May  5 16:56:57.018: INFO: snapshot-validation-webhook-64b8d8cb7b-n7m99 from storage started at 2024-05-05 16:46:09 +0000 UTC (1 container statuses recorded)
  May  5 16:56:57.018: INFO: 	Container snapshot-validation-webhook ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 05/05/24 16:56:57.019
  E0505 16:56:57.884381      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:56:58.885120      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 05/05/24 16:56:59.038
  STEP: Trying to apply a random label on the found node. @ 05/05/24 16:56:59.066
  STEP: verifying the node has the label kubernetes.io/e2e-d5c83860-cd94-4df2-ad08-0cfd50906b06 42 @ 05/05/24 16:56:59.079
  STEP: Trying to relaunch the pod, now with labels. @ 05/05/24 16:56:59.082
  E0505 16:56:59.885191      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:00.885568      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-d5c83860-cd94-4df2-ad08-0cfd50906b06 off the node worker00 @ 05/05/24 16:57:01.097
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-d5c83860-cd94-4df2-ad08-0cfd50906b06 @ 05/05/24 16:57:01.105
  May  5 16:57:01.116: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-5756" for this suite. @ 05/05/24 16:57:01.119
• [4.147 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:155
  STEP: Creating a kubernetes client @ 05/05/24 16:57:01.125
  May  5 16:57:01.125: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename replicaset @ 05/05/24 16:57:01.125
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:57:01.136
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:57:01.14
  May  5 16:57:01.152: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0505 16:57:01.885635      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:02.885936      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:03.888389      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:04.890005      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:05.894239      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:57:06.154: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/05/24 16:57:06.154
  STEP: Scaling up "test-rs" replicaset @ 05/05/24 16:57:06.155
  May  5 16:57:06.170: INFO: Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 05/05/24 16:57:06.17
  May  5 16:57:06.178: INFO: observed ReplicaSet test-rs in namespace replicaset-3074 with ReadyReplicas 1, AvailableReplicas 1
  May  5 16:57:06.197: INFO: observed ReplicaSet test-rs in namespace replicaset-3074 with ReadyReplicas 1, AvailableReplicas 1
  May  5 16:57:06.211: INFO: observed ReplicaSet test-rs in namespace replicaset-3074 with ReadyReplicas 1, AvailableReplicas 1
  May  5 16:57:06.216: INFO: observed ReplicaSet test-rs in namespace replicaset-3074 with ReadyReplicas 1, AvailableReplicas 1
  May  5 16:57:06.868: INFO: observed ReplicaSet test-rs in namespace replicaset-3074 with ReadyReplicas 2, AvailableReplicas 2
  E0505 16:57:06.894983      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:57:07.881: INFO: observed Replicaset test-rs in namespace replicaset-3074 with ReadyReplicas 3 found true
  May  5 16:57:07.881: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3074" for this suite. @ 05/05/24 16:57:07.884
• [6.762 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:641
  STEP: Creating a kubernetes client @ 05/05/24 16:57:07.888
  May  5 16:57:07.888: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename statefulset @ 05/05/24 16:57:07.888
  E0505 16:57:07.895392      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:57:07.896
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:57:07.898
  STEP: Creating service test in namespace statefulset-6300 @ 05/05/24 16:57:07.9
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 05/05/24 16:57:07.903
  STEP: Creating stateful set ss in namespace statefulset-6300 @ 05/05/24 16:57:07.906
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6300 @ 05/05/24 16:57:07.91
  May  5 16:57:07.913: INFO: Found 0 stateful pods, waiting for 1
  E0505 16:57:08.897608      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:09.897596      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:10.900562      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:11.903329      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:12.903434      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:13.904862      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:14.905219      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:15.905620      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:16.905687      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:17.906099      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:57:17.919: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 05/05/24 16:57:17.919
  May  5 16:57:17.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=statefulset-6300 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May  5 16:57:18.013: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May  5 16:57:18.013: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May  5 16:57:18.013: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May  5 16:57:18.016: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0505 16:57:18.907259      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:19.908218      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:20.909500      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:21.910699      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:22.912175      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:23.914490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:24.915542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:25.915590      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:26.915821      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:27.917265      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:57:28.015: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  May  5 16:57:28.015: INFO: Waiting for statefulset status.readyReplicas updated to 0
  May  5 16:57:28.047: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999728s
  E0505 16:57:28.917606      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:57:29.052: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996820967s
  E0505 16:57:29.917954      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:57:30.058: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990856621s
  E0505 16:57:30.918712      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:57:31.063: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.986046844s
  E0505 16:57:31.918848      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:57:32.067: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.980484997s
  E0505 16:57:32.919823      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:57:33.072: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.976940992s
  E0505 16:57:33.920518      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:57:34.079: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.97055033s
  E0505 16:57:34.924474      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:57:35.082: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.963887049s
  E0505 16:57:35.924657      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:57:36.084: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.961955376s
  E0505 16:57:36.946471      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:57:37.088: INFO: Verifying statefulset ss doesn't scale past 1 for another 959.470528ms
  E0505 16:57:37.946463      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6300 @ 05/05/24 16:57:38.09
  May  5 16:57:38.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=statefulset-6300 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May  5 16:57:38.160: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May  5 16:57:38.160: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May  5 16:57:38.160: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May  5 16:57:38.162: INFO: Found 1 stateful pods, waiting for 3
  E0505 16:57:38.946954      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:39.947142      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:40.948473      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:41.949070      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:42.949609      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:43.951215      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:44.951783      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:45.952080      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:46.952989      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:47.953139      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:57:48.166: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  May  5 16:57:48.166: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  May  5 16:57:48.166: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 05/05/24 16:57:48.166
  STEP: Scale down will halt with unhealthy stateful pod @ 05/05/24 16:57:48.166
  May  5 16:57:48.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=statefulset-6300 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May  5 16:57:48.249: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May  5 16:57:48.249: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May  5 16:57:48.249: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May  5 16:57:48.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=statefulset-6300 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May  5 16:57:48.336: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May  5 16:57:48.336: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May  5 16:57:48.336: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May  5 16:57:48.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=statefulset-6300 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May  5 16:57:48.413: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May  5 16:57:48.413: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May  5 16:57:48.413: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May  5 16:57:48.413: INFO: Waiting for statefulset status.readyReplicas updated to 0
  May  5 16:57:48.416: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 3
  E0505 16:57:48.953276      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:49.954551      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:50.954627      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:51.954798      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:52.955955      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:53.958476      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:54.959047      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:55.964012      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:56.965102      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:57:57.965958      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:57:58.419: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  May  5 16:57:58.419: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  May  5 16:57:58.419: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  May  5 16:57:58.428: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999523s
  E0505 16:57:58.966859      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:57:59.431: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997279152s
  E0505 16:57:59.968440      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:58:00.460: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.974973887s
  E0505 16:58:00.969028      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:58:01.464: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.964886525s
  E0505 16:58:01.969961      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:58:02.471: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.960619366s
  E0505 16:58:02.971313      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:58:03.481: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.9509074s
  E0505 16:58:03.972499      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:58:04.487: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.943848868s
  E0505 16:58:04.973711      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:58:05.495: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.937409084s
  E0505 16:58:05.973873      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:58:06.502: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.928725777s
  E0505 16:58:06.974463      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:58:07.508: INFO: Verifying statefulset ss doesn't scale past 3 for another 923.011977ms
  E0505 16:58:07.974953      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6300 @ 05/05/24 16:58:08.509
  May  5 16:58:08.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=statefulset-6300 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May  5 16:58:08.601: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May  5 16:58:08.601: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May  5 16:58:08.601: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May  5 16:58:08.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=statefulset-6300 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May  5 16:58:08.690: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May  5 16:58:08.690: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May  5 16:58:08.690: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May  5 16:58:08.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=statefulset-6300 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May  5 16:58:08.772: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May  5 16:58:08.772: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May  5 16:58:08.772: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May  5 16:58:08.772: INFO: Scaling statefulset ss to 0
  E0505 16:58:08.975178      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:09.975790      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:10.976150      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:11.976487      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:12.976702      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:13.978271      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:14.983366      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:15.983506      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:16.984366      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:17.984593      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 05/05/24 16:58:18.783
  May  5 16:58:18.783: INFO: Deleting all statefulset in ns statefulset-6300
  May  5 16:58:18.786: INFO: Scaling statefulset ss to 0
  May  5 16:58:18.794: INFO: Waiting for statefulset status.replicas updated to 0
  May  5 16:58:18.795: INFO: Deleting statefulset ss
  May  5 16:58:18.814: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-6300" for this suite. @ 05/05/24 16:58:18.817
• [70.933 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:855
  STEP: Creating a kubernetes client @ 05/05/24 16:58:18.821
  May  5 16:58:18.821: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename job @ 05/05/24 16:58:18.822
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:58:18.829
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:58:18.831
  STEP: Creating a suspended job @ 05/05/24 16:58:18.833
  STEP: Patching the Job @ 05/05/24 16:58:18.837
  STEP: Watching for Job to be patched @ 05/05/24 16:58:18.845
  May  5 16:58:18.846: INFO: Event ADDED observed for Job e2e-g95cl in namespace job-6908 with labels: map[e2e-job-label:e2e-g95cl] and annotations: map[]
  May  5 16:58:18.846: INFO: Event MODIFIED observed for Job e2e-g95cl in namespace job-6908 with labels: map[e2e-job-label:e2e-g95cl] and annotations: map[]
  May  5 16:58:18.846: INFO: Event MODIFIED found for Job e2e-g95cl in namespace job-6908 with labels: map[e2e-g95cl:patched e2e-job-label:e2e-g95cl] and annotations: map[]
  STEP: Updating the job @ 05/05/24 16:58:18.847
  STEP: Watching for Job to be updated @ 05/05/24 16:58:18.852
  May  5 16:58:18.853: INFO: Event MODIFIED found for Job e2e-g95cl in namespace job-6908 with labels: map[e2e-g95cl:patched e2e-job-label:e2e-g95cl] and annotations: map[updated:true]
  May  5 16:58:18.853: INFO: Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 05/05/24 16:58:18.854
  May  5 16:58:18.856: INFO: Job: e2e-g95cl as labels: map[e2e-g95cl:patched e2e-job-label:e2e-g95cl]
  STEP: Waiting for job to complete @ 05/05/24 16:58:18.856
  E0505 16:58:18.992440      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:20.022817      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:21.023075      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:22.025618      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:23.027481      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:24.028662      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:25.029717      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:26.030042      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 05/05/24 16:58:26.861
  STEP: Watching for Job to be deleted @ 05/05/24 16:58:26.864
  May  5 16:58:26.865: INFO: Event MODIFIED observed for Job e2e-g95cl in namespace job-6908 with labels: map[e2e-g95cl:patched e2e-job-label:e2e-g95cl] and annotations: map[updated:true]
  May  5 16:58:26.865: INFO: Event MODIFIED observed for Job e2e-g95cl in namespace job-6908 with labels: map[e2e-g95cl:patched e2e-job-label:e2e-g95cl] and annotations: map[updated:true]
  May  5 16:58:26.865: INFO: Event MODIFIED observed for Job e2e-g95cl in namespace job-6908 with labels: map[e2e-g95cl:patched e2e-job-label:e2e-g95cl] and annotations: map[updated:true]
  May  5 16:58:26.866: INFO: Event MODIFIED observed for Job e2e-g95cl in namespace job-6908 with labels: map[e2e-g95cl:patched e2e-job-label:e2e-g95cl] and annotations: map[updated:true]
  May  5 16:58:26.866: INFO: Event MODIFIED observed for Job e2e-g95cl in namespace job-6908 with labels: map[e2e-g95cl:patched e2e-job-label:e2e-g95cl] and annotations: map[updated:true]
  May  5 16:58:26.866: INFO: Event DELETED found for Job e2e-g95cl in namespace job-6908 with labels: map[e2e-g95cl:patched e2e-job-label:e2e-g95cl] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 05/05/24 16:58:26.866
  May  5 16:58:26.867: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-6908" for this suite. @ 05/05/24 16:58:26.877
• [8.061 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/controller_revision.go:126
  STEP: Creating a kubernetes client @ 05/05/24 16:58:26.882
  May  5 16:58:26.882: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename controllerrevisions @ 05/05/24 16:58:26.883
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:58:26.891
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:58:26.893
  STEP: Creating DaemonSet "e2e-hmzkr-daemon-set" @ 05/05/24 16:58:26.902
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/05/24 16:58:26.905
  May  5 16:58:26.909: INFO: Number of nodes with available pods controlled by daemonset e2e-hmzkr-daemon-set: 0
  May  5 16:58:26.909: INFO: Node worker00 is running 0 daemon pod, expected 1
  E0505 16:58:27.031484      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:58:27.908: INFO: Number of nodes with available pods controlled by daemonset e2e-hmzkr-daemon-set: 0
  May  5 16:58:27.908: INFO: Node worker00 is running 0 daemon pod, expected 1
  E0505 16:58:28.032168      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:58:28.912: INFO: Number of nodes with available pods controlled by daemonset e2e-hmzkr-daemon-set: 2
  May  5 16:58:28.912: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset e2e-hmzkr-daemon-set
  STEP: Confirm DaemonSet "e2e-hmzkr-daemon-set" successfully created with "daemonset-name=e2e-hmzkr-daemon-set" label @ 05/05/24 16:58:28.913
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-hmzkr-daemon-set" @ 05/05/24 16:58:28.918
  May  5 16:58:28.920: INFO: Located ControllerRevision: "e2e-hmzkr-daemon-set-d58449789"
  STEP: Patching ControllerRevision "e2e-hmzkr-daemon-set-d58449789" @ 05/05/24 16:58:28.922
  May  5 16:58:28.927: INFO: e2e-hmzkr-daemon-set-d58449789 has been patched
  STEP: Create a new ControllerRevision @ 05/05/24 16:58:28.927
  May  5 16:58:28.932: INFO: Created ControllerRevision: e2e-hmzkr-daemon-set-548f85cf7c
  STEP: Confirm that there are two ControllerRevisions @ 05/05/24 16:58:28.932
  May  5 16:58:28.932: INFO: Requesting list of ControllerRevisions to confirm quantity
  May  5 16:58:28.935: INFO: Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-hmzkr-daemon-set-d58449789" @ 05/05/24 16:58:28.935
  STEP: Confirm that there is only one ControllerRevision @ 05/05/24 16:58:28.938
  May  5 16:58:28.938: INFO: Requesting list of ControllerRevisions to confirm quantity
  May  5 16:58:28.940: INFO: Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-hmzkr-daemon-set-548f85cf7c" @ 05/05/24 16:58:28.942
  May  5 16:58:28.946: INFO: e2e-hmzkr-daemon-set-548f85cf7c has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 05/05/24 16:58:28.946
  W0505 16:58:28.951135      22 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 05/05/24 16:58:28.951
  May  5 16:58:28.951: INFO: Requesting list of ControllerRevisions to confirm quantity
  E0505 16:58:29.032504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:58:29.951: INFO: Requesting list of ControllerRevisions to confirm quantity
  May  5 16:58:29.953: INFO: Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-hmzkr-daemon-set-548f85cf7c=updated" @ 05/05/24 16:58:29.954
  STEP: Confirm that there is only one ControllerRevision @ 05/05/24 16:58:29.959
  May  5 16:58:29.959: INFO: Requesting list of ControllerRevisions to confirm quantity
  May  5 16:58:29.961: INFO: Found 1 ControllerRevisions
  May  5 16:58:29.964: INFO: ControllerRevision "e2e-hmzkr-daemon-set-5f5c45c56" has revision 3
  STEP: Deleting DaemonSet "e2e-hmzkr-daemon-set" @ 05/05/24 16:58:29.966
  STEP: deleting DaemonSet.extensions e2e-hmzkr-daemon-set in namespace controllerrevisions-8021, will wait for the garbage collector to delete the pods @ 05/05/24 16:58:29.966
  May  5 16:58:30.022: INFO: Deleting DaemonSet.extensions e2e-hmzkr-daemon-set took: 3.363704ms
  E0505 16:58:30.033202      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:58:30.122: INFO: Terminating DaemonSet.extensions e2e-hmzkr-daemon-set pods took: 100.058255ms
  E0505 16:58:31.034264      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:58:31.324: INFO: Number of nodes with available pods controlled by daemonset e2e-hmzkr-daemon-set: 0
  May  5 16:58:31.324: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-hmzkr-daemon-set
  May  5 16:58:31.326: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"27037"},"items":null}

  May  5 16:58:31.329: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"27037"},"items":null}

  May  5 16:58:31.333: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-8021" for this suite. @ 05/05/24 16:58:31.335
• [4.456 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:189
  STEP: Creating a kubernetes client @ 05/05/24 16:58:31.339
  May  5 16:58:31.339: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename var-expansion @ 05/05/24 16:58:31.34
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:58:31.349
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:58:31.351
  E0505 16:58:32.034876      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:33.035517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:58:33.363: INFO: Deleting pod "var-expansion-07c2aaab-9bd6-4301-91fa-d9d51ebb8865" in namespace "var-expansion-3831"
  May  5 16:58:33.368: INFO: Wait up to 5m0s for pod "var-expansion-07c2aaab-9bd6-4301-91fa-d9d51ebb8865" to be fully deleted
  E0505 16:58:34.035864      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:35.036790      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:58:35.375: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3831" for this suite. @ 05/05/24 16:58:35.379
• [4.046 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:112
  STEP: Creating a kubernetes client @ 05/05/24 16:58:35.386
  May  5 16:58:35.386: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename replicaset @ 05/05/24 16:58:35.386
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:58:35.393
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:58:35.395
  May  5 16:58:35.397: INFO: Creating ReplicaSet my-hostname-basic-0321f175-bd0a-463f-b9dc-f3bc6e8b5256
  May  5 16:58:35.400: INFO: Pod name my-hostname-basic-0321f175-bd0a-463f-b9dc-f3bc6e8b5256: Found 0 pods out of 1
  E0505 16:58:36.036681      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:37.037272      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:38.037326      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:39.040366      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:40.040291      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:58:40.410: INFO: Pod name my-hostname-basic-0321f175-bd0a-463f-b9dc-f3bc6e8b5256: Found 1 pods out of 1
  May  5 16:58:40.410: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-0321f175-bd0a-463f-b9dc-f3bc6e8b5256" is running
  May  5 16:58:40.412: INFO: Pod "my-hostname-basic-0321f175-bd0a-463f-b9dc-f3bc6e8b5256-wz5bj" is running (conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-05 16:58:36 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-05 16:58:35 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-05 16:58:36 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-05 16:58:36 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-05 16:58:35 +0000 UTC Reason: Message:}])
  May  5 16:58:40.412: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 05/05/24 16:58:40.412
  May  5 16:58:40.417: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-1704" for this suite. @ 05/05/24 16:58:40.419
• [5.038 seconds]
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:276
  STEP: Creating a kubernetes client @ 05/05/24 16:58:40.423
  May  5 16:58:40.423: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/05/24 16:58:40.424
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:58:40.433
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:58:40.435
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 05/05/24 16:58:40.436
  May  5 16:58:40.437: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  E0505 16:58:41.041118      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:58:41.657: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  E0505 16:58:42.041692      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:43.042083      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:44.042069      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:45.045162      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:46.045405      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:58:46.447: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8354" for this suite. @ 05/05/24 16:58:46.452
• [6.041 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:793
  STEP: Creating a kubernetes client @ 05/05/24 16:58:46.465
  May  5 16:58:46.465: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename statefulset @ 05/05/24 16:58:46.465
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:58:46.476
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:58:46.478
  STEP: Creating service test in namespace statefulset-7154 @ 05/05/24 16:58:46.479
  STEP: Looking for a node to schedule stateful set and pod @ 05/05/24 16:58:46.481
  STEP: Creating pod with conflicting port in namespace statefulset-7154 @ 05/05/24 16:58:46.486
  STEP: Waiting until pod test-pod will start running in namespace statefulset-7154 @ 05/05/24 16:58:46.49
  E0505 16:58:47.046903      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:48.047605      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-7154 @ 05/05/24 16:58:48.498
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-7154 @ 05/05/24 16:58:48.505
  May  5 16:58:48.512: INFO: Observed stateful pod in namespace: statefulset-7154, name: ss-0, uid: 625d92fc-373b-48f2-9e76-7bbdf16ced7b, status phase: Pending. Waiting for statefulset controller to delete.
  May  5 16:58:48.527: INFO: Observed stateful pod in namespace: statefulset-7154, name: ss-0, uid: 625d92fc-373b-48f2-9e76-7bbdf16ced7b, status phase: Failed. Waiting for statefulset controller to delete.
  May  5 16:58:48.543: INFO: Observed stateful pod in namespace: statefulset-7154, name: ss-0, uid: 625d92fc-373b-48f2-9e76-7bbdf16ced7b, status phase: Failed. Waiting for statefulset controller to delete.
  May  5 16:58:48.547: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-7154
  STEP: Removing pod with conflicting port in namespace statefulset-7154 @ 05/05/24 16:58:48.547
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-7154 and will be in running state @ 05/05/24 16:58:48.558
  E0505 16:58:49.048668      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:50.050406      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:58:50.565: INFO: Deleting all statefulset in ns statefulset-7154
  May  5 16:58:50.566: INFO: Scaling statefulset ss to 0
  E0505 16:58:51.051392      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:52.051597      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:53.052211      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:54.052171      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:55.052904      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:56.053346      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:57.053718      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:58.054383      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:58:59.055531      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:00.056324      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:59:00.578: INFO: Waiting for statefulset status.replicas updated to 0
  May  5 16:59:00.581: INFO: Deleting statefulset ss
  May  5 16:59:00.599: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7154" for this suite. @ 05/05/24 16:59:00.601
• [14.140 seconds]
------------------------------
SSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:214
  STEP: Creating a kubernetes client @ 05/05/24 16:59:00.605
  May  5 16:59:00.605: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/05/24 16:59:00.606
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:59:00.617
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:59:00.62
  STEP: create the container to handle the HTTPGet hook request. @ 05/05/24 16:59:00.624
  E0505 16:59:01.056766      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:02.058438      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/05/24 16:59:02.635
  E0505 16:59:03.058490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:04.059396      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 05/05/24 16:59:04.666
  E0505 16:59:05.059198      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:06.059752      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 05/05/24 16:59:06.69
  May  5 16:59:06.709: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-2565" for this suite. @ 05/05/24 16:59:06.713
• [6.114 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:75
  STEP: Creating a kubernetes client @ 05/05/24 16:59:06.72
  May  5 16:59:06.720: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename configmap @ 05/05/24 16:59:06.721
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:59:06.736
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:59:06.737
  STEP: Creating configMap with name configmap-test-volume-dd9f29ed-e04e-4c68-afb5-0bf1af0b4ebc @ 05/05/24 16:59:06.739
  STEP: Creating a pod to test consume configMaps @ 05/05/24 16:59:06.742
  E0505 16:59:07.060857      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:08.062920      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:59:08.756
  May  5 16:59:08.759: INFO: Trying to get logs from node worker00 pod pod-configmaps-0fb1533d-7723-49a8-944e-dd7448b4f413 container agnhost-container: <nil>
  STEP: delete the pod @ 05/05/24 16:59:08.766
  May  5 16:59:08.791: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8237" for this suite. @ 05/05/24 16:59:08.794
• [2.079 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:86
  STEP: Creating a kubernetes client @ 05/05/24 16:59:08.798
  May  5 16:59:08.798: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 16:59:08.799
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:59:08.811
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:59:08.817
  STEP: Creating a pod to test downward API volume plugin @ 05/05/24 16:59:08.82
  E0505 16:59:09.063094      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:10.065388      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:11.066533      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:12.067391      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:59:12.841
  May  5 16:59:12.846: INFO: Trying to get logs from node worker00 pod downwardapi-volume-61ccf278-ed5a-4057-af05-454b7bc53a70 container client-container: <nil>
  STEP: delete the pod @ 05/05/24 16:59:12.852
  May  5 16:59:12.879: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-678" for this suite. @ 05/05/24 16:59:12.881
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingressclass.go:268
  STEP: Creating a kubernetes client @ 05/05/24 16:59:12.886
  May  5 16:59:12.886: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename ingressclass @ 05/05/24 16:59:12.887
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:59:12.9
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:59:12.904
  STEP: getting /apis @ 05/05/24 16:59:12.908
  STEP: getting /apis/networking.k8s.io @ 05/05/24 16:59:12.912
  STEP: getting /apis/networking.k8s.iov1 @ 05/05/24 16:59:12.913
  STEP: creating @ 05/05/24 16:59:12.915
  STEP: getting @ 05/05/24 16:59:12.928
  STEP: listing @ 05/05/24 16:59:12.932
  STEP: watching @ 05/05/24 16:59:12.936
  May  5 16:59:12.936: INFO: starting watch
  STEP: patching @ 05/05/24 16:59:12.939
  STEP: updating @ 05/05/24 16:59:12.948
  May  5 16:59:12.953: INFO: waiting for watch events with expected annotations
  May  5 16:59:12.953: INFO: saw patched and updated annotations
  STEP: deleting @ 05/05/24 16:59:12.953
  STEP: deleting a collection @ 05/05/24 16:59:12.966
  May  5 16:59:12.980: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-5166" for this suite. @ 05/05/24 16:59:12.985
• [0.108 seconds]
------------------------------
SS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 05/05/24 16:59:12.995
  May  5 16:59:12.995: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename secrets @ 05/05/24 16:59:12.998
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:59:13.021
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:59:13.032
  STEP: Creating secret with name s-test-opt-del-4f77f5fa-817e-4b67-8dd2-6848dca3d2ea @ 05/05/24 16:59:13.042
  STEP: Creating secret with name s-test-opt-upd-b9f28acd-cf81-4262-b14f-264de2d3a7a2 @ 05/05/24 16:59:13.059
  STEP: Creating the pod @ 05/05/24 16:59:13.064
  E0505 16:59:13.067701      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:14.068563      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:15.070022      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-4f77f5fa-817e-4b67-8dd2-6848dca3d2ea @ 05/05/24 16:59:15.1
  STEP: Updating secret s-test-opt-upd-b9f28acd-cf81-4262-b14f-264de2d3a7a2 @ 05/05/24 16:59:15.103
  STEP: Creating secret with name s-test-opt-create-58dd55ca-18fd-4941-8939-da4ffcefa0b8 @ 05/05/24 16:59:15.105
  STEP: waiting to observe update in volume @ 05/05/24 16:59:15.108
  E0505 16:59:16.069974      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:17.070815      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:59:17.122: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7131" for this suite. @ 05/05/24 16:59:17.125
• [4.133 seconds]
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:391
  STEP: Creating a kubernetes client @ 05/05/24 16:59:17.129
  May  5 16:59:17.129: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/05/24 16:59:17.13
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:59:17.144
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:59:17.147
  STEP: set up a multi version CRD @ 05/05/24 16:59:17.15
  May  5 16:59:17.150: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  E0505 16:59:18.071537      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:19.072624      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:20.073858      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: rename a version @ 05/05/24 16:59:20.396
  STEP: check the new version name is served @ 05/05/24 16:59:20.411
  E0505 16:59:21.083570      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 05/05/24 16:59:21.113
  STEP: check the other version is not changed @ 05/05/24 16:59:21.725
  E0505 16:59:22.084496      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:23.084841      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:24.087398      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:59:24.254: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8268" for this suite. @ 05/05/24 16:59:24.259
• [7.134 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 05/05/24 16:59:24.263
  May  5 16:59:24.263: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename chunking @ 05/05/24 16:59:24.264
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:59:24.274
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:59:24.276
  STEP: creating a large number of resources @ 05/05/24 16:59:24.277
  E0505 16:59:25.087853      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:26.089001      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0505 16:59:26.375296      22 request.go:697] Waited for 1.000834673s due to client-side throttling, not priority and fairness, request: POST:https://10.32.0.1:443/api/v1/namespaces/chunking-6442/podtemplates
  E0505 16:59:27.089654      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:28.090389      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:29.091486      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:30.091866      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:31.092988      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:32.093467      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:33.093647      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:34.094653      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:35.095082      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:36.095745      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:37.096621      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:38.097297      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0505 16:59:38.671269      22 request.go:697] Waited for 1.002373131s due to client-side throttling, not priority and fairness, request: POST:https://10.32.0.1:443/api/v1/namespaces/chunking-6442/podtemplates
  E0505 16:59:39.098556      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:40.099669      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:41.099633      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving those results in paged fashion several times @ 05/05/24 16:59:41.972
  May  5 16:59:42.021: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  May  5 16:59:42.071: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  E0505 16:59:42.100672      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:59:42.122: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  May  5 16:59:42.173: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  May  5 16:59:42.220: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  May  5 16:59:42.267: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  May  5 16:59:42.321: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  May  5 16:59:42.367: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  May  5 16:59:42.418: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  May  5 16:59:42.468: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  May  5 16:59:42.521: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  May  5 16:59:42.570: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  May  5 16:59:42.619: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  May  5 16:59:42.666: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  May  5 16:59:42.717: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  May  5 16:59:42.769: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  May  5 16:59:42.821: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  May  5 16:59:42.867: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  May  5 16:59:42.919: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  May  5 16:59:42.968: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  May  5 16:59:43.020: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  May  5 16:59:43.068: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  E0505 16:59:43.101472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:59:43.119: INFO: Retrieved 17/17 results with rv 28139 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxMzksInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  May  5 16:59:43.171: INFO: Retrieved 9/17 results with rv 28139 and continue 
  May  5 16:59:43.220: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  May  5 16:59:43.271: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  May  5 16:59:43.319: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  May  5 16:59:43.371: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  May  5 16:59:43.421: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  May  5 16:59:43.471: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  May  5 16:59:43.525: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  May  5 16:59:43.571: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  May  5 16:59:43.620: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  May  5 16:59:43.668: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  May  5 16:59:43.721: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  May  5 16:59:43.766: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  May  5 16:59:43.819: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  May  5 16:59:43.870: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  May  5 16:59:43.916: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  May  5 16:59:43.970: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  May  5 16:59:44.020: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  May  5 16:59:44.070: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  E0505 16:59:44.102131      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:59:44.127: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  May  5 16:59:44.170: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  May  5 16:59:44.220: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  May  5 16:59:44.270: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  May  5 16:59:44.321: INFO: Retrieved 17/17 results with rv 28142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  May  5 16:59:44.369: INFO: Retrieved 9/17 results with rv 28142 and continue 
  May  5 16:59:44.421: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  May  5 16:59:44.470: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  May  5 16:59:44.518: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  May  5 16:59:44.569: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  May  5 16:59:44.620: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  May  5 16:59:44.671: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  May  5 16:59:44.719: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  May  5 16:59:44.770: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  May  5 16:59:44.822: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  May  5 16:59:44.870: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  May  5 16:59:44.921: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  May  5 16:59:44.967: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  May  5 16:59:45.018: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  May  5 16:59:45.073: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  E0505 16:59:45.102205      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:59:45.120: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  May  5 16:59:45.170: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  May  5 16:59:45.221: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  May  5 16:59:45.271: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  May  5 16:59:45.319: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  May  5 16:59:45.369: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  May  5 16:59:45.420: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  May  5 16:59:45.470: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  May  5 16:59:45.522: INFO: Retrieved 17/17 results with rv 28147 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjgxNDcsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  May  5 16:59:45.569: INFO: Retrieved 9/17 results with rv 28147 and continue 
  STEP: retrieving those results all at once @ 05/05/24 16:59:45.569
  May  5 16:59:45.628: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-6442" for this suite. @ 05/05/24 16:59:45.67
• [21.460 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 05/05/24 16:59:45.725
  May  5 16:59:45.725: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 16:59:45.726
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:59:45.738
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:59:45.739
  STEP: Creating projection with secret that has name projected-secret-test-map-c394de21-7976-42d5-9aa7-ba65a9c5d367 @ 05/05/24 16:59:45.741
  STEP: Creating a pod to test consume secrets @ 05/05/24 16:59:45.743
  E0505 16:59:46.102656      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:47.104938      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:48.104877      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:49.105542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 16:59:49.762
  May  5 16:59:49.766: INFO: Trying to get logs from node worker00 pod pod-projected-secrets-ed85a2e8-36be-4d1e-b868-b9e6e1abe546 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/05/24 16:59:49.772
  May  5 16:59:49.784: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7919" for this suite. @ 05/05/24 16:59:49.786
• [4.064 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 05/05/24 16:59:49.789
  May  5 16:59:49.789: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename pods @ 05/05/24 16:59:49.789
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:59:49.797
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:59:49.8
  STEP: creating the pod @ 05/05/24 16:59:49.802
  STEP: setting up watch @ 05/05/24 16:59:49.802
  STEP: submitting the pod to kubernetes @ 05/05/24 16:59:49.904
  STEP: verifying the pod is in kubernetes @ 05/05/24 16:59:49.916
  STEP: verifying pod creation was observed @ 05/05/24 16:59:49.92
  E0505 16:59:50.107481      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:51.107592      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 05/05/24 16:59:51.931
  STEP: verifying pod deletion was observed @ 05/05/24 16:59:51.949
  E0505 16:59:52.112780      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:53.113192      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:59:53.599: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6378" for this suite. @ 05/05/24 16:59:53.601
• [3.815 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:69
  STEP: Creating a kubernetes client @ 05/05/24 16:59:53.605
  May  5 16:59:53.605: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/05/24 16:59:53.606
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:59:53.615
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:59:53.616
  May  5 16:59:53.618: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  E0505 16:59:54.114182      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 05/05/24 16:59:54.895
  May  5 16:59:54.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-1867 --namespace=crd-publish-openapi-1867 create -f -'
  E0505 16:59:55.115375      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 16:59:56.115618      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:59:57.010: INFO: stderr: ""
  May  5 16:59:57.010: INFO: stdout: "e2e-test-crd-publish-openapi-4271-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  May  5 16:59:57.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-1867 --namespace=crd-publish-openapi-1867 delete e2e-test-crd-publish-openapi-4271-crds test-foo'
  May  5 16:59:57.055: INFO: stderr: ""
  May  5 16:59:57.055: INFO: stdout: "e2e-test-crd-publish-openapi-4271-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  May  5 16:59:57.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-1867 --namespace=crd-publish-openapi-1867 apply -f -'
  May  5 16:59:57.102: INFO: stderr: ""
  May  5 16:59:57.102: INFO: stdout: "e2e-test-crd-publish-openapi-4271-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  May  5 16:59:57.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-1867 --namespace=crd-publish-openapi-1867 delete e2e-test-crd-publish-openapi-4271-crds test-foo'
  E0505 16:59:57.115849      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:59:57.145: INFO: stderr: ""
  May  5 16:59:57.145: INFO: stdout: "e2e-test-crd-publish-openapi-4271-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 05/05/24 16:59:57.145
  May  5 16:59:57.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-1867 --namespace=crd-publish-openapi-1867 create -f -'
  May  5 16:59:57.193: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 05/05/24 16:59:57.193
  May  5 16:59:57.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-1867 --namespace=crd-publish-openapi-1867 create -f -'
  May  5 16:59:57.243: INFO: rc: 1
  May  5 16:59:57.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-1867 --namespace=crd-publish-openapi-1867 apply -f -'
  May  5 16:59:57.293: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 05/05/24 16:59:57.293
  May  5 16:59:57.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-1867 --namespace=crd-publish-openapi-1867 create -f -'
  May  5 16:59:57.342: INFO: rc: 1
  May  5 16:59:57.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-1867 --namespace=crd-publish-openapi-1867 apply -f -'
  May  5 16:59:57.393: INFO: rc: 1
  STEP: kubectl explain works to explain CR properties @ 05/05/24 16:59:57.393
  May  5 16:59:57.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-1867 explain e2e-test-crd-publish-openapi-4271-crds'
  May  5 16:59:57.436: INFO: stderr: ""
  May  5 16:59:57.436: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-4271-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 05/05/24 16:59:57.436
  May  5 16:59:57.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-1867 explain e2e-test-crd-publish-openapi-4271-crds.metadata'
  May  5 16:59:57.478: INFO: stderr: ""
  May  5 16:59:57.478: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-4271-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  May  5 16:59:57.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-1867 explain e2e-test-crd-publish-openapi-4271-crds.spec'
  May  5 16:59:57.518: INFO: stderr: ""
  May  5 16:59:57.518: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-4271-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  May  5 16:59:57.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-1867 explain e2e-test-crd-publish-openapi-4271-crds.spec.bars'
  May  5 16:59:57.559: INFO: stderr: ""
  May  5 16:59:57.559: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-4271-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 05/05/24 16:59:57.559
  May  5 16:59:57.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=crd-publish-openapi-1867 explain e2e-test-crd-publish-openapi-4271-crds.spec.bars2'
  May  5 16:59:57.601: INFO: rc: 1
  E0505 16:59:58.116777      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 16:59:58.779: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1867" for this suite. @ 05/05/24 16:59:58.784
• [5.182 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:144
  STEP: Creating a kubernetes client @ 05/05/24 16:59:58.788
  May  5 16:59:58.788: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename replicaset @ 05/05/24 16:59:58.79
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 16:59:58.797
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 16:59:58.798
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 05/05/24 16:59:58.8
  May  5 16:59:58.803: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0505 16:59:59.117431      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:00.117980      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:01.118167      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:02.118434      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:03.121118      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:00:03.808: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/05/24 17:00:03.808
  STEP: getting scale subresource @ 05/05/24 17:00:03.808
  STEP: updating a scale subresource @ 05/05/24 17:00:03.811
  STEP: verifying the replicaset Spec.Replicas was modified @ 05/05/24 17:00:03.825
  STEP: Patch a scale subresource @ 05/05/24 17:00:03.831
  May  5 17:00:03.851: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4255" for this suite. @ 05/05/24 17:00:03.856
• [5.081 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:59
  STEP: Creating a kubernetes client @ 05/05/24 17:00:03.868
  May  5 17:00:03.868: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/05/24 17:00:03.869
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:00:03.88
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:00:03.883
  May  5 17:00:03.885: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  E0505 17:00:04.121961      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:00:04.901: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-5612" for this suite. @ 05/05/24 17:00:04.902
• [1.048 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:254
  STEP: Creating a kubernetes client @ 05/05/24 17:00:04.917
  May  5 17:00:04.917: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename namespaces @ 05/05/24 17:00:04.917
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:00:04.925
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:00:04.926
  STEP: Creating a test namespace @ 05/05/24 17:00:04.927
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:00:04.934
  STEP: Creating a service in the namespace @ 05/05/24 17:00:04.935
  STEP: Deleting the namespace @ 05/05/24 17:00:04.938
  STEP: Waiting for the namespace to be removed. @ 05/05/24 17:00:04.941
  E0505 17:00:05.122714      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:06.123452      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:07.125540      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:08.126206      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:09.127031      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:10.127839      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 05/05/24 17:00:10.944
  STEP: Verifying there is no service in the namespace @ 05/05/24 17:00:10.962
  May  5 17:00:10.965: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-9119" for this suite. @ 05/05/24 17:00:10.967
  STEP: Destroying namespace "nsdeletetest-5815" for this suite. @ 05/05/24 17:00:10.971
  May  5 17:00:10.972: INFO: Namespace nsdeletetest-5815 was already deleted
  STEP: Destroying namespace "nsdeletetest-1289" for this suite. @ 05/05/24 17:00:10.972
• [6.060 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 05/05/24 17:00:10.977
  May  5 17:00:10.977: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename deployment @ 05/05/24 17:00:10.977
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:00:10.985
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:00:10.987
  May  5 17:00:10.994: INFO: Pod name rollover-pod: Found 0 pods out of 1
  E0505 17:00:11.128198      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:12.128841      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:13.129278      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:14.129558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:15.133893      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:00:15.997: INFO: Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/05/24 17:00:15.997
  May  5 17:00:15.997: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E0505 17:00:16.134541      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:17.135567      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:00:18.000: INFO: Creating deployment "test-rollover-deployment"
  May  5 17:00:18.017: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
  E0505 17:00:18.136134      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:19.136736      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:00:20.020: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
  May  5 17:00:20.022: INFO: Ensure that both replica sets have 1 created replica
  May  5 17:00:20.025: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  May  5 17:00:20.039: INFO: Updating deployment test-rollover-deployment
  May  5 17:00:20.039: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E0505 17:00:20.136858      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:21.138462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:00:22.047: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
  May  5 17:00:22.056: INFO: Make sure deployment "test-rollover-deployment" is complete
  May  5 17:00:22.061: INFO: all replica sets need to contain the pod-template-hash label
  May  5 17:00:22.061: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 17, 0, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 17, 0, 18, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 17, 0, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 17, 0, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0505 17:00:22.142079      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:23.142456      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:00:24.065: INFO: all replica sets need to contain the pod-template-hash label
  May  5 17:00:24.065: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 17, 0, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 17, 0, 18, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 17, 0, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 17, 0, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0505 17:00:24.143028      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:25.144040      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:00:26.066: INFO: all replica sets need to contain the pod-template-hash label
  May  5 17:00:26.066: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 17, 0, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 17, 0, 18, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 17, 0, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 17, 0, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0505 17:00:26.144680      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:27.145055      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:00:28.065: INFO: all replica sets need to contain the pod-template-hash label
  May  5 17:00:28.065: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 17, 0, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 17, 0, 18, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 17, 0, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 17, 0, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0505 17:00:28.145889      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:29.146213      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:00:30.072: INFO: all replica sets need to contain the pod-template-hash label
  May  5 17:00:30.072: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 17, 0, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 17, 0, 18, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 5, 17, 0, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 5, 17, 0, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0505 17:00:30.147202      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:31.147729      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:00:32.067: INFO: 
  May  5 17:00:32.067: INFO: Ensure that both old replica sets have no replicas
  May  5 17:00:32.074: INFO: Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9676",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "315e74fc-5710-4de2-8bd2-b90819a98f53",
      ResourceVersion: (string) (len=5) "29003",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850525218,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525220,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525230,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525218,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525218,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525230,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525218,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-68774655d5\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  May  5 17:00:32.078: INFO: New ReplicaSet "test-rollover-deployment-68774655d5" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-68774655d5",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9676",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fa3bf683-6f30-4136-8dab-4cb439f7bd49",
      ResourceVersion: (string) (len=5) "28991",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850525220,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "315e74fc-5710-4de2-8bd2-b90819a98f53",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525220,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 33 31 35 65 37 34  66 63 2d 35 37 31 30 2d  |\"315e74fc-5710-|
              00000120  34 64 65 32 2d 38 62 64  32 2d 62 39 30 38 31 39  |4de2-8bd2-b90819|
              00000130  61 39 38 66 35 33 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |a98f53\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525230,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May  5 17:00:32.081: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
  May  5 17:00:32.082: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9676",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1c8e43b4-c5cf-42cc-bbfc-b1711eaf0766",
      ResourceVersion: (string) (len=5) "29002",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850525210,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "315e74fc-5710-4de2-8bd2-b90819a98f53",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525210,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525230,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  33 31 35 65 37 34 66 63  2d 35 37 31 30 2d 34 64  |315e74fc-5710-4d|
              000000c0  65 32 2d 38 62 64 32 2d  62 39 30 38 31 39 61 39  |e2-8bd2-b90819a9|
              000000d0  38 66 35 33 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |8f53\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525230,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May  5 17:00:32.085: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-664fc6c874",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9676",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7c848320-6edb-4914-84d1-8a91e1905d96",
      ResourceVersion: (string) (len=5) "28934",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850525218,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "315e74fc-5710-4de2-8bd2-b90819a98f53",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525220,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 33 31 35 65 37 34  66 63 2d 35 37 31 30 2d  |\"315e74fc-5710-|
              00000120  34 64 65 32 2d 38 62 64  32 2d 62 39 30 38 31 39  |4de2-8bd2-b90819|
              00000130  61 39 38 66 35 33 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |a98f53\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525220,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May  5 17:00:32.090: INFO: Pod "test-rollover-deployment-68774655d5-v5zhf" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-68774655d5-v5zhf",
      GenerateName: (string) (len=36) "test-rollover-deployment-68774655d5-",
      Namespace: (string) (len=15) "deployment-9676",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "34a03221-2421-430f-9a2c-0726a69771d7",
      ResourceVersion: (string) (len=5) "28952",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850525220,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5",
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=17) "10.200.131.182/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "0affb1ca85f541e099be52f1290cc70da5b6760a5b001299244085f971f88f7c",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=17) "10.200.131.182/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-68774655d5",
          UID: (types.UID) (len=36) "fa3bf683-6f30-4136-8dab-4cb439f7bd49",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525220,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525220,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 61  33 62 66 36 38 33 2d 36  |d\":\"fa3bf683-6|
              00000090  66 33 30 2d 34 31 33 36  2d 38 64 61 62 2d 34 63  |f30-4136-8dab-4c|
              000000a0  62 34 33 39 66 37 62 64  34 39 5c 22 7d 22 3a 7b  |b439f7bd49\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525220,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 30 30 2e 31 33 31  2e 31 38 32 5c 22 7d 22  |.200.131.182\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mf4hv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mf4hv",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker00",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525220,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525220,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525220,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525220,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850525220,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.100",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.100"
        }
      },
      PodIP: (string) (len=14) "10.200.131.182",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "10.200.131.182"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850525220,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850525220,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253",
          ContainerID: (string) (len=77) "containerd://0a987c4e3ce1a08860bab25af32e9c1fc2f91983434f46be1adc31126ad2de6e",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:00:32.092: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9676" for this suite. @ 05/05/24 17:00:32.096
• [21.132 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:251
  STEP: Creating a kubernetes client @ 05/05/24 17:00:32.109
  May  5 17:00:32.109: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename downward-api @ 05/05/24 17:00:32.11
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:00:32.118
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:00:32.12
  STEP: Creating a pod to test downward API volume plugin @ 05/05/24 17:00:32.121
  E0505 17:00:32.148797      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:33.150442      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:00:34.128
  May  5 17:00:34.130: INFO: Trying to get logs from node worker00 pod downwardapi-volume-ff04a37b-4fa1-45c3-8d18-0e5dc9c3156f container client-container: <nil>
  STEP: delete the pod @ 05/05/24 17:00:34.133
  E0505 17:00:34.151438      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:00:34.157: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3614" for this suite. @ 05/05/24 17:00:34.16
• [2.054 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 05/05/24 17:00:34.165
  May  5 17:00:34.165: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename daemonsets @ 05/05/24 17:00:34.166
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:00:34.173
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:00:34.175
  May  5 17:00:34.182: INFO: Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 05/05/24 17:00:34.185
  May  5 17:00:34.188: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 17:00:34.188: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 05/05/24 17:00:34.189
  May  5 17:00:34.197: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 17:00:34.197: INFO: Node worker00 is running 0 daemon pod, expected 1
  E0505 17:00:35.151934      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:00:35.198: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May  5 17:00:35.198: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 05/05/24 17:00:35.2
  May  5 17:00:35.212: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May  5 17:00:35.212: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  E0505 17:00:36.152487      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:00:36.212: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 17:00:36.212: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 05/05/24 17:00:36.212
  May  5 17:00:36.229: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 17:00:36.229: INFO: Node worker00 is running 0 daemon pod, expected 1
  E0505 17:00:37.152828      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:00:37.229: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 17:00:37.229: INFO: Node worker00 is running 0 daemon pod, expected 1
  E0505 17:00:38.153641      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:00:38.231: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May  5 17:00:38.231: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 05/05/24 17:00:38.236
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9891, will wait for the garbage collector to delete the pods @ 05/05/24 17:00:38.236
  May  5 17:00:38.294: INFO: Deleting DaemonSet.extensions daemon-set took: 5.517394ms
  May  5 17:00:38.394: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.399461ms
  E0505 17:00:39.153672      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:40.155170      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:00:40.903: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 17:00:40.903: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  May  5 17:00:40.907: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"29174"},"items":null}

  May  5 17:00:40.909: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"29174"},"items":null}

  May  5 17:00:40.925: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-9891" for this suite. @ 05/05/24 17:00:40.929
• [6.769 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:71
  STEP: Creating a kubernetes client @ 05/05/24 17:00:40.934
  May  5 17:00:40.934: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename container-probe @ 05/05/24 17:00:40.934
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:00:40.949
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:00:40.952
  E0505 17:00:41.155750      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:42.156320      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:43.157195      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:44.158098      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:45.159113      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:46.159714      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:47.160441      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:48.160705      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:49.161016      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:50.161133      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:51.161862      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:52.163197      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:53.164476      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:54.165732      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:55.165712      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:56.166438      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:57.167633      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:58.167754      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:00:59.169124      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:00.169420      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:01.170569      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:02.170997      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:01:03.032: INFO: Container started at 2024-05-05 17:00:41 +0000 UTC, pod became ready at 2024-05-05 17:01:01 +0000 UTC
  May  5 17:01:03.032: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-311" for this suite. @ 05/05/24 17:01:03.035
• [22.105 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:220
  STEP: Creating a kubernetes client @ 05/05/24 17:01:03.039
  May  5 17:01:03.039: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename emptydir @ 05/05/24 17:01:03.04
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:01:03.049
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:01:03.052
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 05/05/24 17:01:03.053
  E0505 17:01:03.171136      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:04.175443      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:01:05.063
  May  5 17:01:05.065: INFO: Trying to get logs from node worker00 pod pod-80192f21-bfaa-481f-af4c-55034b02b73a container test-container: <nil>
  STEP: delete the pod @ 05/05/24 17:01:05.07
  May  5 17:01:05.078: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1650" for this suite. @ 05/05/24 17:01:05.08
• [2.046 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:238
  STEP: Creating a kubernetes client @ 05/05/24 17:01:05.086
  May  5 17:01:05.086: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename webhook @ 05/05/24 17:01:05.087
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:01:05.096
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:01:05.099
  STEP: Setting up server cert @ 05/05/24 17:01:05.111
  E0505 17:01:05.178467      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/05/24 17:01:05.34
  STEP: Deploying the webhook pod @ 05/05/24 17:01:05.344
  STEP: Wait for the deployment to be ready @ 05/05/24 17:01:05.35
  May  5 17:01:05.356: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0505 17:01:06.179365      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:07.180058      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/05/24 17:01:07.362
  STEP: Verifying the service has paired with the endpoint @ 05/05/24 17:01:07.376
  E0505 17:01:08.180332      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:01:08.380: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 05/05/24 17:01:08.384
  STEP: create a namespace for the webhook @ 05/05/24 17:01:08.395
  STEP: create a configmap should be unconditionally rejected by the webhook @ 05/05/24 17:01:08.403
  May  5 17:01:08.454: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6703" for this suite. @ 05/05/24 17:01:08.459
  STEP: Destroying namespace "webhook-markers-5958" for this suite. @ 05/05/24 17:01:08.463
  STEP: Destroying namespace "fail-closed-namespace-7377" for this suite. @ 05/05/24 17:01:08.474
• [3.394 seconds]
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:902
  STEP: Creating a kubernetes client @ 05/05/24 17:01:08.482
  May  5 17:01:08.482: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename statefulset @ 05/05/24 17:01:08.484
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:01:08.5
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:01:08.504
  STEP: Creating service test in namespace statefulset-2583 @ 05/05/24 17:01:08.506
  STEP: Creating statefulset ss in namespace statefulset-2583 @ 05/05/24 17:01:08.511
  May  5 17:01:08.523: INFO: Found 0 stateful pods, waiting for 1
  E0505 17:01:09.181197      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:10.181386      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:11.182135      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:12.182276      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:13.182885      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:14.183533      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:15.184789      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:16.185840      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:17.185881      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:18.186348      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:01:18.522: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 05/05/24 17:01:18.525
  STEP: updating a scale subresource @ 05/05/24 17:01:18.527
  STEP: verifying the statefulset Spec.Replicas was modified @ 05/05/24 17:01:18.53
  STEP: Patch a scale subresource @ 05/05/24 17:01:18.532
  STEP: verifying the statefulset Spec.Replicas was modified @ 05/05/24 17:01:18.541
  May  5 17:01:18.545: INFO: Deleting all statefulset in ns statefulset-2583
  May  5 17:01:18.548: INFO: Scaling statefulset ss to 0
  E0505 17:01:19.187864      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:20.188579      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:21.188861      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:22.189637      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:23.190197      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:24.190606      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:25.194789      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:26.195006      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:27.195186      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:28.195854      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:01:28.561: INFO: Waiting for statefulset status.replicas updated to 0
  May  5 17:01:28.565: INFO: Deleting statefulset ss
  May  5 17:01:28.573: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-2583" for this suite. @ 05/05/24 17:01:28.577
• [20.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:251
  STEP: Creating a kubernetes client @ 05/05/24 17:01:28.589
  May  5 17:01:28.589: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 17:01:28.59
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:01:28.608
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:01:28.612
  STEP: Creating a pod to test downward API volume plugin @ 05/05/24 17:01:28.614
  E0505 17:01:29.196462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:30.197368      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:31.197793      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:32.199294      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:01:32.633
  May  5 17:01:32.636: INFO: Trying to get logs from node worker00 pod downwardapi-volume-4e88b73b-6273-4fd8-8b2e-8b2257f87a9c container client-container: <nil>
  STEP: delete the pod @ 05/05/24 17:01:32.643
  May  5 17:01:32.665: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8353" for this suite. @ 05/05/24 17:01:32.668
• [4.082 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 05/05/24 17:01:32.67
  May  5 17:01:32.670: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 05/05/24 17:01:32.671
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:01:32.681
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:01:32.683
  STEP: creating a target pod @ 05/05/24 17:01:32.684
  E0505 17:01:33.200291      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:34.200422      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 05/05/24 17:01:34.696
  E0505 17:01:35.201582      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:36.201837      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:37.202747      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:38.204077      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 05/05/24 17:01:38.711
  May  5 17:01:38.711: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-5293 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 17:01:38.711: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 17:01:38.712: INFO: ExecWithOptions: Clientset creation
  May  5 17:01:38.712: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/ephemeral-containers-test-5293/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  May  5 17:01:38.747: INFO: Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 05/05/24 17:01:38.751
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 05/05/24 17:01:38.753
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 05/05/24 17:01:38.772
  May  5 17:01:38.778: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-5293" for this suite. @ 05/05/24 17:01:38.783
• [6.118 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:90
  STEP: Creating a kubernetes client @ 05/05/24 17:01:38.79
  May  5 17:01:38.790: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename emptydir @ 05/05/24 17:01:38.791
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:01:38.802
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:01:38.805
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 05/05/24 17:01:38.809
  E0505 17:01:39.204856      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:40.204951      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:41.205121      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:42.205731      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:01:42.833
  May  5 17:01:42.834: INFO: Trying to get logs from node worker00 pod pod-d5563b71-0152-41bf-8c64-2b308f64f7c1 container test-container: <nil>
  STEP: delete the pod @ 05/05/24 17:01:42.838
  May  5 17:01:42.855: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2625" for this suite. @ 05/05/24 17:01:42.857
• [4.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 05/05/24 17:01:42.862
  May  5 17:01:42.862: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename pods @ 05/05/24 17:01:42.863
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:01:42.874
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:01:42.877
  STEP: creating the pod @ 05/05/24 17:01:42.879
  STEP: submitting the pod to kubernetes @ 05/05/24 17:01:42.879
  E0505 17:01:43.206545      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:44.206641      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 05/05/24 17:01:44.894
  STEP: updating the pod @ 05/05/24 17:01:44.896
  E0505 17:01:45.206891      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:01:45.402: INFO: Successfully updated pod "pod-update-d45d26ae-1cea-4f37-8777-8ea9d23157e0"
  STEP: verifying the updated pod is in kubernetes @ 05/05/24 17:01:45.404
  May  5 17:01:45.406: INFO: Pod update OK
  May  5 17:01:45.406: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-357" for this suite. @ 05/05/24 17:01:45.407
• [2.550 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:627
  STEP: Creating a kubernetes client @ 05/05/24 17:01:45.412
  May  5 17:01:45.412: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename job @ 05/05/24 17:01:45.413
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:01:45.428
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:01:45.432
  STEP: Creating a job @ 05/05/24 17:01:45.437
  STEP: Ensuring active pods == parallelism @ 05/05/24 17:01:45.443
  E0505 17:01:46.208022      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:47.208896      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete a job @ 05/05/24 17:01:47.448
  STEP: deleting Job.batch foo in namespace job-6993, will wait for the garbage collector to delete the pods @ 05/05/24 17:01:47.448
  May  5 17:01:47.515: INFO: Deleting Job.batch foo took: 12.621175ms
  May  5 17:01:47.617: INFO: Terminating Job.batch foo pods took: 102.015647ms
  E0505 17:01:48.209314      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:49.209514      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 05/05/24 17:01:49.317
  May  5 17:01:49.319: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-6993" for this suite. @ 05/05/24 17:01:49.32
• [3.910 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:134
  STEP: Creating a kubernetes client @ 05/05/24 17:01:49.322
  May  5 17:01:49.322: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename container-probe @ 05/05/24 17:01:49.323
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:01:49.333
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:01:49.336
  STEP: Creating pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569 @ 05/05/24 17:01:49.338
  E0505 17:01:50.211859      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:51.211930      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/05/24 17:01:51.349
  May  5 17:01:51.350: INFO: Initial restart count of pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d is 0
  May  5 17:01:51.351: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:01:52.212478      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:53.212924      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:01:53.357: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:01:54.213367      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:55.213823      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:01:55.369: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:01:56.214382      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:57.215827      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:01:57.372: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:01:58.216137      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:01:59.216622      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:01:59.381: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:00.216394      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:01.216881      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:01.388: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:02.217236      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:03.218363      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:03.399: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:04.219849      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:05.219570      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:05.404: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:06.220350      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:07.221360      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:07.409: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:08.222699      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:09.223732      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:09.415: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:10.224441      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:11.225421      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:11.421: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:12.226601      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:13.227100      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:13.427: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:14.227487      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:15.227761      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:15.431: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:16.228387      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:17.228713      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:17.433: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:18.228947      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:19.229181      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:19.439: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:20.229649      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:21.229679      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:21.441: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:22.231470      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:23.232519      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:23.445: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:24.232658      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:25.234303      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:25.447: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:26.235543      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:27.235819      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:27.453: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:28.240608      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:29.246778      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:29.455: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:30.246645      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:31.251289      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:31.462: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:32.251056      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:33.252290      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:33.468: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:34.252731      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:35.253238      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:35.473: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:36.254090      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:37.255308      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:37.476: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:38.256449      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:39.257830      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:39.479: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  E0505 17:02:40.257874      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:41.258879      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:41.481: INFO: Get pod busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d in namespace container-probe-5569
  May  5 17:02:41.481: INFO: Restart count of pod container-probe-5569/busybox-1bc8463e-5228-4b08-8ba9-9af3edc3750d is now 1 (50.131190809s elapsed)
  STEP: deleting the pod @ 05/05/24 17:02:41.481
  May  5 17:02:41.487: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-5569" for this suite. @ 05/05/24 17:02:41.496
• [52.182 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:889
  STEP: Creating a kubernetes client @ 05/05/24 17:02:41.505
  May  5 17:02:41.505: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename resourcequota @ 05/05/24 17:02:41.506
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:02:41.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:02:41.52
  STEP: Creating a ResourceQuota @ 05/05/24 17:02:41.523
  STEP: Getting a ResourceQuota @ 05/05/24 17:02:41.528
  STEP: Updating a ResourceQuota @ 05/05/24 17:02:41.534
  STEP: Verifying a ResourceQuota was modified @ 05/05/24 17:02:41.537
  STEP: Deleting a ResourceQuota @ 05/05/24 17:02:41.539
  STEP: Verifying the deleted ResourceQuota @ 05/05/24 17:02:41.542
  May  5 17:02:41.545: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5017" for this suite. @ 05/05/24 17:02:41.55
• [0.048 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:245
  STEP: Creating a kubernetes client @ 05/05/24 17:02:41.553
  May  5 17:02:41.553: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename namespaces @ 05/05/24 17:02:41.555
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:02:41.568
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:02:41.571
  STEP: Creating a test namespace @ 05/05/24 17:02:41.573
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:02:41.583
  STEP: Creating a pod in the namespace @ 05/05/24 17:02:41.587
  STEP: Waiting for the pod to have running status @ 05/05/24 17:02:41.595
  E0505 17:02:42.267408      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:43.268074      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the namespace @ 05/05/24 17:02:43.608
  STEP: Waiting for the namespace to be removed. @ 05/05/24 17:02:43.615
  E0505 17:02:44.268524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:45.268675      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:46.269067      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:47.269493      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:48.269749      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:49.269784      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:50.269839      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:51.304408      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:52.304910      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:53.305600      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:54.305812      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 05/05/24 17:02:54.619
  STEP: Verifying there are no pods in the namespace @ 05/05/24 17:02:54.625
  May  5 17:02:54.626: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1121" for this suite. @ 05/05/24 17:02:54.628
  STEP: Destroying namespace "nsdeletetest-3361" for this suite. @ 05/05/24 17:02:54.633
  May  5 17:02:54.637: INFO: Namespace nsdeletetest-3361 was already deleted
  STEP: Destroying namespace "nsdeletetest-3046" for this suite. @ 05/05/24 17:02:54.637
• [13.088 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:372
  STEP: Creating a kubernetes client @ 05/05/24 17:02:54.641
  May  5 17:02:54.641: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename namespaces @ 05/05/24 17:02:54.642
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:02:54.654
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:02:54.657
  STEP: Updating Namespace "namespaces-7979" @ 05/05/24 17:02:54.659
  May  5 17:02:54.667: INFO: Namespace "namespaces-7979" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"36ac1179-7441-4802-bd3c-1c2016f45a78", "kubernetes.io/metadata.name":"namespaces-7979", "namespaces-7979":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  May  5 17:02:54.667: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-7979" for this suite. @ 05/05/24 17:02:54.671
• [0.034 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 05/05/24 17:02:54.675
  May  5 17:02:54.675: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename csiinlinevolumes @ 05/05/24 17:02:54.677
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:02:54.691
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:02:54.695
  STEP: Creating two CSIDrivers @ 05/05/24 17:02:54.699
  STEP: Getting "inline-driver-7eb590ae-4305-4003-90b4-f26676f4d652" & "inline-driver-7713fe48-b2af-4757-9c81-85d65bde598e" @ 05/05/24 17:02:54.72
  STEP: Patching the CSIDriver "inline-driver-7713fe48-b2af-4757-9c81-85d65bde598e" @ 05/05/24 17:02:54.729
  STEP: Updating the CSIDriver "inline-driver-7713fe48-b2af-4757-9c81-85d65bde598e" @ 05/05/24 17:02:54.736
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-5274" @ 05/05/24 17:02:54.746
  STEP: Deleting CSIDriver "inline-driver-7eb590ae-4305-4003-90b4-f26676f4d652" @ 05/05/24 17:02:54.751
  STEP: Confirm deletion of CSIDriver "inline-driver-7eb590ae-4305-4003-90b4-f26676f4d652" @ 05/05/24 17:02:54.758
  STEP: Deleting CSIDriver "inline-driver-7713fe48-b2af-4757-9c81-85d65bde598e" via DeleteCollection @ 05/05/24 17:02:54.761
  STEP: Confirm deletion of CSIDriver "inline-driver-7713fe48-b2af-4757-9c81-85d65bde598e" @ 05/05/24 17:02:54.768
  May  5 17:02:54.771: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-5274" for this suite. @ 05/05/24 17:02:54.775
• [0.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 05/05/24 17:02:54.783
  May  5 17:02:54.783: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename pods @ 05/05/24 17:02:54.784
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:02:54.805
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:02:54.809
  STEP: Create set of pods @ 05/05/24 17:02:54.813
  May  5 17:02:54.830: INFO: created test-pod-1
  May  5 17:02:54.838: INFO: created test-pod-2
  May  5 17:02:54.848: INFO: created test-pod-3
  STEP: waiting for all 3 pods to be running @ 05/05/24 17:02:54.848
  E0505 17:02:55.305718      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:02:56.306468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 05/05/24 17:02:56.917
  May  5 17:02:56.919: INFO: Pod quantity 3 is different from expected quantity 0
  E0505 17:02:57.306416      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:57.923: INFO: Pod quantity 3 is different from expected quantity 0
  E0505 17:02:58.309508      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:58.923: INFO: Pod quantity 3 is different from expected quantity 0
  E0505 17:02:59.311444      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:02:59.921: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-76" for this suite. @ 05/05/24 17:02:59.924
• [5.146 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:120
  STEP: Creating a kubernetes client @ 05/05/24 17:02:59.929
  May  5 17:02:59.929: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename emptydir @ 05/05/24 17:02:59.93
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:02:59.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:02:59.941
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 05/05/24 17:02:59.943
  E0505 17:03:00.311374      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:01.311583      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:02.312568      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:03.312782      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:03:03.957
  May  5 17:03:03.959: INFO: Trying to get logs from node worker00 pod pod-41ea8a08-a16f-4fad-8390-ff657c356c71 container test-container: <nil>
  STEP: delete the pod @ 05/05/24 17:03:03.963
  May  5 17:03:03.973: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7993" for this suite. @ 05/05/24 17:03:03.975
• [4.049 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:371
  STEP: Creating a kubernetes client @ 05/05/24 17:03:03.979
  May  5 17:03:03.979: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename webhook @ 05/05/24 17:03:03.98
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:03:03.988
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:03:03.991
  STEP: Setting up server cert @ 05/05/24 17:03:04.005
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/05/24 17:03:04.217
  STEP: Deploying the webhook pod @ 05/05/24 17:03:04.23
  STEP: Wait for the deployment to be ready @ 05/05/24 17:03:04.237
  May  5 17:03:04.243: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0505 17:03:04.313855      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:05.315362      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/05/24 17:03:06.253
  STEP: Verifying the service has paired with the endpoint @ 05/05/24 17:03:06.277
  E0505 17:03:06.315481      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:03:07.278: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 05/05/24 17:03:07.286
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/05/24 17:03:07.286
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 05/05/24 17:03:07.311
  E0505 17:03:07.316547      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:08.317100      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 05/05/24 17:03:08.332
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/05/24 17:03:08.332
  E0505 17:03:09.317566      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 05/05/24 17:03:09.37
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/05/24 17:03:09.37
  E0505 17:03:10.319763      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:11.320907      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:12.321615      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:13.322186      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:14.323027      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 05/05/24 17:03:14.398
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/05/24 17:03:14.398
  E0505 17:03:15.322793      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:16.323588      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:17.324563      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:18.324897      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:19.325897      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:03:19.478: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8925" for this suite. @ 05/05/24 17:03:19.484
  STEP: Destroying namespace "webhook-markers-2328" for this suite. @ 05/05/24 17:03:19.5
• [15.531 seconds]
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 05/05/24 17:03:19.51
  May  5 17:03:19.510: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename sched-preemption @ 05/05/24 17:03:19.512
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:03:19.533
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:03:19.538
  May  5 17:03:19.569: INFO: Waiting up to 1m0s for all nodes to be ready
  E0505 17:03:20.326652      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:21.327344      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:22.328131      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:23.328725      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:24.329270      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:25.329448      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:26.330183      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:27.332484      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:28.332575      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:29.332941      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:30.334653      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:31.335018      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:32.337172      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:33.337497      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:34.337594      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:35.338581      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:36.338811      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:37.339400      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:38.340491      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:39.340619      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:40.341442      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:41.342011      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:42.342863      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:43.343440      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:44.344699      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:45.344857      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:46.345966      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:47.347988      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:48.351031      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:49.351951      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:50.352585      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:51.353201      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:52.353936      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:53.356962      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:54.357326      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:55.357976      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:56.358452      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:57.358620      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:58.358871      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:03:59.359381      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:00.360559      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:01.360554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:02.360832      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:03.361364      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:04.369847      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:05.374553      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:06.376194      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:07.376566      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:08.377216      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:09.380612      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:10.381529      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:11.382626      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:12.383506      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:13.384444      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:14.384668      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:15.384926      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:16.385805      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:17.387048      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:18.388128      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:19.391347      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:04:19.572: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 05/05/24 17:04:19.574
  May  5 17:04:19.590: INFO: Created pod: pod0-0-sched-preemption-low-priority
  May  5 17:04:19.600: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  May  5 17:04:19.623: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  May  5 17:04:19.632: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 05/05/24 17:04:19.632
  E0505 17:04:20.392507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:21.393675      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 05/05/24 17:04:21.659
  E0505 17:04:22.393710      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:23.395352      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:24.396076      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:25.397480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:04:25.740: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-5896" for this suite. @ 05/05/24 17:04:25.742
• [66.234 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3338
  STEP: Creating a kubernetes client @ 05/05/24 17:04:25.744
  May  5 17:04:25.744: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename services @ 05/05/24 17:04:25.745
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:04:25.752
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:04:25.755
  STEP: creating a Service @ 05/05/24 17:04:25.76
  STEP: watching for the Service to be added @ 05/05/24 17:04:25.765
  May  5 17:04:25.768: INFO: Found Service test-service-dx2nj in namespace services-7267 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 30357}]
  May  5 17:04:25.768: INFO: Service test-service-dx2nj created
  STEP: Getting /status @ 05/05/24 17:04:25.768
  May  5 17:04:25.771: INFO: Service test-service-dx2nj has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 05/05/24 17:04:25.771
  STEP: watching for the Service to be patched @ 05/05/24 17:04:25.782
  May  5 17:04:25.785: INFO: observed Service test-service-dx2nj in namespace services-7267 with annotations: map[] & LoadBalancer: {[]}
  May  5 17:04:25.785: INFO: observed Service test-service-dx2nj in namespace services-7267 with annotations: map[] & LoadBalancer: {[{192.168.0.16  <nil> []}]}
  May  5 17:04:25.785: INFO: Found Service test-service-dx2nj in namespace services-7267 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  <nil> []}]}
  May  5 17:04:25.785: INFO: Service test-service-dx2nj has service status patched
  STEP: updating the ServiceStatus @ 05/05/24 17:04:25.785
  May  5 17:04:25.798: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 05/05/24 17:04:25.798
  May  5 17:04:25.801: INFO: Observed Service test-service-dx2nj in namespace services-7267 with annotations: map[] & Conditions: {[]}
  May  5 17:04:25.801: INFO: Observed Service test-service-dx2nj in namespace services-7267 with annotations: map[] & Conditions: {[{192.168.0.16  <nil> []}]}
  May  5 17:04:25.801: INFO: Observed event: &Service{ObjectMeta:{test-service-dx2nj  services-7267  c56f180e-8a5b-44e7-b25a-2140c64b68f1 30832 0 2024-05-05 17:04:25 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2024-05-05 17:04:25 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:allocateLoadBalancerNodePorts":{},"f:externalTrafficPolicy":{},"f:internalTrafficPolicy":{},"f:loadBalancerClass":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2024-05-05 17:04:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:30357,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.32.0.119,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.32.0.119],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:*example.com/internal-vip,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,IPMode:nil,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  May  5 17:04:25.801: INFO: Observed event: &Service{ObjectMeta:{test-service-dx2nj  services-7267  c56f180e-8a5b-44e7-b25a-2140c64b68f1 30833 0 2024-05-05 17:04:25 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{controller Update v1 2024-05-05 17:04:25 +0000 UTC FieldsV1 {"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status} {e2e.test Update v1 2024-05-05 17:04:25 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:allocateLoadBalancerNodePorts":{},"f:externalTrafficPolicy":{},"f:internalTrafficPolicy":{},"f:loadBalancerClass":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2024-05-05 17:04:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:30357,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.32.0.119,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.32.0.119],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:*example.com/internal-vip,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:192.168.0.16,Hostname:,IPMode:nil,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  May  5 17:04:25.801: INFO: Found Service test-service-dx2nj in namespace services-7267 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  May  5 17:04:25.801: INFO: Service test-service-dx2nj has service status updated
  STEP: patching the service @ 05/05/24 17:04:25.801
  STEP: watching for the Service to be patched @ 05/05/24 17:04:25.809
  May  5 17:04:25.813: INFO: observed Service test-service-dx2nj in namespace services-7267 with labels: map[test-service-static:true]
  May  5 17:04:25.813: INFO: observed Service test-service-dx2nj in namespace services-7267 with labels: map[test-service-static:true]
  May  5 17:04:25.813: INFO: observed Service test-service-dx2nj in namespace services-7267 with labels: map[test-service-static:true]
  May  5 17:04:25.813: INFO: observed Service test-service-dx2nj in namespace services-7267 with labels: map[test-service-static:true]
  May  5 17:04:25.813: INFO: observed Service test-service-dx2nj in namespace services-7267 with labels: map[test-service-static:true]
  May  5 17:04:25.813: INFO: Found Service test-service-dx2nj in namespace services-7267 with labels: map[test-service:patched test-service-static:true]
  May  5 17:04:25.813: INFO: Service test-service-dx2nj patched
  STEP: deleting the service @ 05/05/24 17:04:25.813
  STEP: watching for the Service to be deleted @ 05/05/24 17:04:25.828
  May  5 17:04:25.830: INFO: Observed event: ADDED
  May  5 17:04:25.830: INFO: Observed event: MODIFIED
  May  5 17:04:25.830: INFO: Observed event: MODIFIED
  May  5 17:04:25.830: INFO: Observed event: MODIFIED
  May  5 17:04:25.830: INFO: Observed event: MODIFIED
  May  5 17:04:25.831: INFO: Observed event: MODIFIED
  May  5 17:04:25.831: INFO: Found Service test-service-dx2nj in namespace services-7267 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  May  5 17:04:25.831: INFO: Service test-service-dx2nj deleted
  May  5 17:04:25.831: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7267" for this suite. @ 05/05/24 17:04:25.835
• [0.095 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 05/05/24 17:04:25.839
  May  5 17:04:25.839: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename containers @ 05/05/24 17:04:25.841
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:04:25.852
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:04:25.854
  STEP: Creating a pod to test override all @ 05/05/24 17:04:25.857
  E0505 17:04:26.397946      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:27.400090      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:04:27.869
  May  5 17:04:27.871: INFO: Trying to get logs from node worker00 pod client-containers-9d527667-c51d-4556-bb60-1fe48e5f47f1 container agnhost-container: <nil>
  STEP: delete the pod @ 05/05/24 17:04:27.874
  May  5 17:04:27.882: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-3215" for this suite. @ 05/05/24 17:04:27.885
• [2.050 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 05/05/24 17:04:27.889
  May  5 17:04:27.889: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename watch @ 05/05/24 17:04:27.891
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:04:27.902
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:04:27.904
  STEP: getting a starting resourceVersion @ 05/05/24 17:04:27.906
  STEP: starting a background goroutine to produce watch events @ 05/05/24 17:04:27.908
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 05/05/24 17:04:27.908
  E0505 17:04:28.400658      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:29.400901      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:30.401007      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:04:30.698: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3549" for this suite. @ 05/05/24 17:04:30.747
• [2.905 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1632
  STEP: Creating a kubernetes client @ 05/05/24 17:04:30.794
  May  5 17:04:30.794: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubectl @ 05/05/24 17:04:30.795
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:04:30.801
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:04:30.805
  STEP: creating the pod @ 05/05/24 17:04:30.809
  May  5 17:04:30.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-8488 create -f -'
  May  5 17:04:31.015: INFO: stderr: ""
  May  5 17:04:31.015: INFO: stdout: "pod/pause created\n"
  E0505 17:04:31.401411      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:32.402101      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 05/05/24 17:04:33.026
  May  5 17:04:33.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-8488 label pods pause testing-label=testing-label-value'
  May  5 17:04:33.116: INFO: stderr: ""
  May  5 17:04:33.116: INFO: stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 05/05/24 17:04:33.116
  May  5 17:04:33.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-8488 get pod pause -L testing-label'
  May  5 17:04:33.179: INFO: stderr: ""
  May  5 17:04:33.179: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 05/05/24 17:04:33.179
  May  5 17:04:33.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-8488 label pods pause testing-label-'
  May  5 17:04:33.231: INFO: stderr: ""
  May  5 17:04:33.231: INFO: stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 05/05/24 17:04:33.231
  May  5 17:04:33.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-8488 get pod pause -L testing-label'
  May  5 17:04:33.275: INFO: stderr: ""
  May  5 17:04:33.275: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
  STEP: using delete to clean up resources @ 05/05/24 17:04:33.275
  May  5 17:04:33.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-8488 delete --grace-period=0 --force -f -'
  May  5 17:04:33.324: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May  5 17:04:33.324: INFO: stdout: "pod \"pause\" force deleted\n"
  May  5 17:04:33.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-8488 get rc,svc -l name=pause --no-headers'
  May  5 17:04:33.376: INFO: stderr: "No resources found in kubectl-8488 namespace.\n"
  May  5 17:04:33.376: INFO: stdout: ""
  May  5 17:04:33.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-8488 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  E0505 17:04:33.402433      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:04:33.417: INFO: stderr: ""
  May  5 17:04:33.417: INFO: stdout: ""
  May  5 17:04:33.418: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8488" for this suite. @ 05/05/24 17:04:33.42
• [2.630 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:177
  STEP: Creating a kubernetes client @ 05/05/24 17:04:33.424
  May  5 17:04:33.424: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename crd-webhook @ 05/05/24 17:04:33.426
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:04:33.441
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:04:33.444
  STEP: Setting up server cert @ 05/05/24 17:04:33.446
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 05/05/24 17:04:33.825
  STEP: Deploying the custom resource conversion webhook pod @ 05/05/24 17:04:33.841
  STEP: Wait for the deployment to be ready @ 05/05/24 17:04:33.859
  May  5 17:04:33.873: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0505 17:04:34.403190      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:35.403615      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/05/24 17:04:35.877
  STEP: Verifying the service has paired with the endpoint @ 05/05/24 17:04:35.881
  E0505 17:04:36.404007      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:04:36.882: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  May  5 17:04:36.889: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  E0505 17:04:37.404402      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:38.404410      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:39.405393      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 05/05/24 17:04:39.472
  STEP: Create a v2 custom resource @ 05/05/24 17:04:39.482
  STEP: List CRs in v1 @ 05/05/24 17:04:39.505
  STEP: List CRs in v2 @ 05/05/24 17:04:39.507
  May  5 17:04:40.049: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-2029" for this suite. @ 05/05/24 17:04:40.052
• [6.641 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 05/05/24 17:04:40.065
  May  5 17:04:40.065: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename watch @ 05/05/24 17:04:40.066
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:04:40.082
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:04:40.085
  STEP: creating a watch on configmaps with label A @ 05/05/24 17:04:40.087
  STEP: creating a watch on configmaps with label B @ 05/05/24 17:04:40.088
  STEP: creating a watch on configmaps with label A or B @ 05/05/24 17:04:40.089
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 05/05/24 17:04:40.09
  May  5 17:04:40.095: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6037  44e6156f-22f4-4dae-bce4-0c17686ed978 31183 0 2024-05-05 17:04:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-05 17:04:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  May  5 17:04:40.095: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6037  44e6156f-22f4-4dae-bce4-0c17686ed978 31183 0 2024-05-05 17:04:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-05 17:04:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 05/05/24 17:04:40.095
  May  5 17:04:40.102: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6037  44e6156f-22f4-4dae-bce4-0c17686ed978 31184 0 2024-05-05 17:04:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-05 17:04:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  May  5 17:04:40.102: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6037  44e6156f-22f4-4dae-bce4-0c17686ed978 31184 0 2024-05-05 17:04:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-05 17:04:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 05/05/24 17:04:40.102
  May  5 17:04:40.106: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6037  44e6156f-22f4-4dae-bce4-0c17686ed978 31185 0 2024-05-05 17:04:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-05 17:04:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May  5 17:04:40.107: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6037  44e6156f-22f4-4dae-bce4-0c17686ed978 31185 0 2024-05-05 17:04:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-05 17:04:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 05/05/24 17:04:40.107
  May  5 17:04:40.116: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6037  44e6156f-22f4-4dae-bce4-0c17686ed978 31186 0 2024-05-05 17:04:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-05 17:04:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May  5 17:04:40.116: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6037  44e6156f-22f4-4dae-bce4-0c17686ed978 31186 0 2024-05-05 17:04:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-05 17:04:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 05/05/24 17:04:40.117
  May  5 17:04:40.121: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6037  d827a115-e82d-4259-bf64-667957626cee 31187 0 2024-05-05 17:04:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-05-05 17:04:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  May  5 17:04:40.121: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6037  d827a115-e82d-4259-bf64-667957626cee 31187 0 2024-05-05 17:04:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-05-05 17:04:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0505 17:04:40.406863      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:41.407212      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:42.407729      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:43.412659      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:44.415320      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:45.416181      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:46.416685      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:47.417999      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:48.418285      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:49.419522      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 05/05/24 17:04:50.122
  May  5 17:04:50.130: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6037  d827a115-e82d-4259-bf64-667957626cee 31235 0 2024-05-05 17:04:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-05-05 17:04:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  May  5 17:04:50.130: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6037  d827a115-e82d-4259-bf64-667957626cee 31235 0 2024-05-05 17:04:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-05-05 17:04:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0505 17:04:50.420921      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:51.422687      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:52.422990      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:53.433248      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:54.433538      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:55.434843      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:56.435239      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:57.435834      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:58.439127      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:04:59.440328      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:05:00.131: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-6037" for this suite. @ 05/05/24 17:05:00.136
• [20.087 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 05/05/24 17:05:00.153
  May  5 17:05:00.153: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename dns @ 05/05/24 17:05:00.155
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:05:00.164
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:05:00.168
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 05/05/24 17:05:00.17
  May  5 17:05:00.175: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-136  16079ec2-e90a-4b55-8316-25b2825110b6 31275 0 2024-05-05 17:05:00 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2024-05-05 17:05:00 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p9r5b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.47,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p9r5b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  E0505 17:05:00.441451      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:01.441591      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 05/05/24 17:05:02.181
  May  5 17:05:02.182: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-136 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 17:05:02.182: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 17:05:02.182: INFO: ExecWithOptions: Clientset creation
  May  5 17:05:02.183: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/dns-136/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 05/05/24 17:05:02.234
  May  5 17:05:02.234: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-136 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 17:05:02.234: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 17:05:02.234: INFO: ExecWithOptions: Clientset creation
  May  5 17:05:02.234: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/dns-136/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  May  5 17:05:02.272: INFO: Deleting pod test-dns-nameservers...
  May  5 17:05:02.279: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-136" for this suite. @ 05/05/24 17:05:02.282
• [2.139 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:70
  STEP: Creating a kubernetes client @ 05/05/24 17:05:02.293
  May  5 17:05:02.293: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename replication-controller @ 05/05/24 17:05:02.294
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:05:02.304
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:05:02.307
  STEP: Creating replication controller my-hostname-basic-582bb6d1-5256-44d3-9c19-a4db062d6b51 @ 05/05/24 17:05:02.309
  May  5 17:05:02.313: INFO: Pod name my-hostname-basic-582bb6d1-5256-44d3-9c19-a4db062d6b51: Found 0 pods out of 1
  E0505 17:05:02.442718      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:03.443318      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:04.444191      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:05.444342      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:06.444706      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:05:07.316: INFO: Pod name my-hostname-basic-582bb6d1-5256-44d3-9c19-a4db062d6b51: Found 1 pods out of 1
  May  5 17:05:07.316: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-582bb6d1-5256-44d3-9c19-a4db062d6b51" are running
  May  5 17:05:07.323: INFO: Pod "my-hostname-basic-582bb6d1-5256-44d3-9c19-a4db062d6b51-7jlgp" is running and ready(conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-05 17:05:02 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-05 17:05:02 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-05 17:05:02 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-05 17:05:02 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-05 17:05:02 +0000 UTC Reason: Message:}])
  May  5 17:05:07.323: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 05/05/24 17:05:07.323
  May  5 17:05:07.339: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-733" for this suite. @ 05/05/24 17:05:07.345
• [5.060 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 05/05/24 17:05:07.354
  May  5 17:05:07.354: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename emptydir-wrapper @ 05/05/24 17:05:07.359
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:05:07.386
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:05:07.394
  E0505 17:05:07.448919      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:08.449669      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the secret @ 05/05/24 17:05:09.447
  E0505 17:05:09.450207      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the configmap @ 05/05/24 17:05:09.454
  STEP: Cleaning up the pod @ 05/05/24 17:05:09.458
  May  5 17:05:09.467: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-3131" for this suite. @ 05/05/24 17:05:09.47
• [2.122 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 05/05/24 17:05:09.476
  May  5 17:05:09.476: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename prestop @ 05/05/24 17:05:09.476
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:05:09.487
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:05:09.489
  STEP: Creating server pod server in namespace prestop-6276 @ 05/05/24 17:05:09.492
  STEP: Waiting for pods to come up. @ 05/05/24 17:05:09.499
  E0505 17:05:10.450841      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:11.451618      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating tester pod tester in namespace prestop-6276 @ 05/05/24 17:05:11.511
  E0505 17:05:12.452997      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:13.454045      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pre-stop pod @ 05/05/24 17:05:13.534
  E0505 17:05:14.454336      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:15.458295      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:16.461880      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:17.463791      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:18.465687      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:05:18.547: INFO: Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 05/05/24 17:05:18.547
  May  5 17:05:18.574: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-6276" for this suite. @ 05/05/24 17:05:18.581
• [9.111 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:751
  STEP: Creating a kubernetes client @ 05/05/24 17:05:18.587
  May  5 17:05:18.587: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename statefulset @ 05/05/24 17:05:18.588
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:05:18.61
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:05:18.616
  STEP: Creating service test in namespace statefulset-4228 @ 05/05/24 17:05:18.62
  STEP: Creating stateful set ss in namespace statefulset-4228 @ 05/05/24 17:05:18.631
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4228 @ 05/05/24 17:05:18.64
  May  5 17:05:18.650: INFO: Found 0 stateful pods, waiting for 1
  E0505 17:05:19.466001      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:20.467428      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:21.468215      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:22.469028      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:23.469195      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:24.470911      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:25.471345      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:26.472036      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:27.472020      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:28.472833      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:05:28.646: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 05/05/24 17:05:28.646
  May  5 17:05:28.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=statefulset-4228 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May  5 17:05:28.745: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May  5 17:05:28.745: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May  5 17:05:28.745: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May  5 17:05:28.747: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0505 17:05:29.473654      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:30.493813      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:31.495825      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:32.500614      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:33.502792      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:34.503189      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:35.504189      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:36.506791      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:37.508634      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:38.508463      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:05:38.751: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  May  5 17:05:38.751: INFO: Waiting for statefulset status.readyReplicas updated to 0
  May  5 17:05:38.777: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
  May  5 17:05:38.777: INFO: ss-0  worker00  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:19 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:18 +0000 UTC  }]
  May  5 17:05:38.777: INFO: 
  May  5 17:05:38.777: INFO: StatefulSet ss has not reached scale 3, at 1
  E0505 17:05:39.508492      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:05:39.780: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995303168s
  E0505 17:05:40.509269      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:05:40.784: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992727057s
  E0505 17:05:41.510610      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:05:41.806: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.972587102s
  E0505 17:05:42.512971      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:05:42.814: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.966202149s
  E0505 17:05:43.513504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:05:43.819: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.958914618s
  E0505 17:05:44.513965      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:05:44.830: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.952536956s
  E0505 17:05:45.514672      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:05:45.836: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.942816177s
  E0505 17:05:46.515826      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:05:46.842: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.935036278s
  E0505 17:05:47.516579      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:05:47.848: INFO: Verifying statefulset ss doesn't scale past 3 for another 929.289753ms
  E0505 17:05:48.517143      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4228 @ 05/05/24 17:05:48.848
  May  5 17:05:48.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=statefulset-4228 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May  5 17:05:48.933: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May  5 17:05:48.933: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May  5 17:05:48.933: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May  5 17:05:48.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=statefulset-4228 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May  5 17:05:49.010: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  May  5 17:05:49.010: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May  5 17:05:49.010: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May  5 17:05:49.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=statefulset-4228 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May  5 17:05:49.107: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  May  5 17:05:49.107: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May  5 17:05:49.107: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May  5 17:05:49.109: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  May  5 17:05:49.109: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  May  5 17:05:49.109: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 05/05/24 17:05:49.109
  May  5 17:05:49.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=statefulset-4228 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May  5 17:05:49.204: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May  5 17:05:49.204: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May  5 17:05:49.204: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May  5 17:05:49.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=statefulset-4228 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May  5 17:05:49.301: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May  5 17:05:49.301: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May  5 17:05:49.301: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May  5 17:05:49.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=statefulset-4228 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May  5 17:05:49.372: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May  5 17:05:49.372: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May  5 17:05:49.372: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May  5 17:05:49.372: INFO: Waiting for statefulset status.readyReplicas updated to 0
  May  5 17:05:49.373: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 3
  E0505 17:05:49.520618      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:50.520858      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:51.522142      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:52.522920      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:53.523707      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:54.524612      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:55.525502      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:56.526512      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:57.527687      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:05:58.528202      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:05:59.382: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  May  5 17:05:59.382: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  May  5 17:05:59.382: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  May  5 17:05:59.403: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
  May  5 17:05:59.403: INFO: ss-0  worker00  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:19 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:18 +0000 UTC  }]
  May  5 17:05:59.404: INFO: ss-1  worker01  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:39 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:38 +0000 UTC  }]
  May  5 17:05:59.404: INFO: ss-2  worker00  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:40 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:38 +0000 UTC  }]
  May  5 17:05:59.404: INFO: 
  May  5 17:05:59.404: INFO: StatefulSet ss has not reached scale 0, at 3
  E0505 17:05:59.528620      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:06:00.409: INFO: POD   NODE      PHASE      GRACE  CONDITIONS
  May  5 17:06:00.409: INFO: ss-1  worker01  Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:39 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:50 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:50 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-05 17:05:38 +0000 UTC  }]
  May  5 17:06:00.410: INFO: 
  May  5 17:06:00.410: INFO: StatefulSet ss has not reached scale 0, at 1
  E0505 17:06:00.529641      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:06:01.418: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.990040317s
  E0505 17:06:01.531405      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:06:02.424: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.980692414s
  E0505 17:06:02.531311      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:06:03.429: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.975061728s
  E0505 17:06:03.532059      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:06:04.435: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.968689054s
  E0505 17:06:04.534362      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:06:05.441: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.963748323s
  E0505 17:06:05.534887      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:06:06.444: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.958162308s
  E0505 17:06:06.535642      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:06:07.448: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.955252287s
  E0505 17:06:07.536363      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:06:08.451: INFO: Verifying statefulset ss doesn't scale past 0 for another 950.421453ms
  E0505 17:06:08.536613      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4228 @ 05/05/24 17:06:09.453
  May  5 17:06:09.459: INFO: Scaling statefulset ss to 0
  May  5 17:06:09.466: INFO: Waiting for statefulset status.replicas updated to 0
  May  5 17:06:09.469: INFO: Deleting all statefulset in ns statefulset-4228
  May  5 17:06:09.471: INFO: Scaling statefulset ss to 0
  May  5 17:06:09.475: INFO: Waiting for statefulset status.replicas updated to 0
  May  5 17:06:09.476: INFO: Deleting statefulset ss
  May  5 17:06:09.485: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4228" for this suite. @ 05/05/24 17:06:09.488
• [50.904 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:836
  STEP: Creating a kubernetes client @ 05/05/24 17:06:09.492
  May  5 17:06:09.492: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename daemonsets @ 05/05/24 17:06:09.494
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:06:09.502
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:06:09.505
  STEP: Creating simple DaemonSet "daemon-set" @ 05/05/24 17:06:09.515
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/05/24 17:06:09.517
  May  5 17:06:09.524: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 17:06:09.524: INFO: Node worker00 is running 0 daemon pod, expected 1
  E0505 17:06:09.537046      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:06:10.521: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May  5 17:06:10.521: INFO: Node worker01 is running 0 daemon pod, expected 1
  E0505 17:06:10.537124      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:06:11.526: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May  5 17:06:11.526: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: listing all DaemonSets @ 05/05/24 17:06:11.53
  STEP: DeleteCollection of the DaemonSets @ 05/05/24 17:06:11.532
  STEP: Verify that ReplicaSets have been deleted @ 05/05/24 17:06:11.536
  E0505 17:06:11.540761      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:06:11.551: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"31903"},"items":null}

  May  5 17:06:11.556: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"31903"},"items":[{"metadata":{"name":"daemon-set-67svx","generateName":"daemon-set-","namespace":"daemonsets-7412","uid":"34346ccc-492a-4ab2-8403-413897406f76","resourceVersion":"31902","creationTimestamp":"2024-05-05T17:06:09Z","deletionTimestamp":"2024-05-05T17:06:41Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"b6590d7e0d8af6cd0ae6815b36cf23240d3929fff5dc3fbc5a640b0dee1d6d4c","cni.projectcalico.org/podIP":"10.200.5.18/32","cni.projectcalico.org/podIPs":"10.200.5.18/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"537993cc-fb7e-409b-ab81-f54ec54247c3","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2024-05-05T17:06:09Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-05-05T17:06:09Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"537993cc-fb7e-409b-ab81-f54ec54247c3\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-05-05T17:06:10Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.200.5.18\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-57qmg","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-57qmg","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"worker01","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["worker01"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-05T17:06:10Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-05T17:06:09Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-05T17:06:10Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-05T17:06:10Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-05T17:06:09Z"}],"hostIP":"192.168.58.101","hostIPs":[{"ip":"192.168.58.101"}],"podIP":"10.200.5.18","podIPs":[{"ip":"10.200.5.18"}],"startTime":"2024-05-05T17:06:09Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-05-05T17:06:10Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://47463f6aafe5d91d9f324ccfc6a4b1ac379d4ab60bf928dd1eb8666dc37fd672","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-8pwh5","generateName":"daemon-set-","namespace":"daemonsets-7412","uid":"0e1fa808-a38e-4bea-8620-aea48e67b791","resourceVersion":"31903","creationTimestamp":"2024-05-05T17:06:09Z","deletionTimestamp":"2024-05-05T17:06:41Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"d8249fd09fd8742bfec4fb3149852d9de001e1bf4839cc55fc4e191bb63da99c","cni.projectcalico.org/podIP":"10.200.131.134/32","cni.projectcalico.org/podIPs":"10.200.131.134/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"537993cc-fb7e-409b-ab81-f54ec54247c3","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2024-05-05T17:06:09Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-05-05T17:06:09Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"537993cc-fb7e-409b-ab81-f54ec54247c3\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-05-05T17:06:10Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.200.131.134\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-hdz9z","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-hdz9z","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"worker00","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["worker00"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-05T17:06:10Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-05T17:06:09Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-05T17:06:10Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-05T17:06:10Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-05T17:06:09Z"}],"hostIP":"192.168.58.100","hostIPs":[{"ip":"192.168.58.100"}],"podIP":"10.200.131.134","podIPs":[{"ip":"10.200.131.134"}],"startTime":"2024-05-05T17:06:09Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-05-05T17:06:10Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://eb7c27e31aab2e6dd713b2cfbfd7adfcc55a44436e610fdf37d66af103413a8a","started":true}],"qosClass":"BestEffort"}}]}

  May  5 17:06:11.563: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7412" for this suite. @ 05/05/24 17:06:11.564
• [2.077 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:62
  STEP: Creating a kubernetes client @ 05/05/24 17:06:11.569
  May  5 17:06:11.569: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename limitrange @ 05/05/24 17:06:11.57
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:06:11.58
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:06:11.581
  STEP: Creating a LimitRange @ 05/05/24 17:06:11.584
  STEP: Setting up watch @ 05/05/24 17:06:11.584
  STEP: Submitting a LimitRange @ 05/05/24 17:06:11.686
  STEP: Verifying LimitRange creation was observed @ 05/05/24 17:06:11.693
  STEP: Fetching the LimitRange to ensure it has proper values @ 05/05/24 17:06:11.693
  May  5 17:06:11.697: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  May  5 17:06:11.697: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 05/05/24 17:06:11.697
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 05/05/24 17:06:11.702
  May  5 17:06:11.707: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  May  5 17:06:11.707: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 05/05/24 17:06:11.707
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 05/05/24 17:06:11.713
  May  5 17:06:11.718: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  May  5 17:06:11.718: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 05/05/24 17:06:11.718
  STEP: Failing to create a Pod with more than max resources @ 05/05/24 17:06:11.72
  STEP: Updating a LimitRange @ 05/05/24 17:06:11.723
  STEP: Verifying LimitRange updating is effective @ 05/05/24 17:06:11.729
  E0505 17:06:12.540772      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:13.541674      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 05/05/24 17:06:13.732
  STEP: Failing to create a Pod with more than max resources @ 05/05/24 17:06:13.736
  STEP: Deleting a LimitRange @ 05/05/24 17:06:13.739
  STEP: Verifying the LimitRange was deleted @ 05/05/24 17:06:13.742
  E0505 17:06:14.541914      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:15.542759      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:16.543312      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:17.544506      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:18.544725      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:06:18.750: INFO: limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 05/05/24 17:06:18.75
  May  5 17:06:18.771: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-7284" for this suite. @ 05/05/24 17:06:18.776
• [7.211 seconds]
------------------------------
S
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:168
  STEP: Creating a kubernetes client @ 05/05/24 17:06:18.78
  May  5 17:06:18.780: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename downward-api @ 05/05/24 17:06:18.781
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:06:18.786
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:06:18.79
  STEP: Creating a pod to test downward api env vars @ 05/05/24 17:06:18.793
  E0505 17:06:19.545391      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:20.546017      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:21.548963      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:22.550224      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:06:22.81
  May  5 17:06:22.812: INFO: Trying to get logs from node worker00 pod downward-api-820f4362-1a26-4932-a439-aa0f27574667 container dapi-container: <nil>
  STEP: delete the pod @ 05/05/24 17:06:22.816
  May  5 17:06:22.826: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8851" for this suite. @ 05/05/24 17:06:22.829
• [4.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 05/05/24 17:06:22.834
  May  5 17:06:22.834: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 05/05/24 17:06:22.834
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:06:22.846
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:06:22.848
  STEP: creating a target pod @ 05/05/24 17:06:22.851
  E0505 17:06:23.550677      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:24.551084      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 05/05/24 17:06:24.862
  E0505 17:06:25.552135      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:26.552659      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:27.553551      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:28.553900      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 05/05/24 17:06:28.887
  May  5 17:06:28.887: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-3223 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 17:06:28.887: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 17:06:28.887: INFO: ExecWithOptions: Clientset creation
  May  5 17:06:28.887: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/ephemeral-containers-test-3223/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  May  5 17:06:28.919: INFO: Exec stderr: ""
  May  5 17:06:28.923: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-3223" for this suite. @ 05/05/24 17:06:28.925
• [6.094 seconds]
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:100
  STEP: Creating a kubernetes client @ 05/05/24 17:06:28.928
  May  5 17:06:28.928: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename configmap @ 05/05/24 17:06:28.929
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:06:28.94
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:06:28.942
  STEP: Creating configMap with name configmap-test-volume-map-b79fd950-39c1-435e-a249-d7e2c0bb67ed @ 05/05/24 17:06:28.944
  STEP: Creating a pod to test consume configMaps @ 05/05/24 17:06:28.946
  E0505 17:06:29.554611      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:30.555084      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:31.555547      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:32.555884      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:06:32.969
  May  5 17:06:32.972: INFO: Trying to get logs from node worker00 pod pod-configmaps-802155dd-9ab1-441d-be7b-b462c787ae07 container agnhost-container: <nil>
  STEP: delete the pod @ 05/05/24 17:06:32.976
  May  5 17:06:32.995: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9326" for this suite. @ 05/05/24 17:06:32.999
• [4.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:106
  STEP: Creating a kubernetes client @ 05/05/24 17:06:33.004
  May  5 17:06:33.004: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename runtimeclass @ 05/05/24 17:06:33.004
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:06:33.01
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:06:33.014
  E0505 17:06:33.556417      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:34.556879      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:06:35.049: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-3041" for this suite. @ 05/05/24 17:06:35.054
• [2.055 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:639
  STEP: Creating a kubernetes client @ 05/05/24 17:06:35.06
  May  5 17:06:35.060: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename gc @ 05/05/24 17:06:35.061
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:06:35.069
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:06:35.071
  STEP: create the rc @ 05/05/24 17:06:35.074
  W0505 17:06:35.079180      22 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0505 17:06:35.557830      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:36.558797      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:37.559349      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:38.561449      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:39.562715      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:40.564514      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 05/05/24 17:06:41.103
  STEP: wait for the rc to be deleted @ 05/05/24 17:06:41.117
  E0505 17:06:41.567631      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:06:42.142: INFO: 80 pods remaining
  May  5 17:06:42.142: INFO: 80 pods has nil DeletionTimestamp
  May  5 17:06:42.142: INFO: 
  E0505 17:06:42.568586      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:06:43.276: INFO: 69 pods remaining
  May  5 17:06:43.276: INFO: 68 pods has nil DeletionTimestamp
  May  5 17:06:43.276: INFO: 
  E0505 17:06:43.570672      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:06:44.198: INFO: 60 pods remaining
  May  5 17:06:44.198: INFO: 60 pods has nil DeletionTimestamp
  May  5 17:06:44.198: INFO: 
  E0505 17:06:44.573387      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:06:45.137: INFO: 40 pods remaining
  May  5 17:06:45.137: INFO: 40 pods has nil DeletionTimestamp
  May  5 17:06:45.137: INFO: 
  E0505 17:06:45.572437      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:06:46.227: INFO: 32 pods remaining
  May  5 17:06:46.227: INFO: 28 pods has nil DeletionTimestamp
  May  5 17:06:46.227: INFO: 
  E0505 17:06:46.575449      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:06:47.139: INFO: 20 pods remaining
  May  5 17:06:47.139: INFO: 20 pods has nil DeletionTimestamp
  May  5 17:06:47.139: INFO: 
  E0505 17:06:47.575587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/05/24 17:06:48.212
  May  5 17:06:48.469: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  May  5 17:06:48.470: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5445" for this suite. @ 05/05/24 17:06:48.477
• [13.434 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 05/05/24 17:06:48.494
  May  5 17:06:48.494: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename pod-network-test @ 05/05/24 17:06:48.502
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:06:48.541
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:06:48.551
  STEP: Performing setup for networking test in namespace pod-network-test-4105 @ 05/05/24 17:06:48.562
  STEP: creating a selector @ 05/05/24 17:06:48.563
  STEP: Creating the service pods in kubernetes @ 05/05/24 17:06:48.563
  May  5 17:06:48.563: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0505 17:06:48.576798      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:49.577393      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:50.577734      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:51.579174      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:52.579985      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:53.580509      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:54.581223      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:55.583174      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:56.585203      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:57.585430      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:58.585815      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:06:59.585863      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:00.586798      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:01.588810      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:02.589711      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:03.590059      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:04.590888      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:05.591877      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:06.592542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:07.593423      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:08.594384      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:09.596303      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:10.597353      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 05/05/24 17:07:10.669
  E0505 17:07:11.598703      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:12.600063      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:07:12.679: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  May  5 17:07:12.679: INFO: Breadth first check of 10.200.131.140 on host 192.168.58.100...
  May  5 17:07:12.681: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.131.131:9080/dial?request=hostname&protocol=udp&host=10.200.131.140&port=8081&tries=1'] Namespace:pod-network-test-4105 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 17:07:12.681: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 17:07:12.682: INFO: ExecWithOptions: Clientset creation
  May  5 17:07:12.682: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/pod-network-test-4105/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.200.131.131%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.200.131.140%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  May  5 17:07:12.717: INFO: Waiting for responses: map[]
  May  5 17:07:12.717: INFO: reached 10.200.131.140 after 0/1 tries
  May  5 17:07:12.717: INFO: Breadth first check of 10.200.5.47 on host 192.168.58.101...
  May  5 17:07:12.719: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.131.131:9080/dial?request=hostname&protocol=udp&host=10.200.5.47&port=8081&tries=1'] Namespace:pod-network-test-4105 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 17:07:12.719: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 17:07:12.719: INFO: ExecWithOptions: Clientset creation
  May  5 17:07:12.719: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/pod-network-test-4105/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.200.131.131%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.200.5.47%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  May  5 17:07:12.759: INFO: Waiting for responses: map[]
  May  5 17:07:12.759: INFO: reached 10.200.5.47 after 0/1 tries
  May  5 17:07:12.759: INFO: Going to retry 0 out of 2 pods....
  May  5 17:07:12.759: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-4105" for this suite. @ 05/05/24 17:07:12.761
• [24.284 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:695
  STEP: Creating a kubernetes client @ 05/05/24 17:07:12.78
  May  5 17:07:12.780: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename resourcequota @ 05/05/24 17:07:12.783
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:07:12.793
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:07:12.795
  STEP: Creating a ResourceQuota with terminating scope @ 05/05/24 17:07:12.797
  STEP: Ensuring ResourceQuota status is calculated @ 05/05/24 17:07:12.8
  E0505 17:07:13.600665      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:14.600997      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 05/05/24 17:07:14.805
  STEP: Ensuring ResourceQuota status is calculated @ 05/05/24 17:07:14.809
  E0505 17:07:15.603589      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:16.603868      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 05/05/24 17:07:16.819
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 05/05/24 17:07:16.832
  E0505 17:07:17.605713      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:18.605722      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 05/05/24 17:07:18.837
  E0505 17:07:19.605920      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:20.608331      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/05/24 17:07:20.844
  STEP: Ensuring resource quota status released the pod usage @ 05/05/24 17:07:20.872
  E0505 17:07:21.608706      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:22.609593      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 05/05/24 17:07:22.878
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 05/05/24 17:07:22.894
  E0505 17:07:23.611095      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:24.612182      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 05/05/24 17:07:24.898
  E0505 17:07:25.612678      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:26.613544      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/05/24 17:07:26.901
  STEP: Ensuring resource quota status released the pod usage @ 05/05/24 17:07:26.916
  E0505 17:07:27.614194      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:28.614257      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:07:28.918: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7344" for this suite. @ 05/05/24 17:07:28.921
• [16.145 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 05/05/24 17:07:28.925
  May  5 17:07:28.925: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename pods @ 05/05/24 17:07:28.927
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:07:28.935
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:07:28.939
  STEP: creating pod @ 05/05/24 17:07:28.941
  E0505 17:07:29.614457      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:30.615109      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:07:30.953: INFO: Pod pod-hostip-f1c5c92f-0352-400e-9771-7488b174ed8b has hostIP: 192.168.58.100
  May  5 17:07:30.953: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2998" for this suite. @ 05/05/24 17:07:30.956
• [2.043 seconds]
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 05/05/24 17:07:30.969
  May  5 17:07:30.969: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename daemonsets @ 05/05/24 17:07:30.969
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:07:30.98
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:07:30.983
  May  5 17:07:30.995: INFO: Create a RollingUpdate DaemonSet
  May  5 17:07:30.998: INFO: Check that daemon pods launch on every node of the cluster
  May  5 17:07:31.002: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 17:07:31.002: INFO: Node worker00 is running 0 daemon pod, expected 1
  E0505 17:07:31.616116      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:07:32.006: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 17:07:32.006: INFO: Node worker00 is running 0 daemon pod, expected 1
  E0505 17:07:32.615722      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:07:33.005: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May  5 17:07:33.006: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  May  5 17:07:33.006: INFO: Update the DaemonSet to trigger a rollout
  May  5 17:07:33.013: INFO: Updating DaemonSet daemon-set
  E0505 17:07:33.615672      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:34.616056      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:07:35.020: INFO: Roll back the DaemonSet before rollout is complete
  May  5 17:07:35.025: INFO: Updating DaemonSet daemon-set
  May  5 17:07:35.025: INFO: Make sure DaemonSet rollback is complete
  May  5 17:07:35.028: INFO: Wrong image for pod: daemon-set-2lpg2. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  May  5 17:07:35.028: INFO: Pod daemon-set-2lpg2 is not available
  E0505 17:07:35.621803      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:36.622464      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:37.623465      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:38.624431      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:07:39.026: INFO: Pod daemon-set-lpwvb is not available
  STEP: Deleting DaemonSet "daemon-set" @ 05/05/24 17:07:39.03
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1600, will wait for the garbage collector to delete the pods @ 05/05/24 17:07:39.03
  May  5 17:07:39.085: INFO: Deleting DaemonSet.extensions daemon-set took: 3.764057ms
  May  5 17:07:39.186: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.389253ms
  E0505 17:07:39.625397      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:40.625484      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:07:41.289: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May  5 17:07:41.289: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  May  5 17:07:41.291: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"34889"},"items":null}

  May  5 17:07:41.292: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"34889"},"items":null}

  May  5 17:07:41.299: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1600" for this suite. @ 05/05/24 17:07:41.302
• [10.336 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 05/05/24 17:07:41.305
  May  5 17:07:41.305: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename events @ 05/05/24 17:07:41.306
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:07:41.315
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:07:41.317
  STEP: creating a test event @ 05/05/24 17:07:41.319
  STEP: listing events in all namespaces @ 05/05/24 17:07:41.321
  STEP: listing events in test namespace @ 05/05/24 17:07:41.324
  STEP: listing events with field selection filtering on source @ 05/05/24 17:07:41.325
  STEP: listing events with field selection filtering on reportingController @ 05/05/24 17:07:41.326
  STEP: getting the test event @ 05/05/24 17:07:41.327
  STEP: patching the test event @ 05/05/24 17:07:41.328
  STEP: getting the test event @ 05/05/24 17:07:41.333
  STEP: updating the test event @ 05/05/24 17:07:41.334
  STEP: getting the test event @ 05/05/24 17:07:41.337
  STEP: deleting the test event @ 05/05/24 17:07:41.338
  STEP: listing events in all namespaces @ 05/05/24 17:07:41.34
  STEP: listing events in test namespace @ 05/05/24 17:07:41.343
  May  5 17:07:41.344: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-8483" for this suite. @ 05/05/24 17:07:41.346
• [0.042 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:75
  STEP: Creating a kubernetes client @ 05/05/24 17:07:41.348
  May  5 17:07:41.348: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 17:07:41.348
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:07:41.355
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:07:41.357
  STEP: Creating configMap with name projected-configmap-test-volume-1fd5c674-f7fc-4cf4-b1e3-36ef75103415 @ 05/05/24 17:07:41.359
  STEP: Creating a pod to test consume configMaps @ 05/05/24 17:07:41.36
  E0505 17:07:41.626616      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:42.627878      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:43.629138      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:44.629478      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:07:45.378
  May  5 17:07:45.382: INFO: Trying to get logs from node worker00 pod pod-projected-configmaps-36c6d98d-f16c-488b-9227-126d3770e466 container agnhost-container: <nil>
  STEP: delete the pod @ 05/05/24 17:07:45.386
  May  5 17:07:45.395: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6908" for this suite. @ 05/05/24 17:07:45.397
• [4.053 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 05/05/24 17:07:45.401
  May  5 17:07:45.401: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename disruption @ 05/05/24 17:07:45.402
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:07:45.41
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:07:45.412
  STEP: creating the pdb @ 05/05/24 17:07:45.414
  STEP: Waiting for the pdb to be processed @ 05/05/24 17:07:45.416
  E0505 17:07:45.629421      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:46.630847      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pdb @ 05/05/24 17:07:47.422
  STEP: Waiting for the pdb to be processed @ 05/05/24 17:07:47.43
  E0505 17:07:47.630643      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:48.630963      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching the pdb @ 05/05/24 17:07:49.434
  STEP: Waiting for the pdb to be processed @ 05/05/24 17:07:49.44
  E0505 17:07:49.631125      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:50.631429      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be deleted @ 05/05/24 17:07:51.455
  May  5 17:07:51.459: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-3252" for this suite. @ 05/05/24 17:07:51.465
• [6.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:357
  STEP: Creating a kubernetes client @ 05/05/24 17:07:51.47
  May  5 17:07:51.470: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubectl @ 05/05/24 17:07:51.471
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:07:51.483
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:07:51.485
  STEP: creating a replication controller @ 05/05/24 17:07:51.487
  May  5 17:07:51.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 create -f -'
  May  5 17:07:51.561: INFO: stderr: ""
  May  5 17:07:51.561: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/05/24 17:07:51.561
  May  5 17:07:51.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May  5 17:07:51.617: INFO: stderr: ""
  May  5 17:07:51.617: INFO: stdout: "update-demo-nautilus-7f8qc update-demo-nautilus-zrstp "
  May  5 17:07:51.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 get pods update-demo-nautilus-7f8qc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0505 17:07:51.631826      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:07:51.658: INFO: stderr: ""
  May  5 17:07:51.658: INFO: stdout: ""
  May  5 17:07:51.658: INFO: update-demo-nautilus-7f8qc is created but not running
  E0505 17:07:52.632731      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:53.633931      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:54.634401      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:55.637496      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:07:56.637814      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:07:56.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May  5 17:07:56.716: INFO: stderr: ""
  May  5 17:07:56.716: INFO: stdout: "update-demo-nautilus-7f8qc update-demo-nautilus-zrstp "
  May  5 17:07:56.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 get pods update-demo-nautilus-7f8qc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May  5 17:07:56.773: INFO: stderr: ""
  May  5 17:07:56.773: INFO: stdout: "true"
  May  5 17:07:56.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 get pods update-demo-nautilus-7f8qc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  May  5 17:07:56.827: INFO: stderr: ""
  May  5 17:07:56.827: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May  5 17:07:56.827: INFO: validating pod update-demo-nautilus-7f8qc
  May  5 17:07:56.838: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May  5 17:07:56.838: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May  5 17:07:56.838: INFO: update-demo-nautilus-7f8qc is verified up and running
  May  5 17:07:56.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 get pods update-demo-nautilus-zrstp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May  5 17:07:56.901: INFO: stderr: ""
  May  5 17:07:56.901: INFO: stdout: "true"
  May  5 17:07:56.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 get pods update-demo-nautilus-zrstp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  May  5 17:07:56.953: INFO: stderr: ""
  May  5 17:07:56.953: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May  5 17:07:56.953: INFO: validating pod update-demo-nautilus-zrstp
  May  5 17:07:56.963: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May  5 17:07:56.963: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May  5 17:07:56.963: INFO: update-demo-nautilus-zrstp is verified up and running
  STEP: scaling down the replication controller @ 05/05/24 17:07:56.963
  May  5 17:07:56.965: INFO: scanned /root for discovery docs: <nil>
  May  5 17:07:56.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E0505 17:07:57.639019      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:07:58.035: INFO: stderr: ""
  May  5 17:07:58.035: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/05/24 17:07:58.035
  May  5 17:07:58.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May  5 17:07:58.080: INFO: stderr: ""
  May  5 17:07:58.080: INFO: stdout: "update-demo-nautilus-zrstp "
  May  5 17:07:58.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 get pods update-demo-nautilus-zrstp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May  5 17:07:58.121: INFO: stderr: ""
  May  5 17:07:58.121: INFO: stdout: "true"
  May  5 17:07:58.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 get pods update-demo-nautilus-zrstp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  May  5 17:07:58.162: INFO: stderr: ""
  May  5 17:07:58.162: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May  5 17:07:58.162: INFO: validating pod update-demo-nautilus-zrstp
  May  5 17:07:58.164: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May  5 17:07:58.164: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May  5 17:07:58.164: INFO: update-demo-nautilus-zrstp is verified up and running
  STEP: scaling up the replication controller @ 05/05/24 17:07:58.164
  May  5 17:07:58.166: INFO: scanned /root for discovery docs: <nil>
  May  5 17:07:58.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E0505 17:07:58.639759      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:07:59.229: INFO: stderr: ""
  May  5 17:07:59.229: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/05/24 17:07:59.229
  May  5 17:07:59.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May  5 17:07:59.274: INFO: stderr: ""
  May  5 17:07:59.274: INFO: stdout: "update-demo-nautilus-fjx89 update-demo-nautilus-zrstp "
  May  5 17:07:59.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 get pods update-demo-nautilus-fjx89 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May  5 17:07:59.319: INFO: stderr: ""
  May  5 17:07:59.319: INFO: stdout: ""
  May  5 17:07:59.319: INFO: update-demo-nautilus-fjx89 is created but not running
  E0505 17:07:59.640181      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:00.640540      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:01.640828      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:02.642301      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:03.644765      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:04.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May  5 17:08:04.376: INFO: stderr: ""
  May  5 17:08:04.376: INFO: stdout: "update-demo-nautilus-fjx89 update-demo-nautilus-zrstp "
  May  5 17:08:04.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 get pods update-demo-nautilus-fjx89 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May  5 17:08:04.412: INFO: stderr: ""
  May  5 17:08:04.412: INFO: stdout: "true"
  May  5 17:08:04.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 get pods update-demo-nautilus-fjx89 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  May  5 17:08:04.450: INFO: stderr: ""
  May  5 17:08:04.450: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May  5 17:08:04.450: INFO: validating pod update-demo-nautilus-fjx89
  May  5 17:08:04.452: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May  5 17:08:04.452: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May  5 17:08:04.452: INFO: update-demo-nautilus-fjx89 is verified up and running
  May  5 17:08:04.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 get pods update-demo-nautilus-zrstp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May  5 17:08:04.494: INFO: stderr: ""
  May  5 17:08:04.494: INFO: stdout: "true"
  May  5 17:08:04.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 get pods update-demo-nautilus-zrstp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  May  5 17:08:04.536: INFO: stderr: ""
  May  5 17:08:04.536: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May  5 17:08:04.536: INFO: validating pod update-demo-nautilus-zrstp
  May  5 17:08:04.539: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May  5 17:08:04.539: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May  5 17:08:04.539: INFO: update-demo-nautilus-zrstp is verified up and running
  STEP: using delete to clean up resources @ 05/05/24 17:08:04.539
  May  5 17:08:04.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 delete --grace-period=0 --force -f -'
  May  5 17:08:04.585: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May  5 17:08:04.585: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  May  5 17:08:04.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 get rc,svc -l name=update-demo --no-headers'
  E0505 17:08:04.645976      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:04.657: INFO: stderr: "No resources found in kubectl-69 namespace.\n"
  May  5 17:08:04.657: INFO: stdout: ""
  May  5 17:08:04.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-69 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  May  5 17:08:04.725: INFO: stderr: ""
  May  5 17:08:04.725: INFO: stdout: ""
  May  5 17:08:04.725: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-69" for this suite. @ 05/05/24 17:08:04.731
• [13.266 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:223
  STEP: Creating a kubernetes client @ 05/05/24 17:08:04.739
  May  5 17:08:04.739: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 17:08:04.742
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:08:04.775
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:08:04.778
  STEP: Creating a pod to test downward API volume plugin @ 05/05/24 17:08:04.784
  E0505 17:08:05.646130      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:06.646612      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:08:06.801
  May  5 17:08:06.803: INFO: Trying to get logs from node worker00 pod downwardapi-volume-8b11320f-f5cd-430a-a7b3-4f1a547ca313 container client-container: <nil>
  STEP: delete the pod @ 05/05/24 17:08:06.805
  May  5 17:08:06.812: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2939" for this suite. @ 05/05/24 17:08:06.815
• [2.080 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1838
  STEP: Creating a kubernetes client @ 05/05/24 17:08:06.82
  May  5 17:08:06.820: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubectl @ 05/05/24 17:08:06.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:08:06.828
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:08:06.831
  STEP: starting the proxy server @ 05/05/24 17:08:06.833
  May  5 17:08:06.834: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-4356 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 05/05/24 17:08:06.868
  May  5 17:08:06.874: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4356" for this suite. @ 05/05/24 17:08:06.878
• [0.064 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1731
  STEP: Creating a kubernetes client @ 05/05/24 17:08:06.884
  May  5 17:08:06.884: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubectl @ 05/05/24 17:08:06.884
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:08:06.895
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:08:06.898
  May  5 17:08:06.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-8078 version'
  May  5 17:08:06.941: INFO: stderr: ""
  May  5 17:08:06.941: INFO: stdout: "Client Version: v1.29.4\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nServer Version: v1.29.4\n"
  May  5 17:08:06.941: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8078" for this suite. @ 05/05/24 17:08:06.943
• [0.062 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1698
  STEP: Creating a kubernetes client @ 05/05/24 17:08:06.946
  May  5 17:08:06.946: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubectl @ 05/05/24 17:08:06.946
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:08:06.957
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:08:06.959
  STEP: creating Agnhost RC @ 05/05/24 17:08:06.961
  May  5 17:08:06.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9431 create -f -'
  May  5 17:08:07.055: INFO: stderr: ""
  May  5 17:08:07.055: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 05/05/24 17:08:07.055
  E0505 17:08:07.649024      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:08.058: INFO: Selector matched 1 pods for map[app:agnhost]
  May  5 17:08:08.058: INFO: Found 0 / 1
  E0505 17:08:08.649587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:09.060: INFO: Selector matched 1 pods for map[app:agnhost]
  May  5 17:08:09.060: INFO: Found 1 / 1
  May  5 17:08:09.060: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 05/05/24 17:08:09.06
  May  5 17:08:09.063: INFO: Selector matched 1 pods for map[app:agnhost]
  May  5 17:08:09.063: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  May  5 17:08:09.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9431 patch pod agnhost-primary-vhbrj -p {"metadata":{"annotations":{"x":"y"}}}'
  May  5 17:08:09.119: INFO: stderr: ""
  May  5 17:08:09.119: INFO: stdout: "pod/agnhost-primary-vhbrj patched\n"
  STEP: checking annotations @ 05/05/24 17:08:09.119
  May  5 17:08:09.121: INFO: Selector matched 1 pods for map[app:agnhost]
  May  5 17:08:09.121: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  May  5 17:08:09.121: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9431" for this suite. @ 05/05/24 17:08:09.123
• [2.181 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:169
  STEP: Creating a kubernetes client @ 05/05/24 17:08:09.127
  May  5 17:08:09.127: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/05/24 17:08:09.128
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:08:09.137
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:08:09.139
  STEP: create the container to handle the HTTPGet hook request. @ 05/05/24 17:08:09.145
  E0505 17:08:09.649864      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:10.650507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/05/24 17:08:11.162
  E0505 17:08:11.650518      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:12.651685      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 05/05/24 17:08:13.178
  STEP: delete the pod with lifecycle hook @ 05/05/24 17:08:13.201
  E0505 17:08:13.651760      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:14.651819      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:15.652634      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:16.652664      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:17.211: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-8597" for this suite. @ 05/05/24 17:08:17.213
• [8.090 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 05/05/24 17:08:17.217
  May  5 17:08:17.217: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 17:08:17.218
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:08:17.229
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:08:17.233
  STEP: Creating projection with secret that has name projected-secret-test-83ff0c5c-05e7-4581-89c9-f6ead0f6838c @ 05/05/24 17:08:17.235
  STEP: Creating a pod to test consume secrets @ 05/05/24 17:08:17.239
  E0505 17:08:17.653631      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:18.654708      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:19.655491      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:20.655816      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:08:21.254
  May  5 17:08:21.257: INFO: Trying to get logs from node worker00 pod pod-projected-secrets-4a46d59a-bf2e-4246-8102-8355a9ea7753 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/05/24 17:08:21.26
  May  5 17:08:21.268: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4268" for this suite. @ 05/05/24 17:08:21.27
• [4.056 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:151
  STEP: Creating a kubernetes client @ 05/05/24 17:08:21.273
  May  5 17:08:21.273: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename container-probe @ 05/05/24 17:08:21.274
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:08:21.286
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:08:21.288
  STEP: Creating pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907 @ 05/05/24 17:08:21.289
  E0505 17:08:21.656739      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:22.658396      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/05/24 17:08:23.299
  May  5 17:08:23.305: INFO: Initial restart count of pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b is 0
  May  5 17:08:23.307: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:08:23.659444      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:24.661514      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:25.312: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:08:25.664267      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:26.665119      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:27.318: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:08:27.666464      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:28.666573      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:29.320: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:08:29.667497      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:30.669582      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:31.328: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:08:31.670473      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:32.671012      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:33.334: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:08:33.672282      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:34.672832      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:35.339: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:08:35.673983      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:36.675473      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:37.343: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:08:37.675840      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:38.676471      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:39.345: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:08:39.677413      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:40.678402      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:41.347: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:08:41.678596      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:42.679990      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:43.351: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:08:43.680055      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:44.683267      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:45.356: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:08:45.683625      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:46.683928      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:47.362: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:08:47.685032      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:48.686475      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:49.367: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:08:49.689678      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:50.691713      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:51.369: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:08:51.692372      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:52.692622      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:53.376: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:08:53.693411      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:54.693806      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:55.379: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:08:55.694792      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:56.696424      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:57.385: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:08:57.697676      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:08:58.704721      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:08:59.391: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:08:59.705159      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:00.706384      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:01.394: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:01.707383      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:02.708948      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:03.401: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:03.709837      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:04.710115      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:05.407: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:05.710202      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:06.710951      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:07.414: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:07.711472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:08.711784      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:09.419: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:09.712659      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:10.713898      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:11.423: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:11.714330      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:12.715122      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:13.427: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:13.717430      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:14.716991      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:15.432: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:15.717070      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:16.717546      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:17.438: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:17.718287      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:18.718681      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:19.443: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:19.719187      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:20.733554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:21.447: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:21.734108      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:22.734332      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:23.452: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:23.735422      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:24.735629      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:25.456: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:25.737117      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:26.737924      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:27.463: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:27.738569      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:28.739069      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:29.472: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:29.739151      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:30.739636      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:31.486: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:31.740194      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:32.744501      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:33.492: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:33.745005      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:34.745393      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:35.496: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:35.745985      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:36.747188      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:37.504: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:37.750037      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:38.750565      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:39.510: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:39.751571      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:40.752401      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:41.516: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:41.753488      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:42.754327      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:43.524: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:43.754574      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:44.755669      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:45.530: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:45.756859      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:46.756926      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:47.536: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:47.757373      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:48.757782      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:49.543: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:49.757800      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:50.757947      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:51.547: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:51.759145      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:52.759272      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:53.554: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:53.761366      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:54.761640      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:55.559: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:55.762084      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:56.762299      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:57.566: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:57.762243      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:09:58.762455      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:09:59.570: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:09:59.763612      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:00.763705      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:01.575: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:01.763998      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:02.765108      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:03.580: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:03.765923      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:04.766298      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:05.586: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:05.766601      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:06.766587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:07.591: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:07.769289      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:08.770066      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:09.600: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:09.771340      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:10.772061      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:11.608: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:11.772945      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:12.772947      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:13.613: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:13.774107      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:14.774352      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:15.618: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:15.775500      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:16.775770      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:17.622: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:17.776821      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:18.777432      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:19.627: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:19.778558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:20.779539      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:21.630: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:21.779803      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:22.780057      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:23.635: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:23.780180      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:24.780564      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:25.642: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:25.781106      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:26.782008      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:27.652: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:27.782912      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:28.783719      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:29.657: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:29.784715      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:30.785436      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:31.662: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:31.785860      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:32.786824      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:33.668: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:33.788105      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:34.798916      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:35.674: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:35.799270      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:36.801039      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:37.680: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:37.800925      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:38.801066      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:39.685: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:39.801636      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:40.803730      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:41.689: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:41.804337      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:42.804520      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:43.694: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:43.805819      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:44.806914      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:45.700: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:45.808058      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:46.809272      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:47.705: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:47.809385      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:48.810479      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:49.709: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:49.815618      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:50.817498      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:51.712: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:51.817688      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:52.818039      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:53.720: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:53.819914      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:54.821739      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:55.726: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:55.821681      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:56.822075      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:57.729: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:57.822766      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:10:58.823969      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:10:59.733: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:10:59.824576      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:00.825537      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:01.736: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:01.826785      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:02.828699      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:03.743: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:03.830671      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:04.831135      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:05.749: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:05.831824      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:06.832406      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:07.756: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:07.833110      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:08.833403      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:09.760: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:09.833428      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:10.833923      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:11.766: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:11.834802      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:12.840614      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:13.776: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:13.841987      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:14.842563      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:15.782: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:15.842714      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:16.843326      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:17.789: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:17.843851      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:18.844003      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:19.791: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:19.844124      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:20.845283      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:21.793: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:21.848207      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:22.849527      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:23.799: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:23.850535      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:24.850953      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:25.803: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:25.851467      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:26.851846      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:27.805: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:27.852190      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:28.852570      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:29.808: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:29.853348      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:30.853422      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:31.812: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:31.854444      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:32.854799      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:33.819: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:33.856014      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:34.856516      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:35.823: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:35.859649      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:36.859648      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:37.828: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:37.860276      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:38.860769      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:39.831: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:39.861702      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:40.863565      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:41.833: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:41.864100      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:42.865279      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:43.837: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:43.869651      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:44.869924      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:45.845: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:45.870864      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:46.871108      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:47.849: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:47.871764      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:48.872374      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:49.856: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:49.873725      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:50.874450      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:51.863: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:51.875255      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:52.876016      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:53.868: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:53.876734      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:54.877036      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:55.870: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:55.877825      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:56.878356      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:57.875: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:57.879268      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:11:58.880558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:11:59.879: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:11:59.880998      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:00.881059      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:01.881098      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:12:01.882: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:12:02.881896      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:03.882001      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:12:03.884: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:12:04.885248      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:05.885821      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:12:05.887: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:12:06.886371      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:07.886821      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:12:07.889: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:12:08.887000      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:09.887281      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:12:09.892: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:12:10.887390      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:11.890580      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:12:11.898: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:12:12.891445      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:13.892192      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:12:13.901: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:12:14.892945      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:15.893296      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:12:15.905: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:12:16.893348      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:17.893475      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:12:17.908: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:12:18.894360      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:19.895260      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:12:19.911: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:12:20.895839      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:21.896867      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:12:21.917: INFO: Get pod busybox-b0a058e3-b90a-43d8-b205-d8d37f24273b in namespace container-probe-6907
  E0505 17:12:22.897477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:23.898046      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 05/05/24 17:12:23.918
  May  5 17:12:23.947: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6907" for this suite. @ 05/05/24 17:12:23.952
• [242.685 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:380
  STEP: Creating a kubernetes client @ 05/05/24 17:12:23.959
  May  5 17:12:23.959: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename gc @ 05/05/24 17:12:23.959
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:12:23.969
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:12:23.971
  STEP: create the rc @ 05/05/24 17:12:23.975
  W0505 17:12:23.978839      22 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0505 17:12:24.897812      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:25.900863      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:26.905906      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:27.906724      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:28.907899      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:29.910770      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 05/05/24 17:12:29.997
  STEP: wait for the rc to be deleted @ 05/05/24 17:12:30.025
  E0505 17:12:30.937806      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:31.915235      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:32.915558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:33.918667      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:34.917061      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 05/05/24 17:12:35.032
  E0505 17:12:35.917119      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:36.917454      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:37.918513      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:38.924080      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:39.924255      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:40.924609      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:41.925615      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:42.925980      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:43.926714      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:44.926933      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:45.928007      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:46.928411      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:47.928492      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:48.928838      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:49.930301      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:50.931369      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:51.934372      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:52.934167      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:53.934530      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:54.934982      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:55.936935      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:56.938533      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:57.939668      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:58.940265      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:12:59.941357      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:00.941973      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:01.942451      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:02.942926      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:03.943098      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:04.946187      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/05/24 17:13:05.039
  May  5 17:13:05.075: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  May  5 17:13:05.075: INFO: Deleting pod "simpletest.rc-479ft" in namespace "gc-2770"
  May  5 17:13:05.094: INFO: Deleting pod "simpletest.rc-4gkjz" in namespace "gc-2770"
  May  5 17:13:05.109: INFO: Deleting pod "simpletest.rc-4jhdn" in namespace "gc-2770"
  May  5 17:13:05.125: INFO: Deleting pod "simpletest.rc-4k72q" in namespace "gc-2770"
  May  5 17:13:05.152: INFO: Deleting pod "simpletest.rc-4skgb" in namespace "gc-2770"
  May  5 17:13:05.169: INFO: Deleting pod "simpletest.rc-55ptk" in namespace "gc-2770"
  May  5 17:13:05.186: INFO: Deleting pod "simpletest.rc-5rb96" in namespace "gc-2770"
  May  5 17:13:05.204: INFO: Deleting pod "simpletest.rc-5rmn4" in namespace "gc-2770"
  May  5 17:13:05.227: INFO: Deleting pod "simpletest.rc-6td2k" in namespace "gc-2770"
  May  5 17:13:05.250: INFO: Deleting pod "simpletest.rc-6w9pt" in namespace "gc-2770"
  May  5 17:13:05.307: INFO: Deleting pod "simpletest.rc-6w9rh" in namespace "gc-2770"
  May  5 17:13:05.339: INFO: Deleting pod "simpletest.rc-6xprm" in namespace "gc-2770"
  May  5 17:13:05.374: INFO: Deleting pod "simpletest.rc-77zks" in namespace "gc-2770"
  May  5 17:13:05.428: INFO: Deleting pod "simpletest.rc-7ck22" in namespace "gc-2770"
  May  5 17:13:05.461: INFO: Deleting pod "simpletest.rc-7r75q" in namespace "gc-2770"
  May  5 17:13:05.508: INFO: Deleting pod "simpletest.rc-7zcvn" in namespace "gc-2770"
  May  5 17:13:05.535: INFO: Deleting pod "simpletest.rc-82gvs" in namespace "gc-2770"
  May  5 17:13:05.560: INFO: Deleting pod "simpletest.rc-84zl6" in namespace "gc-2770"
  May  5 17:13:05.601: INFO: Deleting pod "simpletest.rc-85bf4" in namespace "gc-2770"
  May  5 17:13:05.664: INFO: Deleting pod "simpletest.rc-8cvpg" in namespace "gc-2770"
  May  5 17:13:05.699: INFO: Deleting pod "simpletest.rc-8gwkv" in namespace "gc-2770"
  May  5 17:13:05.729: INFO: Deleting pod "simpletest.rc-8pxqf" in namespace "gc-2770"
  May  5 17:13:05.768: INFO: Deleting pod "simpletest.rc-8zbct" in namespace "gc-2770"
  May  5 17:13:05.815: INFO: Deleting pod "simpletest.rc-98mxc" in namespace "gc-2770"
  May  5 17:13:05.851: INFO: Deleting pod "simpletest.rc-9csvs" in namespace "gc-2770"
  May  5 17:13:05.891: INFO: Deleting pod "simpletest.rc-9s6fk" in namespace "gc-2770"
  May  5 17:13:05.945: INFO: Deleting pod "simpletest.rc-b9cmb" in namespace "gc-2770"
  E0505 17:13:05.946937      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:13:05.974: INFO: Deleting pod "simpletest.rc-bg4zs" in namespace "gc-2770"
  May  5 17:13:06.028: INFO: Deleting pod "simpletest.rc-brhkk" in namespace "gc-2770"
  May  5 17:13:06.068: INFO: Deleting pod "simpletest.rc-brl6b" in namespace "gc-2770"
  May  5 17:13:06.126: INFO: Deleting pod "simpletest.rc-cgqp9" in namespace "gc-2770"
  May  5 17:13:06.160: INFO: Deleting pod "simpletest.rc-cwz4g" in namespace "gc-2770"
  May  5 17:13:06.230: INFO: Deleting pod "simpletest.rc-cx968" in namespace "gc-2770"
  May  5 17:13:06.265: INFO: Deleting pod "simpletest.rc-dbsdh" in namespace "gc-2770"
  May  5 17:13:06.300: INFO: Deleting pod "simpletest.rc-dh67v" in namespace "gc-2770"
  May  5 17:13:06.364: INFO: Deleting pod "simpletest.rc-dj54m" in namespace "gc-2770"
  May  5 17:13:06.411: INFO: Deleting pod "simpletest.rc-dmwjb" in namespace "gc-2770"
  May  5 17:13:06.466: INFO: Deleting pod "simpletest.rc-drkjb" in namespace "gc-2770"
  May  5 17:13:06.527: INFO: Deleting pod "simpletest.rc-ffs9g" in namespace "gc-2770"
  May  5 17:13:06.597: INFO: Deleting pod "simpletest.rc-g6kd6" in namespace "gc-2770"
  May  5 17:13:06.683: INFO: Deleting pod "simpletest.rc-g9rqh" in namespace "gc-2770"
  May  5 17:13:06.849: INFO: Deleting pod "simpletest.rc-ggxmh" in namespace "gc-2770"
  E0505 17:13:06.948042      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:13:06.958: INFO: Deleting pod "simpletest.rc-gkzvt" in namespace "gc-2770"
  May  5 17:13:07.004: INFO: Deleting pod "simpletest.rc-gs47h" in namespace "gc-2770"
  May  5 17:13:07.064: INFO: Deleting pod "simpletest.rc-hr77p" in namespace "gc-2770"
  May  5 17:13:07.125: INFO: Deleting pod "simpletest.rc-j27lj" in namespace "gc-2770"
  May  5 17:13:07.220: INFO: Deleting pod "simpletest.rc-j52dr" in namespace "gc-2770"
  May  5 17:13:07.244: INFO: Deleting pod "simpletest.rc-jpqzh" in namespace "gc-2770"
  May  5 17:13:07.324: INFO: Deleting pod "simpletest.rc-jxz97" in namespace "gc-2770"
  May  5 17:13:07.388: INFO: Deleting pod "simpletest.rc-k8vrq" in namespace "gc-2770"
  May  5 17:13:07.429: INFO: Deleting pod "simpletest.rc-kbsdw" in namespace "gc-2770"
  May  5 17:13:07.481: INFO: Deleting pod "simpletest.rc-kn8vm" in namespace "gc-2770"
  May  5 17:13:07.548: INFO: Deleting pod "simpletest.rc-l8k9q" in namespace "gc-2770"
  May  5 17:13:07.593: INFO: Deleting pod "simpletest.rc-lh9xp" in namespace "gc-2770"
  May  5 17:13:07.617: INFO: Deleting pod "simpletest.rc-lhzhz" in namespace "gc-2770"
  May  5 17:13:07.652: INFO: Deleting pod "simpletest.rc-lr2q4" in namespace "gc-2770"
  May  5 17:13:07.751: INFO: Deleting pod "simpletest.rc-m6z6p" in namespace "gc-2770"
  May  5 17:13:07.837: INFO: Deleting pod "simpletest.rc-mgdct" in namespace "gc-2770"
  May  5 17:13:07.933: INFO: Deleting pod "simpletest.rc-mrtpc" in namespace "gc-2770"
  E0505 17:13:07.954613      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:13:08.073: INFO: Deleting pod "simpletest.rc-n2482" in namespace "gc-2770"
  May  5 17:13:08.102: INFO: Deleting pod "simpletest.rc-n4l9q" in namespace "gc-2770"
  May  5 17:13:08.155: INFO: Deleting pod "simpletest.rc-n6949" in namespace "gc-2770"
  May  5 17:13:08.192: INFO: Deleting pod "simpletest.rc-n6q79" in namespace "gc-2770"
  May  5 17:13:08.290: INFO: Deleting pod "simpletest.rc-nd4dd" in namespace "gc-2770"
  May  5 17:13:08.357: INFO: Deleting pod "simpletest.rc-nks6f" in namespace "gc-2770"
  May  5 17:13:08.410: INFO: Deleting pod "simpletest.rc-nw54k" in namespace "gc-2770"
  May  5 17:13:08.499: INFO: Deleting pod "simpletest.rc-pxwz5" in namespace "gc-2770"
  May  5 17:13:08.509: INFO: Deleting pod "simpletest.rc-q2tjl" in namespace "gc-2770"
  May  5 17:13:08.557: INFO: Deleting pod "simpletest.rc-qgkq9" in namespace "gc-2770"
  May  5 17:13:08.629: INFO: Deleting pod "simpletest.rc-qkbf4" in namespace "gc-2770"
  May  5 17:13:08.681: INFO: Deleting pod "simpletest.rc-qlmpl" in namespace "gc-2770"
  May  5 17:13:08.703: INFO: Deleting pod "simpletest.rc-qpfr5" in namespace "gc-2770"
  May  5 17:13:08.736: INFO: Deleting pod "simpletest.rc-qptmk" in namespace "gc-2770"
  May  5 17:13:08.759: INFO: Deleting pod "simpletest.rc-qr9cv" in namespace "gc-2770"
  May  5 17:13:08.789: INFO: Deleting pod "simpletest.rc-qwzcs" in namespace "gc-2770"
  May  5 17:13:08.859: INFO: Deleting pod "simpletest.rc-rnbbh" in namespace "gc-2770"
  May  5 17:13:08.876: INFO: Deleting pod "simpletest.rc-rnqqr" in namespace "gc-2770"
  May  5 17:13:08.926: INFO: Deleting pod "simpletest.rc-sbc4b" in namespace "gc-2770"
  E0505 17:13:08.956578      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:13:08.991: INFO: Deleting pod "simpletest.rc-t5lhc" in namespace "gc-2770"
  May  5 17:13:09.111: INFO: Deleting pod "simpletest.rc-thq7g" in namespace "gc-2770"
  May  5 17:13:09.139: INFO: Deleting pod "simpletest.rc-tk5nc" in namespace "gc-2770"
  May  5 17:13:09.193: INFO: Deleting pod "simpletest.rc-tnk84" in namespace "gc-2770"
  May  5 17:13:09.229: INFO: Deleting pod "simpletest.rc-tr9bw" in namespace "gc-2770"
  May  5 17:13:09.252: INFO: Deleting pod "simpletest.rc-txkcf" in namespace "gc-2770"
  May  5 17:13:09.291: INFO: Deleting pod "simpletest.rc-vd5nl" in namespace "gc-2770"
  May  5 17:13:09.313: INFO: Deleting pod "simpletest.rc-vg4rt" in namespace "gc-2770"
  May  5 17:13:09.397: INFO: Deleting pod "simpletest.rc-vj8p7" in namespace "gc-2770"
  May  5 17:13:09.473: INFO: Deleting pod "simpletest.rc-vnt2w" in namespace "gc-2770"
  May  5 17:13:09.505: INFO: Deleting pod "simpletest.rc-vwx95" in namespace "gc-2770"
  May  5 17:13:09.554: INFO: Deleting pod "simpletest.rc-w7ckd" in namespace "gc-2770"
  May  5 17:13:09.582: INFO: Deleting pod "simpletest.rc-wdm55" in namespace "gc-2770"
  May  5 17:13:09.603: INFO: Deleting pod "simpletest.rc-wsbvh" in namespace "gc-2770"
  May  5 17:13:09.632: INFO: Deleting pod "simpletest.rc-wwztk" in namespace "gc-2770"
  May  5 17:13:09.670: INFO: Deleting pod "simpletest.rc-wxzpc" in namespace "gc-2770"
  May  5 17:13:09.731: INFO: Deleting pod "simpletest.rc-xdqn4" in namespace "gc-2770"
  May  5 17:13:09.756: INFO: Deleting pod "simpletest.rc-xgdpm" in namespace "gc-2770"
  May  5 17:13:09.777: INFO: Deleting pod "simpletest.rc-xh2pc" in namespace "gc-2770"
  May  5 17:13:09.817: INFO: Deleting pod "simpletest.rc-zf768" in namespace "gc-2770"
  May  5 17:13:09.837: INFO: Deleting pod "simpletest.rc-zzckb" in namespace "gc-2770"
  May  5 17:13:09.853: INFO: Deleting pod "simpletest.rc-zzhh8" in namespace "gc-2770"
  May  5 17:13:09.875: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-2770" for this suite. @ 05/05/24 17:13:09.909
• [45.962 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:90
  STEP: Creating a kubernetes client @ 05/05/24 17:13:09.925
  May  5 17:13:09.925: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename configmap @ 05/05/24 17:13:09.928
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:13:09.952
  E0505 17:13:09.959497      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:13:09.968
  STEP: Creating configMap with name configmap-test-volume-map-43a21a7d-3def-4e4a-863a-fc000e6867b8 @ 05/05/24 17:13:09.977
  STEP: Creating a pod to test consume configMaps @ 05/05/24 17:13:09.989
  E0505 17:13:10.959926      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:11.960716      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:12.963477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:13.963036      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:14.963344      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:15.963674      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:13:16.089
  May  5 17:13:16.092: INFO: Trying to get logs from node worker00 pod pod-configmaps-961fe559-1d02-4846-b2ba-7fdffd92570b container agnhost-container: <nil>
  STEP: delete the pod @ 05/05/24 17:13:16.096
  May  5 17:13:16.106: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9721" for this suite. @ 05/05/24 17:13:16.108
• [6.190 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:103
  STEP: Creating a kubernetes client @ 05/05/24 17:13:16.112
  May  5 17:13:16.112: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename resourcequota @ 05/05/24 17:13:16.113
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:13:16.123
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:13:16.126
  STEP: Counting existing ResourceQuota @ 05/05/24 17:13:16.129
  E0505 17:13:16.964517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:17.966138      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:18.971570      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:19.972341      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:20.973894      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/05/24 17:13:21.132
  STEP: Ensuring resource quota status is calculated @ 05/05/24 17:13:21.145
  E0505 17:13:21.974542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:22.974766      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 05/05/24 17:13:23.159
  STEP: Creating a NodePort Service @ 05/05/24 17:13:23.186
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 05/05/24 17:13:23.198
  STEP: Ensuring resource quota status captures service creation @ 05/05/24 17:13:23.21
  E0505 17:13:23.976789      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:24.977560      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 05/05/24 17:13:25.213
  STEP: Ensuring resource quota status released usage @ 05/05/24 17:13:25.244
  E0505 17:13:25.977168      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:26.977601      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:13:27.253: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-395" for this suite. @ 05/05/24 17:13:27.258
• [11.161 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:100
  STEP: Creating a kubernetes client @ 05/05/24 17:13:27.274
  May  5 17:13:27.274: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename emptydir @ 05/05/24 17:13:27.277
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:13:27.29
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:13:27.292
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 05/05/24 17:13:27.294
  E0505 17:13:27.977951      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:28.982426      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:13:29.305
  May  5 17:13:29.307: INFO: Trying to get logs from node worker00 pod pod-3f88c2ef-1023-4e12-9c10-55742002b192 container test-container: <nil>
  STEP: delete the pod @ 05/05/24 17:13:29.31
  May  5 17:13:29.319: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2441" for this suite. @ 05/05/24 17:13:29.323
• [2.052 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:177
  STEP: Creating a kubernetes client @ 05/05/24 17:13:29.327
  May  5 17:13:29.328: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename replicaset @ 05/05/24 17:13:29.329
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:13:29.336
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:13:29.339
  STEP: Create a Replicaset @ 05/05/24 17:13:29.343
  STEP: Verify that the required pods have come up. @ 05/05/24 17:13:29.346
  May  5 17:13:29.349: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0505 17:13:29.983414      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:30.983997      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:31.984840      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:32.985613      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:34.005587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:13:34.352: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/05/24 17:13:34.352
  STEP: Getting /status @ 05/05/24 17:13:34.352
  May  5 17:13:34.356: INFO: Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 05/05/24 17:13:34.356
  May  5 17:13:34.369: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 05/05/24 17:13:34.369
  May  5 17:13:34.373: INFO: Observed &ReplicaSet event: ADDED
  May  5 17:13:34.374: INFO: Observed &ReplicaSet event: MODIFIED
  May  5 17:13:34.374: INFO: Observed &ReplicaSet event: MODIFIED
  May  5 17:13:34.375: INFO: Observed &ReplicaSet event: MODIFIED
  May  5 17:13:34.375: INFO: Found replicaset test-rs in namespace replicaset-4117 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  May  5 17:13:34.375: INFO: Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 05/05/24 17:13:34.375
  May  5 17:13:34.375: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  May  5 17:13:34.387: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 05/05/24 17:13:34.387
  May  5 17:13:34.392: INFO: Observed &ReplicaSet event: ADDED
  May  5 17:13:34.392: INFO: Observed &ReplicaSet event: MODIFIED
  May  5 17:13:34.392: INFO: Observed &ReplicaSet event: MODIFIED
  May  5 17:13:34.392: INFO: Observed &ReplicaSet event: MODIFIED
  May  5 17:13:34.392: INFO: Observed replicaset test-rs in namespace replicaset-4117 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  May  5 17:13:34.393: INFO: Observed &ReplicaSet event: MODIFIED
  May  5 17:13:34.393: INFO: Found replicaset test-rs in namespace replicaset-4117 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  May  5 17:13:34.393: INFO: Replicaset test-rs has a patched status
  May  5 17:13:34.393: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4117" for this suite. @ 05/05/24 17:13:34.405
• [5.086 seconds]
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:141
  STEP: Creating a kubernetes client @ 05/05/24 17:13:34.413
  May  5 17:13:34.413: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename secrets @ 05/05/24 17:13:34.415
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:13:34.429
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:13:34.433
  STEP: Creating projection with secret that has name secret-emptykey-test-4fa25385-4c48-4a7e-a8df-9a137b999de1 @ 05/05/24 17:13:34.437
  May  5 17:13:34.440: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7915" for this suite. @ 05/05/24 17:13:34.447
• [0.042 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 05/05/24 17:13:34.456
  May  5 17:13:34.456: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename subpath @ 05/05/24 17:13:34.462
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:13:34.479
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:13:34.482
  STEP: Setting up data @ 05/05/24 17:13:34.486
  STEP: Creating pod pod-subpath-test-secret-t4kz @ 05/05/24 17:13:34.496
  STEP: Creating a pod to test atomic-volume-subpath @ 05/05/24 17:13:34.496
  E0505 17:13:35.006696      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:36.005955      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:37.006829      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:38.007425      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:39.008665      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:40.008885      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:41.013762      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:42.013962      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:43.014381      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:44.014667      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:45.014831      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:46.015786      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:47.015959      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:48.016497      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:49.016702      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:50.017136      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:51.021511      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:52.022645      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:53.023480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:54.023640      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:55.023847      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:56.024388      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:57.027751      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:13:58.031431      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:13:58.575
  May  5 17:13:58.579: INFO: Trying to get logs from node worker00 pod pod-subpath-test-secret-t4kz container test-container-subpath-secret-t4kz: <nil>
  STEP: delete the pod @ 05/05/24 17:13:58.583
  STEP: Deleting pod pod-subpath-test-secret-t4kz @ 05/05/24 17:13:58.605
  May  5 17:13:58.605: INFO: Deleting pod "pod-subpath-test-secret-t4kz" in namespace "subpath-8590"
  May  5 17:13:58.607: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-8590" for this suite. @ 05/05/24 17:13:58.608
• [24.157 seconds]
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
  STEP: Creating a kubernetes client @ 05/05/24 17:13:58.614
  May  5 17:13:58.614: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubectl @ 05/05/24 17:13:58.616
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:13:58.624
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:13:58.626
  May  5 17:13:58.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9447 create -f -'
  May  5 17:13:58.705: INFO: stderr: ""
  May  5 17:13:58.705: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  May  5 17:13:58.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9447 create -f -'
  May  5 17:13:58.840: INFO: stderr: ""
  May  5 17:13:58.840: INFO: stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 05/05/24 17:13:58.84
  E0505 17:13:59.031190      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:13:59.844: INFO: Selector matched 1 pods for map[app:agnhost]
  May  5 17:13:59.844: INFO: Found 0 / 1
  E0505 17:14:00.031166      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:00.845: INFO: Selector matched 1 pods for map[app:agnhost]
  May  5 17:14:00.845: INFO: Found 1 / 1
  May  5 17:14:00.845: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  May  5 17:14:00.848: INFO: Selector matched 1 pods for map[app:agnhost]
  May  5 17:14:00.848: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  May  5 17:14:00.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9447 describe pod agnhost-primary-fkvbn'
  May  5 17:14:00.893: INFO: stderr: ""
  May  5 17:14:00.893: INFO: stdout: "Name:             agnhost-primary-fkvbn\nNamespace:        kubectl-9447\nPriority:         0\nService Account:  default\nNode:             worker00/192.168.58.100\nStart Time:       Sun, 05 May 2024 17:13:58 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: b4aeadfa1acbf75706d682da2c61c6409cad326f2bfdec9c4dace5850195faf8\n                  cni.projectcalico.org/podIP: 10.200.131.129/32\n                  cni.projectcalico.org/podIPs: 10.200.131.129/32\nStatus:           Running\nIP:               10.200.131.129\nIPs:\n  IP:           10.200.131.129\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://26586cc78c80e5ef0d81a8c04e424e8f919d702539a29020a67892774c38ded6\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.47\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sun, 05 May 2024 17:13:59 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-lmf2w (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-lmf2w:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-9447/agnhost-primary-fkvbn to worker00\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.47\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
  May  5 17:14:00.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9447 describe rc agnhost-primary'
  May  5 17:14:00.936: INFO: stderr: ""
  May  5 17:14:00.936: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-9447\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.47\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-fkvbn\n"
  May  5 17:14:00.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9447 describe service agnhost-primary'
  May  5 17:14:00.983: INFO: stderr: ""
  May  5 17:14:00.983: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-9447\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.32.0.202\nIPs:               10.32.0.202\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.200.131.129:6379\nSession Affinity:  None\nEvents:            <none>\n"
  May  5 17:14:00.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9447 describe node worker00'
  E0505 17:14:01.032464      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:01.044: INFO: stderr: ""
  May  5 17:14:01.044: INFO: stdout: "Name:               worker00\nRoles:              controller,worker\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=worker00\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/controller=true\n                    node-role.kubernetes.io/worker=true\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"cephfs.csi.ceph.com\":\"worker00\",\"rbd.csi.ceph.com\":\"worker00\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 192.168.58.100/24\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.200.131.135\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sun, 05 May 2024 16:00:13 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  worker00\n  AcquireTime:     <unset>\n  RenewTime:       Sun, 05 May 2024 17:13:54 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sun, 05 May 2024 16:04:25 +0000   Sun, 05 May 2024 16:04:25 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Sun, 05 May 2024 17:11:02 +0000   Sun, 05 May 2024 16:00:13 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sun, 05 May 2024 17:11:02 +0000   Sun, 05 May 2024 16:00:13 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sun, 05 May 2024 17:11:02 +0000   Sun, 05 May 2024 16:00:13 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sun, 05 May 2024 17:11:02 +0000   Sun, 05 May 2024 16:00:44 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.58.100\n  Hostname:    worker00\nCapacity:\n  cpu:                    4\n  ephemeral-storage:      31811408Ki\n  example.com/fakecpu:    1k\n  hugepages-2Mi:          0\n  memory:                 4009412Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nAllocatable:\n  cpu:                    4\n  ephemeral-storage:      29317393565\n  example.com/fakecpu:    1k\n  hugepages-2Mi:          0\n  memory:                 3907012Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nSystem Info:\n  Machine ID:                 33ecf1c4cb0c4eb1b03a4a7b500ff113\n  System UUID:                ebff887b-a13d-fe46-9595-c27e98df8f98\n  Boot ID:                    a19809fa-3647-449e-9d19-c1a057327ef9\n  Kernel Version:             6.8.0-31-generic\n  OS Image:                   Ubuntu 24.04 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.7.16\n  Kubelet Version:            v1.30.0\n  Kube-Proxy Version:         v1.30.0\nPodCIDR:                      10.200.0.0/24\nPodCIDRs:                     10.200.0.0/24\nNon-terminated Pods:          (15 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 etcd-worker00                                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         72m\n  kube-system                 gobetween-worker00                                         100m (2%)     0 (0%)      0 (0%)           0 (0%)         72m\n  kube-system                 kube-apiserver-worker00                                    250m (6%)     0 (0%)      0 (0%)           0 (0%)         72m\n  kube-system                 kube-controller-manager-worker00                           200m (5%)     0 (0%)      0 (0%)           0 (0%)         72m\n  kube-system                 kube-proxy-worker00                                        200m (5%)     0 (0%)      0 (0%)           0 (0%)         73m\n  kube-system                 kube-scheduler-worker00                                    100m (2%)     0 (0%)      0 (0%)           0 (0%)         72m\n  kubectl-9447                agnhost-primary-fkvbn                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  networking                  calico-node-qbc8c                                          250m (6%)     0 (0%)      0 (0%)           0 (0%)         73m\n  networking                  metallb-speaker-bb4zq                                      100m (2%)     100m (2%)   100Mi (2%)       100Mi (2%)     27m\n  sonobuoy                    sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         67m\n  sonobuoy                    sonobuoy-e2e-job-919a92fc1d484e90                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         67m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-75c9f5cbb2184229-8sxzt    0 (0%)        0 (0%)      0 (0%)           0 (0%)         67m\n  storage                     ceph-csi-cephfs-nodeplugin-kht47                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         27m\n  storage                     ceph-csi-rbd-nodeplugin-sjzlp                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         27m\n  storage                     ceph-mon-worker00-797bf6469d-wb64d                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         27m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource               Requests     Limits\n  --------               --------     ------\n  cpu                    1200m (30%)  100m (2%)\n  memory                 100Mi (2%)   100Mi (2%)\n  ephemeral-storage      0 (0%)       0 (0%)\n  hugepages-2Mi          0 (0%)       0 (0%)\n  example.com/fakecpu    0            0\n  scheduling.k8s.io/foo  0            0\nEvents:                  <none>\n"
  May  5 17:14:01.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9447 describe namespace kubectl-9447'
  May  5 17:14:01.089: INFO: stderr: ""
  May  5 17:14:01.089: INFO: stdout: "Name:         kubectl-9447\nLabels:       e2e-framework=kubectl\n              e2e-run=36ac1179-7441-4802-bd3c-1c2016f45a78\n              kubernetes.io/metadata.name=kubectl-9447\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  May  5 17:14:01.089: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9447" for this suite. @ 05/05/24 17:14:01.091
• [2.480 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 05/05/24 17:14:01.095
  May  5 17:14:01.095: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename pods @ 05/05/24 17:14:01.095
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:14:01.102
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:14:01.104
  May  5 17:14:01.105: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: creating the pod @ 05/05/24 17:14:01.106
  STEP: submitting the pod to kubernetes @ 05/05/24 17:14:01.106
  E0505 17:14:02.032706      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:03.033817      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:03.170: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3216" for this suite. @ 05/05/24 17:14:03.172
• [2.080 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:274
  STEP: Creating a kubernetes client @ 05/05/24 17:14:03.175
  May  5 17:14:03.175: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename namespaces @ 05/05/24 17:14:03.176
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:14:03.184
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:14:03.186
  STEP: creating a Namespace @ 05/05/24 17:14:03.187
  STEP: patching the Namespace @ 05/05/24 17:14:03.193
  STEP: get the Namespace and ensuring it has the label @ 05/05/24 17:14:03.195
  May  5 17:14:03.197: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-4149" for this suite. @ 05/05/24 17:14:03.199
  STEP: Destroying namespace "nspatchtest-4f7057d5-da3a-4167-888c-c9f555fb2837-3904" for this suite. @ 05/05/24 17:14:03.202
• [0.031 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:54
  STEP: Creating a kubernetes client @ 05/05/24 17:14:03.206
  May  5 17:14:03.206: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename podtemplate @ 05/05/24 17:14:03.207
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:14:03.213
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:14:03.214
  May  5 17:14:03.227: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-1814" for this suite. @ 05/05/24 17:14:03.229
• [0.025 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:527
  STEP: Creating a kubernetes client @ 05/05/24 17:14:03.232
  May  5 17:14:03.232: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename container-probe @ 05/05/24 17:14:03.233
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:14:03.24
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:14:03.241
  STEP: Creating pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682 @ 05/05/24 17:14:03.243
  E0505 17:14:04.035061      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:05.035419      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/05/24 17:14:05.256
  May  5 17:14:05.260: INFO: Initial restart count of pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e is 0
  May  5 17:14:05.262: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:06.066277      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:07.067570      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:07.267: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:08.067578      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:09.069339      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:09.274: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:10.069504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:11.070145      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:11.277: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:12.071389      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:13.071649      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:13.282: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:14.072020      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:15.072855      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:15.287: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:16.072988      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:17.073625      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:17.294: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:18.075478      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:19.075642      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:19.299: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:20.075983      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:21.076472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:21.305: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:22.076830      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:23.077175      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:23.308: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:24.077333      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:25.077587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:25.317: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:26.078578      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:27.078783      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:27.323: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:28.079772      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:29.080818      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:29.331: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:30.080876      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:31.081219      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:31.336: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:32.081557      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:33.086971      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:33.340: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:34.088436      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:35.087681      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:35.343: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:36.088603      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:37.090029      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:37.347: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:38.090774      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:39.091862      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:39.354: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:40.091757      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:41.092117      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:41.361: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:42.093127      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:43.093504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:43.367: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:44.093851      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:45.094845      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:45.375: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:46.096125      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:47.097343      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:47.378: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:48.097710      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:49.099158      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:49.381: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:50.099419      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:51.100998      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:51.386: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:52.100789      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:53.105379      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:53.392: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:54.105507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:55.106196      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:55.404: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:56.108394      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:57.108512      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:57.410: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:14:58.109014      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:14:59.109729      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:14:59.415: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:00.110492      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:01.115588      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:01.417: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:02.115800      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:03.116116      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:03.421: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:04.116300      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:05.116431      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:05.427: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:06.117128      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:07.117814      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:07.431: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:08.121419      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:09.122068      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:09.434: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:10.122902      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:11.123929      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:11.437: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:12.124133      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:13.124802      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:13.461: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:14.125284      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:15.125295      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:15.467: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:16.125475      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:17.126360      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:17.472: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:18.126476      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:19.126857      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:19.480: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:20.128481      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:21.128922      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:21.486: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:22.130046      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:23.130127      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:23.492: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:24.130937      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:25.131221      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:25.497: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:26.131774      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:27.132314      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:27.499: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:28.132207      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:29.135701      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:29.505: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:30.137046      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:31.137941      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:31.514: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:32.140190      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:33.140637      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:33.520: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:34.140783      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:35.141867      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:35.524: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:36.142503      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:37.143451      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:37.528: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:38.143938      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:39.143929      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:39.533: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:40.144213      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:41.144885      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:41.538: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:42.145179      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:43.146133      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:43.544: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:44.148942      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:45.149404      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:45.550: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:46.149860      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:47.150231      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:47.556: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:48.150653      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:49.151120      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:49.564: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:50.151588      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:51.151539      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:51.570: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:52.152100      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:53.154782      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:53.575: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:54.157505      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:55.158564      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:55.578: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:56.158714      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:57.158828      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:57.584: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:15:58.159547      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:15:59.160088      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:15:59.685: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:00.160692      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:01.162462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:01.691: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:02.162786      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:03.162987      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:03.693: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:04.163709      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:05.164468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:05.698: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:06.166030      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:07.166398      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:07.703: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:08.166565      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:09.167615      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:09.712: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:10.168175      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:11.168822      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:11.718: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:12.169938      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:13.171450      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:13.724: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:14.172217      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:15.172295      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:15.730: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:16.173296      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:17.173957      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:17.734: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:18.174144      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:19.174627      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:19.745: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:20.175068      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:21.175737      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:21.750: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:22.176136      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:23.177034      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:23.756: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:24.177914      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:25.178914      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:25.760: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:26.179838      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:27.180407      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:27.768: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:28.181467      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:29.181492      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:29.776: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:30.182044      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:31.182077      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:31.781: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:32.182507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:33.182699      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:33.785: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:34.183040      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:35.183922      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:35.796: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:36.183766      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:37.184550      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:37.802: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:38.187196      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:39.191640      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:39.806: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:40.192351      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:41.192537      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:41.813: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:42.193880      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:43.194151      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:43.821: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:44.194780      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:45.195278      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:45.826: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:46.195702      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:47.196212      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:47.831: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:48.196444      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:49.197780      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:49.837: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:50.198128      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:51.198512      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:51.842: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:52.199500      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:53.199925      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:53.844: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:54.200459      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:55.200969      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:55.850: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:56.201548      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:57.202462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:57.854: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:16:58.203598      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:16:59.204454      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:16:59.857: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:00.204450      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:01.205916      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:01.862: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:02.206035      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:03.206408      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:03.867: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:04.206999      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:05.207597      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:05.872: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:06.207999      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:07.208651      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:07.878: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:08.209894      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:09.210306      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:09.887: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:10.210816      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:11.211960      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:11.893: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:12.213015      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:13.213864      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:13.898: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:14.214386      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:15.214857      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:15.904: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:16.214952      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:17.215245      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:17.908: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:18.215755      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:19.216524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:19.911: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:20.218905      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:21.220280      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:21.916: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:22.220969      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:23.221679      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:23.921: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:24.221729      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:25.222130      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:25.926: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:26.223178      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:27.223813      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:27.931: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:28.224874      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:29.225171      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:29.934: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:30.225916      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:31.282516      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:31.942: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:32.283976      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:33.284218      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:33.947: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:34.285769      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:35.286289      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:35.954: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:36.288733      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:37.289621      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:37.962: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:38.289975      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:39.290442      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:39.965: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:40.291268      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:41.291913      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:41.968: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:42.292552      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:43.293622      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:43.971: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:44.294807      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:45.295823      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:45.981: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:46.295958      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:47.295990      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:47.985: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:48.299998      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:49.300102      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:49.989: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:50.300362      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:51.301136      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:51.993: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:52.302131      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:53.302543      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:53.995: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:54.304009      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:55.303992      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:56.000: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:56.305046      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:57.307628      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:17:58.003: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:17:58.308174      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:17:59.308159      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:18:00.006: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:18:00.309072      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:01.309616      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:18:02.011: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:18:02.310424      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:03.311114      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:18:04.016: INFO: Get pod test-grpc-9130d70b-854e-47d8-bce1-54beafbd612e in namespace container-probe-6682
  E0505 17:18:04.311827      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:05.311831      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 05/05/24 17:18:06.017
  May  5 17:18:06.035: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6682" for this suite. @ 05/05/24 17:18:06.038
• [242.816 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:349
  STEP: Creating a kubernetes client @ 05/05/24 17:18:06.049
  May  5 17:18:06.049: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename disruption @ 05/05/24 17:18:06.051
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:18:06.063
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:18:06.066
  STEP: Creating a pdb that targets all three pods in a test replica set @ 05/05/24 17:18:06.067
  STEP: Waiting for the pdb to be processed @ 05/05/24 17:18:06.071
  E0505 17:18:06.311806      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:07.312731      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 05/05/24 17:18:08.089
  STEP: Waiting for all pods to be running @ 05/05/24 17:18:08.097
  May  5 17:18:08.106: INFO: pods: 1 < 3
  E0505 17:18:08.313504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:09.313867      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 05/05/24 17:18:10.101
  STEP: Updating the pdb to allow a pod to be evicted @ 05/05/24 17:18:10.112
  STEP: Waiting for the pdb to be processed @ 05/05/24 17:18:10.124
  E0505 17:18:10.314008      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:11.314458      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 05/05/24 17:18:12.127
  STEP: Waiting for all pods to be running @ 05/05/24 17:18:12.127
  STEP: Waiting for the pdb to observed all healthy pods @ 05/05/24 17:18:12.13
  STEP: Patching the pdb to disallow a pod to be evicted @ 05/05/24 17:18:12.16
  STEP: Waiting for the pdb to be processed @ 05/05/24 17:18:12.188
  E0505 17:18:12.315417      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:13.315638      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 05/05/24 17:18:14.191
  STEP: locating a running pod @ 05/05/24 17:18:14.194
  STEP: Deleting the pdb to allow a pod to be evicted @ 05/05/24 17:18:14.198
  STEP: Waiting for the pdb to be deleted @ 05/05/24 17:18:14.201
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 05/05/24 17:18:14.202
  STEP: Waiting for all pods to be running @ 05/05/24 17:18:14.203
  May  5 17:18:14.216: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-6806" for this suite. @ 05/05/24 17:18:14.222
• [8.183 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:1031
  STEP: Creating a kubernetes client @ 05/05/24 17:18:14.235
  May  5 17:18:14.235: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename statefulset @ 05/05/24 17:18:14.239
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:18:14.258
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:18:14.262
  STEP: Creating service test in namespace statefulset-4499 @ 05/05/24 17:18:14.265
  STEP: Creating statefulset ss in namespace statefulset-4499 @ 05/05/24 17:18:14.277
  May  5 17:18:14.288: INFO: Found 0 stateful pods, waiting for 1
  E0505 17:18:14.316477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:15.317211      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:16.319233      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:17.320969      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:18.321338      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:19.323683      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:20.323808      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:21.325223      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:22.325693      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:23.326267      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:18:24.291: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 05/05/24 17:18:24.296
  STEP: Getting /status @ 05/05/24 17:18:24.312
  May  5 17:18:24.317: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 05/05/24 17:18:24.317
  May  5 17:18:24.323: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 05/05/24 17:18:24.323
  May  5 17:18:24.325: INFO: Observed &StatefulSet event: ADDED
  May  5 17:18:24.325: INFO: Found Statefulset ss in namespace statefulset-4499 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  May  5 17:18:24.325: INFO: Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 05/05/24 17:18:24.325
  May  5 17:18:24.325: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  E0505 17:18:24.327131      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:18:24.329: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 05/05/24 17:18:24.329
  May  5 17:18:24.330: INFO: Observed &StatefulSet event: ADDED
  May  5 17:18:24.330: INFO: Observed Statefulset ss in namespace statefulset-4499 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  May  5 17:18:24.331: INFO: Observed &StatefulSet event: MODIFIED
  May  5 17:18:24.331: INFO: Deleting all statefulset in ns statefulset-4499
  May  5 17:18:24.333: INFO: Scaling statefulset ss to 0
  E0505 17:18:25.327499      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:26.328501      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:27.328886      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:28.329133      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:29.330632      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:30.334395      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:31.334642      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:32.335077      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:33.336180      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:34.336442      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:18:34.340: INFO: Waiting for statefulset status.replicas updated to 0
  May  5 17:18:34.342: INFO: Deleting statefulset ss
  May  5 17:18:34.360: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4499" for this suite. @ 05/05/24 17:18:34.363
• [20.133 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:530
  STEP: Creating a kubernetes client @ 05/05/24 17:18:34.368
  May  5 17:18:34.368: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename security-context-test @ 05/05/24 17:18:34.371
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:18:34.386
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:18:34.389
  E0505 17:18:35.339420      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:36.339902      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:37.340071      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:38.340196      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:18:38.411: INFO: Got logs for pod "busybox-privileged-false-39d0b28e-2730-4a12-9595-ea661957d511": "ip: RTNETLINK answers: Operation not permitted\n"
  May  5 17:18:38.411: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-7612" for this suite. @ 05/05/24 17:18:38.413
• [4.048 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:48
  STEP: Creating a kubernetes client @ 05/05/24 17:18:38.416
  May  5 17:18:38.416: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 17:18:38.417
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:18:38.424
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:18:38.425
  STEP: Creating configMap with name projected-configmap-test-volume-99788982-2d7d-46a6-805b-6d76e4e6f0a2 @ 05/05/24 17:18:38.426
  STEP: Creating a pod to test consume configMaps @ 05/05/24 17:18:38.428
  E0505 17:18:39.340813      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:40.341482      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:41.341711      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:42.342410      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:18:42.476
  May  5 17:18:42.480: INFO: Trying to get logs from node worker00 pod pod-projected-configmaps-01962812-c4bd-475f-9f16-76ff787223d0 container agnhost-container: <nil>
  STEP: delete the pod @ 05/05/24 17:18:42.485
  May  5 17:18:42.493: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7498" for this suite. @ 05/05/24 17:18:42.495
• [4.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:376
  STEP: Creating a kubernetes client @ 05/05/24 17:18:42.498
  May  5 17:18:42.498: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 17:18:42.499
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:18:42.507
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:18:42.508
  STEP: Creating configMap with name projected-configmap-test-volume-0b7be5bf-e6d4-46cb-b4a8-445f3e6b54b9 @ 05/05/24 17:18:42.51
  STEP: Creating a pod to test consume configMaps @ 05/05/24 17:18:42.512
  E0505 17:18:43.345542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:44.347560      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:45.348591      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:46.349494      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:18:46.524
  May  5 17:18:46.526: INFO: Trying to get logs from node worker00 pod pod-projected-configmaps-003885c4-7ac8-4351-95c6-71d68a9c347d container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 05/05/24 17:18:46.53
  May  5 17:18:46.542: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7910" for this suite. @ 05/05/24 17:18:46.544
• [4.051 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:115
  STEP: Creating a kubernetes client @ 05/05/24 17:18:46.549
  May  5 17:18:46.549: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename var-expansion @ 05/05/24 17:18:46.55
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:18:46.559
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:18:46.561
  STEP: Creating a pod to test substitution in volume subpath @ 05/05/24 17:18:46.563
  E0505 17:18:47.350810      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:48.351490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:49.352127      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:50.352621      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:18:50.579
  May  5 17:18:50.592: INFO: Trying to get logs from node worker00 pod var-expansion-4ff59a17-c006-469b-b991-e5185b10732c container dapi-container: <nil>
  STEP: delete the pod @ 05/05/24 17:18:50.596
  May  5 17:18:50.604: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1876" for this suite. @ 05/05/24 17:18:50.605
• [4.059 seconds]
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:707
  STEP: Creating a kubernetes client @ 05/05/24 17:18:50.608
  May  5 17:18:50.608: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename sched-pred @ 05/05/24 17:18:50.609
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:18:50.616
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:18:50.618
  May  5 17:18:50.620: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  May  5 17:18:50.625: INFO: Waiting for terminating namespaces to be deleted...
  May  5 17:18:50.627: INFO: 
  Logging pods the apiserver thinks is on node worker00 before test
  May  5 17:18:50.634: INFO: etcd-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.635: INFO: 	Container etcd ready: true, restart count 0
  May  5 17:18:50.635: INFO: gobetween-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.635: INFO: 	Container gobetween ready: true, restart count 0
  May  5 17:18:50.635: INFO: kube-apiserver-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.635: INFO: 	Container kube-apiserver ready: true, restart count 0
  May  5 17:18:50.635: INFO: kube-controller-manager-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.635: INFO: 	Container kube-controller-manager ready: true, restart count 0
  May  5 17:18:50.635: INFO: kube-proxy-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.635: INFO: 	Container kube-proxy ready: true, restart count 0
  May  5 17:18:50.635: INFO: kube-scheduler-worker00 from kube-system started at 2024-05-05 15:59:32 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.635: INFO: 	Container kube-scheduler ready: true, restart count 0
  May  5 17:18:50.635: INFO: calico-node-qbc8c from networking started at 2024-05-05 16:00:27 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.636: INFO: 	Container calico-node ready: true, restart count 0
  May  5 17:18:50.636: INFO: metallb-speaker-bb4zq from networking started at 2024-05-05 16:46:32 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.636: INFO: 	Container speaker ready: true, restart count 0
  May  5 17:18:50.636: INFO: sonobuoy from sonobuoy started at 2024-05-05 16:06:18 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.636: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  May  5 17:18:50.636: INFO: sonobuoy-e2e-job-919a92fc1d484e90 from sonobuoy started at 2024-05-05 16:06:24 +0000 UTC (2 container statuses recorded)
  May  5 17:18:50.636: INFO: 	Container e2e ready: true, restart count 0
  May  5 17:18:50.636: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May  5 17:18:50.636: INFO: sonobuoy-systemd-logs-daemon-set-75c9f5cbb2184229-8sxzt from sonobuoy started at 2024-05-05 16:06:24 +0000 UTC (2 container statuses recorded)
  May  5 17:18:50.636: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May  5 17:18:50.636: INFO: 	Container systemd-logs ready: true, restart count 0
  May  5 17:18:50.636: INFO: ceph-csi-cephfs-nodeplugin-kht47 from storage started at 2024-05-05 16:46:33 +0000 UTC (3 container statuses recorded)
  May  5 17:18:50.636: INFO: 	Container csi-cephfsplugin ready: true, restart count 0
  May  5 17:18:50.636: INFO: 	Container driver-registrar ready: true, restart count 0
  May  5 17:18:50.636: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 17:18:50.636: INFO: ceph-csi-rbd-nodeplugin-sjzlp from storage started at 2024-05-05 16:46:33 +0000 UTC (3 container statuses recorded)
  May  5 17:18:50.636: INFO: 	Container csi-rbdplugin ready: true, restart count 0
  May  5 17:18:50.636: INFO: 	Container driver-registrar ready: true, restart count 0
  May  5 17:18:50.636: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 17:18:50.636: INFO: ceph-mon-worker00-797bf6469d-wb64d from storage started at 2024-05-05 16:46:32 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.636: INFO: 	Container ceph-mon ready: true, restart count 0
  May  5 17:18:50.636: INFO: 
  Logging pods the apiserver thinks is on node worker01 before test
  May  5 17:18:50.655: INFO: coredns-5b87cbd9d7-7qqjb from kube-system started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container coredns ready: true, restart count 0
  May  5 17:18:50.655: INFO: coredns-5b87cbd9d7-sbzwr from kube-system started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container coredns ready: true, restart count 0
  May  5 17:18:50.655: INFO: gobetween-worker01 from kube-system started at 2024-05-05 15:59:42 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container gobetween ready: true, restart count 0
  May  5 17:18:50.655: INFO: kube-proxy-worker01 from kube-system started at 2024-05-05 15:59:42 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container kube-proxy ready: true, restart count 0
  May  5 17:18:50.655: INFO: kubernetes-dashboard-api-86d45cdc48-tqjcd from kube-system started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container kubernetes-dashboard-api ready: true, restart count 0
  May  5 17:18:50.655: INFO: kubernetes-dashboard-auth-5d859bc497-tv49r from kube-system started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container kubernetes-dashboard-auth ready: true, restart count 0
  May  5 17:18:50.655: INFO: kubernetes-dashboard-kong-766ffb8f6-bhcg5 from kube-system started at 2024-05-05 16:46:09 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container proxy ready: true, restart count 0
  May  5 17:18:50.655: INFO: kubernetes-dashboard-metrics-scraper-56c9f5cc54-j5nbq from kube-system started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container kubernetes-dashboard-metrics-scraper ready: true, restart count 0
  May  5 17:18:50.655: INFO: kubernetes-dashboard-web-74dcc49f5-5zxqx from kube-system started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container kubernetes-dashboard-web ready: true, restart count 0
  May  5 17:18:50.655: INFO: calico-kube-controllers-758c99c4b5-bblrs from networking started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container calico-kube-controllers ready: true, restart count 0
  May  5 17:18:50.655: INFO: calico-node-7g4c9 from networking started at 2024-05-05 16:00:29 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container calico-node ready: true, restart count 0
  May  5 17:18:50.655: INFO: calico-typha-5cfbc84557-5zvkz from networking started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container calico-typha ready: true, restart count 0
  May  5 17:18:50.655: INFO: metallb-controller-67f4cfb984-rk9hg from networking started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container controller ready: true, restart count 0
  May  5 17:18:50.655: INFO: metallb-speaker-22x22 from networking started at 2024-05-05 16:00:48 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container speaker ready: true, restart count 0
  May  5 17:18:50.655: INFO: sonobuoy-systemd-logs-daemon-set-75c9f5cbb2184229-mw8sz from sonobuoy started at 2024-05-05 16:06:25 +0000 UTC (2 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container systemd-logs ready: true, restart count 0
  May  5 17:18:50.655: INFO: ceph-csi-cephfs-nodeplugin-xsgjl from storage started at 2024-05-05 16:00:29 +0000 UTC (3 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container csi-cephfsplugin ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container driver-registrar ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 17:18:50.655: INFO: ceph-csi-cephfs-provisioner-6dc49995f7-lqt4k from storage started at 2024-05-05 16:00:29 +0000 UTC (5 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container csi-cephfsplugin ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 17:18:50.655: INFO: ceph-csi-cephfs-provisioner-6dc49995f7-svr4r from storage started at 2024-05-05 16:00:29 +0000 UTC (5 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container csi-cephfsplugin ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 17:18:50.655: INFO: ceph-csi-cephfs-provisioner-6dc49995f7-tfb66 from storage started at 2024-05-05 16:00:29 +0000 UTC (5 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container csi-cephfsplugin ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 17:18:50.655: INFO: ceph-csi-rbd-nodeplugin-cmg7z from storage started at 2024-05-05 16:00:29 +0000 UTC (3 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container csi-rbdplugin ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container driver-registrar ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 17:18:50.655: INFO: ceph-csi-rbd-provisioner-55f5bd6544-8f77n from storage started at 2024-05-05 16:00:29 +0000 UTC (7 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container csi-attacher ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-rbdplugin ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-rbdplugin-controller ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 17:18:50.655: INFO: ceph-csi-rbd-provisioner-55f5bd6544-bgrv6 from storage started at 2024-05-05 16:00:29 +0000 UTC (7 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container csi-attacher ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-rbdplugin ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-rbdplugin-controller ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 17:18:50.655: INFO: ceph-csi-rbd-provisioner-55f5bd6544-v9llp from storage started at 2024-05-05 16:00:29 +0000 UTC (7 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container csi-attacher ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-provisioner ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-rbdplugin ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-rbdplugin-controller ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-resizer ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May  5 17:18:50.655: INFO: 	Container liveness-prometheus ready: true, restart count 0
  May  5 17:18:50.655: INFO: ceph-mds-worker01-798b64d68-wr2nm from storage started at 2024-05-05 16:00:29 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container ceph-mds ready: true, restart count 0
  May  5 17:18:50.655: INFO: ceph-mgr-worker01-7c4c56cf76-hn7lr from storage started at 2024-05-05 16:00:29 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container ceph-mgr ready: true, restart count 0
  May  5 17:18:50.655: INFO: ceph-osd-worker01-75d7885b87-5cqv9 from storage started at 2024-05-05 16:00:29 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container ceph-osd ready: true, restart count 0
  May  5 17:18:50.655: INFO: ceph-rgw-worker01-5bd8c8bf8b-k4vwv from storage started at 2024-05-05 16:00:29 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container ceph-rgw ready: true, restart count 0
  May  5 17:18:50.655: INFO: ceph-setup-wh6dw from storage started at 2024-05-05 16:00:28 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container ceph ready: false, restart count 0
  May  5 17:18:50.655: INFO: snapshot-controller-587656f7cd-7n6bj from storage started at 2024-05-05 16:46:09 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container snapshot-controller ready: true, restart count 0
  May  5 17:18:50.655: INFO: snapshot-controller-587656f7cd-wf594 from storage started at 2024-05-05 16:46:08 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container snapshot-controller ready: true, restart count 0
  May  5 17:18:50.655: INFO: snapshot-validation-webhook-64b8d8cb7b-n7m99 from storage started at 2024-05-05 16:46:09 +0000 UTC (1 container statuses recorded)
  May  5 17:18:50.655: INFO: 	Container snapshot-validation-webhook ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 05/05/24 17:18:50.655
  E0505 17:18:51.352910      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:52.354567      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 05/05/24 17:18:52.695
  STEP: Trying to apply a random label on the found node. @ 05/05/24 17:18:52.713
  STEP: verifying the node has the label kubernetes.io/e2e-34da0761-314b-43e6-93b9-60b86e766b03 95 @ 05/05/24 17:18:52.724
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 05/05/24 17:18:52.729
  E0505 17:18:53.354710      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:54.355293      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.58.100 on the node which pod4 resides and expect not scheduled @ 05/05/24 17:18:54.737
  E0505 17:18:55.356501      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:56.357490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:57.359480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:58.360168      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:18:59.360389      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:00.362971      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:01.365529      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:02.365799      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:03.365959      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:04.366778      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:05.367707      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:06.367717      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:07.368205      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:08.370609      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:09.370880      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:10.371046      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:11.372338      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:12.373160      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:13.374236      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:14.375166      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:15.375356      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:16.377361      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:17.379938      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:18.380468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:19.380806      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:20.383981      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:21.385674      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:22.387658      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:23.388553      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:24.389593      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:25.389721      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:26.390527      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:27.393647      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:28.395368      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:29.396523      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:30.396756      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:31.403533      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:32.402784      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:33.403174      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:34.403571      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:35.404763      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:36.405732      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:37.408226      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:38.407554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:39.410475      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:40.411707      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:41.414405      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:42.415466      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:43.416335      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:44.416549      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:45.417476      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:46.417714      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:47.417819      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:48.418905      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:49.419372      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:50.526958      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:51.527489      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:52.533061      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:53.533373      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:54.534103      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:55.534924      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:56.535321      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:57.536277      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:58.540882      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:19:59.541015      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:00.541128      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:01.550851      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:02.551011      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:03.552068      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:04.552118      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:05.552734      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:06.552798      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:07.553260      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:08.554124      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:09.554831      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:10.557044      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:11.558144      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:12.560828      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:13.561351      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:14.561481      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:15.563366      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:16.563561      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:17.565558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:18.566205      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:19.566791      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:20.567359      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:21.569066      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:22.569532      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:23.570422      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:24.570698      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:25.572515      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:26.573392      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:27.573604      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:28.574117      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:29.576367      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:30.577820      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:31.578861      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:32.579306      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:33.579520      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:34.579988      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:35.580134      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:36.581311      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:37.581777      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:38.582599      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:39.583424      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:40.583399      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:41.586772      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:42.587335      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:43.587415      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:44.588153      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:45.588353      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:46.589438      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:47.590404      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:48.590958      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:49.591644      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:50.592459      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:51.593094      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:52.593920      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:53.594847      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:54.596018      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:55.596613      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:56.596585      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:57.596728      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:58.598674      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:20:59.598790      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:00.599799      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:01.600522      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:02.601467      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:03.602077      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:04.603485      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:05.603926      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:06.604658      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:07.605848      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:08.606319      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:09.607105      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:10.607024      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:11.609544      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:12.610176      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:13.613981      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:14.614202      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:15.614627      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:16.616029      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:17.616705      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:18.616938      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:19.619949      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:20.621471      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:21.627455      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:22.627127      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:23.631059      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:24.631896      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:25.632944      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:26.633504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:27.634501      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:28.635284      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:29.636119      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:30.637083      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:31.637343      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:32.638060      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:33.638994      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:34.640277      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:35.641375      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:36.642299      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:37.643086      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:38.643199      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:39.643951      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:40.645552      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:41.646015      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:42.646337      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:43.647328      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:44.647990      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:45.648736      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:46.649522      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:47.650457      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:48.660568      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:49.660513      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:50.660990      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:51.662466      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:52.664517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:53.665727      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:54.666297      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:55.666864      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:56.667177      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:57.667770      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:58.668628      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:21:59.673623      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:00.675560      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:01.678370      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:02.679968      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:03.680878      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:04.680486      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:05.682081      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:06.682513      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:07.683681      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:08.685344      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:09.685754      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:10.686826      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:11.687599      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:12.688826      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:13.689355      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:14.690367      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:15.691859      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:16.692333      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:17.692541      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:18.693843      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:19.693958      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:20.695127      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:21.696165      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:22.696714      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:23.697049      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:24.697957      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:25.698316      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:26.698472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:27.698705      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:28.698933      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:29.699024      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:30.699431      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:31.699932      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:32.700244      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:33.701417      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:34.708427      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:35.709623      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:36.709703      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:37.709996      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:38.710392      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:39.710686      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:40.712324      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:41.712987      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:42.732783      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:43.733064      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:44.733381      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:45.733751      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:46.734560      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:47.735454      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:48.736301      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:49.737060      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:50.738321      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:51.741440      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:52.741930      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:53.742439      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:54.743917      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:55.745099      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:56.745421      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:57.746775      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:58.747413      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:22:59.747699      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:00.747744      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:01.748409      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:02.749958      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:03.750123      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:04.750610      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:05.751617      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:06.752003      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:07.752588      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:08.752998      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:09.755595      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:10.760815      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:11.760745      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:12.761099      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:13.762722      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:14.762338      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:15.764471      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:16.765228      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:17.765415      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:18.766072      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:19.766712      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:20.766935      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:21.767824      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:22.768465      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:23.769622      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:24.770641      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:25.770770      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:26.771446      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:27.774669      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:28.775339      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:29.775666      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:30.775839      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:31.778693      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:32.778910      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:33.780017      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:34.780161      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:35.781300      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:36.781912      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:37.783132      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:38.784106      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:39.785612      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:40.786222      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:41.786953      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:42.787433      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:43.788123      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:44.789170      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:45.789582      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:46.790509      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:47.791367      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:48.791552      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:49.792832      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:50.793337      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:51.794153      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:52.794677      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:53.796444      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-34da0761-314b-43e6-93b9-60b86e766b03 off the node worker00 @ 05/05/24 17:23:54.746
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-34da0761-314b-43e6-93b9-60b86e766b03 @ 05/05/24 17:23:54.772
  May  5 17:23:54.779: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-7448" for this suite. @ 05/05/24 17:23:54.782
• [304.179 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1764
  STEP: Creating a kubernetes client @ 05/05/24 17:23:54.787
  May  5 17:23:54.787: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubectl @ 05/05/24 17:23:54.788
  E0505 17:23:54.796707      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:23:54.802
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:23:54.808
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/05/24 17:23:54.811
  May  5 17:23:54.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9219 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  May  5 17:23:54.866: INFO: stderr: ""
  May  5 17:23:54.866: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 05/05/24 17:23:54.866
  May  5 17:23:54.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-9219 delete pods e2e-test-httpd-pod'
  E0505 17:23:55.796530      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:23:56.757: INFO: stderr: ""
  May  5 17:23:56.757: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  May  5 17:23:56.757: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9219" for this suite. @ 05/05/24 17:23:56.759
• [1.974 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 05/05/24 17:23:56.762
  May  5 17:23:56.762: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename field-validation @ 05/05/24 17:23:56.763
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:23:56.77
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:23:56.773
  STEP: apply creating a deployment @ 05/05/24 17:23:56.775
  May  5 17:23:56.783: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7402" for this suite. @ 05/05/24 17:23:56.785
• [0.027 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 05/05/24 17:23:56.789
  May  5 17:23:56.789: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename pod-network-test @ 05/05/24 17:23:56.79
  E0505 17:23:56.797295      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:23:56.801
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:23:56.804
  STEP: Performing setup for networking test in namespace pod-network-test-3204 @ 05/05/24 17:23:56.805
  STEP: creating a selector @ 05/05/24 17:23:56.805
  STEP: Creating the service pods in kubernetes @ 05/05/24 17:23:56.805
  May  5 17:23:56.805: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0505 17:23:57.797507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:58.797749      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:23:59.798765      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:00.798998      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:01.799815      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:02.800811      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:03.801930      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:04.802907      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:05.803720      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:06.804138      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:07.804991      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:08.806251      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 05/05/24 17:24:08.863
  E0505 17:24:09.806661      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:10.807634      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:24:10.888: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  May  5 17:24:10.888: INFO: Breadth first check of 10.200.131.160 on host 192.168.58.100...
  May  5 17:24:10.889: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.131.145:9080/dial?request=hostname&protocol=http&host=10.200.131.160&port=8083&tries=1'] Namespace:pod-network-test-3204 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 17:24:10.889: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 17:24:10.889: INFO: ExecWithOptions: Clientset creation
  May  5 17:24:10.889: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/pod-network-test-3204/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.200.131.145%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.200.131.160%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  May  5 17:24:10.934: INFO: Waiting for responses: map[]
  May  5 17:24:10.934: INFO: reached 10.200.131.160 after 0/1 tries
  May  5 17:24:10.934: INFO: Breadth first check of 10.200.5.50 on host 192.168.58.101...
  May  5 17:24:10.935: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.131.145:9080/dial?request=hostname&protocol=http&host=10.200.5.50&port=8083&tries=1'] Namespace:pod-network-test-3204 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May  5 17:24:10.935: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 17:24:10.936: INFO: ExecWithOptions: Clientset creation
  May  5 17:24:10.936: INFO: ExecWithOptions: execute(POST https://10.32.0.1:443/api/v1/namespaces/pod-network-test-3204/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.200.131.145%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.200.5.50%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  May  5 17:24:10.969: INFO: Waiting for responses: map[]
  May  5 17:24:10.969: INFO: reached 10.200.5.50 after 0/1 tries
  May  5 17:24:10.969: INFO: Going to retry 0 out of 2 pods....
  May  5 17:24:10.969: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-3204" for this suite. @ 05/05/24 17:24:10.971
• [14.184 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:200
  STEP: Creating a kubernetes client @ 05/05/24 17:24:10.973
  May  5 17:24:10.973: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename emptydir @ 05/05/24 17:24:10.974
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:24:10.984
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:24:10.987
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 05/05/24 17:24:10.988
  E0505 17:24:11.807682      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:12.807779      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:24:12.999
  May  5 17:24:13.001: INFO: Trying to get logs from node worker00 pod pod-f8f4d563-bbca-4366-8785-d901d4a4999a container test-container: <nil>
  STEP: delete the pod @ 05/05/24 17:24:13.005
  May  5 17:24:13.013: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4032" for this suite. @ 05/05/24 17:24:13.015
• [2.045 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 05/05/24 17:24:13.019
  May  5 17:24:13.019: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename deployment @ 05/05/24 17:24:13.02
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:24:13.031
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:24:13.034
  May  5 17:24:13.037: INFO: Creating deployment "webserver-deployment"
  May  5 17:24:13.040: INFO: Waiting for observed generation 1
  E0505 17:24:13.808495      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:14.809763      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:24:15.049: INFO: Waiting for all required pods to come up
  May  5 17:24:15.052: INFO: Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 05/05/24 17:24:15.052
  E0505 17:24:15.820489      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:16.821567      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:24:17.060: INFO: Waiting for deployment "webserver-deployment" to complete
  May  5 17:24:17.065: INFO: Updating deployment "webserver-deployment" with a non-existent image
  May  5 17:24:17.069: INFO: Updating deployment webserver-deployment
  May  5 17:24:17.069: INFO: Waiting for observed generation 2
  E0505 17:24:17.823127      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:18.823164      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:24:19.077: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  May  5 17:24:19.080: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
  May  5 17:24:19.082: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  May  5 17:24:19.087: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  May  5 17:24:19.087: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
  May  5 17:24:19.088: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  May  5 17:24:19.090: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  May  5 17:24:19.090: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
  May  5 17:24:19.096: INFO: Updating deployment webserver-deployment
  May  5 17:24:19.096: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  May  5 17:24:19.101: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
  May  5 17:24:19.107: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
  May  5 17:24:19.127: INFO: Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "58568685-132e-467e-84c6-cc1c12c98f0a",
      ResourceVersion: (string) (len=5) "42281",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526653,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 3,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=59) "ReplicaSet \"webserver-deployment-9b4f5bf69\" is progressing."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  May  5 17:24:19.154: INFO: New ReplicaSet "webserver-deployment-9b4f5bf69" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "cb6ce7a5-eee6-4f2c-9bc5-86a9c8b809d8",
      ResourceVersion: (string) (len=5) "42275",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526657,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "58568685-132e-467e-84c6-cc1c12c98f0a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 35 38 35 36 38 36  38 35 2d 31 33 32 65 2d  |\"58568685-132e-|
              00000120  34 36 37 65 2d 38 34 63  36 2d 63 63 31 63 31 32  |467e-84c6-cc1c12|
              00000130  63 39 38 66 30 61 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |c98f0a\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May  5 17:24:19.163: INFO: All old ReplicaSets of Deployment "webserver-deployment":
  May  5 17:24:19.164: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
      ResourceVersion: (string) (len=5) "42273",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526653,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "58568685-132e-467e-84c6-cc1c12c98f0a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 35 38 35 36 38 36  38 35 2d 31 33 32 65 2d  |\"58568685-132e-|
              00000120  34 36 37 65 2d 38 34 63  36 2d 63 63 31 63 31 32  |467e-84c6-cc1c12|
              00000130  63 39 38 66 30 61 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |c98f0a\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May  5 17:24:19.199: INFO: Pod "webserver-deployment-557759b7c7-47cbh" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-47cbh",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b10d9b70-f742-4170-84c9-1d2f698a3616",
      ResourceVersion: (string) (len=5) "42310",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526659,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 32  39 32 62 39 38 34 2d 35  |d\":\"5292b984-5|
              00000090  30 35 35 2d 34 39 36 63  2d 39 38 37 65 2d 30 37  |055-496c-987e-07|
              000000a0  63 64 38 32 61 66 62 62  62 32 5c 22 7d 22 3a 7b  |cd82afbbb2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7mpz8",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7mpz8",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.204: INFO: Pod "webserver-deployment-557759b7c7-5k4dj" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-5k4dj",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b4b5a3ce-fb62-42ba-90b1-3bf43b4dc96e",
      ResourceVersion: (string) (len=5) "42304",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526659,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 32  39 32 62 39 38 34 2d 35  |d\":\"5292b984-5|
              00000090  30 35 35 2d 34 39 36 63  2d 39 38 37 65 2d 30 37  |055-496c-987e-07|
              000000a0  63 64 38 32 61 66 62 62  62 32 5c 22 7d 22 3a 7b  |cd82afbbb2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-d9w8v",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-d9w8v",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.209: INFO: Pod "webserver-deployment-557759b7c7-5znwr" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-5znwr",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0b705fc8-6949-4783-8161-26a73f02524d",
      ResourceVersion: (string) (len=5) "42298",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526659,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 32  39 32 62 39 38 34 2d 35  |d\":\"5292b984-5|
              00000090  30 35 35 2d 34 39 36 63  2d 39 38 37 65 2d 30 37  |055-496c-987e-07|
              000000a0  63 64 38 32 61 66 62 62  62 32 5c 22 7d 22 3a 7b  |cd82afbbb2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-f56f8",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-f56f8",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.215: INFO: Pod "webserver-deployment-557759b7c7-6dvzp" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-6dvzp",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "64702f95-a83f-4ed1-9fb2-c02ced5c505f",
      ResourceVersion: (string) (len=5) "42110",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526653,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "f31a622de9542b51031c8006855aaeaafdeedafd615dca3eefb98a4f5522f7d7",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=17) "10.200.131.161/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=17) "10.200.131.161/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 32  39 32 62 39 38 34 2d 35  |d\":\"5292b984-5|
              00000090  30 35 35 2d 34 39 36 63  2d 39 38 37 65 2d 30 37  |055-496c-987e-07|
              000000a0  63 64 38 32 61 66 62 62  62 32 5c 22 7d 22 3a 7b  |cd82afbbb2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 30 30 2e 31 33 31  2e 31 36 31 5c 22 7d 22  |.200.131.161\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-67vmk",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-67vmk",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker00",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.100",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.100"
        }
      },
      PodIP: (string) (len=14) "10.200.131.161",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "10.200.131.161"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526653,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850526654,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://f228dabedc169b69dfe94f71e8812f8a0d5e7f8f03e3f3ddee2f77d705a70a43",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.229: INFO: Pod "webserver-deployment-557759b7c7-bgq75" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-bgq75",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1bba1a87-74cc-4963-b5f6-3b0604b969dc",
      ResourceVersion: (string) (len=5) "42107",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526653,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "3ecf00475d45b26e3d24253bcd83b2c7ccae228570f413d43b94cd79c82376b6",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=17) "10.200.131.173/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=17) "10.200.131.173/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 32  39 32 62 39 38 34 2d 35  |d\":\"5292b984-5|
              00000090  30 35 35 2d 34 39 36 63  2d 39 38 37 65 2d 30 37  |055-496c-987e-07|
              000000a0  63 64 38 32 61 66 62 62  62 32 5c 22 7d 22 3a 7b  |cd82afbbb2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 30 30 2e 31 33 31  2e 31 37 33 5c 22 7d 22  |.200.131.173\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-sxg2x",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-sxg2x",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker00",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.100",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.100"
        }
      },
      PodIP: (string) (len=14) "10.200.131.173",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "10.200.131.173"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526653,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850526653,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://fff08b0093a04fcd24c070c15cdfe71d4ac366d538098c27a0536890b14946ea",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.253: INFO: Pod "webserver-deployment-557759b7c7-bgvtv" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-bgvtv",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3f2a7952-4a4b-43f5-b04e-ea58ada50331",
      ResourceVersion: (string) (len=5) "42091",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526653,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "3d08bc64a171686ce2174304c2cca355b508859b51ed01b6a066e3d35d3d41ee",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.200.5.62/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.200.5.62/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 32  39 32 62 39 38 34 2d 35  |d\":\"5292b984-5|
              00000090  30 35 35 2d 34 39 36 63  2d 39 38 37 65 2d 30 37  |055-496c-987e-07|
              000000a0  63 64 38 32 61 66 62 62  62 32 5c 22 7d 22 3a 7b  |cd82afbbb2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 30 30 2e 35 2e 36  32 5c 22 7d 22 3a 7b 22  |.200.5.62\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-95v6s",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-95v6s",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.101",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.101"
        }
      },
      PodIP: (string) (len=11) "10.200.5.62",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.200.5.62"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526653,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850526653,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://94b08ae95213dfba8a55809cd90078765b76305291496d5da3c958226def246b",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.259: INFO: Pod "webserver-deployment-557759b7c7-cgh2n" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-cgh2n",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fa69d469-fc5f-4672-b0d3-00e4663a8cd8",
      ResourceVersion: (string) (len=5) "42307",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526659,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 32  39 32 62 39 38 34 2d 35  |d\":\"5292b984-5|
              00000090  30 35 35 2d 34 39 36 63  2d 39 38 37 65 2d 30 37  |055-496c-987e-07|
              000000a0  63 64 38 32 61 66 62 62  62 32 5c 22 7d 22 3a 7b  |cd82afbbb2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9tmmv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9tmmv",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker00",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.267: INFO: Pod "webserver-deployment-557759b7c7-cwjmc" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-cwjmc",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4a8c649b-41e7-4d16-b610-784dd978a113",
      ResourceVersion: (string) (len=5) "42312",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526659,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 32  39 32 62 39 38 34 2d 35  |d\":\"5292b984-5|
              00000090  30 35 35 2d 34 39 36 63  2d 39 38 37 65 2d 30 37  |055-496c-987e-07|
              000000a0  63 64 38 32 61 66 62 62  62 32 5c 22 7d 22 3a 7b  |cd82afbbb2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-s88gr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-s88gr",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.271: INFO: Pod "webserver-deployment-557759b7c7-gbhbf" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-gbhbf",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "30739a43-4637-49d8-af0c-bbbd81f08d2a",
      ResourceVersion: (string) (len=5) "42306",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526659,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 32  39 32 62 39 38 34 2d 35  |d\":\"5292b984-5|
              00000090  30 35 35 2d 34 39 36 63  2d 39 38 37 65 2d 30 37  |055-496c-987e-07|
              000000a0  63 64 38 32 61 66 62 62  62 32 5c 22 7d 22 3a 7b  |cd82afbbb2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-zcxtz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-zcxtz",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.275: INFO: Pod "webserver-deployment-557759b7c7-h52fw" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-h52fw",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8bc8e71a-a3b0-4be0-b7f8-c54623bba6c0",
      ResourceVersion: (string) (len=5) "42305",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526659,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 32  39 32 62 39 38 34 2d 35  |d\":\"5292b984-5|
              00000090  30 35 35 2d 34 39 36 63  2d 39 38 37 65 2d 30 37  |055-496c-987e-07|
              000000a0  63 64 38 32 61 66 62 62  62 32 5c 22 7d 22 3a 7b  |cd82afbbb2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-hndxt",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-hndxt",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.101",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.101"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526659,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.287: INFO: Pod "webserver-deployment-557759b7c7-jslwb" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-jslwb",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a2e7a6ee-a030-4fec-a199-4fb99259a0da",
      ResourceVersion: (string) (len=5) "42299",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526659,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 32  39 32 62 39 38 34 2d 35  |d\":\"5292b984-5|
              00000090  30 35 35 2d 34 39 36 63  2d 39 38 37 65 2d 30 37  |055-496c-987e-07|
              000000a0  63 64 38 32 61 66 62 62  62 32 5c 22 7d 22 3a 7b  |cd82afbbb2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-lvk42",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-lvk42",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker00",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.345: INFO: Pod "webserver-deployment-557759b7c7-jvpjt" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-jvpjt",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fc1bbeeb-d144-49a7-b223-62d9dc708c4d",
      ResourceVersion: (string) (len=5) "42096",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526653,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "ecfa7f6dfa32483dd6cf2a7a2caf8f4bcd697a2f024f75fdd1d53f80c0240ac5",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.200.5.60/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.200.5.60/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 32  39 32 62 39 38 34 2d 35  |d\":\"5292b984-5|
              00000090  30 35 35 2d 34 39 36 63  2d 39 38 37 65 2d 30 37  |055-496c-987e-07|
              000000a0  63 64 38 32 61 66 62 62  62 32 5c 22 7d 22 3a 7b  |cd82afbbb2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 30 30 2e 35 2e 36  30 5c 22 7d 22 3a 7b 22  |.200.5.60\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-r2sgt",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-r2sgt",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.101",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.101"
        }
      },
      PodIP: (string) (len=11) "10.200.5.60",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.200.5.60"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526653,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850526653,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://212197c433ff0d7b6d488b9a616c556f4b2c8dbf551228f4fa265ba51d60e7c6",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.358: INFO: Pod "webserver-deployment-557759b7c7-mpc4x" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-mpc4x",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "47ee9849-6432-48c4-9caa-6ebbcc3e4392",
      ResourceVersion: (string) (len=5) "42286",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526659,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 32  39 32 62 39 38 34 2d 35  |d\":\"5292b984-5|
              00000090  30 35 35 2d 34 39 36 63  2d 39 38 37 65 2d 30 37  |055-496c-987e-07|
              000000a0  63 64 38 32 61 66 62 62  62 32 5c 22 7d 22 3a 7b  |cd82afbbb2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6tn86",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6tn86",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.361: INFO: Pod "webserver-deployment-557759b7c7-nmmnd" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-nmmnd",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e5e16097-e35d-4169-bcca-ff9061648e2c",
      ResourceVersion: (string) (len=5) "42291",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526659,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 32  39 32 62 39 38 34 2d 35  |d\":\"5292b984-5|
              00000090  30 35 35 2d 34 39 36 63  2d 39 38 37 65 2d 30 37  |055-496c-987e-07|
              000000a0  63 64 38 32 61 66 62 62  62 32 5c 22 7d 22 3a 7b  |cd82afbbb2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ntgt7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ntgt7",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.364: INFO: Pod "webserver-deployment-557759b7c7-rjphq" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-rjphq",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "32cec232-6362-4e18-9c6d-a0143e1f4e67",
      ResourceVersion: (string) (len=5) "42112",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526653,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "cb96a95c547a0ab4ea3c619bec72637ef35d0e97e9e5bee1db147efc11f3eb44",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=17) "10.200.131.172/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=17) "10.200.131.172/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 32  39 32 62 39 38 34 2d 35  |d\":\"5292b984-5|
              00000090  30 35 35 2d 34 39 36 63  2d 39 38 37 65 2d 30 37  |055-496c-987e-07|
              000000a0  63 64 38 32 61 66 62 62  62 32 5c 22 7d 22 3a 7b  |cd82afbbb2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 30 30 2e 31 33 31  2e 31 37 32 5c 22 7d 22  |.200.131.172\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-spwqt",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-spwqt",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker00",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.100",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.100"
        }
      },
      PodIP: (string) (len=14) "10.200.131.172",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "10.200.131.172"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526653,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850526654,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://abb5802a554d80d4cec351de77197df03f6f98649195c8951abcd7ce578d988e",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.381: INFO: Pod "webserver-deployment-557759b7c7-rmw9m" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-rmw9m",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "52745d8d-f391-4e1d-b250-d6f1ff332ffb",
      ResourceVersion: (string) (len=5) "42088",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526653,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.200.5.32/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.200.5.32/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "79a03bbe9c38ed54070bf054191218ee8f29731a82da00a56379d044207aee17"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 32  39 32 62 39 38 34 2d 35  |d\":\"5292b984-5|
              00000090  30 35 35 2d 34 39 36 63  2d 39 38 37 65 2d 30 37  |055-496c-987e-07|
              000000a0  63 64 38 32 61 66 62 62  62 32 5c 22 7d 22 3a 7b  |cd82afbbb2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 30 30 2e 35 2e 33  32 5c 22 7d 22 3a 7b 22  |.200.5.32\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-k48dx",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-k48dx",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.101",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.101"
        }
      },
      PodIP: (string) (len=11) "10.200.5.32",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.200.5.32"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526653,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850526653,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://590b2531520e1bbfb4d738dfee9772c2cee7933b2f2df0a5a46cfb608d7d447f",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.388: INFO: Pod "webserver-deployment-557759b7c7-t4fzb" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-t4fzb",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "44ecc028-1381-4418-ad4d-84d5d3ce3b15",
      ResourceVersion: (string) (len=5) "42309",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526659,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 32  39 32 62 39 38 34 2d 35  |d\":\"5292b984-5|
              00000090  30 35 35 2d 34 39 36 63  2d 39 38 37 65 2d 30 37  |055-496c-987e-07|
              000000a0  63 64 38 32 61 66 62 62  62 32 5c 22 7d 22 3a 7b  |cd82afbbb2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-rslvb",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-rslvb",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.394: INFO: Pod "webserver-deployment-557759b7c7-wkgfc" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-wkgfc",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a4b064b3-b369-4d78-b76d-138f5209c2a0",
      ResourceVersion: (string) (len=5) "42311",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526659,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 32  39 32 62 39 38 34 2d 35  |d\":\"5292b984-5|
              00000090  30 35 35 2d 34 39 36 63  2d 39 38 37 65 2d 30 37  |055-496c-987e-07|
              000000a0  63 64 38 32 61 66 62 62  62 32 5c 22 7d 22 3a 7b  |cd82afbbb2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-rgz9l",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-rgz9l",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.400: INFO: Pod "webserver-deployment-557759b7c7-xv9qr" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-xv9qr",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "bd11369f-6d69-416a-9d5d-5c31fd209b60",
      ResourceVersion: (string) (len=5) "42116",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526653,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=17) "10.200.131.164/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "958d6d392a195bb973b97acf614ec814fcb6452447820f891e0579a61946c517",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=17) "10.200.131.164/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 32  39 32 62 39 38 34 2d 35  |d\":\"5292b984-5|
              00000090  30 35 35 2d 34 39 36 63  2d 39 38 37 65 2d 30 37  |055-496c-987e-07|
              000000a0  63 64 38 32 61 66 62 62  62 32 5c 22 7d 22 3a 7b  |cd82afbbb2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 30 30 2e 31 33 31  2e 31 36 34 5c 22 7d 22  |.200.131.164\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-p7wb5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-p7wb5",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker00",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.100",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.100"
        }
      },
      PodIP: (string) (len=14) "10.200.131.164",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "10.200.131.164"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526653,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850526654,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://89a814eacb9c7c2a7166276f88d1d3d439f9e0ee7d29fb011fe6ec599e17ef78",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.408: INFO: Pod "webserver-deployment-557759b7c7-xvwjr" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-xvwjr",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "aa10a3db-c15f-4236-b858-93bb6145d488",
      ResourceVersion: (string) (len=5) "42119",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526653,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "cb9890b89015b6276acd9a069d168a1d9304029ca5fe03b20b2c3325ac359344",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=17) "10.200.131.174/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=17) "10.200.131.174/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5292b984-5055-496c-987e-07cd82afbbb2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 32  39 32 62 39 38 34 2d 35  |d\":\"5292b984-5|
              00000090  30 35 35 2d 34 39 36 63  2d 39 38 37 65 2d 30 37  |055-496c-987e-07|
              000000a0  63 64 38 32 61 66 62 62  62 32 5c 22 7d 22 3a 7b  |cd82afbbb2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 30 30 2e 31 33 31  2e 31 37 34 5c 22 7d 22  |.200.131.174\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-k582h",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-k582h",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker00",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.100",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.100"
        }
      },
      PodIP: (string) (len=14) "10.200.131.174",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "10.200.131.174"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526653,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850526654,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://8bbcb9345e2e8afda14d3290cd5824760f048362e94c3dacddcdc76099c2d14c",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.417: INFO: Pod "webserver-deployment-9b4f5bf69-2p247" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-2p247",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4900e2f2-257d-4621-852f-8e124fe2640c",
      ResourceVersion: (string) (len=5) "42302",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526659,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "cb6ce7a5-eee6-4f2c-9bc5-86a9c8b809d8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 62  36 63 65 37 61 35 2d 65  |d\":\"cb6ce7a5-e|
              00000090  65 65 36 2d 34 66 32 63  2d 39 62 63 35 2d 38 36  |ee6-4f2c-9bc5-86|
              000000a0  61 39 63 38 62 38 30 39  64 38 5c 22 7d 22 3a 7b  |a9c8b809d8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9cb7k",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9cb7k",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.427: INFO: Pod "webserver-deployment-9b4f5bf69-bgn6m" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-bgn6m",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4a6877c6-fdfe-4f6b-8014-175c248b326e",
      ResourceVersion: (string) (len=5) "42251",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526657,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "9291dc5d62cc7325dec1356f23c40129c95669ba6fffa613e69e7982311f2ae4",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=17) "10.200.131.151/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=17) "10.200.131.151/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "cb6ce7a5-eee6-4f2c-9bc5-86a9c8b809d8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 62  36 63 65 37 61 35 2d 65  |d\":\"cb6ce7a5-e|
              00000090  65 65 36 2d 34 66 32 63  2d 39 62 63 35 2d 38 36  |ee6-4f2c-9bc5-86|
              000000a0  61 39 63 38 62 38 30 39  64 38 5c 22 7d 22 3a 7b  |a9c8b809d8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-746s5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-746s5",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker00",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.100",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.100"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526657,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.435: INFO: Pod "webserver-deployment-9b4f5bf69-h5x8s" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-h5x8s",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3c61dda1-ce1f-4e3b-bbbd-be4dadb7cb00",
      ResourceVersion: (string) (len=5) "42296",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526659,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "cb6ce7a5-eee6-4f2c-9bc5-86a9c8b809d8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 62  36 63 65 37 61 35 2d 65  |d\":\"cb6ce7a5-e|
              00000090  65 65 36 2d 34 66 32 63  2d 39 62 63 35 2d 38 36  |ee6-4f2c-9bc5-86|
              000000a0  61 39 63 38 62 38 30 39  64 38 5c 22 7d 22 3a 7b  |a9c8b809d8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-frs4q",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-frs4q",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.439: INFO: Pod "webserver-deployment-9b4f5bf69-jqvhw" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-jqvhw",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e2d71a64-bd21-493d-9f7b-b7fc195c4323",
      ResourceVersion: (string) (len=5) "42301",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526659,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "cb6ce7a5-eee6-4f2c-9bc5-86a9c8b809d8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 62  36 63 65 37 61 35 2d 65  |d\":\"cb6ce7a5-e|
              00000090  65 65 36 2d 34 66 32 63  2d 39 62 63 35 2d 38 36  |ee6-4f2c-9bc5-86|
              000000a0  61 39 63 38 62 38 30 39  64 38 5c 22 7d 22 3a 7b  |a9c8b809d8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6ncpw",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6ncpw",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.442: INFO: Pod "webserver-deployment-9b4f5bf69-kzfw4" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-kzfw4",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c4567385-f736-4b0b-b266-9db30567915c",
      ResourceVersion: (string) (len=5) "42256",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526657,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "8ac0a2365a01b8eceaf26a3f0e2cf5d10da91241a831c4cb971c5c504291428d",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.200.5.47/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.200.5.47/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "cb6ce7a5-eee6-4f2c-9bc5-86a9c8b809d8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 62  36 63 65 37 61 35 2d 65  |d\":\"cb6ce7a5-e|
              00000090  65 65 36 2d 34 66 32 63  2d 39 62 63 35 2d 38 36  |ee6-4f2c-9bc5-86|
              000000a0  61 39 63 38 62 38 30 39  64 38 5c 22 7d 22 3a 7b  |a9c8b809d8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-5g2zr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-5g2zr",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.101",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.101"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526657,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.449: INFO: Pod "webserver-deployment-9b4f5bf69-lk465" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-lk465",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d7f2dd21-d37e-427d-b429-552c693ee43c",
      ResourceVersion: (string) (len=5) "42303",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526659,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "cb6ce7a5-eee6-4f2c-9bc5-86a9c8b809d8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 62  36 63 65 37 61 35 2d 65  |d\":\"cb6ce7a5-e|
              00000090  65 65 36 2d 34 66 32 63  2d 39 62 63 35 2d 38 36  |ee6-4f2c-9bc5-86|
              000000a0  61 39 63 38 62 38 30 39  64 38 5c 22 7d 22 3a 7b  |a9c8b809d8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vj5d5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vj5d5",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.454: INFO: Pod "webserver-deployment-9b4f5bf69-p8cpc" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-p8cpc",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d802fc05-cfec-4eb6-ac30-fd0c07278c84",
      ResourceVersion: (string) (len=5) "42293",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526659,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "cb6ce7a5-eee6-4f2c-9bc5-86a9c8b809d8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 62  36 63 65 37 61 35 2d 65  |d\":\"cb6ce7a5-e|
              00000090  65 65 36 2d 34 66 32 63  2d 39 62 63 35 2d 38 36  |ee6-4f2c-9bc5-86|
              000000a0  61 39 63 38 62 38 30 39  64 38 5c 22 7d 22 3a 7b  |a9c8b809d8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bj9n2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bj9n2",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker00",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.460: INFO: Pod "webserver-deployment-9b4f5bf69-qlq7s" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-qlq7s",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "40bf9bd4-3e62-46ab-89c3-528f575dbf89",
      ResourceVersion: (string) (len=5) "42250",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526657,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "7f2024434cfdbbd757673898b8e45c5366a93c3dab101fd1c3aebca7d6a8c080",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.200.5.20/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.200.5.20/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "cb6ce7a5-eee6-4f2c-9bc5-86a9c8b809d8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 62  36 63 65 37 61 35 2d 65  |d\":\"cb6ce7a5-e|
              00000090  65 65 36 2d 34 66 32 63  2d 39 62 63 35 2d 38 36  |ee6-4f2c-9bc5-86|
              000000a0  61 39 63 38 62 38 30 39  64 38 5c 22 7d 22 3a 7b  |a9c8b809d8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-rpncr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-rpncr",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.101",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.101"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526657,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.478: INFO: Pod "webserver-deployment-9b4f5bf69-r65vw" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-r65vw",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "40ce68e6-fd0d-45e7-94d8-50b2ffb67c40",
      ResourceVersion: (string) (len=5) "42244",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526657,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "927ba273b3db270cb8533b15e1d96a9297db685b82df8e8e45f565848c188715",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.200.5.53/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.200.5.53/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "cb6ce7a5-eee6-4f2c-9bc5-86a9c8b809d8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 62  36 63 65 37 61 35 2d 65  |d\":\"cb6ce7a5-e|
              00000090  65 65 36 2d 34 66 32 63  2d 39 62 63 35 2d 38 36  |ee6-4f2c-9bc5-86|
              000000a0  61 39 63 38 62 38 30 39  64 38 5c 22 7d 22 3a 7b  |a9c8b809d8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-nssjt",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-nssjt",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.101",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.101"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526657,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.495: INFO: Pod "webserver-deployment-9b4f5bf69-ss7vn" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-ss7vn",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "64f942ec-5b38-4112-9615-4ebd24527bcb",
      ResourceVersion: (string) (len=5) "42297",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526659,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "cb6ce7a5-eee6-4f2c-9bc5-86a9c8b809d8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 62  36 63 65 37 61 35 2d 65  |d\":\"cb6ce7a5-e|
              00000090  65 65 36 2d 34 66 32 63  2d 39 62 63 35 2d 38 36  |ee6-4f2c-9bc5-86|
              000000a0  61 39 63 38 62 38 30 39  64 38 5c 22 7d 22 3a 7b  |a9c8b809d8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9q7mm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9q7mm",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker00",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.501: INFO: Pod "webserver-deployment-9b4f5bf69-vslqb" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-vslqb",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f2425eab-961f-4520-8c73-f9e1468b41e7",
      ResourceVersion: (string) (len=5) "42300",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526659,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "cb6ce7a5-eee6-4f2c-9bc5-86a9c8b809d8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526659,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 62  36 63 65 37 61 35 2d 65  |d\":\"cb6ce7a5-e|
              00000090  65 65 36 2d 34 66 32 63  2d 39 62 63 35 2d 38 36  |ee6-4f2c-9bc5-86|
              000000a0  61 39 63 38 62 38 30 39  64 38 5c 22 7d 22 3a 7b  |a9c8b809d8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-fs797",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-fs797",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.506: INFO: Pod "webserver-deployment-9b4f5bf69-xksdg" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-xksdg",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1744",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "44c00839-c415-4e92-a840-8484d9e7cce4",
      ResourceVersion: (string) (len=5) "42245",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526657,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "a548ccda77cfc018d119591d8ec3a010d1e84c46bc38ace7ee4c9b15fdfc61d2",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=17) "10.200.131.144/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=17) "10.200.131.144/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "cb6ce7a5-eee6-4f2c-9bc5-86a9c8b809d8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 62  36 63 65 37 61 35 2d 65  |d\":\"cb6ce7a5-e|
              00000090  65 65 36 2d 34 66 32 63  2d 39 62 63 35 2d 38 36  |ee6-4f2c-9bc5-86|
              000000a0  61 39 63 38 62 38 30 39  64 38 5c 22 7d 22 3a 7b  |a9c8b809d8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4gvww",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4gvww",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker00",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850526657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.100",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.100"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850526657,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:24:19.536: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1744" for this suite. @ 05/05/24 17:24:19.575
• [6.631 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:47
  STEP: Creating a kubernetes client @ 05/05/24 17:24:19.735
  May  5 17:24:19.735: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename secrets @ 05/05/24 17:24:19.754
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:24:19.814
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:24:19.823
  E0505 17:24:19.824339      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating secret with name secret-test-aae84538-b994-463e-9e80-e9bc677cbd04 @ 05/05/24 17:24:19.827
  STEP: Creating a pod to test consume secrets @ 05/05/24 17:24:19.836
  E0505 17:24:20.824442      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:21.827851      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:22.826101      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:23.826282      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:24.829027      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:25.829424      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:24:25.955
  May  5 17:24:25.960: INFO: Trying to get logs from node worker01 pod pod-secrets-362107b8-ef78-4d96-8b46-d5469c1b481a container secret-env-test: <nil>
  STEP: delete the pod @ 05/05/24 17:24:25.995
  May  5 17:24:26.035: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8801" for this suite. @ 05/05/24 17:24:26.044
• [6.321 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:442
  STEP: Creating a kubernetes client @ 05/05/24 17:24:26.06
  May  5 17:24:26.060: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/05/24 17:24:26.064
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:24:26.085
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:24:26.092
  STEP: set up a multi version CRD @ 05/05/24 17:24:26.098
  May  5 17:24:26.099: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  E0505 17:24:26.830241      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:27.830316      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:28.830889      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mark a version not serverd @ 05/05/24 17:24:29.153
  STEP: check the unserved version gets removed @ 05/05/24 17:24:29.162
  STEP: check the other version is not changed @ 05/05/24 17:24:29.813
  E0505 17:24:29.831791      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:30.832526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:31.832968      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:24:32.219: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8515" for this suite. @ 05/05/24 17:24:32.228
• [6.174 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:195
  STEP: Creating a kubernetes client @ 05/05/24 17:24:32.232
  May  5 17:24:32.232: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename downward-api @ 05/05/24 17:24:32.232
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:24:32.241
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:24:32.243
  STEP: Creating a pod to test downward API volume plugin @ 05/05/24 17:24:32.246
  E0505 17:24:32.833255      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:33.833936      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:34.834122      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:35.835184      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:24:36.264
  May  5 17:24:36.268: INFO: Trying to get logs from node worker00 pod downwardapi-volume-3e3f14d3-2fbe-48c6-8a78-8123cc439c29 container client-container: <nil>
  STEP: delete the pod @ 05/05/24 17:24:36.273
  May  5 17:24:36.292: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2074" for this suite. @ 05/05/24 17:24:36.295
• [4.067 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:195
  STEP: Creating a kubernetes client @ 05/05/24 17:24:36.299
  May  5 17:24:36.299: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 17:24:36.301
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:24:36.31
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:24:36.312
  STEP: Creating a pod to test downward API volume plugin @ 05/05/24 17:24:36.315
  E0505 17:24:36.835439      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:37.837149      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:38.840630      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:39.841008      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:24:40.328
  May  5 17:24:40.330: INFO: Trying to get logs from node worker00 pod downwardapi-volume-64114fc5-82cf-4f1a-bf08-f09b4a7f5859 container client-container: <nil>
  STEP: delete the pod @ 05/05/24 17:24:40.332
  May  5 17:24:40.337: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9518" for this suite. @ 05/05/24 17:24:40.34
• [4.046 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:263
  STEP: Creating a kubernetes client @ 05/05/24 17:24:40.345
  May  5 17:24:40.345: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 17:24:40.347
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:24:40.355
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:24:40.358
  STEP: Creating a pod to test downward API volume plugin @ 05/05/24 17:24:40.36
  E0505 17:24:40.843139      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:41.843380      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:42.844045      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:43.844556      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:24:44.385
  May  5 17:24:44.389: INFO: Trying to get logs from node worker00 pod downwardapi-volume-7df8f702-3452-4269-ba43-93b1e109c44b container client-container: <nil>
  STEP: delete the pod @ 05/05/24 17:24:44.395
  May  5 17:24:44.409: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5415" for this suite. @ 05/05/24 17:24:44.411
• [4.070 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:130
  STEP: Creating a kubernetes client @ 05/05/24 17:24:44.415
  May  5 17:24:44.415: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename emptydir @ 05/05/24 17:24:44.415
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:24:44.427
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:24:44.429
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 05/05/24 17:24:44.431
  E0505 17:24:44.847332      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:45.845528      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:46.846444      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:47.846507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:24:48.446
  May  5 17:24:48.448: INFO: Trying to get logs from node worker00 pod pod-73e3e99e-9118-4235-8f52-3a74043ea99d container test-container: <nil>
  STEP: delete the pod @ 05/05/24 17:24:48.452
  May  5 17:24:48.464: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-783" for this suite. @ 05/05/24 17:24:48.47
• [4.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 05/05/24 17:24:48.474
  May  5 17:24:48.474: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename secrets @ 05/05/24 17:24:48.474
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:24:48.49
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:24:48.495
  STEP: Creating secret with name secret-test-9c8a1c8e-a15e-4f57-90d2-9b64caa04981 @ 05/05/24 17:24:48.499
  STEP: Creating a pod to test consume secrets @ 05/05/24 17:24:48.504
  E0505 17:24:48.847435      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:49.848506      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:24:50.52
  May  5 17:24:50.522: INFO: Trying to get logs from node worker00 pod pod-secrets-31115840-0581-4d0f-ac29-f3a18cc75a61 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/05/24 17:24:50.525
  May  5 17:24:50.534: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5185" for this suite. @ 05/05/24 17:24:50.536
• [2.065 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:199
  STEP: Creating a kubernetes client @ 05/05/24 17:24:50.539
  May  5 17:24:50.539: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/05/24 17:24:50.541
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:24:50.553
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:24:50.554
  STEP: fetching the /apis discovery document @ 05/05/24 17:24:50.558
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 05/05/24 17:24:50.559
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 05/05/24 17:24:50.559
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 05/05/24 17:24:50.56
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 05/05/24 17:24:50.561
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 05/05/24 17:24:50.561
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 05/05/24 17:24:50.563
  May  5 17:24:50.563: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-1598" for this suite. @ 05/05/24 17:24:50.566
• [0.030 seconds]
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:80
  STEP: Creating a kubernetes client @ 05/05/24 17:24:50.569
  May  5 17:24:50.569: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename svcaccounts @ 05/05/24 17:24:50.571
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:24:50.581
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:24:50.585
  E0505 17:24:50.849949      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:51.851101      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 05/05/24 17:24:52.615
  May  5 17:24:52.615: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8259 pod-service-account-d5fdb3e4-f8cf-4464-8a8c-68d07f4db0ac -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 05/05/24 17:24:52.692
  May  5 17:24:52.693: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8259 pod-service-account-d5fdb3e4-f8cf-4464-8a8c-68d07f4db0ac -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 05/05/24 17:24:52.764
  May  5 17:24:52.764: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8259 pod-service-account-d5fdb3e4-f8cf-4464-8a8c-68d07f4db0ac -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  May  5 17:24:52.840: INFO: Got root ca configmap in namespace "svcaccounts-8259"
  E0505 17:24:52.852178      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:24:52.852: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8259" for this suite. @ 05/05/24 17:24:52.855
• [2.289 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:140
  STEP: Creating a kubernetes client @ 05/05/24 17:24:52.858
  May  5 17:24:52.858: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename emptydir @ 05/05/24 17:24:52.859
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:24:52.871
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:24:52.873
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 05/05/24 17:24:52.874
  E0505 17:24:53.852423      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:54.853491      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:55.854060      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:56.854832      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:24:56.893
  May  5 17:24:56.897: INFO: Trying to get logs from node worker00 pod pod-a0fc478c-3ccb-4e38-a435-3f1bdc25cd36 container test-container: <nil>
  STEP: delete the pod @ 05/05/24 17:24:56.908
  May  5 17:24:56.937: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3729" for this suite. @ 05/05/24 17:24:56.939
• [4.084 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:208
  STEP: Creating a kubernetes client @ 05/05/24 17:24:56.943
  May  5 17:24:56.943: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename endpointslice @ 05/05/24 17:24:56.945
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:24:56.958
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:24:56.962
  E0505 17:24:57.855164      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:58.857420      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:24:59.859369      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:00.859606      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:01.860447      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 05/05/24 17:25:02.009
  E0505 17:25:02.861706      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:03.862730      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:04.863585      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:05.864392      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:06.865162      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing matching pods with named port @ 05/05/24 17:25:07.018
  E0505 17:25:07.867032      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:08.867675      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:09.867819      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:10.868293      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:11.868364      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 05/05/24 17:25:12.027
  E0505 17:25:12.869155      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:13.870372      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:14.870537      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:15.870769      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:16.871357      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: recreating EndpointSlices after they've been deleted @ 05/05/24 17:25:17.037
  May  5 17:25:17.071: INFO: EndpointSlice for Service endpointslice-5698/example-named-port not found
  E0505 17:25:17.871895      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:18.872232      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:19.874538      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:20.874700      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:21.875617      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:22.876259      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:23.877721      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:24.877802      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:25.879632      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:26.879786      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:25:27.079: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-5698" for this suite. @ 05/05/24 17:25:27.082
• [30.144 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:424
  STEP: Creating a kubernetes client @ 05/05/24 17:25:27.087
  May  5 17:25:27.087: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename configmap @ 05/05/24 17:25:27.089
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:25:27.097
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:25:27.1
  STEP: Creating configMap with name configmap-test-volume-6a4e2189-e202-41f8-a822-ae458706911c @ 05/05/24 17:25:27.102
  STEP: Creating a pod to test consume configMaps @ 05/05/24 17:25:27.104
  E0505 17:25:27.880649      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:28.881730      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:29.882045      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:30.882308      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:25:31.123
  May  5 17:25:31.126: INFO: Trying to get logs from node worker00 pod pod-configmaps-d4f13303-b060-45c2-9365-9843ceb83843 container configmap-volume-test: <nil>
  STEP: delete the pod @ 05/05/24 17:25:31.131
  May  5 17:25:31.142: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6355" for this suite. @ 05/05/24 17:25:31.144
• [4.061 seconds]
------------------------------
SSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:123
  STEP: Creating a kubernetes client @ 05/05/24 17:25:31.148
  May  5 17:25:31.148: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename podtemplate @ 05/05/24 17:25:31.148
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:25:31.156
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:25:31.158
  STEP: Create set of pod templates @ 05/05/24 17:25:31.16
  May  5 17:25:31.165: INFO: created test-podtemplate-1
  May  5 17:25:31.168: INFO: created test-podtemplate-2
  May  5 17:25:31.176: INFO: created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 05/05/24 17:25:31.176
  STEP: delete collection of pod templates @ 05/05/24 17:25:31.182
  May  5 17:25:31.182: INFO: requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 05/05/24 17:25:31.191
  May  5 17:25:31.191: INFO: requesting list of pod templates to confirm quantity
  May  5 17:25:31.194: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-4876" for this suite. @ 05/05/24 17:25:31.197
• [0.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:572
  STEP: Creating a kubernetes client @ 05/05/24 17:25:31.206
  May  5 17:25:31.206: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename job @ 05/05/24 17:25:31.207
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:25:31.222
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:25:31.226
  STEP: Creating a job @ 05/05/24 17:25:31.228
  STEP: Ensuring job reaches completions @ 05/05/24 17:25:31.232
  E0505 17:25:31.883192      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:32.883772      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:33.884838      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:34.886084      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:35.886779      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:36.887547      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:37.887725      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:38.888072      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:39.891198      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:40.892351      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:25:41.237: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-3080" for this suite. @ 05/05/24 17:25:41.24
• [10.048 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:234
  STEP: Creating a kubernetes client @ 05/05/24 17:25:41.256
  May  5 17:25:41.256: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename resourcequota @ 05/05/24 17:25:41.257
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:25:41.27
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:25:41.273
  STEP: Counting existing ResourceQuota @ 05/05/24 17:25:41.274
  E0505 17:25:41.894443      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:42.894720      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:43.895107      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:44.896213      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:45.897423      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/05/24 17:25:46.277
  STEP: Ensuring resource quota status is calculated @ 05/05/24 17:25:46.283
  E0505 17:25:46.897524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:47.899452      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 05/05/24 17:25:48.286
  STEP: Ensuring ResourceQuota status captures the pod usage @ 05/05/24 17:25:48.311
  E0505 17:25:48.901464      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:49.901338      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 05/05/24 17:25:50.313
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 05/05/24 17:25:50.314
  STEP: Ensuring a pod cannot update its resource requirements @ 05/05/24 17:25:50.315
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 05/05/24 17:25:50.317
  E0505 17:25:50.901392      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:51.902148      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/05/24 17:25:52.322
  STEP: Ensuring resource quota status released the pod usage @ 05/05/24 17:25:52.344
  E0505 17:25:52.903152      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:53.903576      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:25:54.351: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3756" for this suite. @ 05/05/24 17:25:54.356
• [13.115 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 05/05/24 17:25:54.371
  May  5 17:25:54.371: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename containers @ 05/05/24 17:25:54.373
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:25:54.383
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:25:54.386
  STEP: Creating a pod to test override arguments @ 05/05/24 17:25:54.389
  E0505 17:25:54.907007      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:55.908060      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:56.908786      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:57.909524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:25:58.41
  May  5 17:25:58.411: INFO: Trying to get logs from node worker00 pod client-containers-5a413c25-2255-4506-b9c6-966cec5ad371 container agnhost-container: <nil>
  STEP: delete the pod @ 05/05/24 17:25:58.416
  May  5 17:25:58.438: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-3047" for this suite. @ 05/05/24 17:25:58.44
• [4.074 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:110
  STEP: Creating a kubernetes client @ 05/05/24 17:25:58.448
  May  5 17:25:58.448: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename emptydir @ 05/05/24 17:25:58.449
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:25:58.46
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:25:58.464
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 05/05/24 17:25:58.466
  E0505 17:25:58.909867      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:25:59.910856      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:00.911760      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:01.912919      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:26:02.48
  May  5 17:26:02.482: INFO: Trying to get logs from node worker00 pod pod-8728ceed-0945-4352-8d6f-71cfa6453b25 container test-container: <nil>
  STEP: delete the pod @ 05/05/24 17:26:02.485
  May  5 17:26:02.503: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2097" for this suite. @ 05/05/24 17:26:02.504
• [4.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 05/05/24 17:26:02.507
  May  5 17:26:02.507: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename subpath @ 05/05/24 17:26:02.508
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:26:02.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:26:02.521
  STEP: Setting up data @ 05/05/24 17:26:02.522
  STEP: Creating pod pod-subpath-test-configmap-z2rh @ 05/05/24 17:26:02.527
  STEP: Creating a pod to test atomic-volume-subpath @ 05/05/24 17:26:02.527
  E0505 17:26:02.912907      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:03.913550      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:04.913441      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:05.914011      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:06.915649      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:07.916648      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:08.916628      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:09.919573      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:10.919904      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:11.920141      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:12.920280      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:13.921144      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:14.921413      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:15.921710      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:16.922690      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:17.922745      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:18.923887      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:19.924908      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:20.925325      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:21.925674      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:22.927075      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:23.927278      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:24.927377      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:25.928414      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:26:26.6
  May  5 17:26:26.604: INFO: Trying to get logs from node worker00 pod pod-subpath-test-configmap-z2rh container test-container-subpath-configmap-z2rh: <nil>
  STEP: delete the pod @ 05/05/24 17:26:26.61
  STEP: Deleting pod pod-subpath-test-configmap-z2rh @ 05/05/24 17:26:26.628
  May  5 17:26:26.628: INFO: Deleting pod "pod-subpath-test-configmap-z2rh" in namespace "subpath-5191"
  May  5 17:26:26.630: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-5191" for this suite. @ 05/05/24 17:26:26.633
• [24.129 seconds]
------------------------------
SS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 05/05/24 17:26:26.636
  May  5 17:26:26.636: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename pods @ 05/05/24 17:26:26.636
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:26:26.645
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:26:26.647
  STEP: creating the pod @ 05/05/24 17:26:26.649
  STEP: submitting the pod to kubernetes @ 05/05/24 17:26:26.649
  W0505 17:26:26.653836      22 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E0505 17:26:26.929886      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:27.930902      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 05/05/24 17:26:28.69
  STEP: updating the pod @ 05/05/24 17:26:28.691
  E0505 17:26:28.933595      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:26:29.207: INFO: Successfully updated pod "pod-update-activedeadlineseconds-2f73d0f0-4258-4533-80fc-9f5ddf20aa0b"
  E0505 17:26:29.934202      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:30.934924      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:31.935248      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:32.935460      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:26:33.225: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5377" for this suite. @ 05/05/24 17:26:33.235
• [6.620 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 05/05/24 17:26:33.256
  May  5 17:26:33.256: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename disruption @ 05/05/24 17:26:33.258
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:26:33.272
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:26:33.276
  STEP: Waiting for the pdb to be processed @ 05/05/24 17:26:33.284
  E0505 17:26:33.935749      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:34.936540      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 05/05/24 17:26:35.29
  STEP: Waiting for all pods to be running @ 05/05/24 17:26:35.312
  May  5 17:26:35.318: INFO: running pods: 0 < 1
  E0505 17:26:35.937716      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:36.938125      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 05/05/24 17:26:37.318
  STEP: Waiting for the pdb to be processed @ 05/05/24 17:26:37.338
  STEP: Patching PodDisruptionBudget status @ 05/05/24 17:26:37.343
  STEP: Waiting for the pdb to be processed @ 05/05/24 17:26:37.348
  May  5 17:26:37.352: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-1141" for this suite. @ 05/05/24 17:26:37.354
• [4.101 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:498
  STEP: Creating a kubernetes client @ 05/05/24 17:26:37.358
  May  5 17:26:37.358: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename webhook @ 05/05/24 17:26:37.359
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:26:37.371
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:26:37.374
  STEP: Setting up server cert @ 05/05/24 17:26:37.388
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/05/24 17:26:37.701
  STEP: Deploying the webhook pod @ 05/05/24 17:26:37.705
  STEP: Wait for the deployment to be ready @ 05/05/24 17:26:37.711
  May  5 17:26:37.718: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0505 17:26:37.938941      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:38.942176      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/05/24 17:26:39.732
  STEP: Verifying the service has paired with the endpoint @ 05/05/24 17:26:39.737
  E0505 17:26:39.943343      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:26:40.738: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 05/05/24 17:26:40.745
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 05/05/24 17:26:40.757
  STEP: Creating a configMap that should not be mutated @ 05/05/24 17:26:40.761
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 05/05/24 17:26:40.771
  STEP: Creating a configMap that should be mutated @ 05/05/24 17:26:40.777
  May  5 17:26:40.815: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6456" for this suite. @ 05/05/24 17:26:40.817
  STEP: Destroying namespace "webhook-markers-2466" for this suite. @ 05/05/24 17:26:40.822
• [3.471 seconds]
------------------------------
SSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2177
  STEP: Creating a kubernetes client @ 05/05/24 17:26:40.829
  May  5 17:26:40.829: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename services @ 05/05/24 17:26:40.83
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:26:40.846
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:26:40.849
  STEP: creating service in namespace services-9808 @ 05/05/24 17:26:40.853
  STEP: creating service affinity-clusterip in namespace services-9808 @ 05/05/24 17:26:40.853
  STEP: creating replication controller affinity-clusterip in namespace services-9808 @ 05/05/24 17:26:40.86
  I0505 17:26:40.869714      22 runners.go:197] Created replication controller with name: affinity-clusterip, namespace: services-9808, replica count: 3
  E0505 17:26:40.944100      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:41.945271      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:42.946172      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0505 17:26:43.921871      22 runners.go:197] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May  5 17:26:43.928: INFO: Creating new exec pod
  E0505 17:26:43.947223      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:44.947372      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:45.948300      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:26:46.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-9808 exec execpod-affinitywd5bz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  E0505 17:26:46.949420      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:26:47.008: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  May  5 17:26:47.008: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May  5 17:26:47.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-9808 exec execpod-affinitywd5bz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.179 80'
  May  5 17:26:47.085: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.32.0.179 80\nConnection to 10.32.0.179 80 port [tcp/http] succeeded!\n"
  May  5 17:26:47.085: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May  5 17:26:47.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-9808 exec execpod-affinitywd5bz -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.32.0.179:80/ ; done'
  May  5 17:26:47.211: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.179:80/\n"
  May  5 17:26:47.211: INFO: stdout: "\naffinity-clusterip-kz4g7\naffinity-clusterip-kz4g7\naffinity-clusterip-kz4g7\naffinity-clusterip-kz4g7\naffinity-clusterip-kz4g7\naffinity-clusterip-kz4g7\naffinity-clusterip-kz4g7\naffinity-clusterip-kz4g7\naffinity-clusterip-kz4g7\naffinity-clusterip-kz4g7\naffinity-clusterip-kz4g7\naffinity-clusterip-kz4g7\naffinity-clusterip-kz4g7\naffinity-clusterip-kz4g7\naffinity-clusterip-kz4g7\naffinity-clusterip-kz4g7"
  May  5 17:26:47.211: INFO: Received response from host: affinity-clusterip-kz4g7
  May  5 17:26:47.211: INFO: Received response from host: affinity-clusterip-kz4g7
  May  5 17:26:47.211: INFO: Received response from host: affinity-clusterip-kz4g7
  May  5 17:26:47.211: INFO: Received response from host: affinity-clusterip-kz4g7
  May  5 17:26:47.211: INFO: Received response from host: affinity-clusterip-kz4g7
  May  5 17:26:47.211: INFO: Received response from host: affinity-clusterip-kz4g7
  May  5 17:26:47.211: INFO: Received response from host: affinity-clusterip-kz4g7
  May  5 17:26:47.211: INFO: Received response from host: affinity-clusterip-kz4g7
  May  5 17:26:47.211: INFO: Received response from host: affinity-clusterip-kz4g7
  May  5 17:26:47.211: INFO: Received response from host: affinity-clusterip-kz4g7
  May  5 17:26:47.211: INFO: Received response from host: affinity-clusterip-kz4g7
  May  5 17:26:47.211: INFO: Received response from host: affinity-clusterip-kz4g7
  May  5 17:26:47.211: INFO: Received response from host: affinity-clusterip-kz4g7
  May  5 17:26:47.211: INFO: Received response from host: affinity-clusterip-kz4g7
  May  5 17:26:47.211: INFO: Received response from host: affinity-clusterip-kz4g7
  May  5 17:26:47.211: INFO: Received response from host: affinity-clusterip-kz4g7
  May  5 17:26:47.211: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-9808, will wait for the garbage collector to delete the pods @ 05/05/24 17:26:47.237
  May  5 17:26:47.304: INFO: Deleting ReplicationController affinity-clusterip took: 3.388387ms
  May  5 17:26:47.405: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.305428ms
  E0505 17:26:47.949806      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:48.950731      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:49.958958      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:26:50.222: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9808" for this suite. @ 05/05/24 17:26:50.226
• [9.405 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 05/05/24 17:26:50.234
  May  5 17:26:50.234: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename container-runtime @ 05/05/24 17:26:50.236
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:26:50.245
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:26:50.249
  STEP: create the container @ 05/05/24 17:26:50.251
  W0505 17:26:50.256172      22 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 05/05/24 17:26:50.257
  E0505 17:26:50.959133      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:51.959177      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/05/24 17:26:52.269
  STEP: the container should be terminated @ 05/05/24 17:26:52.273
  STEP: the termination message should be set @ 05/05/24 17:26:52.273
  May  5 17:26:52.273: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 05/05/24 17:26:52.273
  May  5 17:26:52.290: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-9974" for this suite. @ 05/05/24 17:26:52.292
• [2.061 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 05/05/24 17:26:52.296
  May  5 17:26:52.296: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename container-runtime @ 05/05/24 17:26:52.297
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:26:52.308
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:26:52.312
  STEP: create the container @ 05/05/24 17:26:52.314
  W0505 17:26:52.319113      22 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 05/05/24 17:26:52.319
  E0505 17:26:52.959345      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:53.960507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/05/24 17:26:54.332
  STEP: the container should be terminated @ 05/05/24 17:26:54.334
  STEP: the termination message should be set @ 05/05/24 17:26:54.334
  May  5 17:26:54.334: INFO: Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 05/05/24 17:26:54.334
  May  5 17:26:54.347: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-4903" for this suite. @ 05/05/24 17:26:54.35
• [2.057 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 05/05/24 17:26:54.353
  May  5 17:26:54.353: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename cronjob @ 05/05/24 17:26:54.354
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:26:54.364
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:26:54.366
  STEP: Creating a cronjob @ 05/05/24 17:26:54.367
  STEP: Ensuring more than one job is running at a time @ 05/05/24 17:26:54.372
  E0505 17:26:54.961341      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:55.961763      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:56.962316      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:57.963461      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:58.963828      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:26:59.964876      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:00.965930      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:01.967419      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:02.969404      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:03.970517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:04.970792      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:05.971487      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:06.973414      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:07.973645      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:08.974110      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:09.974513      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:10.975634      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:11.977857      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:12.978880      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:13.980305      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:14.981407      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:15.981786      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:16.982593      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:17.983026      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:18.983360      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:19.986546      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:20.987396      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:21.987443      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:22.989030      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:23.992851      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:24.994192      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:26.067445      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:27.067518      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:28.068391      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:29.069693      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:30.069784      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:31.070821      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:32.071924      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:33.072433      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:34.072726      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:35.073679      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:36.073828      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:37.075511      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:38.076381      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:39.076577      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:40.076678      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:41.077676      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:42.080001      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:43.080835      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:44.081367      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:45.082181      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:46.083012      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:47.084423      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:48.084733      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:49.085318      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:50.086020      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:51.086525      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:52.086824      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:53.087689      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:54.091912      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:55.092815      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:56.094019      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:57.094529      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:58.094796      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:27:59.096058      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:00.097826      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 05/05/24 17:28:00.374
  STEP: Removing cronjob @ 05/05/24 17:28:00.376
  May  5 17:28:00.388: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-1601" for this suite. @ 05/05/24 17:28:00.392
• [66.042 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 05/05/24 17:28:00.395
  May  5 17:28:00.395: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename watch @ 05/05/24 17:28:00.397
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:28:00.409
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:28:00.413
  STEP: creating a new configmap @ 05/05/24 17:28:00.415
  STEP: modifying the configmap once @ 05/05/24 17:28:00.419
  STEP: modifying the configmap a second time @ 05/05/24 17:28:00.434
  STEP: deleting the configmap @ 05/05/24 17:28:00.441
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 05/05/24 17:28:00.443
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 05/05/24 17:28:00.445
  May  5 17:28:00.445: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2475  60458cf5-d661-4524-867c-84f6f2aa9895 44612 0 2024-05-05 17:28:00 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-05-05 17:28:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May  5 17:28:00.445: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2475  60458cf5-d661-4524-867c-84f6f2aa9895 44613 0 2024-05-05 17:28:00 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-05-05 17:28:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May  5 17:28:00.445: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-2475" for this suite. @ 05/05/24 17:28:00.449
• [0.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 05/05/24 17:28:00.456
  May  5 17:28:00.456: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename subpath @ 05/05/24 17:28:00.457
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:28:00.471
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:28:00.473
  STEP: Setting up data @ 05/05/24 17:28:00.475
  STEP: Creating pod pod-subpath-test-downwardapi-rkzn @ 05/05/24 17:28:00.482
  STEP: Creating a pod to test atomic-volume-subpath @ 05/05/24 17:28:00.482
  E0505 17:28:01.098807      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:02.100271      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:03.100925      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:04.102028      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:05.102520      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:06.102984      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:07.103764      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:08.105771      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:09.106322      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:10.106296      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:11.106668      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:12.107570      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:13.107937      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:14.108610      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:15.109388      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:16.110408      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:17.110695      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:18.112580      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:19.113996      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:20.114979      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:21.115555      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:22.116078      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:28:22.56
  May  5 17:28:22.562: INFO: Trying to get logs from node worker00 pod pod-subpath-test-downwardapi-rkzn container test-container-subpath-downwardapi-rkzn: <nil>
  STEP: delete the pod @ 05/05/24 17:28:22.567
  STEP: Deleting pod pod-subpath-test-downwardapi-rkzn @ 05/05/24 17:28:22.576
  May  5 17:28:22.576: INFO: Deleting pod "pod-subpath-test-downwardapi-rkzn" in namespace "subpath-9764"
  May  5 17:28:22.579: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-9764" for this suite. @ 05/05/24 17:28:22.581
• [22.129 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:119
  STEP: Creating a kubernetes client @ 05/05/24 17:28:22.586
  May  5 17:28:22.586: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename webhook @ 05/05/24 17:28:22.586
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:28:22.596
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:28:22.6
  STEP: Setting up server cert @ 05/05/24 17:28:22.615
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/05/24 17:28:22.799
  STEP: Deploying the webhook pod @ 05/05/24 17:28:22.814
  STEP: Wait for the deployment to be ready @ 05/05/24 17:28:22.821
  May  5 17:28:22.827: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0505 17:28:23.116089      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:24.119781      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/05/24 17:28:24.836
  STEP: Verifying the service has paired with the endpoint @ 05/05/24 17:28:24.853
  E0505 17:28:25.120300      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:28:25.856: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 05/05/24 17:28:25.866
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 05/05/24 17:28:25.867
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 05/05/24 17:28:25.867
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 05/05/24 17:28:25.867
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 05/05/24 17:28:25.869
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 05/05/24 17:28:25.869
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 05/05/24 17:28:25.871
  May  5 17:28:25.910: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1501" for this suite. @ 05/05/24 17:28:25.911
  STEP: Destroying namespace "webhook-markers-7500" for this suite. @ 05/05/24 17:28:25.917
• [3.338 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 05/05/24 17:28:25.924
  May  5 17:28:25.924: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename container-runtime @ 05/05/24 17:28:25.926
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:28:25.99
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:28:25.994
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 05/05/24 17:28:26.001
  E0505 17:28:26.120715      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:27.121435      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:28.122501      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:29.122941      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:30.123684      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:31.124605      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:32.125598      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:33.127145      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:34.128517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:35.129543      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:36.130373      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:37.132006      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:38.133192      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:39.134233      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:40.135205      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:41.135443      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:42.136774      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:43.137859      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:44.138943      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:45.140034      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 05/05/24 17:28:46.113
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 05/05/24 17:28:46.116
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 05/05/24 17:28:46.121
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 05/05/24 17:28:46.121
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 05/05/24 17:28:46.141
  E0505 17:28:46.143112      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:47.143392      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:48.146773      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:49.149646      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 05/05/24 17:28:49.161
  E0505 17:28:50.149897      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 05/05/24 17:28:50.169
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 05/05/24 17:28:50.173
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 05/05/24 17:28:50.173
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 05/05/24 17:28:50.187
  E0505 17:28:51.150564      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 05/05/24 17:28:51.192
  E0505 17:28:52.150740      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:53.151926      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 05/05/24 17:28:53.201
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 05/05/24 17:28:53.203
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 05/05/24 17:28:53.203
  May  5 17:28:53.212: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-1056" for this suite. @ 05/05/24 17:28:53.214
• [27.295 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:164
  STEP: Creating a kubernetes client @ 05/05/24 17:28:53.222
  May  5 17:28:53.222: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename downward-api @ 05/05/24 17:28:53.224
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:28:53.235
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:28:53.238
  STEP: Creating the pod @ 05/05/24 17:28:53.241
  E0505 17:28:54.152362      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:55.153516      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:28:55.778: INFO: Successfully updated pod "annotationupdate64da1b4a-f0c1-4166-9fb2-6a91cb212093"
  E0505 17:28:56.154787      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:57.155809      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:28:57.793: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3833" for this suite. @ 05/05/24 17:28:57.797
• [4.580 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:309
  STEP: Creating a kubernetes client @ 05/05/24 17:28:57.802
  May  5 17:28:57.802: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/05/24 17:28:57.802
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:28:57.814
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:28:57.816
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 05/05/24 17:28:57.817
  May  5 17:28:57.818: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  E0505 17:28:58.155939      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:28:59.158936      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:00.160779      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:01.160670      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:02.160477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 05/05/24 17:29:02.655
  May  5 17:29:02.656: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  E0505 17:29:03.161419      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:29:03.871: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  E0505 17:29:04.161890      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:05.162481      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:06.162288      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:07.162679      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:08.163134      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:29:08.597: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-789" for this suite. @ 05/05/24 17:29:08.601
• [10.802 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 05/05/24 17:29:08.604
  May  5 17:29:08.604: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename watch @ 05/05/24 17:29:08.605
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:29:08.613
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:29:08.616
  STEP: creating a watch on configmaps with a certain label @ 05/05/24 17:29:08.618
  STEP: creating a new configmap @ 05/05/24 17:29:08.619
  STEP: modifying the configmap once @ 05/05/24 17:29:08.622
  STEP: changing the label value of the configmap @ 05/05/24 17:29:08.625
  STEP: Expecting to observe a delete notification for the watched object @ 05/05/24 17:29:08.63
  May  5 17:29:08.630: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2996  6d803bb1-87de-451d-8e21-9bc8c2e83fdc 45153 0 2024-05-05 17:29:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-05 17:29:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  May  5 17:29:08.630: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2996  6d803bb1-87de-451d-8e21-9bc8c2e83fdc 45154 0 2024-05-05 17:29:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-05 17:29:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  May  5 17:29:08.630: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2996  6d803bb1-87de-451d-8e21-9bc8c2e83fdc 45155 0 2024-05-05 17:29:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-05 17:29:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 05/05/24 17:29:08.63
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 05/05/24 17:29:08.636
  E0505 17:29:09.167769      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:10.168543      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:11.169529      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:12.171729      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:13.172768      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:14.173212      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:15.173885      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:16.174834      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:17.176145      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:18.177773      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 05/05/24 17:29:18.637
  STEP: modifying the configmap a third time @ 05/05/24 17:29:18.646
  STEP: deleting the configmap @ 05/05/24 17:29:18.65
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 05/05/24 17:29:18.653
  May  5 17:29:18.653: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2996  6d803bb1-87de-451d-8e21-9bc8c2e83fdc 45199 0 2024-05-05 17:29:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-05 17:29:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May  5 17:29:18.653: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2996  6d803bb1-87de-451d-8e21-9bc8c2e83fdc 45200 0 2024-05-05 17:29:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-05 17:29:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  May  5 17:29:18.653: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2996  6d803bb1-87de-451d-8e21-9bc8c2e83fdc 45201 0 2024-05-05 17:29:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-05 17:29:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  May  5 17:29:18.653: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-2996" for this suite. @ 05/05/24 17:29:18.656
• [10.055 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 05/05/24 17:29:18.661
  May  5 17:29:18.661: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename field-validation @ 05/05/24 17:29:18.662
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:29:18.728
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:29:18.732
  May  5 17:29:18.734: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  E0505 17:29:19.178448      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:20.179049      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:21.180907      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0505 17:29:21.268912      22 warnings.go:70] unknown field "alpha"
  W0505 17:29:21.268939      22 warnings.go:70] unknown field "beta"
  W0505 17:29:21.268948      22 warnings.go:70] unknown field "delta"
  W0505 17:29:21.268957      22 warnings.go:70] unknown field "epsilon"
  W0505 17:29:21.268966      22 warnings.go:70] unknown field "gamma"
  May  5 17:29:21.803: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8183" for this suite. @ 05/05/24 17:29:21.806
• [3.149 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:655
  STEP: Creating a kubernetes client @ 05/05/24 17:29:21.81
  May  5 17:29:21.810: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename job @ 05/05/24 17:29:21.811
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:29:21.821
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:29:21.823
  STEP: Creating a job @ 05/05/24 17:29:21.824
  STEP: Ensuring active pods == parallelism @ 05/05/24 17:29:21.828
  E0505 17:29:22.181384      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:23.181742      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 05/05/24 17:29:23.836
  E0505 17:29:24.181960      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:29:24.371: INFO: Successfully updated pod "adopt-release-9mpwk"
  STEP: Checking that the Job readopts the Pod @ 05/05/24 17:29:24.371
  E0505 17:29:25.182530      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:26.183005      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 05/05/24 17:29:26.383
  May  5 17:29:26.894: INFO: Successfully updated pod "adopt-release-9mpwk"
  STEP: Checking that the Job releases the Pod @ 05/05/24 17:29:26.894
  E0505 17:29:27.182786      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:28.184018      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:29:28.903: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-9466" for this suite. @ 05/05/24 17:29:28.906
• [7.111 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:160
  STEP: Creating a kubernetes client @ 05/05/24 17:29:28.922
  May  5 17:29:28.922: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename emptydir @ 05/05/24 17:29:28.923
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:29:28.932
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:29:28.934
  STEP: Creating a pod to test emptydir volume type on node default medium @ 05/05/24 17:29:28.936
  E0505 17:29:29.184541      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:30.186492      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:31.187347      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:32.187341      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:29:32.953
  May  5 17:29:32.959: INFO: Trying to get logs from node worker01 pod pod-52798994-051b-4fb1-ba0e-3f6eb2c856af container test-container: <nil>
  STEP: delete the pod @ 05/05/24 17:29:32.976
  May  5 17:29:32.996: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4543" for this suite. @ 05/05/24 17:29:32.997
• [4.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:480
  STEP: Creating a kubernetes client @ 05/05/24 17:29:33.001
  May  5 17:29:33.001: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename gc @ 05/05/24 17:29:33.002
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:29:33.008
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:29:33.012
  STEP: create the deployment @ 05/05/24 17:29:33.016
  W0505 17:29:33.018973      22 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 05/05/24 17:29:33.019
  E0505 17:29:33.188358      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 05/05/24 17:29:33.521
  STEP: wait for all rs to be garbage collected @ 05/05/24 17:29:33.53
  STEP: expected 0 rs, got 1 rs @ 05/05/24 17:29:33.535
  STEP: expected 0 pods, got 2 pods @ 05/05/24 17:29:33.54
  STEP: Gathering metrics @ 05/05/24 17:29:34.039
  May  5 17:29:34.138: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  May  5 17:29:34.138: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5145" for this suite. @ 05/05/24 17:29:34.146
• [1.151 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:125
  STEP: Creating a kubernetes client @ 05/05/24 17:29:34.152
  May  5 17:29:34.152: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename configmap @ 05/05/24 17:29:34.157
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:29:34.189
  E0505 17:29:34.189826      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:29:34.202
  STEP: Creating configMap with name configmap-test-upd-5ac63b27-0de7-4930-8d2c-5ced882658c4 @ 05/05/24 17:29:34.214
  STEP: Creating the pod @ 05/05/24 17:29:34.231
  E0505 17:29:35.194427      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:36.195975      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap configmap-test-upd-5ac63b27-0de7-4930-8d2c-5ced882658c4 @ 05/05/24 17:29:36.29
  STEP: waiting to observe update in volume @ 05/05/24 17:29:36.293
  E0505 17:29:37.196976      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:38.197217      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:39.198034      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:40.198480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:29:40.306: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9759" for this suite. @ 05/05/24 17:29:40.308
• [6.159 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:357
  STEP: Creating a kubernetes client @ 05/05/24 17:29:40.313
  May  5 17:29:40.313: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/05/24 17:29:40.313
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:29:40.322
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:29:40.325
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 05/05/24 17:29:40.327
  May  5 17:29:40.327: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  E0505 17:29:41.199001      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:29:41.505: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  E0505 17:29:42.199450      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:43.199665      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:44.200542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:45.201486      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:46.202292      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:29:46.267: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-209" for this suite. @ 05/05/24 17:29:46.271
• [5.962 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:163
  STEP: Creating a kubernetes client @ 05/05/24 17:29:46.275
  May  5 17:29:46.275: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename resourcequota @ 05/05/24 17:29:46.275
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:29:46.284
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:29:46.286
  STEP: Discovering how many secrets are in namespace by default @ 05/05/24 17:29:46.287
  E0505 17:29:47.203656      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:48.204490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:49.205458      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:50.206022      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:51.208197      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 05/05/24 17:29:51.291
  E0505 17:29:52.208864      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:53.208944      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:54.211510      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:55.211468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:56.212488      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/05/24 17:29:56.297
  STEP: Ensuring resource quota status is calculated @ 05/05/24 17:29:56.306
  E0505 17:29:57.212470      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:29:58.213077      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 05/05/24 17:29:58.311
  STEP: Ensuring resource quota status captures secret creation @ 05/05/24 17:29:58.322
  E0505 17:29:59.213282      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:00.213718      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 05/05/24 17:30:00.325
  STEP: Ensuring resource quota status released usage @ 05/05/24 17:30:00.34
  E0505 17:30:01.214265      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:02.215717      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:30:02.343: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4600" for this suite. @ 05/05/24 17:30:02.345
• [16.073 seconds]
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 05/05/24 17:30:02.348
  May  5 17:30:02.348: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename init-container @ 05/05/24 17:30:02.349
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:30:02.358
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:30:02.36
  STEP: creating the pod @ 05/05/24 17:30:02.362
  May  5 17:30:02.362: INFO: PodSpec: initContainers in spec.initContainers
  E0505 17:30:03.216959      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:04.217664      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:05.217651      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:06.217930      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:30:06.986: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-1480" for this suite. @ 05/05/24 17:30:06.988
• [4.645 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 05/05/24 17:30:06.993
  May  5 17:30:06.993: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename sched-preemption @ 05/05/24 17:30:06.994
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:30:07.006
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:30:07.008
  May  5 17:30:07.018: INFO: Waiting up to 1m0s for all nodes to be ready
  E0505 17:30:07.218167      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:08.218788      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:09.219229      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:10.219283      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:11.219531      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:12.220080      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:13.221143      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:14.224946      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:15.225113      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:16.228029      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:17.230802      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:18.231488      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:19.232445      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:20.233351      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:21.234107      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:22.234779      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:23.235431      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:24.236720      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:25.237917      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:26.238462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:27.239939      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:28.241348      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:29.242865      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:30.242162      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:31.242173      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:32.243655      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:33.243792      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:34.244050      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:35.244551      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:36.245176      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:37.245959      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:38.246859      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:39.247792      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:40.249420      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:41.257438      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:42.257757      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:43.258722      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:44.259621      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:45.259544      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:46.260038      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:47.260370      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:48.261760      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:49.262849      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:50.263012      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:51.266622      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:52.267916      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:53.268744      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:54.269834      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:55.270058      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:56.270785      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:57.270874      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:58.272817      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:30:59.274019      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:00.274587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:01.275738      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:02.276821      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:03.277438      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:04.277634      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:05.278147      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:06.278863      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:31:07.022: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 05/05/24 17:31:07.024
  May  5 17:31:07.049: INFO: Created pod: pod0-0-sched-preemption-low-priority
  May  5 17:31:07.055: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  May  5 17:31:07.070: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  May  5 17:31:07.079: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 05/05/24 17:31:07.079
  E0505 17:31:07.279404      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:08.279816      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 05/05/24 17:31:09.098
  E0505 17:31:09.280285      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:10.283497      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:31:11.139: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-3806" for this suite. @ 05/05/24 17:31:11.141
• [64.150 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:622
  STEP: Creating a kubernetes client @ 05/05/24 17:31:11.144
  May  5 17:31:11.144: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename field-validation @ 05/05/24 17:31:11.144
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:31:11.153
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:31:11.157
  May  5 17:31:11.159: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  E0505 17:31:11.283557      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:12.284300      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:13.284875      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0505 17:31:13.706355      22 warnings.go:70] unknown field "alpha"
  W0505 17:31:13.706391      22 warnings.go:70] unknown field "beta"
  W0505 17:31:13.706404      22 warnings.go:70] unknown field "delta"
  W0505 17:31:13.706417      22 warnings.go:70] unknown field "epsilon"
  W0505 17:31:13.706429      22 warnings.go:70] unknown field "gamma"
  May  5 17:31:14.225: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-2579" for this suite. @ 05/05/24 17:31:14.228
• [3.090 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:430
  STEP: Creating a kubernetes client @ 05/05/24 17:31:14.235
  May  5 17:31:14.235: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename pv @ 05/05/24 17:31:14.236
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:31:14.246
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:31:14.249
  STEP: Creating initial PV and PVC @ 05/05/24 17:31:14.25
  May  5 17:31:14.250: INFO: Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-5541" @ 05/05/24 17:31:14.262
  STEP: Listing PVCs in namespace "pv-5541" @ 05/05/24 17:31:14.266
  STEP: Patching the PV "pv-5541-9f8vb" @ 05/05/24 17:31:14.271
  STEP: Patching the PVC "pvc-9tgdj" @ 05/05/24 17:31:14.283
  E0505 17:31:14.284858      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Getting PV "pv-5541-9f8vb" @ 05/05/24 17:31:14.293
  STEP: Getting PVC "pvc-9tgdj" @ 05/05/24 17:31:14.294
  STEP: Deleting PVC "pvc-9tgdj" @ 05/05/24 17:31:14.295
  STEP: Confirm deletion of PVC "pvc-9tgdj" @ 05/05/24 17:31:14.301
  E0505 17:31:15.285747      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:16.285688      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-5541-9f8vb" @ 05/05/24 17:31:16.311
  STEP: Confirm deletion of PV "pv-5541-9f8vb" @ 05/05/24 17:31:16.32
  E0505 17:31:17.287079      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:18.289630      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating another PV & PVC @ 05/05/24 17:31:18.329
  May  5 17:31:18.329: INFO: Creating a PV followed by a PVC
  STEP: Updating the PV "pv-5541-8fd6g" @ 05/05/24 17:31:18.35
  STEP: Updating the PVC "pvc-2kxgk" @ 05/05/24 17:31:18.358
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-2kxgk=updated" @ 05/05/24 17:31:18.366
  STEP: Deleting PVC "pvc-2kxgk" via DeleteCollection @ 05/05/24 17:31:18.369
  STEP: Confirm deletion of PVC "pvc-2kxgk" @ 05/05/24 17:31:18.378
  E0505 17:31:19.290238      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:20.290618      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-5541-8fd6g" via DeleteCollection @ 05/05/24 17:31:20.384
  STEP: Confirm deletion of PV "pv-5541-8fd6g" @ 05/05/24 17:31:20.392
  E0505 17:31:21.292749      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:22.294621      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:31:22.403: INFO: AfterEach: deleting 1 PVCs and 1 PVs...
  May  5 17:31:22.404: INFO: Deleting PersistentVolumeClaim "pvc-2kxgk"
  May  5 17:31:22.407: INFO: Deleting PersistentVolume "pv-5541-8fd6g"
  May  5 17:31:22.410: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-5541" for this suite. @ 05/05/24 17:31:22.413
• [8.188 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:270
  STEP: Creating a kubernetes client @ 05/05/24 17:31:22.424
  May  5 17:31:22.424: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/05/24 17:31:22.425
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:31:22.434
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:31:22.444
  May  5 17:31:22.447: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  E0505 17:31:23.295292      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:24.296105      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:25.296387      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:31:25.631: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-1183" for this suite. @ 05/05/24 17:31:25.637
• [3.217 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 05/05/24 17:31:25.641
  May  5 17:31:25.641: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename subpath @ 05/05/24 17:31:25.642
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:31:25.65
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:31:25.653
  STEP: Setting up data @ 05/05/24 17:31:25.655
  STEP: Creating pod pod-subpath-test-projected-xgf2 @ 05/05/24 17:31:25.662
  STEP: Creating a pod to test atomic-volume-subpath @ 05/05/24 17:31:25.662
  E0505 17:31:26.297602      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:27.297639      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:28.297782      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:29.298532      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:30.299778      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:31.299987      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:32.300593      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:33.300768      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:34.301093      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:35.302894      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:36.305114      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:37.307366      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:38.307926      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:39.307880      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:40.308395      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:41.312023      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:42.311655      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:43.318362      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:44.319085      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:45.319470      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:46.319843      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:47.326426      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:48.327544      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:49.328870      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:31:49.755
  May  5 17:31:49.759: INFO: Trying to get logs from node worker00 pod pod-subpath-test-projected-xgf2 container test-container-subpath-projected-xgf2: <nil>
  STEP: delete the pod @ 05/05/24 17:31:49.764
  STEP: Deleting pod pod-subpath-test-projected-xgf2 @ 05/05/24 17:31:49.785
  May  5 17:31:49.785: INFO: Deleting pod "pod-subpath-test-projected-xgf2" in namespace "subpath-5322"
  May  5 17:31:49.787: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-5322" for this suite. @ 05/05/24 17:31:49.789
• [24.152 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:105
  STEP: Creating a kubernetes client @ 05/05/24 17:31:49.792
  May  5 17:31:49.792: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename endpointslice @ 05/05/24 17:31:49.793
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:31:49.807
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:31:49.81
  E0505 17:31:50.329677      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:51.330645      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:31:51.840: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-9635" for this suite. @ 05/05/24 17:31:51.842
• [2.052 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:142
  STEP: Creating a kubernetes client @ 05/05/24 17:31:51.847
  May  5 17:31:51.847: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename crd-webhook @ 05/05/24 17:31:51.848
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:31:51.857
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:31:51.862
  STEP: Setting up server cert @ 05/05/24 17:31:51.863
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 05/05/24 17:31:52.016
  STEP: Deploying the custom resource conversion webhook pod @ 05/05/24 17:31:52.02
  STEP: Wait for the deployment to be ready @ 05/05/24 17:31:52.026
  May  5 17:31:52.033: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0505 17:31:52.331587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:53.337298      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/05/24 17:31:54.04
  STEP: Verifying the service has paired with the endpoint @ 05/05/24 17:31:54.045
  E0505 17:31:54.337898      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:31:55.046: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  May  5 17:31:55.054: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  E0505 17:31:55.338669      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:56.339275      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:57.339936      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 05/05/24 17:31:57.661
  STEP: v2 custom resource should be converted @ 05/05/24 17:31:57.667
  May  5 17:31:58.241: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-995" for this suite. @ 05/05/24 17:31:58.243
• [6.407 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 05/05/24 17:31:58.259
  May  5 17:31:58.259: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename chunking @ 05/05/24 17:31:58.26
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:31:58.28
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:31:58.284
  STEP: creating a large number of resources @ 05/05/24 17:31:58.286
  E0505 17:31:58.340118      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:31:59.340194      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0505 17:31:59.419271      22 request.go:697] Waited for 1.003725402s due to client-side throttling, not priority and fairness, request: POST:https://10.32.0.1:443/api/v1/namespaces/chunking-4779/podtemplates
  E0505 17:32:00.341000      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:01.341974      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:02.342587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:03.344015      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:04.345131      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:05.345374      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:06.346633      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:07.347895      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:08.348750      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:09.349033      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:10.349162      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:11.350231      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0505 17:32:11.718903      22 request.go:697] Waited for 1.00494045s due to client-side throttling, not priority and fairness, request: POST:https://10.32.0.1:443/api/v1/namespaces/chunking-4779/podtemplates
  E0505 17:32:12.350946      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:13.351729      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:14.352756      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:15.353102      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the first page @ 05/05/24 17:32:15.97
  May  5 17:32:16.017: INFO: Retrieved 40/40 results with rv 46909 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page until the token expires @ 05/05/24 17:32:16.017
  E0505 17:32:16.354028      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:17.355013      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:18.356283      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:19.358476      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:20.363543      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:21.364462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:22.365690      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:23.366197      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:24.366939      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:25.367167      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:26.367575      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:27.368245      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:28.368953      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:29.370060      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:30.371407      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:31.373215      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:32.373487      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:33.374419      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:34.374627      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:35.375410      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:32:36.024: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:32:36.375486      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:37.378510      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:38.379051      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:39.379330      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:40.379528      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:41.380207      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:42.381411      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:43.381521      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:44.381664      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:45.381862      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:46.382031      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:47.384522      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:48.384722      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:49.390227      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:50.390370      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:51.390514      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:52.391133      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:53.391637      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:54.392465      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:55.394488      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:32:56.024: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:32:56.395958      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:57.396395      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:58.397089      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:32:59.399877      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:00.400971      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:01.402055      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:02.402514      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:03.402854      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:04.403364      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:05.403370      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:06.404099      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:07.404625      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:08.406550      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:09.406198      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:10.406708      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:11.408246      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:12.409636      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:13.410575      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:14.410710      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:15.412316      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:33:16.026: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:33:16.413005      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:17.413294      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:18.414459      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:19.414490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:20.414679      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:21.415861      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:22.416983      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:23.417208      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:24.418294      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:25.419228      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:26.419779      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:27.419975      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:28.420636      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:29.420605      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:30.421095      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:31.421980      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:32.422488      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:33.423246      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:34.423644      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:35.424308      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:33:36.022: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:33:36.426252      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:37.428510      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:38.428781      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:39.428700      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:40.429295      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:41.429541      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:42.430107      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:43.430896      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:44.431321      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:45.431955      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:46.432198      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:47.432939      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:48.434405      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:49.436744      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:50.436960      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:51.458251      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:52.459544      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:53.460492      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:54.460932      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:55.463855      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:33:56.031: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:33:56.463869      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:57.465468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:58.465453      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:33:59.465672      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:00.467561      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:01.467848      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:02.468756      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:03.469386      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:04.469502      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:05.469965      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:06.470306      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:07.470969      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:08.472308      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:09.472528      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:10.472631      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:11.473579      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:12.474121      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:13.474288      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:14.476141      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:15.476456      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:34:16.024: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:34:16.477562      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:17.480665      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:18.481768      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:19.483333      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:20.483520      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:21.483908      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:22.484259      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:23.484154      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:24.484389      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:25.486541      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:26.486489      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:27.487470      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:28.488191      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:29.488609      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:30.489007      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:31.491120      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:32.493184      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:33.493940      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:34.493961      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:35.494438      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:34:36.020: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:34:36.495828      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:37.496233      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:38.496626      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:39.497269      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:40.497507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:41.497913      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:42.498529      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:43.499286      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:44.499754      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:45.499784      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:46.500034      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:47.502099      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:48.502862      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:49.502948      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:50.503719      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:51.505024      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:52.505957      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:53.505980      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:54.507328      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:55.508066      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:34:56.023: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:34:56.515475      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:57.516480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:58.517049      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:34:59.519548      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:00.520495      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:01.520415      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:02.521531      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:03.521646      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:04.522059      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:05.523143      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:06.523669      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:07.524540      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:08.524700      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:09.525117      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:10.526593      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:11.527059      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:12.527888      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:13.528325      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:14.530603      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:15.532518      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:35:16.023: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:35:16.533048      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:17.534911      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:18.535096      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:19.535930      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:20.535970      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:21.546219      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:22.546386      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:23.554118      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:24.555425      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:25.556251      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:26.558067      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:27.558563      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:28.559384      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:29.559591      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:30.560034      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:31.560480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:32.561621      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:33.563233      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:34.565034      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:35.565314      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:35:36.022: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:35:36.566471      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:37.569170      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:38.570820      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:39.571989      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:40.573634      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:41.574113      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:42.574413      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:43.575476      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:44.576038      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:45.576551      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:46.577094      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:47.577714      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:48.577833      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:49.578507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:50.579506      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:51.580491      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:52.580581      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:53.580775      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:54.582109      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:55.582868      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:35:56.026: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:35:56.583370      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:57.583908      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:58.584605      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:35:59.585089      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:00.587089      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:01.597981      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:02.587732      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:03.587944      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:04.588368      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:05.590679      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:06.591086      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:07.591856      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:08.592340      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:09.592612      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:10.592771      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:11.594356      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:12.595696      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:13.596482      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:14.596825      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:15.598618      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:36:16.025: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:36:16.602891      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:17.604598      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:18.605685      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:19.606629      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:20.607472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:21.607589      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:22.609158      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:23.613254      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:24.624511      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:25.624892      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:26.625034      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:27.625095      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:28.629213      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:29.629504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:30.631790      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:31.632664      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:32.633384      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:33.633493      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:34.633915      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:35.634501      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:36:36.022: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:36:36.635178      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:37.635736      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:38.636220      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:39.636446      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:40.646712      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:41.647634      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:42.648152      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:43.649406      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:44.650527      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:45.651525      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:46.651972      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:47.652704      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:48.653753      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:49.654596      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:50.654675      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:51.656552      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:52.657518      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:53.658362      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:54.658777      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:55.659422      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:36:56.025: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:36:56.660555      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:57.661715      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:58.663526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:36:59.664936      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:00.664734      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:01.665826      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:02.665880      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:03.667725      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:04.669139      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:05.669811      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:06.670389      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:07.671669      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:08.672744      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:09.673426      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:10.674310      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:11.674170      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:12.674454      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:13.675815      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:14.676606      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:15.682539      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:37:16.024: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:37:16.683561      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:17.683622      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:18.684112      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:19.684401      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:20.685351      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:21.685971      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:22.686635      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:23.686867      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:24.688021      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:25.688536      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:26.689585      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:27.689868      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:28.689957      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:29.691389      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:30.691491      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:31.691995      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:32.692518      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:33.693145      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:34.693646      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:35.694130      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:37:36.025: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:37:36.695406      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:37.695564      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:38.696203      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:39.696661      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:40.696975      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:41.697800      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:42.698205      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:43.698729      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:44.698937      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:45.699254      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:46.699475      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:47.700506      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:48.700710      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:49.701102      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:50.701423      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:51.701640      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:52.703661      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:53.704508      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:54.704764      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:55.706866      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:37:56.026: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:37:56.706930      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:57.707363      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:58.707674      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:37:59.712103      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:00.712599      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:01.713502      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:02.714587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:03.715036      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:04.715521      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:05.716115      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:06.716489      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:07.718232      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:08.719592      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:09.720514      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:10.720858      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:11.721320      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:12.721622      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:13.722584      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:14.724150      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:15.724265      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:38:16.022: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:38:16.725066      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:17.725462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:18.725908      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:19.725892      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:20.726147      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:21.726607      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:22.727550      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:23.728289      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:24.728330      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:25.729336      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:26.732769      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:27.732659      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:28.733658      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:29.735549      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:30.736361      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:31.737752      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:32.737997      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:33.738261      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:34.738458      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:35.740472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:38:36.022: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:38:36.741371      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:37.742778      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:38.742893      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:39.746534      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:40.746398      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:41.746550      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:42.748038      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:43.748534      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:44.748880      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:45.749022      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:46.749373      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:47.749709      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:48.751203      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:49.750831      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:50.754302      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:51.756820      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:52.756913      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:53.757961      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:54.759544      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:55.760769      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:38:56.025: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:38:56.761401      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:57.763583      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:58.763981      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:38:59.764660      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:00.764787      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:01.766396      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:02.766547      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:03.767148      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:04.767463      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:05.767649      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:06.768065      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:07.769778      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:08.772492      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:09.772903      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:10.773981      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:11.773987      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:12.775195      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:13.775790      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:14.776610      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:15.777391      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:39:16.021: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:39:16.804676      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:17.806515      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:18.806925      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:19.808532      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:20.809144      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:21.811626      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:22.811985      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:23.816791      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:24.816938      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:25.818462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:26.818851      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:27.820037      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:28.821550      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:29.822582      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:30.823442      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:31.846705      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:32.847770      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:33.848174      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:34.848507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:35.850318      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:39:36.020: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:39:36.850653      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:37.851053      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:38.852393      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:39.852469      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:40.852728      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:41.853363      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:42.853464      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:43.853673      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:44.853755      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:45.854674      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:46.855956      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:47.857246      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:48.857337      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:49.857735      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:50.858423      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:51.859403      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:52.860813      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:53.861339      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:54.861648      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:55.862423      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:39:56.024: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5MDksInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0505 17:39:56.865994      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:57.866630      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:58.866855      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:39:59.867496      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:00.867983      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:01.868579      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:02.869549      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:03.870607      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:04.870840      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:05.871345      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:06.871954      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:07.873526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:08.875407      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:09.876592      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:10.877336      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:11.878543      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:12.879738      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:13.880328      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:14.880653      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:15.884454      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:40:16.021: INFO: got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  May  5 17:40:16.021: INFO: Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 05/05/24 17:40:16.021
  STEP: retrieving all remaining pages @ 05/05/24 17:40:16.025
  May  5 17:40:16.027: INFO: Retrieved 40/40 results with rv 48583 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDg1ODMsInN0YXJ0IjoidGVtcGxhdGUtMDExOVx1MDAwMCJ9
  May  5 17:40:16.029: INFO: Retrieved 40/40 results with rv 48583 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDg1ODMsInN0YXJ0IjoidGVtcGxhdGUtMDE1OVx1MDAwMCJ9
  May  5 17:40:16.032: INFO: Retrieved 40/40 results with rv 48583 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDg1ODMsInN0YXJ0IjoidGVtcGxhdGUtMDE5OVx1MDAwMCJ9
  May  5 17:40:16.034: INFO: Retrieved 40/40 results with rv 48583 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDg1ODMsInN0YXJ0IjoidGVtcGxhdGUtMDIzOVx1MDAwMCJ9
  May  5 17:40:16.036: INFO: Retrieved 40/40 results with rv 48583 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDg1ODMsInN0YXJ0IjoidGVtcGxhdGUtMDI3OVx1MDAwMCJ9
  May  5 17:40:16.038: INFO: Retrieved 40/40 results with rv 48583 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDg1ODMsInN0YXJ0IjoidGVtcGxhdGUtMDMxOVx1MDAwMCJ9
  May  5 17:40:16.040: INFO: Retrieved 40/40 results with rv 48583 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDg1ODMsInN0YXJ0IjoidGVtcGxhdGUtMDM1OVx1MDAwMCJ9
  May  5 17:40:16.042: INFO: Retrieved 40/40 results with rv 48583 and continue 
  May  5 17:40:16.043: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-4779" for this suite. @ 05/05/24 17:40:16.044
• [497.788 seconds]
------------------------------
SSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 05/05/24 17:40:16.047
  May  5 17:40:16.047: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename dns @ 05/05/24 17:40:16.048
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:40:16.059
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:40:16.063
  STEP: Creating a test externalName service @ 05/05/24 17:40:16.065
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7627.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7627.svc.cluster.local; sleep 1; done
   @ 05/05/24 17:40:16.069
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7627.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7627.svc.cluster.local; sleep 1; done
   @ 05/05/24 17:40:16.069
  STEP: creating a pod to probe DNS @ 05/05/24 17:40:16.07
  STEP: submitting the pod to kubernetes @ 05/05/24 17:40:16.07
  E0505 17:40:16.886179      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:17.886472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:18.887763      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:19.888164      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:20.888331      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:21.889344      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:22.889368      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:23.890455      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:24.890628      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:25.892755      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:26.892765      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:27.893850      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:28.894754      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:29.895114      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:30.895486      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:31.896258      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:32.896713      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:33.897646      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:34.898837      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:35.898903      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:36.899377      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:37.899787      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:38.900354      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:39.900472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:40.900892      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:41.901371      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:42.902545      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:43.903240      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:44.903926      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:45.904045      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:46.904751      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:47.905708      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:48.906320      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:49.906272      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:50.906426      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:51.907180      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:52.908546      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:53.909153      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:54.910118      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:55.910426      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:56.910982      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:57.911088      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:58.911521      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:40:59.911723      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:00.912079      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:01.912093      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:02.912371      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:03.912801      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:04.913342      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:05.913663      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:06.917315      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:07.917511      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:08.917750      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:09.917965      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:10.918024      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:11.918161      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:12.918342      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:13.919091      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:14.919320      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:15.919485      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:16.919978      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:17.920918      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/05/24 17:41:18.245
  STEP: looking for the results for each expected name from probers @ 05/05/24 17:41:18.248
  May  5 17:41:18.268: INFO: DNS probes using dns-test-9dcc7274-0b2b-40df-8c74-68ac1bf74765 succeeded

  STEP: changing the externalName to bar.example.com @ 05/05/24 17:41:18.268
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7627.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7627.svc.cluster.local; sleep 1; done
   @ 05/05/24 17:41:18.277
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7627.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7627.svc.cluster.local; sleep 1; done
   @ 05/05/24 17:41:18.278
  STEP: creating a second pod to probe DNS @ 05/05/24 17:41:18.278
  STEP: submitting the pod to kubernetes @ 05/05/24 17:41:18.278
  E0505 17:41:18.924742      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:19.925003      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/05/24 17:41:20.292
  STEP: looking for the results for each expected name from probers @ 05/05/24 17:41:20.297
  May  5 17:41:20.313: INFO: File wheezy_udp@dns-test-service-3.dns-7627.svc.cluster.local from pod  dns-7627/dns-test-e84a288c-6b40-488d-bf07-39a931ef9323 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May  5 17:41:20.318: INFO: File jessie_udp@dns-test-service-3.dns-7627.svc.cluster.local from pod  dns-7627/dns-test-e84a288c-6b40-488d-bf07-39a931ef9323 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May  5 17:41:20.318: INFO: Lookups using dns-7627/dns-test-e84a288c-6b40-488d-bf07-39a931ef9323 failed for: [wheezy_udp@dns-test-service-3.dns-7627.svc.cluster.local jessie_udp@dns-test-service-3.dns-7627.svc.cluster.local]

  May  5 17:41:20.335: INFO: Pod client logs for webserver: 
  May  5 17:41:20.340: INFO: Pod client logs for querier: 
  May  5 17:41:20.346: INFO: Pod client logs for jessie-querier: 
  E0505 17:41:20.925181      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:21.925993      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:22.932578      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:23.940683      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:24.941373      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:41:25.306: INFO: File wheezy_udp@dns-test-service-3.dns-7627.svc.cluster.local from pod  dns-7627/dns-test-e84a288c-6b40-488d-bf07-39a931ef9323 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May  5 17:41:25.317: INFO: File jessie_udp@dns-test-service-3.dns-7627.svc.cluster.local from pod  dns-7627/dns-test-e84a288c-6b40-488d-bf07-39a931ef9323 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May  5 17:41:25.317: INFO: Lookups using dns-7627/dns-test-e84a288c-6b40-488d-bf07-39a931ef9323 failed for: [wheezy_udp@dns-test-service-3.dns-7627.svc.cluster.local jessie_udp@dns-test-service-3.dns-7627.svc.cluster.local]

  May  5 17:41:25.328: INFO: Pod client logs for webserver: 
  May  5 17:41:25.334: INFO: Pod client logs for querier: 
  May  5 17:41:25.339: INFO: Pod client logs for jessie-querier: 
  E0505 17:41:25.941658      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:26.942184      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:27.942400      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:28.942795      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:29.943581      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:41:30.305: INFO: File wheezy_udp@dns-test-service-3.dns-7627.svc.cluster.local from pod  dns-7627/dns-test-e84a288c-6b40-488d-bf07-39a931ef9323 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May  5 17:41:30.311: INFO: File jessie_udp@dns-test-service-3.dns-7627.svc.cluster.local from pod  dns-7627/dns-test-e84a288c-6b40-488d-bf07-39a931ef9323 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May  5 17:41:30.311: INFO: Lookups using dns-7627/dns-test-e84a288c-6b40-488d-bf07-39a931ef9323 failed for: [wheezy_udp@dns-test-service-3.dns-7627.svc.cluster.local jessie_udp@dns-test-service-3.dns-7627.svc.cluster.local]

  May  5 17:41:30.319: INFO: Pod client logs for webserver: 
  May  5 17:41:30.323: INFO: Pod client logs for querier: 
  May  5 17:41:30.326: INFO: Pod client logs for jessie-querier: 
  E0505 17:41:30.944527      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:31.945913      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:32.947145      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:33.947774      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:34.948119      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:41:35.307: INFO: File wheezy_udp@dns-test-service-3.dns-7627.svc.cluster.local from pod  dns-7627/dns-test-e84a288c-6b40-488d-bf07-39a931ef9323 contains '' instead of 'bar.example.com.'
  May  5 17:41:35.313: INFO: File jessie_udp@dns-test-service-3.dns-7627.svc.cluster.local from pod  dns-7627/dns-test-e84a288c-6b40-488d-bf07-39a931ef9323 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May  5 17:41:35.313: INFO: Lookups using dns-7627/dns-test-e84a288c-6b40-488d-bf07-39a931ef9323 failed for: [wheezy_udp@dns-test-service-3.dns-7627.svc.cluster.local jessie_udp@dns-test-service-3.dns-7627.svc.cluster.local]

  May  5 17:41:35.319: INFO: Pod client logs for webserver: 
  May  5 17:41:35.334: INFO: Pod client logs for querier: 
  May  5 17:41:35.338: INFO: Pod client logs for jessie-querier: 
  E0505 17:41:35.948585      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:36.949668      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:37.950117      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:38.951145      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:39.951846      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:41:40.303: INFO: File wheezy_udp@dns-test-service-3.dns-7627.svc.cluster.local from pod  dns-7627/dns-test-e84a288c-6b40-488d-bf07-39a931ef9323 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May  5 17:41:40.311: INFO: File jessie_udp@dns-test-service-3.dns-7627.svc.cluster.local from pod  dns-7627/dns-test-e84a288c-6b40-488d-bf07-39a931ef9323 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May  5 17:41:40.311: INFO: Lookups using dns-7627/dns-test-e84a288c-6b40-488d-bf07-39a931ef9323 failed for: [wheezy_udp@dns-test-service-3.dns-7627.svc.cluster.local jessie_udp@dns-test-service-3.dns-7627.svc.cluster.local]

  May  5 17:41:40.320: INFO: Pod client logs for webserver: 
  May  5 17:41:40.331: INFO: Pod client logs for querier: 
  May  5 17:41:40.344: INFO: Pod client logs for jessie-querier: 
  E0505 17:41:40.952758      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:41.953610      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:42.953735      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:43.954593      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:44.955008      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:41:45.300: INFO: File wheezy_udp@dns-test-service-3.dns-7627.svc.cluster.local from pod  dns-7627/dns-test-e84a288c-6b40-488d-bf07-39a931ef9323 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May  5 17:41:45.302: INFO: File jessie_udp@dns-test-service-3.dns-7627.svc.cluster.local from pod  dns-7627/dns-test-e84a288c-6b40-488d-bf07-39a931ef9323 contains '' instead of 'bar.example.com.'
  May  5 17:41:45.302: INFO: Lookups using dns-7627/dns-test-e84a288c-6b40-488d-bf07-39a931ef9323 failed for: [wheezy_udp@dns-test-service-3.dns-7627.svc.cluster.local jessie_udp@dns-test-service-3.dns-7627.svc.cluster.local]

  May  5 17:41:45.305: INFO: Pod client logs for webserver: 
  May  5 17:41:45.309: INFO: Pod client logs for querier: 
  May  5 17:41:45.312: INFO: Pod client logs for jessie-querier: 
  E0505 17:41:45.955211      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:46.955863      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:47.956655      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:48.956716      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:49.957763      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:41:50.303: INFO: DNS probes using dns-test-e84a288c-6b40-488d-bf07-39a931ef9323 succeeded

  STEP: changing the service to type=ClusterIP @ 05/05/24 17:41:50.303
  W0505 17:41:50.326536      22 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7627.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7627.svc.cluster.local; sleep 1; done
   @ 05/05/24 17:41:50.326
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7627.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7627.svc.cluster.local; sleep 1; done
   @ 05/05/24 17:41:50.326
  STEP: creating a third pod to probe DNS @ 05/05/24 17:41:50.326
  STEP: submitting the pod to kubernetes @ 05/05/24 17:41:50.331
  E0505 17:41:50.958671      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:51.959878      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/05/24 17:41:52.347
  STEP: looking for the results for each expected name from probers @ 05/05/24 17:41:52.349
  May  5 17:41:52.355: INFO: DNS probes using dns-test-f1b8263d-d88b-49c9-9ecf-88145356bea1 succeeded

  STEP: deleting the pod @ 05/05/24 17:41:52.355
  STEP: deleting the pod @ 05/05/24 17:41:52.372
  STEP: deleting the pod @ 05/05/24 17:41:52.38
  STEP: deleting the test externalName service @ 05/05/24 17:41:52.394
  May  5 17:41:52.412: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-7627" for this suite. @ 05/05/24 17:41:52.42
• [96.390 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:153
  STEP: Creating a kubernetes client @ 05/05/24 17:41:52.438
  May  5 17:41:52.438: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/05/24 17:41:52.442
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:41:52.469
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:41:52.482
  STEP: create the container to handle the HTTPGet hook request. @ 05/05/24 17:41:52.492
  E0505 17:41:52.960752      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:53.961345      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/05/24 17:41:54.512
  E0505 17:41:54.961762      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:55.962437      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 05/05/24 17:41:56.525
  E0505 17:41:56.965035      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:57.965290      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 05/05/24 17:41:58.533
  May  5 17:41:58.538: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4429" for this suite. @ 05/05/24 17:41:58.54
• [6.106 seconds]
------------------------------
SS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:131
  STEP: Creating a kubernetes client @ 05/05/24 17:41:58.543
  May  5 17:41:58.543: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename runtimeclass @ 05/05/24 17:41:58.545
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:41:58.552
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:41:58.555
  E0505 17:41:58.966292      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:41:59.967298      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:42:00.579: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-3474" for this suite. @ 05/05/24 17:42:00.581
• [2.040 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:742
  STEP: Creating a kubernetes client @ 05/05/24 17:42:00.584
  May  5 17:42:00.584: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename svcaccounts @ 05/05/24 17:42:00.585
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:42:00.597
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:42:00.599
  May  5 17:42:00.602: INFO: Got root ca configmap in namespace "svcaccounts-7358"
  May  5 17:42:00.605: INFO: Deleted root ca configmap in namespace "svcaccounts-7358"
  E0505 17:42:00.968203      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for a new root ca configmap created @ 05/05/24 17:42:01.107
  May  5 17:42:01.109: INFO: Recreated root ca configmap in namespace "svcaccounts-7358"
  May  5 17:42:01.111: INFO: Updated root ca configmap in namespace "svcaccounts-7358"
  STEP: waiting for the root ca configmap reconciled @ 05/05/24 17:42:01.611
  May  5 17:42:01.616: INFO: Reconciled root ca configmap in namespace "svcaccounts-7358"
  May  5 17:42:01.616: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7358" for this suite. @ 05/05/24 17:42:01.62
• [1.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 05/05/24 17:42:01.637
  May  5 17:42:01.637: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename watch @ 05/05/24 17:42:01.638
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:42:01.646
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:42:01.647
  STEP: creating a watch on configmaps @ 05/05/24 17:42:01.648
  STEP: creating a new configmap @ 05/05/24 17:42:01.649
  STEP: modifying the configmap once @ 05/05/24 17:42:01.651
  STEP: closing the watch once it receives two notifications @ 05/05/24 17:42:01.654
  May  5 17:42:01.654: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1581  4e80be9d-bf01-4e9b-890f-fac226fdaafe 49554 0 2024-05-05 17:42:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-05-05 17:42:01 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  May  5 17:42:01.654: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1581  4e80be9d-bf01-4e9b-890f-fac226fdaafe 49555 0 2024-05-05 17:42:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-05-05 17:42:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 05/05/24 17:42:01.654
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 05/05/24 17:42:01.657
  STEP: deleting the configmap @ 05/05/24 17:42:01.658
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 05/05/24 17:42:01.66
  May  5 17:42:01.660: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1581  4e80be9d-bf01-4e9b-890f-fac226fdaafe 49556 0 2024-05-05 17:42:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-05-05 17:42:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May  5 17:42:01.660: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1581  4e80be9d-bf01-4e9b-890f-fac226fdaafe 49557 0 2024-05-05 17:42:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-05-05 17:42:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May  5 17:42:01.660: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-1581" for this suite. @ 05/05/24 17:42:01.662
• [0.028 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 05/05/24 17:42:01.665
  May  5 17:42:01.665: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename secrets @ 05/05/24 17:42:01.666
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:42:01.674
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:42:01.676
  STEP: Creating secret with name secret-test-171f4ec7-62ae-4516-a97e-02a844523d29 @ 05/05/24 17:42:01.685
  STEP: Creating a pod to test consume secrets @ 05/05/24 17:42:01.687
  E0505 17:42:01.969056      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:02.972688      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:03.972732      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:04.974135      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:42:05.698
  May  5 17:42:05.700: INFO: Trying to get logs from node worker00 pod pod-secrets-93413120-054c-4623-8e5e-eb9ff5b43943 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/05/24 17:42:05.708
  May  5 17:42:05.717: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8784" for this suite. @ 05/05/24 17:42:05.719
  STEP: Destroying namespace "secret-namespace-5869" for this suite. @ 05/05/24 17:42:05.722
• [4.061 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:170
  STEP: Creating a kubernetes client @ 05/05/24 17:42:05.726
  May  5 17:42:05.726: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename security-context @ 05/05/24 17:42:05.727
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:42:05.734
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:42:05.738
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 05/05/24 17:42:05.74
  E0505 17:42:05.978756      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:06.980661      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:42:07.755
  May  5 17:42:07.758: INFO: Trying to get logs from node worker00 pod security-context-93e00274-0c83-426c-b76c-2621d4c6f856 container test-container: <nil>
  STEP: delete the pod @ 05/05/24 17:42:07.761
  May  5 17:42:07.768: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-2419" for this suite. @ 05/05/24 17:42:07.771
• [2.049 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:322
  STEP: Creating a kubernetes client @ 05/05/24 17:42:07.777
  May  5 17:42:07.777: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename gc @ 05/05/24 17:42:07.778
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:42:07.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:42:07.787
  STEP: create the rc @ 05/05/24 17:42:07.79
  W0505 17:42:07.795626      22 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0505 17:42:07.981504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:08.981810      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:09.982275      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:10.982843      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:11.983599      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 05/05/24 17:42:12.798
  STEP: wait for all pods to be garbage collected @ 05/05/24 17:42:12.805
  E0505 17:42:12.984724      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:13.984990      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:14.985616      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:15.986535      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:16.986663      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/05/24 17:42:17.811
  May  5 17:42:17.860: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  May  5 17:42:17.860: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5315" for this suite. @ 05/05/24 17:42:17.863
• [10.092 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:166
  STEP: Creating a kubernetes client @ 05/05/24 17:42:17.869
  May  5 17:42:17.869: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename replicaset @ 05/05/24 17:42:17.87
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:42:17.879
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:42:17.882
  STEP: Create a ReplicaSet @ 05/05/24 17:42:17.885
  STEP: Verify that the required pods have come up @ 05/05/24 17:42:17.89
  May  5 17:42:17.892: INFO: Pod name sample-pod: Found 0 pods out of 3
  E0505 17:42:17.987343      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:18.988387      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:19.989332      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:20.992480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:21.993943      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:42:22.898: INFO: Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 05/05/24 17:42:22.898
  May  5 17:42:22.904: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 05/05/24 17:42:22.904
  STEP: DeleteCollection of the ReplicaSets @ 05/05/24 17:42:22.908
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 05/05/24 17:42:22.916
  May  5 17:42:22.919: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-1070" for this suite. @ 05/05/24 17:42:22.923
• [5.066 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 05/05/24 17:42:22.935
  May  5 17:42:22.935: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename deployment @ 05/05/24 17:42:22.936
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:42:22.96
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:42:22.965
  May  5 17:42:22.974: INFO: Creating deployment "test-recreate-deployment"
  May  5 17:42:22.978: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
  May  5 17:42:22.985: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
  E0505 17:42:22.994608      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:23.994719      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:42:24.994: INFO: Waiting deployment "test-recreate-deployment" to complete
  E0505 17:42:24.994911      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:42:24.998: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
  May  5 17:42:25.005: INFO: Updating deployment test-recreate-deployment
  May  5 17:42:25.005: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  May  5 17:42:25.060: INFO: Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-830",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "362f17f0-fca4-400d-aec8-08c801fb01b9",
      ResourceVersion: (string) (len=5) "49922",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850527742,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850527745,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850527745,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850527745,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850527745,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850527745,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850527743,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=63) "ReplicaSet \"test-recreate-deployment-76fb77d45\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  May  5 17:42:25.066: INFO: New ReplicaSet "test-recreate-deployment-76fb77d45" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-830",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "cd9e0938-a8e2-4c5e-b902-ff02dab2a06b",
      ResourceVersion: (string) (len=5) "49920",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850527745,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "362f17f0-fca4-400d-aec8-08c801fb01b9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850527745,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 33 36 32 66 31 37  66 30 2d 66 63 61 34 2d  |\"362f17f0-fca4-|
              00000120  34 30 30 64 2d 61 65 63  38 2d 30 38 63 38 30 31  |400d-aec8-08c801|
              00000130  66 62 30 31 62 39 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |fb01b9\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850527745,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45",
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May  5 17:42:25.066: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
  May  5 17:42:25.067: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-5cf87b5b86",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-830",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a5f83365-6e30-4217-86bd-b93e3d62fa0f",
      ResourceVersion: (string) (len=5) "49911",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850527742,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86",
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "362f17f0-fca4-400d-aec8-08c801fb01b9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850527745,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 33 36 32 66 31 37  66 30 2d 66 63 61 34 2d  |\"362f17f0-fca4-|
              00000120  34 30 30 64 2d 61 65 63  38 2d 30 38 63 38 30 31  |400d-aec8-08c801|
              00000130  66 62 30 31 62 39 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |fb01b9\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850527745,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86",
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May  5 17:42:25.080: INFO: Pod "test-recreate-deployment-76fb77d45-jfbtz" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-recreate-deployment-76fb77d45-jfbtz",
      GenerateName: (string) (len=35) "test-recreate-deployment-76fb77d45-",
      Namespace: (string) (len=14) "deployment-830",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7bc6c956-0d9f-4245-aaad-899c0ec0e0d4",
      ResourceVersion: (string) (len=5) "49923",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850527745,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
          UID: (types.UID) (len=36) "cd9e0938-a8e2-4c5e-b902-ff02dab2a06b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850527745,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 64  39 65 30 39 33 38 2d 61  |d\":\"cd9e0938-a|
              00000090  38 65 32 2d 34 63 35 65  2d 62 39 30 32 2d 66 66  |8e2-4c5e-b902-ff|
              000000a0  30 32 64 61 62 32 61 30  36 62 5c 22 7d 22 3a 7b  |02dab2a06b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850527745,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-zcdd9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-zcdd9",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker00",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850527745,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850527745,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850527745,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850527745,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850527745,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.100",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.100"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850527745,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:42:25.085: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-830" for this suite. @ 05/05/24 17:42:25.095
• [2.166 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 05/05/24 17:42:25.102
  May  5 17:42:25.102: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 17:42:25.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:42:25.111
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:42:25.113
  STEP: Creating configMap with name configmap-projected-all-test-volume-00d7a314-97fe-4379-a75b-5118c15c4075 @ 05/05/24 17:42:25.115
  STEP: Creating secret with name secret-projected-all-test-volume-4d25fa74-e0cd-46a0-8e0b-1adc587c3b20 @ 05/05/24 17:42:25.118
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 05/05/24 17:42:25.121
  E0505 17:42:25.996016      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:26.997922      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:27.998643      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:28.999660      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:42:29.144
  May  5 17:42:29.147: INFO: Trying to get logs from node worker00 pod projected-volume-7c55c325-e1ee-447f-bc41-222ecb311f44 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 05/05/24 17:42:29.152
  May  5 17:42:29.165: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5926" for this suite. @ 05/05/24 17:42:29.166
• [4.067 seconds]
------------------------------
SS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 05/05/24 17:42:29.169
  May  5 17:42:29.169: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename cronjob @ 05/05/24 17:42:29.169
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:42:29.176
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:42:29.177
  STEP: Creating a suspended cronjob @ 05/05/24 17:42:29.179
  STEP: Ensuring no jobs are scheduled @ 05/05/24 17:42:29.183
  E0505 17:42:30.000642      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:31.000706      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:32.001390      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:33.003843      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:34.003905      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:35.004020      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:36.005250      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:37.005815      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:38.006035      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:39.007614      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:40.007723      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:41.008980      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:42.009570      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:43.010914      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:44.012705      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:45.012773      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:46.013446      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:47.015344      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:48.016152      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:49.016978      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:50.017198      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:51.018141      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:52.018183      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:53.018435      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:54.019700      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:55.020561      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:56.021716      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:57.022140      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:58.023693      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:42:59.026164      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:00.026350      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:01.026583      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:02.026907      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:03.026954      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:04.032520      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:05.034115      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:06.034198      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:07.035309      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:08.035523      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:09.037395      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:10.037894      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:11.041078      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:12.044415      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:13.045031      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:14.045025      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:15.045913      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:16.047586      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:17.047869      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:18.048307      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:19.048553      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:20.050058      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:21.051210      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:22.052512      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:23.054084      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:24.054414      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:25.055407      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:26.055520      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:27.056373      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:28.056489      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:29.056800      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:30.058480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:31.058937      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:32.063796      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:33.064409      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:34.065663      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:35.065790      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:36.066450      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:37.067458      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:38.067670      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:39.068963      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:40.069456      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:41.070383      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:42.071174      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:43.071822      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:44.073207      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:45.073546      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:46.080626      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:47.080979      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:48.082710      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:49.083554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:50.084652      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:51.085080      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:52.086419      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:53.086563      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:54.087751      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:55.088615      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:56.088782      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:57.089022      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:58.089473      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:43:59.092688      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:00.092789      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:01.094049      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:02.096408      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:03.103838      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:04.108524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:05.109762      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:06.111157      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:07.112542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:08.112699      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:09.112635      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:10.113619      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:11.113892      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:12.114650      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:13.115780      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:14.115925      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:15.116629      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:16.117034      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:17.119321      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:18.119851      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:19.121452      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:20.121884      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:21.122184      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:22.122906      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:23.123460      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:24.124004      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:25.124728      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:26.124821      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:27.125619      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:28.126294      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:29.126470      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:30.126889      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:31.129572      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:32.130025      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:33.130381      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:34.132906      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:35.133121      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:36.134001      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:37.135492      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:38.135574      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:39.135935      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:40.136326      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:41.137740      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:42.139005      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:43.139563      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:44.140625      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:45.140717      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:46.140958      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:47.142133      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:48.142905      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:49.143742      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:50.143832      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:51.144528      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:52.145130      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:53.148553      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:54.148086      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:55.148311      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:56.148897      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:57.149683      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:58.150425      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:44:59.150721      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:00.151257      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:01.151437      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:02.151618      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:03.152061      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:04.152896      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:05.153631      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:06.154053      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:07.158897      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:08.159735      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:09.162426      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:10.162537      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:11.163870      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:12.164121      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:13.170223      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:14.170685      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:15.171106      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:16.171916      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:17.171986      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:18.172440      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:19.173296      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:20.176557      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:21.177464      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:22.178230      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:23.179133      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:24.181351      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:25.181645      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:26.182524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:27.182750      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:28.183816      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:29.185795      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:30.186609      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:31.186693      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:32.187394      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:33.187396      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:34.188121      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:35.188342      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:36.188836      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:37.188968      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:38.189720      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:39.190462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:40.191112      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:41.192646      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:42.193043      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:43.193450      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:44.193885      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:45.194120      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:46.194856      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:47.195686      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:48.195709      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:49.199050      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:50.199490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:51.200465      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:52.205690      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:53.206392      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:54.206795      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:55.206827      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:56.208001      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:57.209819      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:58.210524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:45:59.212122      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:00.212537      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:01.213419      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:02.214005      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:03.214161      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:04.214299      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:05.215154      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:06.215545      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:07.216719      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:08.217842      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:09.218892      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:10.219426      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:11.220403      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:12.220518      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:13.221587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:14.222215      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:15.222765      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:16.223151      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:17.223752      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:18.224043      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:19.224518      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:20.226539      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:21.226834      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:22.229321      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:23.230466      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:24.231080      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:25.231923      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:26.233021      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:27.233932      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:28.234390      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:29.235753      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:30.236517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:31.236811      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:32.238532      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:33.242969      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:34.242903      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:35.244778      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:36.247873      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:37.249583      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:38.250080      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:39.250973      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:40.251655      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:41.255226      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:42.255180      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:43.255524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:44.256524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:45.257345      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:46.257827      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:47.259913      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:48.260477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:49.261444      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:50.261337      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:51.262948      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:52.263271      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:53.264033      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:54.264239      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:55.265988      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:56.266286      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:57.266997      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:58.267674      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:46:59.267936      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:00.268177      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:01.268689      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:02.269190      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:03.269418      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:04.269453      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:05.269768      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:06.270828      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:07.271174      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:08.271306      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:09.271987      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:10.272531      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:11.272858      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:12.272876      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:13.273767      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:14.276161      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:15.277720      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:16.278095      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:17.278600      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:18.279556      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:19.281515      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:20.281521      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:21.281610      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:22.281982      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:23.282914      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:24.283410      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:25.283669      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:26.284097      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:27.284515      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:28.284932      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 05/05/24 17:47:29.195
  STEP: Removing cronjob @ 05/05/24 17:47:29.198
  May  5 17:47:29.203: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-3339" for this suite. @ 05/05/24 17:47:29.206
• [300.039 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 05/05/24 17:47:29.208
  May  5 17:47:29.208: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename secrets @ 05/05/24 17:47:29.209
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:47:29.216
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:47:29.217
  May  5 17:47:29.232: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-119" for this suite. @ 05/05/24 17:47:29.234
• [0.029 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:301
  STEP: Creating a kubernetes client @ 05/05/24 17:47:29.237
  May  5 17:47:29.237: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename webhook @ 05/05/24 17:47:29.237
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:47:29.244
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:47:29.246
  STEP: Setting up server cert @ 05/05/24 17:47:29.257
  E0505 17:47:29.284906      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/05/24 17:47:29.365
  STEP: Deploying the webhook pod @ 05/05/24 17:47:29.371
  STEP: Wait for the deployment to be ready @ 05/05/24 17:47:29.381
  May  5 17:47:29.386: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0505 17:47:30.287547      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:31.287420      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/05/24 17:47:31.401
  STEP: Verifying the service has paired with the endpoint @ 05/05/24 17:47:31.409
  E0505 17:47:32.287541      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:47:32.410: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 05/05/24 17:47:32.417
  STEP: Creating a custom resource definition that should be denied by the webhook @ 05/05/24 17:47:32.425
  May  5 17:47:32.425: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  May  5 17:47:32.448: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5749" for this suite. @ 05/05/24 17:47:32.453
  STEP: Destroying namespace "webhook-markers-2705" for this suite. @ 05/05/24 17:47:32.456
• [3.222 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:125
  STEP: Creating a kubernetes client @ 05/05/24 17:47:32.458
  May  5 17:47:32.458: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 17:47:32.459
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:47:32.467
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:47:32.469
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-991040cb-7173-4d7a-9133-49fc25eb1731 @ 05/05/24 17:47:32.472
  STEP: Creating the pod @ 05/05/24 17:47:32.474
  E0505 17:47:33.290192      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:34.290303      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-991040cb-7173-4d7a-9133-49fc25eb1731 @ 05/05/24 17:47:34.492
  STEP: waiting to observe update in volume @ 05/05/24 17:47:34.495
  E0505 17:47:35.290413      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:36.290661      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:47:36.506: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6021" for this suite. @ 05/05/24 17:47:36.509
• [4.064 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2214
  STEP: Creating a kubernetes client @ 05/05/24 17:47:36.522
  May  5 17:47:36.523: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename services @ 05/05/24 17:47:36.523
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:47:36.532
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:47:36.534
  STEP: creating service in namespace services-9824 @ 05/05/24 17:47:36.535
  STEP: creating service affinity-nodeport in namespace services-9824 @ 05/05/24 17:47:36.535
  STEP: creating replication controller affinity-nodeport in namespace services-9824 @ 05/05/24 17:47:36.541
  I0505 17:47:36.548908      22 runners.go:197] Created replication controller with name: affinity-nodeport, namespace: services-9824, replica count: 3
  E0505 17:47:37.292593      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:38.292850      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:39.293813      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0505 17:47:39.600462      22 runners.go:197] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May  5 17:47:39.612: INFO: Creating new exec pod
  E0505 17:47:40.294671      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:41.295805      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:42.298338      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:47:42.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-9824 exec execpod-affinity5mpl9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  May  5 17:47:42.719: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  May  5 17:47:42.719: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May  5 17:47:42.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-9824 exec execpod-affinity5mpl9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.73 80'
  May  5 17:47:42.802: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.32.0.73 80\nConnection to 10.32.0.73 80 port [tcp/http] succeeded!\n"
  May  5 17:47:42.802: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May  5 17:47:42.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-9824 exec execpod-affinity5mpl9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.58.100 31830'
  May  5 17:47:42.906: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.58.100 31830\nConnection to 192.168.58.100 31830 port [tcp/*] succeeded!\n"
  May  5 17:47:42.906: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May  5 17:47:42.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-9824 exec execpod-affinity5mpl9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.58.101 31830'
  May  5 17:47:43.004: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.58.101 31830\nConnection to 192.168.58.101 31830 port [tcp/*] succeeded!\n"
  May  5 17:47:43.004: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May  5 17:47:43.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-9824 exec execpod-affinity5mpl9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.58.100:31830/ ; done'
  May  5 17:47:43.208: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:31830/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:31830/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:31830/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:31830/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:31830/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:31830/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:31830/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:31830/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:31830/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:31830/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:31830/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:31830/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:31830/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:31830/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:31830/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.58.100:31830/\n"
  May  5 17:47:43.208: INFO: stdout: "\naffinity-nodeport-vtfn5\naffinity-nodeport-vtfn5\naffinity-nodeport-vtfn5\naffinity-nodeport-vtfn5\naffinity-nodeport-vtfn5\naffinity-nodeport-vtfn5\naffinity-nodeport-vtfn5\naffinity-nodeport-vtfn5\naffinity-nodeport-vtfn5\naffinity-nodeport-vtfn5\naffinity-nodeport-vtfn5\naffinity-nodeport-vtfn5\naffinity-nodeport-vtfn5\naffinity-nodeport-vtfn5\naffinity-nodeport-vtfn5\naffinity-nodeport-vtfn5"
  May  5 17:47:43.208: INFO: Received response from host: affinity-nodeport-vtfn5
  May  5 17:47:43.208: INFO: Received response from host: affinity-nodeport-vtfn5
  May  5 17:47:43.209: INFO: Received response from host: affinity-nodeport-vtfn5
  May  5 17:47:43.209: INFO: Received response from host: affinity-nodeport-vtfn5
  May  5 17:47:43.209: INFO: Received response from host: affinity-nodeport-vtfn5
  May  5 17:47:43.209: INFO: Received response from host: affinity-nodeport-vtfn5
  May  5 17:47:43.209: INFO: Received response from host: affinity-nodeport-vtfn5
  May  5 17:47:43.209: INFO: Received response from host: affinity-nodeport-vtfn5
  May  5 17:47:43.209: INFO: Received response from host: affinity-nodeport-vtfn5
  May  5 17:47:43.209: INFO: Received response from host: affinity-nodeport-vtfn5
  May  5 17:47:43.209: INFO: Received response from host: affinity-nodeport-vtfn5
  May  5 17:47:43.209: INFO: Received response from host: affinity-nodeport-vtfn5
  May  5 17:47:43.209: INFO: Received response from host: affinity-nodeport-vtfn5
  May  5 17:47:43.209: INFO: Received response from host: affinity-nodeport-vtfn5
  May  5 17:47:43.209: INFO: Received response from host: affinity-nodeport-vtfn5
  May  5 17:47:43.209: INFO: Received response from host: affinity-nodeport-vtfn5
  May  5 17:47:43.209: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-9824, will wait for the garbage collector to delete the pods @ 05/05/24 17:47:43.222
  May  5 17:47:43.286: INFO: Deleting ReplicationController affinity-nodeport took: 7.743422ms
  E0505 17:47:43.305228      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:47:43.387: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.952793ms
  E0505 17:47:44.304591      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:45.304748      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:47:46.202: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9824" for this suite. @ 05/05/24 17:47:46.207
• [9.691 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:948
  STEP: Creating a kubernetes client @ 05/05/24 17:47:46.214
  May  5 17:47:46.215: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename resourcequota @ 05/05/24 17:47:46.218
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:47:46.234
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:47:46.236
  STEP: Creating a ResourceQuota @ 05/05/24 17:47:46.238
  STEP: Getting a ResourceQuota @ 05/05/24 17:47:46.244
  STEP: Listing all ResourceQuotas with LabelSelector @ 05/05/24 17:47:46.246
  STEP: Patching the ResourceQuota @ 05/05/24 17:47:46.248
  STEP: Deleting a Collection of ResourceQuotas @ 05/05/24 17:47:46.251
  STEP: Verifying the deleted ResourceQuota @ 05/05/24 17:47:46.258
  May  5 17:47:46.260: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7886" for this suite. @ 05/05/24 17:47:46.263
• [0.051 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lease.go:73
  STEP: Creating a kubernetes client @ 05/05/24 17:47:46.266
  May  5 17:47:46.266: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename lease-test @ 05/05/24 17:47:46.267
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:47:46.279
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:47:46.281
  E0505 17:47:46.305136      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:47:46.311: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-198" for this suite. @ 05/05/24 17:47:46.313
• [0.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:808
  STEP: Creating a kubernetes client @ 05/05/24 17:47:46.318
  May  5 17:47:46.318: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename resourcequota @ 05/05/24 17:47:46.319
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:47:46.333
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:47:46.336
  STEP: Creating a ResourceQuota with best effort scope @ 05/05/24 17:47:46.339
  STEP: Ensuring ResourceQuota status is calculated @ 05/05/24 17:47:46.343
  E0505 17:47:47.305449      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:48.307468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not best effort scope @ 05/05/24 17:47:48.347
  STEP: Ensuring ResourceQuota status is calculated @ 05/05/24 17:47:48.351
  E0505 17:47:49.309360      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:50.310627      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a best-effort pod @ 05/05/24 17:47:50.359
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 05/05/24 17:47:50.372
  E0505 17:47:51.311146      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:52.311403      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 05/05/24 17:47:52.377
  E0505 17:47:53.311976      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:54.312298      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/05/24 17:47:54.383
  STEP: Ensuring resource quota status released the pod usage @ 05/05/24 17:47:54.397
  E0505 17:47:55.312564      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:56.313433      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a not best-effort pod @ 05/05/24 17:47:56.403
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 05/05/24 17:47:56.416
  E0505 17:47:57.313421      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:47:58.314427      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 05/05/24 17:47:58.418
  E0505 17:47:59.314692      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:00.315792      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/05/24 17:48:00.426
  STEP: Ensuring resource quota status released the pod usage @ 05/05/24 17:48:00.44
  E0505 17:48:01.316507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:02.317760      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:48:02.443: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1454" for this suite. @ 05/05/24 17:48:02.446
• [16.131 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:95
  STEP: Creating a kubernetes client @ 05/05/24 17:48:02.45
  May  5 17:48:02.450: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename replication-controller @ 05/05/24 17:48:02.451
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:48:02.461
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:48:02.465
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 05/05/24 17:48:02.466
  E0505 17:48:03.318914      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:04.319353      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 05/05/24 17:48:04.481
  STEP: Then the orphan pod is adopted @ 05/05/24 17:48:04.497
  E0505 17:48:05.319331      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:48:05.512: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-5627" for this suite. @ 05/05/24 17:48:05.516
• [3.071 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3129
  STEP: Creating a kubernetes client @ 05/05/24 17:48:05.521
  May  5 17:48:05.521: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename services @ 05/05/24 17:48:05.522
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:48:05.534
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:48:05.537
  STEP: fetching services @ 05/05/24 17:48:05.54
  May  5 17:48:05.543: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8159" for this suite. @ 05/05/24 17:48:05.545
• [0.029 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:176
  STEP: Creating a kubernetes client @ 05/05/24 17:48:05.55
  May  5 17:48:05.550: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename configmap @ 05/05/24 17:48:05.551
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:48:05.606
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:48:05.608
  STEP: Creating configMap with name configmap-test-upd-f3d88857-d0d9-443a-b220-30ad5503e1b1 @ 05/05/24 17:48:05.613
  STEP: Creating the pod @ 05/05/24 17:48:05.616
  E0505 17:48:06.319438      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:07.321280      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 05/05/24 17:48:07.635
  STEP: Waiting for pod with binary data @ 05/05/24 17:48:07.645
  May  5 17:48:07.650: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5162" for this suite. @ 05/05/24 17:48:07.654
• [2.110 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 05/05/24 17:48:07.662
  May  5 17:48:07.662: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename certificates @ 05/05/24 17:48:07.663
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:48:07.678
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:48:07.681
  STEP: getting /apis @ 05/05/24 17:48:08.262
  STEP: getting /apis/certificates.k8s.io @ 05/05/24 17:48:08.265
  STEP: getting /apis/certificates.k8s.io/v1 @ 05/05/24 17:48:08.265
  STEP: creating @ 05/05/24 17:48:08.266
  STEP: getting @ 05/05/24 17:48:08.294
  STEP: listing @ 05/05/24 17:48:08.295
  STEP: watching @ 05/05/24 17:48:08.296
  May  5 17:48:08.296: INFO: starting watch
  STEP: patching @ 05/05/24 17:48:08.297
  STEP: updating @ 05/05/24 17:48:08.3
  May  5 17:48:08.303: INFO: waiting for watch events with expected annotations
  May  5 17:48:08.303: INFO: saw patched and updated annotations
  STEP: getting /approval @ 05/05/24 17:48:08.303
  STEP: patching /approval @ 05/05/24 17:48:08.305
  STEP: updating /approval @ 05/05/24 17:48:08.31
  STEP: getting /status @ 05/05/24 17:48:08.315
  STEP: patching /status @ 05/05/24 17:48:08.319
  E0505 17:48:08.321030      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating /status @ 05/05/24 17:48:08.325
  STEP: deleting @ 05/05/24 17:48:08.332
  STEP: deleting a collection @ 05/05/24 17:48:08.339
  May  5 17:48:08.351: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-4825" for this suite. @ 05/05/24 17:48:08.355
• [0.701 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 05/05/24 17:48:08.363
  May  5 17:48:08.363: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 17:48:08.364
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:48:08.38
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:48:08.385
  STEP: Creating projection with secret that has name projected-secret-test-44bd51f1-b104-4282-aa14-5dfc5a9e7bae @ 05/05/24 17:48:08.388
  STEP: Creating a pod to test consume secrets @ 05/05/24 17:48:08.394
  E0505 17:48:09.321418      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:10.323618      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:11.324854      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:12.326333      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:48:12.427
  May  5 17:48:12.433: INFO: Trying to get logs from node worker00 pod pod-projected-secrets-f69da81c-2805-4f58-a89a-02bc4550c86d container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/05/24 17:48:12.44
  May  5 17:48:12.455: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1035" for this suite. @ 05/05/24 17:48:12.464
• [4.108 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 05/05/24 17:48:12.472
  May  5 17:48:12.472: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename deployment @ 05/05/24 17:48:12.474
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:48:12.488
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:48:12.494
  May  5 17:48:12.496: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
  May  5 17:48:12.503: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0505 17:48:13.326851      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:14.327535      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:15.328901      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:16.329364      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:17.329711      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:48:17.505: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/05/24 17:48:17.505
  May  5 17:48:17.505: INFO: Creating deployment "test-rolling-update-deployment"
  May  5 17:48:17.509: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  May  5 17:48:17.513: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  E0505 17:48:18.330545      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:19.331369      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:48:19.521: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
  May  5 17:48:19.525: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  May  5 17:48:19.532: INFO: Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6127",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e59c1bd0-be75-4ee7-8729-bc54e06703cb",
      ResourceVersion: (string) (len=5) "51750",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850528097,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850528097,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850528099,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850528097,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850528097,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850528099,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850528097,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=83) "ReplicaSet \"test-rolling-update-deployment-7ddb77f68b\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  May  5 17:48:19.537: INFO: New ReplicaSet "test-rolling-update-deployment-7ddb77f68b" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rolling-update-deployment-7ddb77f68b",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6127",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "450eb8cc-483c-4628-8c2c-da68b5e771de",
      ResourceVersion: (string) (len=5) "51740",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850528097,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "e59c1bd0-be75-4ee7-8729-bc54e06703cb",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850528097,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 65 35 39 63 31 62  64 30 2d 62 65 37 35 2d  |\"e59c1bd0-be75-|
              00000120  34 65 65 37 2d 38 37 32  39 2d 62 63 35 34 65 30  |4ee7-8729-bc54e0|
              00000130  36 37 30 33 63 62 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |6703cb\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850528099,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May  5 17:48:19.541: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
  May  5 17:48:19.542: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6127",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0b45848c-0d97-4951-b535-cce73dec37fb",
      ResourceVersion: (string) (len=5) "51749",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850528092,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "e59c1bd0-be75-4ee7-8729-bc54e06703cb",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850528092,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850528099,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 65 35 39 63 31 62 64  |"uid\":\"e59c1bd|
              000000b0  30 2d 62 65 37 35 2d 34  65 65 37 2d 38 37 32 39  |0-be75-4ee7-8729|
              000000c0  2d 62 63 35 34 65 30 36  37 30 33 63 62 5c 22 7d  |-bc54e06703cb\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850528099,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May  5 17:48:19.549: INFO: Pod "test-rolling-update-deployment-7ddb77f68b-lr9qr" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=47) "test-rolling-update-deployment-7ddb77f68b-lr9qr",
      GenerateName: (string) (len=42) "test-rolling-update-deployment-7ddb77f68b-",
      Namespace: (string) (len=15) "deployment-6127",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b06c3a3f-35ec-49ae-80e2-bbdfcb8f9510",
      ResourceVersion: (string) (len=5) "51739",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850528097,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "1c768c1c18ea1c0b0457e8d0d35cc9c6decaaf7b6f40487e173e504a8aaf3161",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=17) "10.200.131.181/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=17) "10.200.131.181/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=41) "test-rolling-update-deployment-7ddb77f68b",
          UID: (types.UID) (len=36) "450eb8cc-483c-4628-8c2c-da68b5e771de",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850528097,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850528097,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 35  30 65 62 38 63 63 2d 34  |d\":\"450eb8cc-4|
              00000090  38 33 63 2d 34 36 32 38  2d 38 63 32 63 2d 64 61  |83c-4628-8c2c-da|
              000000a0  36 38 62 35 65 37 37 31  64 65 5c 22 7d 22 3a 7b  |68b5e771de\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850528099,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 30 30 2e 31 33 31  2e 31 38 31 5c 22 7d 22  |.200.131.181\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-g865v",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-g865v",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker00",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850528098,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850528097,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850528098,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850528098,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850528097,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.58.100",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.58.100"
        }
      },
      PodIP: (string) (len=14) "10.200.131.181",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "10.200.131.181"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850528097,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850528098,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253",
          ContainerID: (string) (len=77) "containerd://da65afe8dc3dd7b51c28114c86ffc365f61e62513f90b5aec48e4f9fdca405b8",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May  5 17:48:19.554: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6127" for this suite. @ 05/05/24 17:48:19.56
• [7.107 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:646
  STEP: Creating a kubernetes client @ 05/05/24 17:48:19.58
  May  5 17:48:19.580: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename webhook @ 05/05/24 17:48:19.582
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:48:19.597
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:48:19.602
  STEP: Setting up server cert @ 05/05/24 17:48:19.621
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/05/24 17:48:20.038
  STEP: Deploying the webhook pod @ 05/05/24 17:48:20.046
  STEP: Wait for the deployment to be ready @ 05/05/24 17:48:20.078
  May  5 17:48:20.084: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0505 17:48:20.331831      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:21.332768      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/05/24 17:48:22.09
  STEP: Verifying the service has paired with the endpoint @ 05/05/24 17:48:22.112
  E0505 17:48:22.334460      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:48:23.112: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 05/05/24 17:48:23.154
  STEP: Creating a configMap that should be mutated @ 05/05/24 17:48:23.161
  STEP: Deleting the collection of validation webhooks @ 05/05/24 17:48:23.178
  STEP: Creating a configMap that should not be mutated @ 05/05/24 17:48:23.2
  May  5 17:48:23.228: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8950" for this suite. @ 05/05/24 17:48:23.231
  STEP: Destroying namespace "webhook-markers-7827" for this suite. @ 05/05/24 17:48:23.234
• [3.662 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1416
  STEP: Creating a kubernetes client @ 05/05/24 17:48:23.243
  May  5 17:48:23.243: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename services @ 05/05/24 17:48:23.244
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:48:23.259
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:48:23.262
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-7095 @ 05/05/24 17:48:23.264
  STEP: changing the ExternalName service to type=ClusterIP @ 05/05/24 17:48:23.268
  STEP: creating replication controller externalname-service in namespace services-7095 @ 05/05/24 17:48:23.279
  I0505 17:48:23.287933      22 runners.go:197] Created replication controller with name: externalname-service, namespace: services-7095, replica count: 2
  E0505 17:48:23.336673      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:24.337015      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:25.337272      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:26.337464      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0505 17:48:26.340476      22 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May  5 17:48:26.340: INFO: Creating new exec pod
  E0505 17:48:27.337472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:28.340637      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:29.341320      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:48:29.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-7095 exec execpodzhjq5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  May  5 17:48:29.450: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  May  5 17:48:29.450: INFO: stdout: ""
  E0505 17:48:30.342801      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:48:30.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-7095 exec execpodzhjq5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  May  5 17:48:30.438: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  May  5 17:48:30.438: INFO: stdout: "externalname-service-pl5kh"
  May  5 17:48:30.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-7095 exec execpodzhjq5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.172 80'
  May  5 17:48:30.514: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.32.0.172 80\nConnection to 10.32.0.172 80 port [tcp/http] succeeded!\n"
  May  5 17:48:30.514: INFO: stdout: ""
  E0505 17:48:31.346677      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:48:31.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-7095 exec execpodzhjq5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.172 80'
  May  5 17:48:31.515: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.32.0.172 80\nConnection to 10.32.0.172 80 port [tcp/http] succeeded!\n"
  May  5 17:48:31.515: INFO: stdout: "externalname-service-pl5kh"
  May  5 17:48:31.516: INFO: Cleaning up the ExternalName to ClusterIP test service
  May  5 17:48:31.547: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7095" for this suite. @ 05/05/24 17:48:31.551
• [8.314 seconds]
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 05/05/24 17:48:31.559
  May  5 17:48:31.560: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename sched-preemption @ 05/05/24 17:48:31.562
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:48:31.579
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:48:31.582
  May  5 17:48:31.597: INFO: Waiting up to 1m0s for all nodes to be ready
  E0505 17:48:32.347449      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:33.348613      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:34.348998      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:35.349558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:36.349903      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:37.350088      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:38.351180      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:39.351507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:40.358382      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:41.365270      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:42.366690      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:43.368985      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:44.369912      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:45.370308      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:46.370431      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:47.371076      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:48.371689      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:49.372614      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:50.372873      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:51.373210      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:52.374345      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:53.374710      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:54.375076      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:55.377557      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:56.378448      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:57.379551      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:58.379883      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:48:59.379965      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:00.380511      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:01.381374      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:02.383517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:03.383927      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:04.384336      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:05.384985      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:06.385468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:07.385918      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:08.389896      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:09.390576      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:10.391112      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:11.392777      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:12.393184      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:13.393602      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:14.393853      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:15.394181      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:16.394438      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:17.395461      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:18.395734      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:19.396461      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:20.397388      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:21.397974      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:22.399363      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:23.399789      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:24.401112      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:25.402266      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:26.402656      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:27.402985      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:28.403845      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:29.404344      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:30.404542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:31.404663      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:49:31.605: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 05/05/24 17:49:31.61
  May  5 17:49:31.610: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename sched-preemption-path @ 05/05/24 17:49:31.612
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:49:31.64
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:49:31.645
  May  5 17:49:31.665: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  May  5 17:49:31.669: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  May  5 17:49:31.748: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-3231" for this suite. @ 05/05/24 17:49:31.754
  May  5 17:49:31.761: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-5495" for this suite. @ 05/05/24 17:49:31.766
• [60.215 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:210
  STEP: Creating a kubernetes client @ 05/05/24 17:49:31.775
  May  5 17:49:31.775: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename emptydir @ 05/05/24 17:49:31.776
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:49:31.801
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:49:31.807
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 05/05/24 17:49:31.815
  E0505 17:49:32.406343      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:33.407296      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:34.407674      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:35.408595      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:49:35.852
  May  5 17:49:35.855: INFO: Trying to get logs from node worker00 pod pod-0fdd6922-711d-474e-9045-694caa787034 container test-container: <nil>
  STEP: delete the pod @ 05/05/24 17:49:35.862
  May  5 17:49:35.877: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9613" for this suite. @ 05/05/24 17:49:35.879
• [4.109 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 05/05/24 17:49:35.884
  May  5 17:49:35.884: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename subjectreview @ 05/05/24 17:49:35.885
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:49:35.897
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:49:35.9
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-7335" @ 05/05/24 17:49:35.904
  May  5 17:49:35.909: INFO: saUsername: "system:serviceaccount:subjectreview-7335:e2e"
  May  5 17:49:35.909: INFO: saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-7335"}
  May  5 17:49:35.909: INFO: saUID: "ff681684-7cfb-47ed-92b9-000c82374a03"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-7335:e2e" @ 05/05/24 17:49:35.909
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-7335:e2e" @ 05/05/24 17:49:35.909
  May  5 17:49:35.912: INFO: sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-7335:e2e" api 'list' configmaps in "subjectreview-7335" namespace @ 05/05/24 17:49:35.912
  May  5 17:49:35.916: INFO: SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-7335:e2e" @ 05/05/24 17:49:35.916
  May  5 17:49:35.920: INFO: lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  May  5 17:49:35.920: INFO: LocalSubjectAccessReview has been verified
  May  5 17:49:35.920: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-7335" for this suite. @ 05/05/24 17:49:35.927
• [0.049 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:539
  STEP: Creating a kubernetes client @ 05/05/24 17:49:35.933
  May  5 17:49:35.933: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename gc @ 05/05/24 17:49:35.934
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:49:35.946
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:49:35.952
  STEP: create the deployment @ 05/05/24 17:49:35.955
  W0505 17:49:35.960317      22 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 05/05/24 17:49:35.96
  E0505 17:49:36.409275      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 05/05/24 17:49:36.472
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 05/05/24 17:49:36.478
  STEP: Gathering metrics @ 05/05/24 17:49:36.995
  May  5 17:49:37.061: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  May  5 17:49:37.061: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-4755" for this suite. @ 05/05/24 17:49:37.066
• [1.142 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2199
  STEP: Creating a kubernetes client @ 05/05/24 17:49:37.074
  May  5 17:49:37.074: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename services @ 05/05/24 17:49:37.075
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:49:37.098
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:49:37.11
  STEP: creating service in namespace services-3521 @ 05/05/24 17:49:37.116
  STEP: creating service affinity-clusterip-transition in namespace services-3521 @ 05/05/24 17:49:37.116
  STEP: creating replication controller affinity-clusterip-transition in namespace services-3521 @ 05/05/24 17:49:37.135
  I0505 17:49:37.155823      22 runners.go:197] Created replication controller with name: affinity-clusterip-transition, namespace: services-3521, replica count: 3
  E0505 17:49:37.409376      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:38.410134      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:39.415208      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0505 17:49:40.207241      22 runners.go:197] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May  5 17:49:40.211: INFO: Creating new exec pod
  E0505 17:49:40.416460      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:41.417079      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:42.418143      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:49:43.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-3521 exec execpod-affinitytv7v7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  May  5 17:49:43.362: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  May  5 17:49:43.362: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May  5 17:49:43.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-3521 exec execpod-affinitytv7v7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.32.0.37 80'
  E0505 17:49:43.419252      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:49:43.447: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.32.0.37 80\nConnection to 10.32.0.37 80 port [tcp/http] succeeded!\n"
  May  5 17:49:43.447: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May  5 17:49:43.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-3521 exec execpod-affinitytv7v7 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.32.0.37:80/ ; done'
  May  5 17:49:43.632: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n"
  May  5 17:49:43.632: INFO: stdout: "\naffinity-clusterip-transition-2dwn6\naffinity-clusterip-transition-2dwn6\naffinity-clusterip-transition-mqg5g\naffinity-clusterip-transition-2dwn6\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-2dwn6\naffinity-clusterip-transition-2dwn6\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-mqg5g\naffinity-clusterip-transition-mqg5g\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-mqg5g\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-6kvb5"
  May  5 17:49:43.632: INFO: Received response from host: affinity-clusterip-transition-2dwn6
  May  5 17:49:43.632: INFO: Received response from host: affinity-clusterip-transition-2dwn6
  May  5 17:49:43.632: INFO: Received response from host: affinity-clusterip-transition-mqg5g
  May  5 17:49:43.632: INFO: Received response from host: affinity-clusterip-transition-2dwn6
  May  5 17:49:43.632: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.632: INFO: Received response from host: affinity-clusterip-transition-2dwn6
  May  5 17:49:43.632: INFO: Received response from host: affinity-clusterip-transition-2dwn6
  May  5 17:49:43.632: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.632: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.632: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.632: INFO: Received response from host: affinity-clusterip-transition-mqg5g
  May  5 17:49:43.632: INFO: Received response from host: affinity-clusterip-transition-mqg5g
  May  5 17:49:43.632: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.632: INFO: Received response from host: affinity-clusterip-transition-mqg5g
  May  5 17:49:43.632: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.632: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=services-3521 exec execpod-affinitytv7v7 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.32.0.37:80/ ; done'
  May  5 17:49:43.816: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.32.0.37:80/\n"
  May  5 17:49:43.816: INFO: stdout: "\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-6kvb5\naffinity-clusterip-transition-6kvb5"
  May  5 17:49:43.816: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.816: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.816: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.816: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.816: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.816: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.816: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.816: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.816: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.816: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.816: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.816: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.816: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.816: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.816: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.816: INFO: Received response from host: affinity-clusterip-transition-6kvb5
  May  5 17:49:43.816: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-3521, will wait for the garbage collector to delete the pods @ 05/05/24 17:49:43.83
  May  5 17:49:43.894: INFO: Deleting ReplicationController affinity-clusterip-transition took: 5.004029ms
  May  5 17:49:43.994: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.128006ms
  E0505 17:49:44.420083      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:45.421360      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:46.427637      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:47.428681      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:49:47.627: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3521" for this suite. @ 05/05/24 17:49:47.635
• [10.572 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:611
  STEP: Creating a kubernetes client @ 05/05/24 17:49:47.648
  May  5 17:49:47.648: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename security-context-test @ 05/05/24 17:49:47.651
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:49:47.67
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:49:47.678
  E0505 17:49:48.428924      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:49.429404      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:50.430007      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:51.433026      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:49:51.725: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-8599" for this suite. @ 05/05/24 17:49:51.728
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 05/05/24 17:49:51.734
  May  5 17:49:51.734: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename secrets @ 05/05/24 17:49:51.736
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:49:51.753
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:49:51.757
  STEP: Creating secret with name secret-test-c03ccff5-4f5b-4912-baef-55c3c8007b20 @ 05/05/24 17:49:51.759
  STEP: Creating a pod to test consume secrets @ 05/05/24 17:49:51.763
  E0505 17:49:52.433407      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:53.434110      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:49:53.78
  May  5 17:49:53.782: INFO: Trying to get logs from node worker00 pod pod-secrets-4870fe92-ddb8-484d-9959-f8a2537c9bd5 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/05/24 17:49:53.785
  May  5 17:49:53.798: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3730" for this suite. @ 05/05/24 17:49:53.802
• [2.074 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:158
  STEP: Creating a kubernetes client @ 05/05/24 17:49:53.814
  May  5 17:49:53.814: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename runtimeclass @ 05/05/24 17:49:53.815
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:49:53.825
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:49:53.829
  STEP: Deleting RuntimeClass runtimeclass-5845-delete-me @ 05/05/24 17:49:53.834
  STEP: Waiting for the RuntimeClass to disappear @ 05/05/24 17:49:53.842
  May  5 17:49:53.849: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-5845" for this suite. @ 05/05/24 17:49:53.851
• [0.041 seconds]
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1538
  STEP: Creating a kubernetes client @ 05/05/24 17:49:53.855
  May  5 17:49:53.855: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename kubectl @ 05/05/24 17:49:53.856
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:49:53.868
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:49:53.873
  STEP: creating Agnhost RC @ 05/05/24 17:49:53.876
  May  5 17:49:53.876: INFO: namespace kubectl-1906
  May  5 17:49:53.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-1906 create -f -'
  May  5 17:49:54.013: INFO: stderr: ""
  May  5 17:49:54.013: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 05/05/24 17:49:54.013
  E0505 17:49:54.434617      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:49:55.019: INFO: Selector matched 1 pods for map[app:agnhost]
  May  5 17:49:55.019: INFO: Found 0 / 1
  E0505 17:49:55.435755      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:49:56.017: INFO: Selector matched 1 pods for map[app:agnhost]
  May  5 17:49:56.017: INFO: Found 1 / 1
  May  5 17:49:56.017: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  May  5 17:49:56.020: INFO: Selector matched 1 pods for map[app:agnhost]
  May  5 17:49:56.020: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  May  5 17:49:56.020: INFO: wait on agnhost-primary startup in kubectl-1906 
  May  5 17:49:56.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-1906 logs agnhost-primary-s525x agnhost-primary'
  May  5 17:49:56.140: INFO: stderr: ""
  May  5 17:49:56.140: INFO: stdout: "Paused\n"
  STEP: exposing RC @ 05/05/24 17:49:56.14
  May  5 17:49:56.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-1906 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  May  5 17:49:56.266: INFO: stderr: ""
  May  5 17:49:56.266: INFO: stdout: "service/rm2 exposed\n"
  May  5 17:49:56.272: INFO: Service rm2 in namespace kubectl-1906 found.
  E0505 17:49:56.436053      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:57.437504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: exposing service @ 05/05/24 17:49:58.28
  May  5 17:49:58.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3397920030 --namespace=kubectl-1906 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  May  5 17:49:58.340: INFO: stderr: ""
  May  5 17:49:58.340: INFO: stdout: "service/rm3 exposed\n"
  May  5 17:49:58.344: INFO: Service rm3 in namespace kubectl-1906 found.
  E0505 17:49:58.438757      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:49:59.438831      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:50:00.350: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1906" for this suite. @ 05/05/24 17:50:00.356
• [6.517 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:58
  STEP: Creating a kubernetes client @ 05/05/24 17:50:00.372
  May  5 17:50:00.372: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename projected @ 05/05/24 17:50:00.374
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:50:00.386
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:50:00.388
  STEP: Creating configMap with name projected-configmap-test-volume-5cd7606a-c047-49e8-bd23-961e47897f7f @ 05/05/24 17:50:00.39
  STEP: Creating a pod to test consume configMaps @ 05/05/24 17:50:00.394
  E0505 17:50:00.439816      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:01.440528      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:02.440969      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:03.441740      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/05/24 17:50:04.412
  May  5 17:50:04.414: INFO: Trying to get logs from node worker00 pod pod-projected-configmaps-e03a1003-46d9-45e1-8def-8be27b166509 container agnhost-container: <nil>
  STEP: delete the pod @ 05/05/24 17:50:04.418
  May  5 17:50:04.439: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0505 17:50:04.442367      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "projected-5482" for this suite. @ 05/05/24 17:50:04.442
• [4.074 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 05/05/24 17:50:04.447
  May  5 17:50:04.447: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename containers @ 05/05/24 17:50:04.448
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:50:04.458
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:50:04.461
  E0505 17:50:05.442468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:06.443975      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:50:06.473: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-6132" for this suite. @ 05/05/24 17:50:06.475
• [2.031 seconds]
------------------------------
SSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 05/05/24 17:50:06.478
  May  5 17:50:06.478: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename taint-single-pod @ 05/05/24 17:50:06.479
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:50:06.487
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:50:06.489
  May  5 17:50:06.492: INFO: Waiting up to 1m0s for all nodes to be ready
  E0505 17:50:07.444541      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:08.445042      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:09.445124      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:10.445588      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:11.446495      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:12.446849      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:13.448605      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:14.449008      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:15.449813      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:16.452917      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:17.454340      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:18.454427      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:19.454666      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:20.455328      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:21.456432      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:22.457171      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:23.457469      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:24.458464      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:25.460518      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:26.460866      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:27.461734      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:28.462935      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:29.466367      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:30.466627      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:31.467657      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:32.470534      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:33.474615      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:34.474917      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:35.475604      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:36.476015      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:37.478399      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:38.478999      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:39.479330      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:40.479852      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:41.481472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:42.481493      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:43.482449      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:44.482946      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:45.483440      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:46.484467      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:47.485473      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:48.485785      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:49.486394      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:50.486699      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:51.487948      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:52.489505      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:53.493126      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:54.493517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:55.493629      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:56.493692      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:57.497683      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:58.497693      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:50:59.498019      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:00.498539      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:01.502884      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:02.502702      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:03.503078      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:04.504092      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:05.507585      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:51:06.493: INFO: Waiting for terminating namespaces to be deleted...
  May  5 17:51:06.499: INFO: Starting informer...
  STEP: Starting pod... @ 05/05/24 17:51:06.499
  E0505 17:51:06.508064      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:51:06.730: INFO: Pod is running on worker00. Tainting Node
  STEP: Trying to apply a taint on the Node @ 05/05/24 17:51:06.73
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/05/24 17:51:06.748
  STEP: Waiting short time to make sure Pod is queued for deletion @ 05/05/24 17:51:06.757
  May  5 17:51:06.757: INFO: Pod wasn't evicted. Proceeding
  May  5 17:51:06.757: INFO: Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/05/24 17:51:06.781
  STEP: Waiting some time to make sure that toleration time passed. @ 05/05/24 17:51:06.794
  E0505 17:51:07.508895      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:08.509147      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:09.509385      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:10.509941      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:11.510799      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:12.511417      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:13.512788      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:14.512918      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:15.513683      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:16.514824      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:17.514830      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:18.520367      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:19.522388      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:20.522520      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:21.522989      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:22.523914      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:23.524587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:24.525346      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:25.525918      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:26.526809      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:27.527552      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:28.527724      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:29.528617      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:30.529201      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:31.529192      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:32.532369      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:33.532339      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:34.533434      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:35.536325      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:36.536167      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:37.536894      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:38.537441      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:39.542456      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:40.545487      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:41.545780      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:42.546147      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:43.547531      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:44.547919      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:45.548273      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:46.548433      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:47.549076      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:48.550463      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:49.551719      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:50.552047      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:51.552427      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:52.553965      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:53.554915      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:54.559526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:55.560626      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:56.561828      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:57.562719      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:58.562951      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:51:59.563207      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:00.563433      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:01.563506      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:02.564660      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:03.565742      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:04.566529      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:05.567304      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:06.568962      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:07.569085      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:08.570742      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:09.571737      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:10.572677      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:11.573293      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:12.574011      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:13.574470      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:14.575036      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:15.575271      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:16.575668      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:17.576712      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:18.577337      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:19.578003      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:20.579457      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:21.580554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:52:21.795: INFO: Pod wasn't evicted. Test successful
  May  5 17:52:21.795: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-7826" for this suite. @ 05/05/24 17:52:21.8
• [135.338 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 05/05/24 17:52:21.817
  May  5 17:52:21.817: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename server-version @ 05/05/24 17:52:21.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:52:21.84
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:52:21.842
  STEP: Request ServerVersion @ 05/05/24 17:52:21.845
  STEP: Confirm major version @ 05/05/24 17:52:21.846
  May  5 17:52:21.847: INFO: Major version: 1
  STEP: Confirm minor version @ 05/05/24 17:52:21.847
  May  5 17:52:21.847: INFO: cleanMinorVersion: 29
  May  5 17:52:21.847: INFO: Minor version: 29
  May  5 17:52:21.847: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-5631" for this suite. @ 05/05/24 17:52:21.85
• [0.040 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:155
  STEP: Creating a kubernetes client @ 05/05/24 17:52:21.857
  May  5 17:52:21.857: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename var-expansion @ 05/05/24 17:52:21.86
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:52:21.872
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:52:21.879
  E0505 17:52:22.581468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:23.581776      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:52:23.904: INFO: Deleting pod "var-expansion-f5362b69-7ff3-4b9c-a282-821bc82edb01" in namespace "var-expansion-9484"
  May  5 17:52:23.924: INFO: Wait up to 5m0s for pod "var-expansion-f5362b69-7ff3-4b9c-a282-821bc82edb01" to be fully deleted
  E0505 17:52:24.582460      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:25.583462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:26.584069      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0505 17:52:27.585074      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:52:27.942: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-9484" for this suite. @ 05/05/24 17:52:27.949
• [6.112 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 05/05/24 17:52:27.97
  May  5 17:52:27.971: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: Building a namespace api object, basename svc-latency @ 05/05/24 17:52:27.974
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/05/24 17:52:27.994
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/05/24 17:52:28.003
  May  5 17:52:28.009: INFO: >>> kubeConfig: /tmp/kubeconfig-3397920030
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-5754 @ 05/05/24 17:52:28.013
  I0505 17:52:28.023259      22 runners.go:197] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5754, replica count: 1
  E0505 17:52:28.586127      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0505 17:52:29.084254      22 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0505 17:52:29.587292      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0505 17:52:30.084866      22 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May  5 17:52:30.196: INFO: Created: latency-svc-7xsq4
  May  5 17:52:30.204: INFO: Got endpoints: latency-svc-7xsq4 [19.145787ms]
  May  5 17:52:30.222: INFO: Created: latency-svc-fbff5
  May  5 17:52:30.229: INFO: Got endpoints: latency-svc-fbff5 [24.517248ms]
  May  5 17:52:30.242: INFO: Created: latency-svc-2vfvv
  May  5 17:52:30.243: INFO: Created: latency-svc-crzww
  May  5 17:52:30.244: INFO: Got endpoints: latency-svc-crzww [40.162672ms]
  May  5 17:52:30.255: INFO: Created: latency-svc-9bwjx
  May  5 17:52:30.256: INFO: Got endpoints: latency-svc-2vfvv [51.916219ms]
  May  5 17:52:30.259: INFO: Got endpoints: latency-svc-9bwjx [54.525846ms]
  May  5 17:52:30.267: INFO: Created: latency-svc-q6rcr
  May  5 17:52:30.270: INFO: Got endpoints: latency-svc-q6rcr [65.208898ms]
  May  5 17:52:30.283: INFO: Created: latency-svc-sz877
  May  5 17:52:30.287: INFO: Created: latency-svc-6xvdd
  May  5 17:52:30.296: INFO: Got endpoints: latency-svc-sz877 [90.455665ms]
  May  5 17:52:30.299: INFO: Created: latency-svc-cg54c
  May  5 17:52:30.303: INFO: Got endpoints: latency-svc-6xvdd [97.685055ms]
  May  5 17:52:30.314: INFO: Got endpoints: latency-svc-cg54c [108.811551ms]
  May  5 17:52:30.315: INFO: Created: latency-svc-6gvx9
  May  5 17:52:30.325: INFO: Got endpoints: latency-svc-6gvx9 [120.282562ms]
  May  5 17:52:30.329: INFO: Created: latency-svc-ffnw2
  May  5 17:52:30.335: INFO: Got endpoints: latency-svc-ffnw2 [129.571904ms]
  May  5 17:52:30.341: INFO: Created: latency-svc-5bxnl
  May  5 17:52:30.347: INFO: Created: latency-svc-g927t
  May  5 17:52:30.355: INFO: Got endpoints: latency-svc-5bxnl [149.964985ms]
  May  5 17:52:30.358: INFO: Created: latency-svc-lptbl
  May  5 17:52:30.366: INFO: Created: latency-svc-cltnz
  May  5 17:52:30.371: INFO: Got endpoints: latency-svc-g927t [166.101129ms]
  May  5 17:52:30.372: INFO: Got endpoints: latency-svc-lptbl [166.194872ms]
  May  5 17:52:30.384: INFO: Got endpoints: latency-svc-cltnz [179.170894ms]
  May  5 17:52:30.384: INFO: Created: latency-svc-4tftj
  May  5 17:52:30.391: INFO: Got endpoints: latency-svc-4tftj [185.685835ms]
  May  5 17:52:30.400: INFO: Created: latency-svc-lpvc2
  May  5 17:52:30.406: INFO: Got endpoints: latency-svc-lpvc2 [176.700166ms]
  May  5 17:52:30.481: INFO: Created: latency-svc-hnkjx
  May  5 17:52:30.481: INFO: Created: latency-svc-lz46r
  May  5 17:52:30.483: INFO: Created: latency-svc-h55j8
  May  5 17:52:30.483: INFO: Created: latency-svc-9x2wn
  May  5 17:52:30.483: INFO: Created: latency-svc-nw5pg
  May  5 17:52:30.483: INFO: Created: latency-svc-rpj78
  May  5 17:52:30.483: INFO: Created: latency-svc-q9lz4
  May  5 17:52:30.483: INFO: Created: latency-svc-z78gx
  May  5 17:52:30.483: INFO: Created: latency-svc-484wv
  May  5 17:52:30.487: INFO: Created: latency-svc-zk8ql
  May  5 17:52:30.489: INFO: Created: latency-svc-qthbt
  May  5 17:52:30.489: INFO: Created: latency-svc-crqzm
  May  5 17:52:30.489: INFO: Created: latency-svc-cxrx5
  May  5 17:52:30.493: INFO: Got endpoints: latency-svc-nw5pg [190.106536ms]
  May  5 17:52:30.495: INFO: Got endpoints: latency-svc-zk8ql [160.135592ms]
  May  5 17:52:30.497: INFO: Created: latency-svc-dbvz2
  May  5 17:52:30.512: INFO: Created: latency-svc-ddq4h
  May  5 17:52:30.513: INFO: Got endpoints: latency-svc-lz46r [242.48559ms]
  May  5 17:52:30.513: INFO: Got endpoints: latency-svc-h55j8 [122.272329ms]
  May  5 17:52:30.513: INFO: Got endpoints: latency-svc-crqzm [199.10737ms]
  May  5 17:52:30.514: INFO: Got endpoints: latency-svc-484wv [188.933886ms]
  May  5 17:52:30.514: INFO: Got endpoints: latency-svc-ddq4h [142.071963ms]
  May  5 17:52:30.514: INFO: Got endpoints: latency-svc-dbvz2 [158.845898ms]
  May  5 17:52:30.520: INFO: Got endpoints: latency-svc-cxrx5 [261.097264ms]
  May  5 17:52:30.537: INFO: Created: latency-svc-7w72z
  May  5 17:52:30.537: INFO: Got endpoints: latency-svc-qthbt [152.934268ms]
  May  5 17:52:30.537: INFO: Got endpoints: latency-svc-hnkjx [165.536624ms]
  May  5 17:52:30.541: INFO: Got endpoints: latency-svc-rpj78 [285.11029ms]
  May  5 17:52:30.546: INFO: Got endpoints: latency-svc-z78gx [140.408496ms]
  May  5 17:52:30.548: INFO: Got endpoints: latency-svc-7w72z [54.941119ms]
  May  5 17:52:30.548: INFO: Got endpoints: latency-svc-q9lz4 [252.516435ms]
  May  5 17:52:30.548: INFO: Got endpoints: latency-svc-9x2wn [304.158191ms]
  May  5 17:52:30.558: INFO: Created: latency-svc-58r6s
  May  5 17:52:30.569: INFO: Created: latency-svc-97fdn
  May  5 17:52:30.570: INFO: Got endpoints: latency-svc-58r6s [74.990316ms]
  May  5 17:52:30.577: INFO: Got endpoints: latency-svc-97fdn [63.665036ms]
  May  5 17:52:30.582: INFO: Created: latency-svc-tzqsw
  May  5 17:52:30.587: INFO: Got endpoints: latency-svc-tzqsw [73.351535ms]
  E0505 17:52:30.587521      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:52:30.598: INFO: Created: latency-svc-v8j2j
  May  5 17:52:30.607: INFO: Got endpoints: latency-svc-v8j2j [93.364511ms]
  May  5 17:52:30.607: INFO: Created: latency-svc-nblng
  May  5 17:52:30.616: INFO: Got endpoints: latency-svc-nblng [102.43408ms]
  May  5 17:52:30.618: INFO: Created: latency-svc-97cc6
  May  5 17:52:30.629: INFO: Created: latency-svc-4fmj2
  May  5 17:52:30.634: INFO: Created: latency-svc-llkmz
  May  5 17:52:30.642: INFO: Created: latency-svc-rtsgj
  May  5 17:52:30.657: INFO: Created: latency-svc-6b2d6
  May  5 17:52:30.658: INFO: Got endpoints: latency-svc-97cc6 [138.187208ms]
  May  5 17:52:30.662: INFO: Created: latency-svc-7r2bv
  May  5 17:52:30.669: INFO: Created: latency-svc-krpsx
  May  5 17:52:30.678: INFO: Created: latency-svc-mklcz
  May  5 17:52:30.683: INFO: Created: latency-svc-t4rhq
  May  5 17:52:30.698: INFO: Created: latency-svc-kjqc9
  May  5 17:52:30.705: INFO: Created: latency-svc-mrfzj
  May  5 17:52:30.711: INFO: Got endpoints: latency-svc-4fmj2 [197.636861ms]
  May  5 17:52:30.718: INFO: Created: latency-svc-hxk7l
  May  5 17:52:30.727: INFO: Created: latency-svc-mm8c7
  May  5 17:52:30.735: INFO: Created: latency-svc-g986w
  May  5 17:52:30.740: INFO: Created: latency-svc-cc42x
  May  5 17:52:30.744: INFO: Created: latency-svc-2g54f
  May  5 17:52:30.756: INFO: Got endpoints: latency-svc-llkmz [242.405565ms]
  May  5 17:52:30.756: INFO: Created: latency-svc-q6c8t
  May  5 17:52:30.768: INFO: Created: latency-svc-q9dpp
  May  5 17:52:30.803: INFO: Got endpoints: latency-svc-rtsgj [265.289569ms]
  May  5 17:52:30.814: INFO: Created: latency-svc-v4lpz
  May  5 17:52:30.852: INFO: Got endpoints: latency-svc-6b2d6 [311.179691ms]
  May  5 17:52:30.864: INFO: Created: latency-svc-9ttjd
  May  5 17:52:30.905: INFO: Got endpoints: latency-svc-7r2bv [358.850368ms]
  May  5 17:52:30.915: INFO: Created: latency-svc-ttkqp
  May  5 17:52:30.955: INFO: Got endpoints: latency-svc-krpsx [406.269102ms]
  May  5 17:52:30.966: INFO: Created: latency-svc-7lkc8
  May  5 17:52:31.002: INFO: Got endpoints: latency-svc-mklcz [453.865874ms]
  May  5 17:52:31.014: INFO: Created: latency-svc-4g42k
  May  5 17:52:31.052: INFO: Got endpoints: latency-svc-t4rhq [503.875218ms]
  May  5 17:52:31.062: INFO: Created: latency-svc-vfvqj
  May  5 17:52:31.105: INFO: Got endpoints: latency-svc-kjqc9 [534.877018ms]
  May  5 17:52:31.116: INFO: Created: latency-svc-mxmh9
  May  5 17:52:31.153: INFO: Got endpoints: latency-svc-mrfzj [576.333294ms]
  May  5 17:52:31.161: INFO: Created: latency-svc-bdnn5
  May  5 17:52:31.203: INFO: Got endpoints: latency-svc-hxk7l [616.074136ms]
  May  5 17:52:31.214: INFO: Created: latency-svc-vcjhc
  May  5 17:52:31.253: INFO: Got endpoints: latency-svc-mm8c7 [645.910139ms]
  May  5 17:52:31.258: INFO: Created: latency-svc-p4scb
  May  5 17:52:31.302: INFO: Got endpoints: latency-svc-cc42x [764.610167ms]
  May  5 17:52:31.310: INFO: Created: latency-svc-72wz8
  May  5 17:52:31.353: INFO: Got endpoints: latency-svc-g986w [735.244543ms]
  May  5 17:52:31.363: INFO: Created: latency-svc-rcrbc
  May  5 17:52:31.402: INFO: Got endpoints: latency-svc-2g54f [743.452964ms]
  May  5 17:52:31.411: INFO: Created: latency-svc-kmhfk
  May  5 17:52:31.457: INFO: Got endpoints: latency-svc-q6c8t [746.259915ms]
  May  5 17:52:31.471: INFO: Created: latency-svc-p9zsj
  May  5 17:52:31.501: INFO: Got endpoints: latency-svc-q9dpp [745.192046ms]
  May  5 17:52:31.509: INFO: Created: latency-svc-vdvm5
  May  5 17:52:31.553: INFO: Got endpoints: latency-svc-v4lpz [749.892797ms]
  May  5 17:52:31.562: INFO: Created: latency-svc-ql8lv
  E0505 17:52:31.588516      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:52:31.603: INFO: Got endpoints: latency-svc-9ttjd [750.999619ms]
  May  5 17:52:31.613: INFO: Created: latency-svc-4n6hs
  May  5 17:52:31.652: INFO: Got endpoints: latency-svc-ttkqp [746.326686ms]
  May  5 17:52:31.661: INFO: Created: latency-svc-5jjq6
  May  5 17:52:31.707: INFO: Got endpoints: latency-svc-7lkc8 [752.077755ms]
  May  5 17:52:31.715: INFO: Created: latency-svc-d846n
  May  5 17:52:31.755: INFO: Got endpoints: latency-svc-4g42k [752.324436ms]
  May  5 17:52:31.763: INFO: Created: latency-svc-25ws4
  May  5 17:52:31.802: INFO: Got endpoints: latency-svc-vfvqj [749.320793ms]
  May  5 17:52:31.814: INFO: Created: latency-svc-x46tq
  May  5 17:52:31.852: INFO: Got endpoints: latency-svc-mxmh9 [747.474445ms]
  May  5 17:52:31.861: INFO: Created: latency-svc-g8dfs
  May  5 17:52:31.912: INFO: Got endpoints: latency-svc-bdnn5 [758.616954ms]
  May  5 17:52:31.923: INFO: Created: latency-svc-7q8g2
  May  5 17:52:31.960: INFO: Got endpoints: latency-svc-vcjhc [755.00963ms]
  May  5 17:52:31.969: INFO: Created: latency-svc-5t4x7
  May  5 17:52:32.015: INFO: Got endpoints: latency-svc-p4scb [762.015282ms]
  May  5 17:52:32.022: INFO: Created: latency-svc-ljg5g
  May  5 17:52:32.052: INFO: Got endpoints: latency-svc-72wz8 [750.195115ms]
  May  5 17:52:32.064: INFO: Created: latency-svc-lxr5p
  May  5 17:52:32.103: INFO: Got endpoints: latency-svc-rcrbc [749.471863ms]
  May  5 17:52:32.113: INFO: Created: latency-svc-kz665
  May  5 17:52:32.152: INFO: Got endpoints: latency-svc-kmhfk [750.100633ms]
  May  5 17:52:32.165: INFO: Created: latency-svc-85jcv
  May  5 17:52:32.213: INFO: Got endpoints: latency-svc-p9zsj [753.723492ms]
  May  5 17:52:32.228: INFO: Created: latency-svc-n7ttb
  May  5 17:52:32.256: INFO: Got endpoints: latency-svc-vdvm5 [754.497062ms]
  May  5 17:52:32.264: INFO: Created: latency-svc-lgtj4
  May  5 17:52:32.306: INFO: Got endpoints: latency-svc-ql8lv [752.4999ms]
  May  5 17:52:32.318: INFO: Created: latency-svc-f55cm
  May  5 17:52:32.353: INFO: Got endpoints: latency-svc-4n6hs [749.511304ms]
  May  5 17:52:32.368: INFO: Created: latency-svc-rfnnc
  May  5 17:52:32.401: INFO: Got endpoints: latency-svc-5jjq6 [749.820189ms]
  May  5 17:52:32.413: INFO: Created: latency-svc-vfsq8
  May  5 17:52:32.455: INFO: Got endpoints: latency-svc-d846n [747.89119ms]
  May  5 17:52:32.464: INFO: Created: latency-svc-ldncd
  May  5 17:52:32.504: INFO: Got endpoints: latency-svc-25ws4 [749.255218ms]
  May  5 17:52:32.514: INFO: Created: latency-svc-jm9nf
  May  5 17:52:32.551: INFO: Got endpoints: latency-svc-x46tq [749.552512ms]
  May  5 17:52:32.565: INFO: Created: latency-svc-q6ccv
  E0505 17:52:32.589097      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:52:32.607: INFO: Got endpoints: latency-svc-g8dfs [754.664631ms]
  May  5 17:52:32.617: INFO: Created: latency-svc-jccm5
  May  5 17:52:32.652: INFO: Got endpoints: latency-svc-7q8g2 [740.56096ms]
  May  5 17:52:32.662: INFO: Created: latency-svc-9hftj
  May  5 17:52:32.707: INFO: Got endpoints: latency-svc-5t4x7 [747.251254ms]
  May  5 17:52:32.718: INFO: Created: latency-svc-qk9zw
  May  5 17:52:32.752: INFO: Got endpoints: latency-svc-ljg5g [736.966301ms]
  May  5 17:52:32.759: INFO: Created: latency-svc-q8f6x
  May  5 17:52:32.802: INFO: Got endpoints: latency-svc-lxr5p [749.552969ms]
  May  5 17:52:32.808: INFO: Created: latency-svc-vbbnp
  May  5 17:52:32.854: INFO: Got endpoints: latency-svc-kz665 [751.057965ms]
  May  5 17:52:32.864: INFO: Created: latency-svc-48lzj
  May  5 17:52:32.901: INFO: Got endpoints: latency-svc-85jcv [748.602956ms]
  May  5 17:52:32.914: INFO: Created: latency-svc-6wfw5
  May  5 17:52:32.954: INFO: Got endpoints: latency-svc-n7ttb [740.71131ms]
  May  5 17:52:32.963: INFO: Created: latency-svc-5s2vm
  May  5 17:52:33.002: INFO: Got endpoints: latency-svc-lgtj4 [746.390193ms]
  May  5 17:52:33.014: INFO: Created: latency-svc-4rvht
  May  5 17:52:33.052: INFO: Got endpoints: latency-svc-f55cm [746.378974ms]
  May  5 17:52:33.062: INFO: Created: latency-svc-mzzmt
  May  5 17:52:33.102: INFO: Got endpoints: latency-svc-rfnnc [749.03087ms]
  May  5 17:52:33.115: INFO: Created: latency-svc-bpwvn
  May  5 17:52:33.152: INFO: Got endpoints: latency-svc-vfsq8 [750.407724ms]
  May  5 17:52:33.167: INFO: Created: latency-svc-s2tcr
  May  5 17:52:33.206: INFO: Got endpoints: latency-svc-ldncd [751.020627ms]
  May  5 17:52:33.223: INFO: Created: latency-svc-755vk
  May  5 17:52:33.253: INFO: Got endpoints: latency-svc-jm9nf [749.015661ms]
  May  5 17:52:33.267: INFO: Created: latency-svc-mm8tz
  May  5 17:52:33.303: INFO: Got endpoints: latency-svc-q6ccv [751.192758ms]
  May  5 17:52:33.313: INFO: Created: latency-svc-lwcx6
  May  5 17:52:33.353: INFO: Got endpoints: latency-svc-jccm5 [745.977053ms]
  May  5 17:52:33.363: INFO: Created: latency-svc-5qtw8
  May  5 17:52:33.400: INFO: Got endpoints: latency-svc-9hftj [747.832975ms]
  May  5 17:52:33.407: INFO: Created: latency-svc-kkcgd
  May  5 17:52:33.454: INFO: Got endpoints: latency-svc-qk9zw [747.092971ms]
  May  5 17:52:33.465: INFO: Created: latency-svc-fk7fn
  May  5 17:52:33.503: INFO: Got endpoints: latency-svc-q8f6x [750.681577ms]
  May  5 17:52:33.517: INFO: Created: latency-svc-p5jvz
  May  5 17:52:33.552: INFO: Got endpoints: latency-svc-vbbnp [750.912412ms]
  May  5 17:52:33.561: INFO: Created: latency-svc-h7mjb
  E0505 17:52:33.589713      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:52:33.604: INFO: Got endpoints: latency-svc-48lzj [749.648079ms]
  May  5 17:52:33.617: INFO: Created: latency-svc-t9h45
  May  5 17:52:33.658: INFO: Got endpoints: latency-svc-6wfw5 [756.916449ms]
  May  5 17:52:33.676: INFO: Created: latency-svc-kprxm
  May  5 17:52:33.714: INFO: Got endpoints: latency-svc-5s2vm [760.296996ms]
  May  5 17:52:33.728: INFO: Created: latency-svc-fg9tb
  May  5 17:52:33.755: INFO: Got endpoints: latency-svc-4rvht [752.110692ms]
  May  5 17:52:33.764: INFO: Created: latency-svc-pf26b
  May  5 17:52:33.805: INFO: Got endpoints: latency-svc-mzzmt [752.232521ms]
  May  5 17:52:33.813: INFO: Created: latency-svc-krb7r
  May  5 17:52:33.852: INFO: Got endpoints: latency-svc-bpwvn [749.967657ms]
  May  5 17:52:33.862: INFO: Created: latency-svc-8kczd
  May  5 17:52:33.904: INFO: Got endpoints: latency-svc-s2tcr [751.876326ms]
  May  5 17:52:33.915: INFO: Created: latency-svc-kbl8c
  May  5 17:52:33.957: INFO: Got endpoints: latency-svc-755vk [751.409348ms]
  May  5 17:52:33.964: INFO: Created: latency-svc-6wklf
  May  5 17:52:34.002: INFO: Got endpoints: latency-svc-mm8tz [749.102231ms]
  May  5 17:52:34.017: INFO: Created: latency-svc-ckzd8
  May  5 17:52:34.051: INFO: Got endpoints: latency-svc-lwcx6 [748.643359ms]
  May  5 17:52:34.062: INFO: Created: latency-svc-qnx2t
  May  5 17:52:34.105: INFO: Got endpoints: latency-svc-5qtw8 [751.91463ms]
  May  5 17:52:34.117: INFO: Created: latency-svc-g2wwg
  May  5 17:52:34.153: INFO: Got endpoints: latency-svc-kkcgd [753.216759ms]
  May  5 17:52:34.161: INFO: Created: latency-svc-dmjvq
  May  5 17:52:34.206: INFO: Got endpoints: latency-svc-fk7fn [751.075631ms]
  May  5 17:52:34.220: INFO: Created: latency-svc-j84l8
  May  5 17:52:34.255: INFO: Got endpoints: latency-svc-p5jvz [751.904231ms]
  May  5 17:52:34.263: INFO: Created: latency-svc-4f6rd
  May  5 17:52:34.304: INFO: Got endpoints: latency-svc-h7mjb [750.802915ms]
  May  5 17:52:34.314: INFO: Created: latency-svc-5c7lp
  May  5 17:52:34.356: INFO: Got endpoints: latency-svc-t9h45 [751.453258ms]
  May  5 17:52:34.362: INFO: Created: latency-svc-4hwr6
  May  5 17:52:34.405: INFO: Got endpoints: latency-svc-kprxm [746.84312ms]
  May  5 17:52:34.418: INFO: Created: latency-svc-7g9s2
  May  5 17:52:34.457: INFO: Got endpoints: latency-svc-fg9tb [742.697658ms]
  May  5 17:52:34.467: INFO: Created: latency-svc-q8kll
  May  5 17:52:34.505: INFO: Got endpoints: latency-svc-pf26b [750.855311ms]
  May  5 17:52:34.519: INFO: Created: latency-svc-t6p7w
  May  5 17:52:34.554: INFO: Got endpoints: latency-svc-krb7r [749.0264ms]
  May  5 17:52:34.567: INFO: Created: latency-svc-klmxb
  E0505 17:52:34.590032      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:52:34.604: INFO: Got endpoints: latency-svc-8kczd [752.255416ms]
  May  5 17:52:34.621: INFO: Created: latency-svc-twvbq
  May  5 17:52:34.653: INFO: Got endpoints: latency-svc-kbl8c [748.406014ms]
  May  5 17:52:34.660: INFO: Created: latency-svc-59wcd
  May  5 17:52:34.706: INFO: Got endpoints: latency-svc-6wklf [749.113958ms]
  May  5 17:52:34.718: INFO: Created: latency-svc-hb9p8
  May  5 17:52:34.755: INFO: Got endpoints: latency-svc-ckzd8 [752.934027ms]
  May  5 17:52:34.762: INFO: Created: latency-svc-lpxdj
  May  5 17:52:34.801: INFO: Got endpoints: latency-svc-qnx2t [749.884295ms]
  May  5 17:52:34.817: INFO: Created: latency-svc-xlt42
  May  5 17:52:34.854: INFO: Got endpoints: latency-svc-g2wwg [748.583655ms]
  May  5 17:52:34.861: INFO: Created: latency-svc-j629h
  May  5 17:52:34.900: INFO: Got endpoints: latency-svc-dmjvq [746.843015ms]
  May  5 17:52:34.914: INFO: Created: latency-svc-n9ns9
  May  5 17:52:34.958: INFO: Got endpoints: latency-svc-j84l8 [751.505263ms]
  May  5 17:52:34.970: INFO: Created: latency-svc-765qx
  May  5 17:52:35.011: INFO: Got endpoints: latency-svc-4f6rd [756.480042ms]
  May  5 17:52:35.023: INFO: Created: latency-svc-xnbx8
  May  5 17:52:35.055: INFO: Got endpoints: latency-svc-5c7lp [751.186707ms]
  May  5 17:52:35.068: INFO: Created: latency-svc-pgj69
  May  5 17:52:35.105: INFO: Got endpoints: latency-svc-4hwr6 [748.763777ms]
  May  5 17:52:35.116: INFO: Created: latency-svc-cmxh9
  May  5 17:52:35.155: INFO: Got endpoints: latency-svc-7g9s2 [749.52727ms]
  May  5 17:52:35.162: INFO: Created: latency-svc-dpxls
  May  5 17:52:35.206: INFO: Got endpoints: latency-svc-q8kll [748.352676ms]
  May  5 17:52:35.224: INFO: Created: latency-svc-rcktq
  May  5 17:52:35.254: INFO: Got endpoints: latency-svc-t6p7w [748.861596ms]
  May  5 17:52:35.264: INFO: Created: latency-svc-pbcxp
  May  5 17:52:35.306: INFO: Got endpoints: latency-svc-klmxb [751.506122ms]
  May  5 17:52:35.323: INFO: Created: latency-svc-qhzwb
  May  5 17:52:35.354: INFO: Got endpoints: latency-svc-twvbq [749.76123ms]
  May  5 17:52:35.367: INFO: Created: latency-svc-c9l52
  May  5 17:52:35.405: INFO: Got endpoints: latency-svc-59wcd [752.195571ms]
  May  5 17:52:35.418: INFO: Created: latency-svc-mrqs2
  May  5 17:52:35.461: INFO: Got endpoints: latency-svc-hb9p8 [754.622126ms]
  May  5 17:52:35.473: INFO: Created: latency-svc-fkgfm
  May  5 17:52:35.508: INFO: Got endpoints: latency-svc-lpxdj [752.237213ms]
  May  5 17:52:35.520: INFO: Created: latency-svc-4zw7h
  May  5 17:52:35.557: INFO: Got endpoints: latency-svc-xlt42 [755.3116ms]
  May  5 17:52:35.567: INFO: Created: latency-svc-9tkdr
  E0505 17:52:35.591032      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:52:35.607: INFO: Got endpoints: latency-svc-j629h [753.409719ms]
  May  5 17:52:35.619: INFO: Created: latency-svc-sd6rq
  May  5 17:52:35.660: INFO: Got endpoints: latency-svc-n9ns9 [759.985584ms]
  May  5 17:52:35.671: INFO: Created: latency-svc-fmgrr
  May  5 17:52:35.705: INFO: Got endpoints: latency-svc-765qx [745.934168ms]
  May  5 17:52:35.723: INFO: Created: latency-svc-x2fxj
  May  5 17:52:35.754: INFO: Got endpoints: latency-svc-xnbx8 [742.689681ms]
  May  5 17:52:35.768: INFO: Created: latency-svc-bgrhn
  May  5 17:52:35.809: INFO: Got endpoints: latency-svc-pgj69 [754.07057ms]
  May  5 17:52:35.819: INFO: Created: latency-svc-vtrpx
  May  5 17:52:35.861: INFO: Got endpoints: latency-svc-cmxh9 [756.310881ms]
  May  5 17:52:35.875: INFO: Created: latency-svc-r74jn
  May  5 17:52:35.905: INFO: Got endpoints: latency-svc-dpxls [749.407457ms]
  May  5 17:52:35.924: INFO: Created: latency-svc-6qrmp
  May  5 17:52:35.955: INFO: Got endpoints: latency-svc-rcktq [749.267861ms]
  May  5 17:52:35.972: INFO: Created: latency-svc-bvl7k
  May  5 17:52:36.005: INFO: Got endpoints: latency-svc-pbcxp [750.652599ms]
  May  5 17:52:36.020: INFO: Created: latency-svc-w4z6q
  May  5 17:52:36.056: INFO: Got endpoints: latency-svc-qhzwb [749.098295ms]
  May  5 17:52:36.066: INFO: Created: latency-svc-sv5j7
  May  5 17:52:36.105: INFO: Got endpoints: latency-svc-c9l52 [750.150424ms]
  May  5 17:52:36.113: INFO: Created: latency-svc-6mhmn
  May  5 17:52:36.153: INFO: Got endpoints: latency-svc-mrqs2 [747.532132ms]
  May  5 17:52:36.166: INFO: Created: latency-svc-2hgwz
  May  5 17:52:36.217: INFO: Got endpoints: latency-svc-fkgfm [755.563904ms]
  May  5 17:52:36.232: INFO: Created: latency-svc-cvftw
  May  5 17:52:36.256: INFO: Got endpoints: latency-svc-4zw7h [747.70399ms]
  May  5 17:52:36.273: INFO: Created: latency-svc-hvjqm
  May  5 17:52:36.303: INFO: Got endpoints: latency-svc-9tkdr [745.693535ms]
  May  5 17:52:36.313: INFO: Created: latency-svc-hshv9
  May  5 17:52:36.354: INFO: Got endpoints: latency-svc-sd6rq [746.980193ms]
  May  5 17:52:36.366: INFO: Created: latency-svc-rbxm4
  May  5 17:52:36.403: INFO: Got endpoints: latency-svc-fmgrr [742.32147ms]
  May  5 17:52:36.415: INFO: Created: latency-svc-sdwbc
  May  5 17:52:36.459: INFO: Got endpoints: latency-svc-x2fxj [754.687251ms]
  May  5 17:52:36.474: INFO: Created: latency-svc-z486d
  May  5 17:52:36.503: INFO: Got endpoints: latency-svc-bgrhn [748.243417ms]
  May  5 17:52:36.515: INFO: Created: latency-svc-dfgcr
  May  5 17:52:36.553: INFO: Got endpoints: latency-svc-vtrpx [743.858126ms]
  May  5 17:52:36.569: INFO: Created: latency-svc-vmr8z
  E0505 17:52:36.592024      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:52:36.604: INFO: Got endpoints: latency-svc-r74jn [742.363014ms]
  May  5 17:52:36.618: INFO: Created: latency-svc-lgg58
  May  5 17:52:36.652: INFO: Got endpoints: latency-svc-6qrmp [747.843946ms]
  May  5 17:52:36.661: INFO: Created: latency-svc-85m4n
  May  5 17:52:36.708: INFO: Got endpoints: latency-svc-bvl7k [751.699751ms]
  May  5 17:52:36.719: INFO: Created: latency-svc-bsfc9
  May  5 17:52:36.763: INFO: Got endpoints: latency-svc-w4z6q [758.039122ms]
  May  5 17:52:36.774: INFO: Created: latency-svc-v2w8r
  May  5 17:52:36.803: INFO: Got endpoints: latency-svc-sv5j7 [747.165625ms]
  May  5 17:52:36.815: INFO: Created: latency-svc-72642
  May  5 17:52:36.853: INFO: Got endpoints: latency-svc-6mhmn [748.662749ms]
  May  5 17:52:36.865: INFO: Created: latency-svc-hmwsz
  May  5 17:52:36.905: INFO: Got endpoints: latency-svc-2hgwz [752.557796ms]
  May  5 17:52:36.916: INFO: Created: latency-svc-fpg5j
  May  5 17:52:36.954: INFO: Got endpoints: latency-svc-cvftw [737.654388ms]
  May  5 17:52:36.970: INFO: Created: latency-svc-7hb7q
  May  5 17:52:37.009: INFO: Got endpoints: latency-svc-hvjqm [753.298539ms]
  May  5 17:52:37.019: INFO: Created: latency-svc-4v68g
  May  5 17:52:37.051: INFO: Got endpoints: latency-svc-hshv9 [748.211451ms]
  May  5 17:52:37.069: INFO: Created: latency-svc-v5x87
  May  5 17:52:37.104: INFO: Got endpoints: latency-svc-rbxm4 [749.814988ms]
  May  5 17:52:37.114: INFO: Created: latency-svc-rhbch
  May  5 17:52:37.156: INFO: Got endpoints: latency-svc-sdwbc [753.576991ms]
  May  5 17:52:37.170: INFO: Created: latency-svc-hgdqh
  May  5 17:52:37.211: INFO: Got endpoints: latency-svc-z486d [751.26134ms]
  May  5 17:52:37.231: INFO: Created: latency-svc-fxlzf
  May  5 17:52:37.256: INFO: Got endpoints: latency-svc-dfgcr [752.936487ms]
  May  5 17:52:37.272: INFO: Created: latency-svc-zwqbv
  May  5 17:52:37.304: INFO: Got endpoints: latency-svc-vmr8z [750.569623ms]
  May  5 17:52:37.320: INFO: Created: latency-svc-w7mnt
  May  5 17:52:37.352: INFO: Got endpoints: latency-svc-lgg58 [748.241555ms]
  May  5 17:52:37.363: INFO: Created: latency-svc-mjbqr
  May  5 17:52:37.406: INFO: Got endpoints: latency-svc-85m4n [753.856074ms]
  May  5 17:52:37.423: INFO: Created: latency-svc-8zsh5
  May  5 17:52:37.460: INFO: Got endpoints: latency-svc-bsfc9 [749.516637ms]
  May  5 17:52:37.469: INFO: Created: latency-svc-cnfp9
  May  5 17:52:37.506: INFO: Got endpoints: latency-svc-v2w8r [742.911402ms]
  May  5 17:52:37.520: INFO: Created: latency-svc-c72tg
  May  5 17:52:37.554: INFO: Got endpoints: latency-svc-72642 [751.190765ms]
  May  5 17:52:37.565: INFO: Created: latency-svc-6ssh7
  E0505 17:52:37.592733      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:52:37.606: INFO: Got endpoints: latency-svc-hmwsz [752.35748ms]
  May  5 17:52:37.622: INFO: Created: latency-svc-kzxkc
  May  5 17:52:37.658: INFO: Got endpoints: latency-svc-fpg5j [752.271353ms]
  May  5 17:52:37.667: INFO: Created: latency-svc-lxd22
  May  5 17:52:37.711: INFO: Got endpoints: latency-svc-7hb7q [756.497889ms]
  May  5 17:52:37.723: INFO: Created: latency-svc-gwfrj
  May  5 17:52:37.753: INFO: Got endpoints: latency-svc-4v68g [744.230654ms]
  May  5 17:52:37.764: INFO: Created: latency-svc-gk45t
  May  5 17:52:37.806: INFO: Got endpoints: latency-svc-v5x87 [754.413951ms]
  May  5 17:52:37.817: INFO: Created: latency-svc-455r9
  May  5 17:52:37.862: INFO: Got endpoints: latency-svc-rhbch [757.67873ms]
  May  5 17:52:37.874: INFO: Created: latency-svc-z7h9m
  May  5 17:52:37.906: INFO: Got endpoints: latency-svc-hgdqh [749.794845ms]
  May  5 17:52:37.915: INFO: Created: latency-svc-zzk2z
  May  5 17:52:37.959: INFO: Got endpoints: latency-svc-fxlzf [748.047586ms]
  May  5 17:52:37.978: INFO: Created: latency-svc-89mn4
  May  5 17:52:38.017: INFO: Got endpoints: latency-svc-zwqbv [761.572123ms]
  May  5 17:52:38.051: INFO: Created: latency-svc-czngq
  May  5 17:52:38.056: INFO: Got endpoints: latency-svc-w7mnt [751.842962ms]
  May  5 17:52:38.110: INFO: Got endpoints: latency-svc-mjbqr [758.286243ms]
  May  5 17:52:38.152: INFO: Got endpoints: latency-svc-8zsh5 [745.210204ms]
  May  5 17:52:38.209: INFO: Got endpoints: latency-svc-cnfp9 [748.613801ms]
  May  5 17:52:38.252: INFO: Got endpoints: latency-svc-c72tg [745.881814ms]
  May  5 17:52:38.309: INFO: Got endpoints: latency-svc-6ssh7 [754.775629ms]
  May  5 17:52:38.357: INFO: Got endpoints: latency-svc-kzxkc [750.962454ms]
  May  5 17:52:38.404: INFO: Got endpoints: latency-svc-lxd22 [746.154535ms]
  May  5 17:52:38.462: INFO: Got endpoints: latency-svc-gwfrj [751.129629ms]
  May  5 17:52:38.507: INFO: Got endpoints: latency-svc-gk45t [753.211855ms]
  May  5 17:52:38.552: INFO: Got endpoints: latency-svc-455r9 [745.792281ms]
  E0505 17:52:38.594328      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  May  5 17:52:38.604: INFO: Got endpoints: latency-svc-z7h9m [741.989991ms]
  May  5 17:52:38.651: INFO: Got endpoints: latency-svc-zzk2z [744.06508ms]
  May  5 17:52:38.705: INFO: Got endpoints: latency-svc-89mn4 [742.289281ms]
  May  5 17:52:38.753: INFO: Got endpoints: latency-svc-czngq [733.999818ms]
  May  5 17:52:38.753: INFO: Latencies: [24.517248ms 40.162672ms 51.916219ms 54.525846ms 54.941119ms 63.665036ms 65.208898ms 73.351535ms 74.990316ms 90.455665ms 93.364511ms 97.685055ms 102.43408ms 108.811551ms 120.282562ms 122.272329ms 129.571904ms 138.187208ms 140.408496ms 142.071963ms 149.964985ms 152.934268ms 158.845898ms 160.135592ms 165.536624ms 166.101129ms 166.194872ms 176.700166ms 179.170894ms 185.685835ms 188.933886ms 190.106536ms 197.636861ms 199.10737ms 242.405565ms 242.48559ms 252.516435ms 261.097264ms 265.289569ms 285.11029ms 304.158191ms 311.179691ms 358.850368ms 406.269102ms 453.865874ms 503.875218ms 534.877018ms 576.333294ms 616.074136ms 645.910139ms 733.999818ms 735.244543ms 736.966301ms 737.654388ms 740.56096ms 740.71131ms 741.989991ms 742.289281ms 742.32147ms 742.363014ms 742.689681ms 742.697658ms 742.911402ms 743.452964ms 743.858126ms 744.06508ms 744.230654ms 745.192046ms 745.210204ms 745.693535ms 745.792281ms 745.881814ms 745.934168ms 745.977053ms 746.154535ms 746.259915ms 746.326686ms 746.378974ms 746.390193ms 746.843015ms 746.84312ms 746.980193ms 747.092971ms 747.165625ms 747.251254ms 747.474445ms 747.532132ms 747.70399ms 747.832975ms 747.843946ms 747.89119ms 748.047586ms 748.211451ms 748.241555ms 748.243417ms 748.352676ms 748.406014ms 748.583655ms 748.602956ms 748.613801ms 748.643359ms 748.662749ms 748.763777ms 748.861596ms 749.015661ms 749.0264ms 749.03087ms 749.098295ms 749.102231ms 749.113958ms 749.255218ms 749.267861ms 749.320793ms 749.407457ms 749.471863ms 749.511304ms 749.516637ms 749.52727ms 749.552512ms 749.552969ms 749.648079ms 749.76123ms 749.794845ms 749.814988ms 749.820189ms 749.884295ms 749.892797ms 749.967657ms 750.100633ms 750.150424ms 750.195115ms 750.407724ms 750.569623ms 750.652599ms 750.681577ms 750.802915ms 750.855311ms 750.912412ms 750.962454ms 750.999619ms 751.020627ms 751.057965ms 751.075631ms 751.129629ms 751.186707ms 751.190765ms 751.192758ms 751.26134ms 751.409348ms 751.453258ms 751.505263ms 751.506122ms 751.699751ms 751.842962ms 751.876326ms 751.904231ms 751.91463ms 752.077755ms 752.110692ms 752.195571ms 752.232521ms 752.237213ms 752.255416ms 752.271353ms 752.324436ms 752.35748ms 752.4999ms 752.557796ms 752.934027ms 752.936487ms 753.211855ms 753.216759ms 753.298539ms 753.409719ms 753.576991ms 753.723492ms 753.856074ms 754.07057ms 754.413951ms 754.497062ms 754.622126ms 754.664631ms 754.687251ms 754.775629ms 755.00963ms 755.3116ms 755.563904ms 756.310881ms 756.480042ms 756.497889ms 756.916449ms 757.67873ms 758.039122ms 758.286243ms 758.616954ms 759.985584ms 760.296996ms 761.572123ms 762.015282ms 764.610167ms]
  May  5 17:52:38.753: INFO: 50 %ile: 748.643359ms
  May  5 17:52:38.753: INFO: 90 %ile: 754.622126ms
  May  5 17:52:38.753: INFO: 99 %ile: 762.015282ms
  May  5 17:52:38.753: INFO: Total sample count: 200
  May  5 17:52:38.753: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-5754" for this suite. @ 05/05/24 17:52:38.761
• [10.805 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:88
  May  5 17:52:38.781: INFO: Running AfterSuite actions on node 1
  May  5 17:52:38.781: INFO: Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
k8s.io/kubernetes/test/e2e/e2e_test.go:161
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
k8s.io/kubernetes/test/e2e/framework/test_context.go:621
[ReportAfterSuite] PASSED [0.067 seconds]
------------------------------

Ran 388 of 7407 Specs in 6336.457 seconds
SUCCESS! -- 388 Passed | 0 Failed | 0 Pending | 7019 Skipped
PASS

Ginkgo ran 1 suite in 1h45m37.19191156s
Test Suite Passed
