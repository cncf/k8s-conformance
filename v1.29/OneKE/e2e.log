  I0513 15:21:54.883385      17 e2e.go:117] Starting e2e run "50111627-8bdf-4f1e-a872-7707fb8f813f" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1715613713 - will randomize all specs

Will run 388 of 7407 specs
------------------------------
[ReportBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e_test.go:157
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:77
  May 13 15:21:55.091: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 15:21:55.092: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
  May 13 15:21:55.133: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  May 13 15:21:55.137: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'rke2-canal' (0 seconds elapsed)
  May 13 15:21:55.137: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'rke2-multus' (0 seconds elapsed)
  May 13 15:21:55.137: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'rke2-multus-rke2-whereabouts' (0 seconds elapsed)
  May 13 15:21:55.137: INFO: e2e test version: v1.29.4
  May 13 15:21:55.138: INFO: kube-apiserver version: v1.29.4+rke2r1
  May 13 15:21:55.138: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 15:21:55.149: INFO: Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.058 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 05/13/24 15:21:55.376
  May 13 15:21:55.376: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename pods @ 05/13/24 15:21:55.377
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:21:55.39
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:21:55.391
  STEP: creating the pod @ 05/13/24 15:21:55.392
  STEP: submitting the pod to kubernetes @ 05/13/24 15:21:55.392
  STEP: verifying the pod is in kubernetes @ 05/13/24 15:21:57.413
  STEP: updating the pod @ 05/13/24 15:21:57.415
  May 13 15:21:57.924: INFO: Successfully updated pod "pod-update-b0d93413-f1fc-4dbc-b5f9-1aa89a581970"
  STEP: verifying the updated pod is in kubernetes @ 05/13/24 15:21:57.926
  May 13 15:21:57.927: INFO: Pod update OK
  May 13 15:21:57.927: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7443" for this suite. @ 05/13/24 15:21:57.93
• [2.559 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:86
  STEP: Creating a kubernetes client @ 05/13/24 15:21:57.936
  May 13 15:21:57.936: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/13/24 15:21:57.936
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:21:57.949
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:21:57.95
  May 13 15:21:57.951: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 15:22:03.762: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-4604" for this suite. @ 05/13/24 15:22:03.765
• [5.835 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:70
  STEP: Creating a kubernetes client @ 05/13/24 15:22:03.772
  May 13 15:22:03.772: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename downward-api @ 05/13/24 15:22:03.774
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:22:03.783
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:22:03.786
  STEP: Creating a pod to test downward API volume plugin @ 05/13/24 15:22:03.788
  STEP: Saw pod success @ 05/13/24 15:22:09.816
  May 13 15:22:09.817: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod downwardapi-volume-1a64482a-8674-4ada-8435-5941307f8bb3 container client-container: <nil>
  STEP: delete the pod @ 05/13/24 15:22:09.844
  May 13 15:22:09.853: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2240" for this suite. @ 05/13/24 15:22:09.856
• [6.087 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1373
  STEP: Creating a kubernetes client @ 05/13/24 15:22:09.859
  May 13 15:22:09.859: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubectl @ 05/13/24 15:22:09.86
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:22:09.87
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:22:09.872
  STEP: validating cluster-info @ 05/13/24 15:22:09.873
  May 13 15:22:09.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-9170 cluster-info'
  May 13 15:22:09.935: INFO: stderr: ""
  May 13 15:22:09.935: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  May 13 15:22:09.935: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9170" for this suite. @ 05/13/24 15:22:09.937
• [0.085 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:498
  STEP: Creating a kubernetes client @ 05/13/24 15:22:09.945
  May 13 15:22:09.945: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename webhook @ 05/13/24 15:22:09.945
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:22:09.957
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:22:09.959
  STEP: Setting up server cert @ 05/13/24 15:22:09.974
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/13/24 15:22:10.292
  STEP: Deploying the webhook pod @ 05/13/24 15:22:10.295
  STEP: Wait for the deployment to be ready @ 05/13/24 15:22:10.306
  May 13 15:22:10.309: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 05/13/24 15:22:12.332
  STEP: Verifying the service has paired with the endpoint @ 05/13/24 15:22:12.343
  May 13 15:22:13.344: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 05/13/24 15:22:13.346
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 05/13/24 15:22:13.36
  STEP: Creating a configMap that should not be mutated @ 05/13/24 15:22:13.363
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 05/13/24 15:22:13.368
  STEP: Creating a configMap that should be mutated @ 05/13/24 15:22:13.372
  May 13 15:22:13.418: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7987" for this suite. @ 05/13/24 15:22:13.423
  STEP: Destroying namespace "webhook-markers-1814" for this suite. @ 05/13/24 15:22:13.429
• [3.488 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 05/13/24 15:22:13.433
  May 13 15:22:13.433: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename daemonsets @ 05/13/24 15:22:13.435
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:22:13.444
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:22:13.445
  May 13 15:22:13.459: INFO: Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 05/13/24 15:22:13.461
  May 13 15:22:13.463: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 15:22:13.463: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 05/13/24 15:22:13.463
  May 13 15:22:13.480: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 15:22:13.480: INFO: Node oneke-ip-172-16-100-7 is running 0 daemon pod, expected 1
  May 13 15:22:14.484: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 15:22:14.485: INFO: Node oneke-ip-172-16-100-7 is running 0 daemon pod, expected 1
  May 13 15:22:15.480: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 15:22:15.480: INFO: Node oneke-ip-172-16-100-7 is running 0 daemon pod, expected 1
  May 13 15:22:16.480: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 15:22:16.480: INFO: Node oneke-ip-172-16-100-7 is running 0 daemon pod, expected 1
  May 13 15:22:17.480: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May 13 15:22:17.480: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 05/13/24 15:22:17.487
  May 13 15:22:17.504: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May 13 15:22:17.504: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  May 13 15:22:18.503: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 15:22:18.503: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 05/13/24 15:22:18.503
  May 13 15:22:18.515: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 15:22:18.516: INFO: Node oneke-ip-172-16-100-7 is running 0 daemon pod, expected 1
  May 13 15:22:19.512: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 15:22:19.512: INFO: Node oneke-ip-172-16-100-7 is running 0 daemon pod, expected 1
  May 13 15:22:20.522: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 15:22:20.523: INFO: Node oneke-ip-172-16-100-7 is running 0 daemon pod, expected 1
  May 13 15:22:21.518: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May 13 15:22:21.518: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 05/13/24 15:22:21.525
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4150, will wait for the garbage collector to delete the pods @ 05/13/24 15:22:21.526
  May 13 15:22:21.584: INFO: Deleting DaemonSet.extensions daemon-set took: 7.001989ms
  May 13 15:22:21.687: INFO: Terminating DaemonSet.extensions daemon-set pods took: 103.284827ms
  May 13 15:22:23.790: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 15:22:23.790: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  May 13 15:22:23.792: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"8102"},"items":null}

  May 13 15:22:23.793: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"8102"},"items":null}

  May 13 15:22:23.808: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4150" for this suite. @ 05/13/24 15:22:23.81
• [10.382 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 05/13/24 15:22:23.816
  May 13 15:22:23.816: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename containers @ 05/13/24 15:22:23.817
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:22:23.829
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:22:23.831
  STEP: Creating a pod to test override arguments @ 05/13/24 15:22:23.832
  STEP: Saw pod success @ 05/13/24 15:22:29.857
  May 13 15:22:29.861: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod client-containers-7819d26b-e942-4990-8d9e-eaf4508b76e1 container agnhost-container: <nil>
  STEP: delete the pod @ 05/13/24 15:22:29.902
  May 13 15:22:29.912: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-134" for this suite. @ 05/13/24 15:22:29.914
• [6.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:58
  STEP: Creating a kubernetes client @ 05/13/24 15:22:29.92
  May 13 15:22:29.920: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 15:22:29.921
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:22:29.932
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:22:29.934
  STEP: Creating configMap with name projected-configmap-test-volume-2a85319a-3d09-47b7-b15d-2eb2e551f0e3 @ 05/13/24 15:22:29.936
  STEP: Creating a pod to test consume configMaps @ 05/13/24 15:22:29.938
  STEP: Saw pod success @ 05/13/24 15:22:33.955
  May 13 15:22:33.960: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-projected-configmaps-cb09c4aa-0375-4408-a910-5f5cdea32907 container agnhost-container: <nil>
  STEP: delete the pod @ 05/13/24 15:22:33.975
  May 13 15:22:33.992: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1270" for this suite. @ 05/13/24 15:22:33.996
• [4.081 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:530
  STEP: Creating a kubernetes client @ 05/13/24 15:22:34.006
  May 13 15:22:34.006: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename security-context-test @ 05/13/24 15:22:34.007
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:22:34.018
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:22:34.02
  May 13 15:22:38.041: INFO: Got logs for pod "busybox-privileged-false-401d7cd1-366e-458d-aae7-bec203fcdbb6": "ip: RTNETLINK answers: Operation not permitted\n"
  May 13 15:22:38.041: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-3423" for this suite. @ 05/13/24 15:22:38.043
• [4.039 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:446
  STEP: Creating a kubernetes client @ 05/13/24 15:22:38.046
  May 13 15:22:38.046: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename sched-pred @ 05/13/24 15:22:38.047
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:22:38.057
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:22:38.059
  May 13 15:22:38.060: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  May 13 15:22:38.064: INFO: Waiting for terminating namespaces to be deleted...
  May 13 15:22:38.065: INFO: 
  Logging pods the apiserver thinks is on node oneke-ip-172-16-100-5 before test
  May 13 15:22:38.074: INFO: helm-install-one-longhorn-wvqgt from kube-system started at 2024-05-13 15:02:03 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.074: INFO: 	Container helm ready: false, restart count 0
  May 13 15:22:38.074: INFO: helm-install-one-metallb-l5s2p from kube-system started at 2024-05-13 15:02:03 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.074: INFO: 	Container helm ready: false, restart count 0
  May 13 15:22:38.074: INFO: helm-install-one-traefik-m29wc from kube-system started at 2024-05-13 15:02:03 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.074: INFO: 	Container helm ready: false, restart count 0
  May 13 15:22:38.074: INFO: helm-install-rke2-metrics-server-gvmzm from kube-system started at 2024-05-13 15:02:03 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.074: INFO: 	Container helm ready: false, restart count 0
  May 13 15:22:38.074: INFO: helm-install-rke2-snapshot-controller-5m7fr from kube-system started at 2024-05-13 15:02:03 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.074: INFO: 	Container helm ready: false, restart count 1
  May 13 15:22:38.074: INFO: helm-install-rke2-snapshot-controller-crd-j6zcf from kube-system started at 2024-05-13 15:02:03 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.074: INFO: 	Container helm ready: false, restart count 0
  May 13 15:22:38.075: INFO: helm-install-rke2-snapshot-validation-webhook-gpm58 from kube-system started at 2024-05-13 15:02:03 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.075: INFO: 	Container helm ready: false, restart count 0
  May 13 15:22:38.075: INFO: kube-proxy-oneke-ip-172-16-100-5 from kube-system started at 2024-05-13 15:01:47 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.075: INFO: 	Container kube-proxy ready: true, restart count 0
  May 13 15:22:38.075: INFO: rke2-canal-clmwk from kube-system started at 2024-05-13 15:01:49 +0000 UTC (2 container statuses recorded)
  May 13 15:22:38.075: INFO: 	Container calico-node ready: true, restart count 0
  May 13 15:22:38.075: INFO: 	Container kube-flannel ready: true, restart count 0
  May 13 15:22:38.075: INFO: rke2-coredns-rke2-coredns-5b7d84d764-ns6g6 from kube-system started at 2024-05-13 15:02:03 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.075: INFO: 	Container coredns ready: true, restart count 0
  May 13 15:22:38.075: INFO: rke2-coredns-rke2-coredns-autoscaler-b49765765-kp5j2 from kube-system started at 2024-05-13 15:02:03 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.075: INFO: 	Container autoscaler ready: true, restart count 0
  May 13 15:22:38.075: INFO: rke2-metrics-server-655477f655-4n2vw from kube-system started at 2024-05-13 15:02:26 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.075: INFO: 	Container metrics-server ready: true, restart count 0
  May 13 15:22:38.075: INFO: rke2-multus-lqh56 from kube-system started at 2024-05-13 15:01:48 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.075: INFO: 	Container kube-rke2-multus ready: true, restart count 0
  May 13 15:22:38.075: INFO: rke2-multus-rke2-whereabouts-lchrb from kube-system started at 2024-05-13 15:01:48 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.075: INFO: 	Container rke2-whereabouts ready: true, restart count 1
  May 13 15:22:38.075: INFO: rke2-snapshot-controller-59cc9cd8f4-8k87q from kube-system started at 2024-05-13 15:02:29 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.075: INFO: 	Container rke2-snapshot-controller ready: true, restart count 0
  May 13 15:22:38.076: INFO: rke2-snapshot-validation-webhook-54c5989b65-x2drx from kube-system started at 2024-05-13 15:02:27 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.076: INFO: 	Container rke2-snapshot-validation-webhook ready: true, restart count 0
  May 13 15:22:38.076: INFO: csi-attacher-5468df46f9-v6jz6 from longhorn-system started at 2024-05-13 15:07:42 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.076: INFO: 	Container csi-attacher ready: true, restart count 0
  May 13 15:22:38.076: INFO: csi-provisioner-76d7d4cb9-9mxhl from longhorn-system started at 2024-05-13 15:07:42 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.076: INFO: 	Container csi-provisioner ready: true, restart count 0
  May 13 15:22:38.076: INFO: csi-resizer-7b5d5bd7cd-lpbch from longhorn-system started at 2024-05-13 15:07:42 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.076: INFO: 	Container csi-resizer ready: true, restart count 0
  May 13 15:22:38.076: INFO: csi-snapshotter-6d8678cd76-psd2q from longhorn-system started at 2024-05-13 15:07:43 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.076: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May 13 15:22:38.076: INFO: engine-image-ei-5cefaf2b-zmmnk from longhorn-system started at 2024-05-13 15:02:59 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.076: INFO: 	Container engine-image-ei-5cefaf2b ready: true, restart count 0
  May 13 15:22:38.076: INFO: instance-manager-55ef780465ba1d7a0e8ce28cb186ca26 from longhorn-system started at 2024-05-13 15:02:59 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.076: INFO: 	Container instance-manager ready: true, restart count 0
  May 13 15:22:38.076: INFO: longhorn-csi-plugin-sff29 from longhorn-system started at 2024-05-13 15:07:43 +0000 UTC (3 container statuses recorded)
  May 13 15:22:38.076: INFO: 	Container longhorn-csi-plugin ready: true, restart count 0
  May 13 15:22:38.076: INFO: 	Container longhorn-liveness-probe ready: true, restart count 0
  May 13 15:22:38.076: INFO: 	Container node-driver-registrar ready: true, restart count 0
  May 13 15:22:38.076: INFO: longhorn-manager-m4r7g from longhorn-system started at 2024-05-13 15:02:29 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.077: INFO: 	Container longhorn-manager ready: true, restart count 0
  May 13 15:22:38.077: INFO: one-metallb-controller-5dbfcc4788-rblgs from metallb-system started at 2024-05-13 15:02:28 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.077: INFO: 	Container controller ready: true, restart count 0
  May 13 15:22:38.077: INFO: one-metallb-speaker-dj68w from metallb-system started at 2024-05-13 15:02:28 +0000 UTC (4 container statuses recorded)
  May 13 15:22:38.077: INFO: 	Container frr ready: true, restart count 0
  May 13 15:22:38.077: INFO: 	Container frr-metrics ready: true, restart count 0
  May 13 15:22:38.077: INFO: 	Container reloader ready: true, restart count 0
  May 13 15:22:38.077: INFO: 	Container speaker ready: true, restart count 0
  May 13 15:22:38.077: INFO: busybox-privileged-false-401d7cd1-366e-458d-aae7-bec203fcdbb6 from security-context-test-3423 started at 2024-05-13 15:22:34 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.077: INFO: 	Container busybox-privileged-false-401d7cd1-366e-458d-aae7-bec203fcdbb6 ready: false, restart count 0
  May 13 15:22:38.077: INFO: sonobuoy from sonobuoy started at 2024-05-13 15:21:42 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.077: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  May 13 15:22:38.077: INFO: sonobuoy-systemd-logs-daemon-set-6a4de22bea6049d2-97q5l from sonobuoy started at 2024-05-13 15:21:45 +0000 UTC (2 container statuses recorded)
  May 13 15:22:38.077: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 13 15:22:38.077: INFO: 	Container systemd-logs ready: true, restart count 0
  May 13 15:22:38.077: INFO: one-traefik-795c67dd65-mrqfk from traefik-system started at 2024-05-13 15:02:27 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.077: INFO: 	Container one-traefik ready: true, restart count 0
  May 13 15:22:38.077: INFO: 
  Logging pods the apiserver thinks is on node oneke-ip-172-16-100-7 before test
  May 13 15:22:38.085: INFO: kube-proxy-oneke-ip-172-16-100-7 from kube-system started at 2024-05-13 15:11:56 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.085: INFO: 	Container kube-proxy ready: true, restart count 0
  May 13 15:22:38.085: INFO: rke2-canal-2xv8f from kube-system started at 2024-05-13 15:11:57 +0000 UTC (2 container statuses recorded)
  May 13 15:22:38.085: INFO: 	Container calico-node ready: true, restart count 0
  May 13 15:22:38.085: INFO: 	Container kube-flannel ready: true, restart count 0
  May 13 15:22:38.085: INFO: rke2-multus-rke2-whereabouts-q2xbr from kube-system started at 2024-05-13 15:11:57 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.085: INFO: 	Container rke2-whereabouts ready: true, restart count 1
  May 13 15:22:38.085: INFO: rke2-multus-txzvb from kube-system started at 2024-05-13 15:11:57 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.085: INFO: 	Container kube-rke2-multus ready: true, restart count 2
  May 13 15:22:38.085: INFO: engine-image-ei-5cefaf2b-9j4sf from longhorn-system started at 2024-05-13 15:12:12 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.085: INFO: 	Container engine-image-ei-5cefaf2b ready: true, restart count 0
  May 13 15:22:38.085: INFO: instance-manager-1185f042d485c71dda675ea2338775ca from longhorn-system started at 2024-05-13 15:12:37 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.085: INFO: 	Container instance-manager ready: true, restart count 0
  May 13 15:22:38.085: INFO: longhorn-csi-plugin-wmfzz from longhorn-system started at 2024-05-13 15:12:12 +0000 UTC (3 container statuses recorded)
  May 13 15:22:38.085: INFO: 	Container longhorn-csi-plugin ready: true, restart count 0
  May 13 15:22:38.085: INFO: 	Container longhorn-liveness-probe ready: true, restart count 0
  May 13 15:22:38.085: INFO: 	Container node-driver-registrar ready: true, restart count 0
  May 13 15:22:38.085: INFO: longhorn-manager-42nnc from longhorn-system started at 2024-05-13 15:12:12 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.086: INFO: 	Container longhorn-manager ready: true, restart count 0
  May 13 15:22:38.086: INFO: one-metallb-speaker-mt7mb from metallb-system started at 2024-05-13 15:12:12 +0000 UTC (4 container statuses recorded)
  May 13 15:22:38.086: INFO: 	Container frr ready: true, restart count 0
  May 13 15:22:38.086: INFO: 	Container frr-metrics ready: true, restart count 0
  May 13 15:22:38.086: INFO: 	Container reloader ready: true, restart count 0
  May 13 15:22:38.086: INFO: 	Container speaker ready: true, restart count 0
  May 13 15:22:38.086: INFO: sonobuoy-systemd-logs-daemon-set-6a4de22bea6049d2-dx4h8 from sonobuoy started at 2024-05-13 15:21:45 +0000 UTC (2 container statuses recorded)
  May 13 15:22:38.086: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 13 15:22:38.086: INFO: 	Container systemd-logs ready: true, restart count 0
  May 13 15:22:38.086: INFO: one-traefik-795c67dd65-k9k5j from traefik-system started at 2024-05-13 15:12:14 +0000 UTC (1 container statuses recorded)
  May 13 15:22:38.086: INFO: 	Container one-traefik ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 05/13/24 15:22:38.086
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.17cf159f900b1fc8], Reason = [FailedScheduling], Message = [0/4 nodes are available: 1 node(s) had untolerated taint {CriticalAddonsOnly: true}, 1 node(s) had untolerated taint {node.longhorn.io/create-default-disk: true}, 2 node(s) didn't match Pod's node affinity/selector. preemption: 0/4 nodes are available: 4 Preemption is not helpful for scheduling.] @ 05/13/24 15:22:38.117
  May 13 15:22:39.120: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-9112" for this suite. @ 05/13/24 15:22:39.126
• [1.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:785
  STEP: Creating a kubernetes client @ 05/13/24 15:22:39.135
  May 13 15:22:39.135: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename services @ 05/13/24 15:22:39.138
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:22:39.149
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:22:39.155
  STEP: creating service endpoint-test2 in namespace services-5139 @ 05/13/24 15:22:39.16
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5139 to expose endpoints map[] @ 05/13/24 15:22:39.171
  May 13 15:22:39.183: INFO: successfully validated that service endpoint-test2 in namespace services-5139 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-5139 @ 05/13/24 15:22:39.183
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5139 to expose endpoints map[pod1:[80]] @ 05/13/24 15:22:41.227
  May 13 15:22:41.245: INFO: successfully validated that service endpoint-test2 in namespace services-5139 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 05/13/24 15:22:41.245
  May 13 15:22:41.245: INFO: Creating new exec pod
  May 13 15:22:44.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-5139 exec execpodf6f2c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  May 13 15:22:44.446: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  May 13 15:22:44.446: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 13 15:22:44.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-5139 exec execpodf6f2c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.189.87 80'
  May 13 15:22:44.622: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.189.87 80\nConnection to 10.43.189.87 80 port [tcp/http] succeeded!\n"
  May 13 15:22:44.622: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-5139 @ 05/13/24 15:22:44.622
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5139 to expose endpoints map[pod1:[80] pod2:[80]] @ 05/13/24 15:22:46.643
  May 13 15:22:46.659: INFO: successfully validated that service endpoint-test2 in namespace services-5139 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 05/13/24 15:22:46.659
  May 13 15:22:47.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-5139 exec execpodf6f2c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  May 13 15:22:47.790: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  May 13 15:22:47.790: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 13 15:22:47.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-5139 exec execpodf6f2c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.189.87 80'
  May 13 15:22:47.892: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.189.87 80\nConnection to 10.43.189.87 80 port [tcp/http] succeeded!\n"
  May 13 15:22:47.892: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-5139 @ 05/13/24 15:22:47.892
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5139 to expose endpoints map[pod2:[80]] @ 05/13/24 15:22:47.905
  May 13 15:22:47.926: INFO: successfully validated that service endpoint-test2 in namespace services-5139 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 05/13/24 15:22:47.926
  May 13 15:22:48.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-5139 exec execpodf6f2c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  May 13 15:22:49.029: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  May 13 15:22:49.029: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 13 15:22:49.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-5139 exec execpodf6f2c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.189.87 80'
  May 13 15:22:49.123: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.189.87 80\nConnection to 10.43.189.87 80 port [tcp/http] succeeded!\n"
  May 13 15:22:49.123: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-5139 @ 05/13/24 15:22:49.123
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5139 to expose endpoints map[] @ 05/13/24 15:22:49.142
  May 13 15:22:49.152: INFO: successfully validated that service endpoint-test2 in namespace services-5139 exposes endpoints map[]
  May 13 15:22:49.198: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5139" for this suite. @ 05/13/24 15:22:49.215
• [10.104 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:425
  STEP: Creating a kubernetes client @ 05/13/24 15:22:49.24
  May 13 15:22:49.240: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename replication-controller @ 05/13/24 15:22:49.241
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:22:49.257
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:22:49.261
  STEP: Creating ReplicationController "e2e-rc-nqkc9" @ 05/13/24 15:22:49.264
  May 13 15:22:49.269: INFO: Get Replication Controller "e2e-rc-nqkc9" to confirm replicas
  May 13 15:22:50.270: INFO: Get Replication Controller "e2e-rc-nqkc9" to confirm replicas
  May 13 15:22:50.272: INFO: Found 1 replicas for "e2e-rc-nqkc9" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-nqkc9" @ 05/13/24 15:22:50.272
  STEP: Updating a scale subresource @ 05/13/24 15:22:50.274
  STEP: Verifying replicas where modified for replication controller "e2e-rc-nqkc9" @ 05/13/24 15:22:50.28
  May 13 15:22:50.280: INFO: Get Replication Controller "e2e-rc-nqkc9" to confirm replicas
  May 13 15:22:51.280: INFO: Get Replication Controller "e2e-rc-nqkc9" to confirm replicas
  May 13 15:22:51.281: INFO: Found 2 replicas for "e2e-rc-nqkc9" replication controller
  May 13 15:22:51.281: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-2161" for this suite. @ 05/13/24 15:22:51.283
• [2.048 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:289
  STEP: Creating a kubernetes client @ 05/13/24 15:22:51.289
  May 13 15:22:51.289: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename field-validation @ 05/13/24 15:22:51.29
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:22:51.3
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:22:51.301
  May 13 15:22:51.303: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 15:22:54.379: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6641" for this suite. @ 05/13/24 15:22:54.383
• [3.099 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:641
  STEP: Creating a kubernetes client @ 05/13/24 15:22:54.389
  May 13 15:22:54.389: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename statefulset @ 05/13/24 15:22:54.39
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:22:54.405
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:22:54.407
  STEP: Creating service test in namespace statefulset-1628 @ 05/13/24 15:22:54.41
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 05/13/24 15:22:54.416
  STEP: Creating stateful set ss in namespace statefulset-1628 @ 05/13/24 15:22:54.424
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1628 @ 05/13/24 15:22:54.434
  May 13 15:22:54.436: INFO: Found 0 stateful pods, waiting for 1
  May 13 15:23:04.438: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 05/13/24 15:23:04.438
  May 13 15:23:04.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=statefulset-1628 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May 13 15:23:04.617: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May 13 15:23:04.617: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May 13 15:23:04.617: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May 13 15:23:04.619: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  May 13 15:23:14.619: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  May 13 15:23:14.619: INFO: Waiting for statefulset status.readyReplicas updated to 0
  May 13 15:23:14.627: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999782s
  May 13 15:23:15.630: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995892103s
  May 13 15:23:16.633: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.993658256s
  May 13 15:23:17.643: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.990656306s
  May 13 15:23:18.652: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.980667677s
  May 13 15:23:19.656: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.970867004s
  May 13 15:23:20.659: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.967805897s
  May 13 15:23:21.668: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.96387429s
  May 13 15:23:22.670: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.956297808s
  May 13 15:23:23.677: INFO: Verifying statefulset ss doesn't scale past 1 for another 953.841956ms
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1628 @ 05/13/24 15:23:24.677
  May 13 15:23:24.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=statefulset-1628 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May 13 15:23:24.802: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May 13 15:23:24.802: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May 13 15:23:24.802: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May 13 15:23:24.814: INFO: Found 1 stateful pods, waiting for 3
  May 13 15:23:34.826: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  May 13 15:23:34.827: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  May 13 15:23:34.827: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 05/13/24 15:23:34.827
  STEP: Scale down will halt with unhealthy stateful pod @ 05/13/24 15:23:34.827
  May 13 15:23:34.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=statefulset-1628 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May 13 15:23:34.955: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May 13 15:23:34.955: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May 13 15:23:34.955: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May 13 15:23:34.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=statefulset-1628 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May 13 15:23:35.125: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May 13 15:23:35.125: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May 13 15:23:35.125: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May 13 15:23:35.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=statefulset-1628 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May 13 15:23:35.242: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May 13 15:23:35.242: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May 13 15:23:35.242: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May 13 15:23:35.242: INFO: Waiting for statefulset status.readyReplicas updated to 0
  May 13 15:23:35.243: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 2
  May 13 15:23:45.246: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  May 13 15:23:45.246: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  May 13 15:23:45.246: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  May 13 15:23:45.254: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999741s
  May 13 15:23:46.263: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995817792s
  May 13 15:23:47.269: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98523129s
  May 13 15:23:48.271: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.980535962s
  May 13 15:23:49.276: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.978716982s
  May 13 15:23:50.278: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.973791404s
  May 13 15:23:51.292: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.970370821s
  May 13 15:23:52.296: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.957564241s
  May 13 15:23:53.299: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.953380013s
  May 13 15:23:54.303: INFO: Verifying statefulset ss doesn't scale past 3 for another 950.505416ms
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1628 @ 05/13/24 15:23:55.304
  May 13 15:23:55.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=statefulset-1628 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May 13 15:23:55.410: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May 13 15:23:55.410: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May 13 15:23:55.410: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May 13 15:23:55.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=statefulset-1628 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May 13 15:23:55.501: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May 13 15:23:55.501: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May 13 15:23:55.501: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May 13 15:23:55.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=statefulset-1628 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May 13 15:23:55.605: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May 13 15:23:55.605: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May 13 15:23:55.605: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May 13 15:23:55.605: INFO: Scaling statefulset ss to 0
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 05/13/24 15:24:05.611
  May 13 15:24:05.612: INFO: Deleting all statefulset in ns statefulset-1628
  May 13 15:24:05.613: INFO: Scaling statefulset ss to 0
  May 13 15:24:05.617: INFO: Waiting for statefulset status.replicas updated to 0
  May 13 15:24:05.618: INFO: Deleting statefulset ss
  May 13 15:24:05.627: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1628" for this suite. @ 05/13/24 15:24:05.633
• [71.248 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:90
  STEP: Creating a kubernetes client @ 05/13/24 15:24:05.637
  May 13 15:24:05.637: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename emptydir @ 05/13/24 15:24:05.638
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:24:05.666
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:24:05.672
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 05/13/24 15:24:05.675
  STEP: Saw pod success @ 05/13/24 15:24:09.705
  May 13 15:24:09.706: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-4a9154d9-be16-465a-805b-950aebba99a5 container test-container: <nil>
  STEP: delete the pod @ 05/13/24 15:24:09.716
  May 13 15:24:09.726: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2461" for this suite. @ 05/13/24 15:24:09.728
• [4.094 seconds]
------------------------------
S
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2236
  STEP: Creating a kubernetes client @ 05/13/24 15:24:09.733
  May 13 15:24:09.733: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename services @ 05/13/24 15:24:09.734
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:24:09.742
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:24:09.744
  STEP: creating service in namespace services-6530 @ 05/13/24 15:24:09.747
  STEP: creating service affinity-nodeport-transition in namespace services-6530 @ 05/13/24 15:24:09.747
  STEP: creating replication controller affinity-nodeport-transition in namespace services-6530 @ 05/13/24 15:24:09.755
  I0513 15:24:09.770987      17 runners.go:197] Created replication controller with name: affinity-nodeport-transition, namespace: services-6530, replica count: 3
  I0513 15:24:12.826380      17 runners.go:197] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May 13 15:24:12.831: INFO: Creating new exec pod
  May 13 15:24:15.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-6530 exec execpod-affinityx8wjd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  May 13 15:24:15.947: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-transition 80\n+ echo hostName\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  May 13 15:24:15.947: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 13 15:24:15.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-6530 exec execpod-affinityx8wjd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.121.175 80'
  May 13 15:24:16.066: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.121.175 80\nConnection to 10.43.121.175 80 port [tcp/http] succeeded!\n"
  May 13 15:24:16.066: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 13 15:24:16.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-6530 exec execpod-affinityx8wjd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.16.100.5 32723'
  May 13 15:24:16.176: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.16.100.5 32723\nConnection to 172.16.100.5 32723 port [tcp/*] succeeded!\n"
  May 13 15:24:16.176: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 13 15:24:16.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-6530 exec execpod-affinityx8wjd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.16.100.7 32723'
  May 13 15:24:16.285: INFO: stderr: "+ nc -v -t -w 2 172.16.100.7 32723\n+ echo hostName\nConnection to 172.16.100.7 32723 port [tcp/*] succeeded!\n"
  May 13 15:24:16.285: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 13 15:24:16.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-6530 exec execpod-affinityx8wjd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.16.100.5:32723/ ; done'
  May 13 15:24:16.462: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n"
  May 13 15:24:16.462: INFO: stdout: "\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-7sqk2\naffinity-nodeport-transition-cn7v9\naffinity-nodeport-transition-cn7v9\naffinity-nodeport-transition-7sqk2\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-7sqk2\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-cn7v9\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-7sqk2\naffinity-nodeport-transition-cn7v9\naffinity-nodeport-transition-7sqk2\naffinity-nodeport-transition-7sqk2"
  May 13 15:24:16.462: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.462: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.462: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.462: INFO: Received response from host: affinity-nodeport-transition-7sqk2
  May 13 15:24:16.462: INFO: Received response from host: affinity-nodeport-transition-cn7v9
  May 13 15:24:16.462: INFO: Received response from host: affinity-nodeport-transition-cn7v9
  May 13 15:24:16.462: INFO: Received response from host: affinity-nodeport-transition-7sqk2
  May 13 15:24:16.462: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.462: INFO: Received response from host: affinity-nodeport-transition-7sqk2
  May 13 15:24:16.462: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.462: INFO: Received response from host: affinity-nodeport-transition-cn7v9
  May 13 15:24:16.462: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.462: INFO: Received response from host: affinity-nodeport-transition-7sqk2
  May 13 15:24:16.462: INFO: Received response from host: affinity-nodeport-transition-cn7v9
  May 13 15:24:16.462: INFO: Received response from host: affinity-nodeport-transition-7sqk2
  May 13 15:24:16.462: INFO: Received response from host: affinity-nodeport-transition-7sqk2
  May 13 15:24:16.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-6530 exec execpod-affinityx8wjd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.16.100.5:32723/ ; done'
  May 13 15:24:16.696: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:32723/\n"
  May 13 15:24:16.696: INFO: stdout: "\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-tvmg6\naffinity-nodeport-transition-tvmg6"
  May 13 15:24:16.696: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.696: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.696: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.696: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.696: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.696: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.696: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.696: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.696: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.696: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.696: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.696: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.696: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.696: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.696: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.696: INFO: Received response from host: affinity-nodeport-transition-tvmg6
  May 13 15:24:16.696: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-6530, will wait for the garbage collector to delete the pods @ 05/13/24 15:24:16.726
  May 13 15:24:16.782: INFO: Deleting ReplicationController affinity-nodeport-transition took: 3.744647ms
  May 13 15:24:16.883: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.479887ms
  May 13 15:24:20.197: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6530" for this suite. @ 05/13/24 15:24:20.2
• [10.471 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 05/13/24 15:24:20.203
  May 13 15:24:20.203: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename taint-multiple-pods @ 05/13/24 15:24:20.204
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:24:20.215
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:24:20.216
  May 13 15:24:20.218: INFO: Waiting up to 1m0s for all nodes to be ready
  May 13 15:25:20.218: INFO: Waiting for terminating namespaces to be deleted...
  May 13 15:25:20.221: INFO: Starting informer...
  STEP: Starting pods... @ 05/13/24 15:25:20.221
  May 13 15:25:20.433: INFO: Pod1 is running on oneke-ip-172-16-100-5. Tainting Node
  May 13 15:25:22.647: INFO: Pod2 is running on oneke-ip-172-16-100-5. Tainting Node
  STEP: Trying to apply a taint on the Node @ 05/13/24 15:25:22.647
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/13/24 15:25:22.665
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 05/13/24 15:25:22.724
  May 13 15:25:28.500: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
  May 13 15:25:48.555: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/13/24 15:25:48.571
  May 13 15:25:48.576: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-6340" for this suite. @ 05/13/24 15:25:48.622
• [88.432 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:191
  STEP: Creating a kubernetes client @ 05/13/24 15:25:48.636
  May 13 15:25:48.636: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename runtimeclass @ 05/13/24 15:25:48.637
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:25:48.656
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:25:48.662
  STEP: getting /apis @ 05/13/24 15:25:48.668
  STEP: getting /apis/node.k8s.io @ 05/13/24 15:25:48.676
  STEP: getting /apis/node.k8s.io/v1 @ 05/13/24 15:25:48.677
  STEP: creating @ 05/13/24 15:25:48.677
  STEP: watching @ 05/13/24 15:25:48.752
  May 13 15:25:48.752: INFO: starting watch
  STEP: getting @ 05/13/24 15:25:48.755
  STEP: listing @ 05/13/24 15:25:48.755
  STEP: patching @ 05/13/24 15:25:48.756
  STEP: updating @ 05/13/24 15:25:48.759
  May 13 15:25:48.762: INFO: waiting for watch events with expected annotations
  STEP: deleting @ 05/13/24 15:25:48.762
  STEP: deleting a collection @ 05/13/24 15:25:48.767
  May 13 15:25:48.773: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-6974" for this suite. @ 05/13/24 15:25:48.775
• [0.142 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:130
  STEP: Creating a kubernetes client @ 05/13/24 15:25:48.779
  May 13 15:25:48.779: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename emptydir @ 05/13/24 15:25:48.779
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:25:48.792
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:25:48.794
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 05/13/24 15:25:48.795
  STEP: Saw pod success @ 05/13/24 15:25:52.806
  May 13 15:25:52.807: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-42365871-3f64-4acc-9b09-7c7d1dcfa9c4 container test-container: <nil>
  STEP: delete the pod @ 05/13/24 15:25:52.818
  May 13 15:25:52.828: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6983" for this suite. @ 05/13/24 15:25:52.831
• [4.058 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1632
  STEP: Creating a kubernetes client @ 05/13/24 15:25:52.837
  May 13 15:25:52.837: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubectl @ 05/13/24 15:25:52.838
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:25:52.851
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:25:52.853
  STEP: creating the pod @ 05/13/24 15:25:52.855
  May 13 15:25:52.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3838 create -f -'
  May 13 15:25:52.982: INFO: stderr: ""
  May 13 15:25:52.982: INFO: stdout: "pod/pause created\n"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 05/13/24 15:25:54.987
  May 13 15:25:54.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3838 label pods pause testing-label=testing-label-value'
  May 13 15:25:55.063: INFO: stderr: ""
  May 13 15:25:55.063: INFO: stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 05/13/24 15:25:55.063
  May 13 15:25:55.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3838 get pod pause -L testing-label'
  May 13 15:25:55.112: INFO: stderr: ""
  May 13 15:25:55.112: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 05/13/24 15:25:55.112
  May 13 15:25:55.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3838 label pods pause testing-label-'
  May 13 15:25:55.170: INFO: stderr: ""
  May 13 15:25:55.170: INFO: stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 05/13/24 15:25:55.17
  May 13 15:25:55.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3838 get pod pause -L testing-label'
  May 13 15:25:55.219: INFO: stderr: ""
  May 13 15:25:55.219: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
  STEP: using delete to clean up resources @ 05/13/24 15:25:55.219
  May 13 15:25:55.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3838 delete --grace-period=0 --force -f -'
  May 13 15:25:55.274: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May 13 15:25:55.274: INFO: stdout: "pod \"pause\" force deleted\n"
  May 13 15:25:55.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3838 get rc,svc -l name=pause --no-headers'
  May 13 15:25:55.342: INFO: stderr: "No resources found in kubectl-3838 namespace.\n"
  May 13 15:25:55.342: INFO: stdout: ""
  May 13 15:25:55.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3838 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  May 13 15:25:55.388: INFO: stderr: ""
  May 13 15:25:55.388: INFO: stdout: ""
  May 13 15:25:55.388: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3838" for this suite. @ 05/13/24 15:25:55.39
• [2.557 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:357
  STEP: Creating a kubernetes client @ 05/13/24 15:25:55.395
  May 13 15:25:55.395: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubectl @ 05/13/24 15:25:55.396
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:25:55.406
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:25:55.407
  STEP: creating a replication controller @ 05/13/24 15:25:55.408
  May 13 15:25:55.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 create -f -'
  May 13 15:25:55.501: INFO: stderr: ""
  May 13 15:25:55.501: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/13/24 15:25:55.501
  May 13 15:25:55.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May 13 15:25:55.586: INFO: stderr: ""
  May 13 15:25:55.586: INFO: stdout: "update-demo-nautilus-hqqz7 update-demo-nautilus-n7nx6 "
  May 13 15:25:55.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 get pods update-demo-nautilus-hqqz7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 13 15:25:55.634: INFO: stderr: ""
  May 13 15:25:55.634: INFO: stdout: ""
  May 13 15:25:55.634: INFO: update-demo-nautilus-hqqz7 is created but not running
  May 13 15:26:00.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May 13 15:26:00.721: INFO: stderr: ""
  May 13 15:26:00.721: INFO: stdout: "update-demo-nautilus-hqqz7 update-demo-nautilus-n7nx6 "
  May 13 15:26:00.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 get pods update-demo-nautilus-hqqz7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 13 15:26:00.786: INFO: stderr: ""
  May 13 15:26:00.786: INFO: stdout: "true"
  May 13 15:26:00.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 get pods update-demo-nautilus-hqqz7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  May 13 15:26:00.851: INFO: stderr: ""
  May 13 15:26:00.851: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May 13 15:26:00.851: INFO: validating pod update-demo-nautilus-hqqz7
  May 13 15:26:00.855: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May 13 15:26:00.855: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May 13 15:26:00.855: INFO: update-demo-nautilus-hqqz7 is verified up and running
  May 13 15:26:00.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 get pods update-demo-nautilus-n7nx6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 13 15:26:00.930: INFO: stderr: ""
  May 13 15:26:00.930: INFO: stdout: "true"
  May 13 15:26:00.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 get pods update-demo-nautilus-n7nx6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  May 13 15:26:01.016: INFO: stderr: ""
  May 13 15:26:01.016: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May 13 15:26:01.016: INFO: validating pod update-demo-nautilus-n7nx6
  May 13 15:26:01.021: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May 13 15:26:01.021: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May 13 15:26:01.021: INFO: update-demo-nautilus-n7nx6 is verified up and running
  STEP: scaling down the replication controller @ 05/13/24 15:26:01.021
  May 13 15:26:01.024: INFO: scanned /root for discovery docs: <nil>
  May 13 15:26:01.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  May 13 15:26:02.115: INFO: stderr: ""
  May 13 15:26:02.115: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/13/24 15:26:02.115
  May 13 15:26:02.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May 13 15:26:02.170: INFO: stderr: ""
  May 13 15:26:02.170: INFO: stdout: "update-demo-nautilus-hqqz7 update-demo-nautilus-n7nx6 "
  STEP: Replicas for name=update-demo: expected=1 actual=2 @ 05/13/24 15:26:02.17
  May 13 15:26:07.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May 13 15:26:07.232: INFO: stderr: ""
  May 13 15:26:07.232: INFO: stdout: "update-demo-nautilus-n7nx6 "
  May 13 15:26:07.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 get pods update-demo-nautilus-n7nx6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 13 15:26:07.276: INFO: stderr: ""
  May 13 15:26:07.276: INFO: stdout: "true"
  May 13 15:26:07.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 get pods update-demo-nautilus-n7nx6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  May 13 15:26:07.327: INFO: stderr: ""
  May 13 15:26:07.327: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May 13 15:26:07.327: INFO: validating pod update-demo-nautilus-n7nx6
  May 13 15:26:07.329: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May 13 15:26:07.329: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May 13 15:26:07.329: INFO: update-demo-nautilus-n7nx6 is verified up and running
  STEP: scaling up the replication controller @ 05/13/24 15:26:07.329
  May 13 15:26:07.331: INFO: scanned /root for discovery docs: <nil>
  May 13 15:26:07.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  May 13 15:26:08.414: INFO: stderr: ""
  May 13 15:26:08.414: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/13/24 15:26:08.414
  May 13 15:26:08.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May 13 15:26:08.482: INFO: stderr: ""
  May 13 15:26:08.482: INFO: stdout: "update-demo-nautilus-gq5q9 update-demo-nautilus-n7nx6 "
  May 13 15:26:08.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 get pods update-demo-nautilus-gq5q9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 13 15:26:08.537: INFO: stderr: ""
  May 13 15:26:08.537: INFO: stdout: ""
  May 13 15:26:08.537: INFO: update-demo-nautilus-gq5q9 is created but not running
  May 13 15:26:13.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May 13 15:26:13.595: INFO: stderr: ""
  May 13 15:26:13.595: INFO: stdout: "update-demo-nautilus-gq5q9 update-demo-nautilus-n7nx6 "
  May 13 15:26:13.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 get pods update-demo-nautilus-gq5q9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 13 15:26:13.652: INFO: stderr: ""
  May 13 15:26:13.652: INFO: stdout: "true"
  May 13 15:26:13.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 get pods update-demo-nautilus-gq5q9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  May 13 15:26:13.711: INFO: stderr: ""
  May 13 15:26:13.711: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May 13 15:26:13.711: INFO: validating pod update-demo-nautilus-gq5q9
  May 13 15:26:13.715: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May 13 15:26:13.715: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May 13 15:26:13.715: INFO: update-demo-nautilus-gq5q9 is verified up and running
  May 13 15:26:13.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 get pods update-demo-nautilus-n7nx6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 13 15:26:13.773: INFO: stderr: ""
  May 13 15:26:13.773: INFO: stdout: "true"
  May 13 15:26:13.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 get pods update-demo-nautilus-n7nx6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  May 13 15:26:13.827: INFO: stderr: ""
  May 13 15:26:13.827: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May 13 15:26:13.827: INFO: validating pod update-demo-nautilus-n7nx6
  May 13 15:26:13.829: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May 13 15:26:13.829: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May 13 15:26:13.829: INFO: update-demo-nautilus-n7nx6 is verified up and running
  STEP: using delete to clean up resources @ 05/13/24 15:26:13.829
  May 13 15:26:13.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 delete --grace-period=0 --force -f -'
  May 13 15:26:13.889: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May 13 15:26:13.889: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  May 13 15:26:13.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 get rc,svc -l name=update-demo --no-headers'
  May 13 15:26:13.962: INFO: stderr: "No resources found in kubectl-5786 namespace.\n"
  May 13 15:26:13.962: INFO: stdout: ""
  May 13 15:26:13.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5786 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  May 13 15:26:14.019: INFO: stderr: ""
  May 13 15:26:14.019: INFO: stdout: ""
  May 13 15:26:14.019: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5786" for this suite. @ 05/13/24 15:26:14.022
• [18.631 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 05/13/24 15:26:14.027
  May 13 15:26:14.027: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename containers @ 05/13/24 15:26:14.028
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:26:14.037
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:26:14.038
  May 13 15:26:16.064: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-6980" for this suite. @ 05/13/24 15:26:16.077
• [2.064 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:397
  STEP: Creating a kubernetes client @ 05/13/24 15:26:16.091
  May 13 15:26:16.091: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename resourcequota @ 05/13/24 15:26:16.092
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:26:16.101
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:26:16.103
  STEP: Counting existing ResourceQuota @ 05/13/24 15:26:16.107
  STEP: Creating a ResourceQuota @ 05/13/24 15:26:21.116
  STEP: Ensuring resource quota status is calculated @ 05/13/24 15:26:21.129
  STEP: Creating a ReplicationController @ 05/13/24 15:26:23.143
  STEP: Ensuring resource quota status captures replication controller creation @ 05/13/24 15:26:23.158
  STEP: Deleting a ReplicationController @ 05/13/24 15:26:25.161
  STEP: Ensuring resource quota status released usage @ 05/13/24 15:26:25.163
  May 13 15:26:27.169: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2106" for this suite. @ 05/13/24 15:26:27.174
• [11.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:180
  STEP: Creating a kubernetes client @ 05/13/24 15:26:27.183
  May 13 15:26:27.183: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename emptydir @ 05/13/24 15:26:27.184
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:26:27.202
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:26:27.204
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 05/13/24 15:26:27.207
  STEP: Saw pod success @ 05/13/24 15:26:31.23
  May 13 15:26:31.231: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-e6b50a16-d2e7-4381-b388-595172aa17e9 container test-container: <nil>
  STEP: delete the pod @ 05/13/24 15:26:31.238
  May 13 15:26:31.246: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9383" for this suite. @ 05/13/24 15:26:31.248
• [4.069 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:113
  STEP: Creating a kubernetes client @ 05/13/24 15:26:31.253
  May 13 15:26:31.253: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename replication-controller @ 05/13/24 15:26:31.254
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:26:31.263
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:26:31.264
  STEP: creating a ReplicationController @ 05/13/24 15:26:31.267
  STEP: waiting for RC to be added @ 05/13/24 15:26:31.27
  STEP: waiting for available Replicas @ 05/13/24 15:26:31.27
  STEP: patching ReplicationController @ 05/13/24 15:26:33.828
  STEP: waiting for RC to be modified @ 05/13/24 15:26:33.833
  STEP: patching ReplicationController status @ 05/13/24 15:26:33.833
  STEP: waiting for RC to be modified @ 05/13/24 15:26:33.836
  STEP: waiting for available Replicas @ 05/13/24 15:26:33.836
  STEP: fetching ReplicationController status @ 05/13/24 15:26:33.84
  STEP: patching ReplicationController scale @ 05/13/24 15:26:33.841
  STEP: waiting for RC to be modified @ 05/13/24 15:26:33.844
  STEP: waiting for ReplicationController's scale to be the max amount @ 05/13/24 15:26:33.844
  STEP: fetching ReplicationController; ensuring that it's patched @ 05/13/24 15:26:35.796
  STEP: updating ReplicationController status @ 05/13/24 15:26:35.798
  STEP: waiting for RC to be modified @ 05/13/24 15:26:35.801
  STEP: listing all ReplicationControllers @ 05/13/24 15:26:35.802
  STEP: checking that ReplicationController has expected values @ 05/13/24 15:26:35.804
  STEP: deleting ReplicationControllers by collection @ 05/13/24 15:26:35.805
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 05/13/24 15:26:35.809
  May 13 15:26:35.837: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0513 15:26:35.840675      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-8165" for this suite. @ 05/13/24 15:26:35.841
• [4.590 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:875
  STEP: Creating a kubernetes client @ 05/13/24 15:26:35.843
  May 13 15:26:35.843: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename daemonsets @ 05/13/24 15:26:35.845
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:26:35.857
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:26:35.858
  STEP: Creating simple DaemonSet "daemon-set" @ 05/13/24 15:26:35.87
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/13/24 15:26:35.874
  May 13 15:26:35.877: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 15:26:35.877: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 15:26:35.881: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 15:26:35.881: INFO: Node oneke-ip-172-16-100-5 is running 0 daemon pod, expected 1
  E0513 15:26:36.840746      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:26:36.880: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 15:26:36.880: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 15:26:36.883: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May 13 15:26:36.883: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Getting /status @ 05/13/24 15:26:36.886
  May 13 15:26:36.889: INFO: Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 05/13/24 15:26:36.889
  May 13 15:26:36.897: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 05/13/24 15:26:36.897
  May 13 15:26:36.900: INFO: Observed &DaemonSet event: ADDED
  May 13 15:26:36.901: INFO: Observed &DaemonSet event: MODIFIED
  May 13 15:26:36.901: INFO: Observed &DaemonSet event: MODIFIED
  May 13 15:26:36.901: INFO: Observed &DaemonSet event: MODIFIED
  May 13 15:26:36.901: INFO: Observed &DaemonSet event: MODIFIED
  May 13 15:26:36.901: INFO: Found daemon set daemon-set in namespace daemonsets-1556 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  May 13 15:26:36.901: INFO: Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 05/13/24 15:26:36.901
  STEP: watching for the daemon set status to be patched @ 05/13/24 15:26:36.908
  May 13 15:26:36.910: INFO: Observed &DaemonSet event: ADDED
  May 13 15:26:36.910: INFO: Observed &DaemonSet event: MODIFIED
  May 13 15:26:36.910: INFO: Observed &DaemonSet event: MODIFIED
  May 13 15:26:36.911: INFO: Observed &DaemonSet event: MODIFIED
  May 13 15:26:36.911: INFO: Observed &DaemonSet event: MODIFIED
  May 13 15:26:36.911: INFO: Observed daemon set daemon-set in namespace daemonsets-1556 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  May 13 15:26:36.911: INFO: Observed &DaemonSet event: MODIFIED
  May 13 15:26:36.911: INFO: Found daemon set daemon-set in namespace daemonsets-1556 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  May 13 15:26:36.911: INFO: Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 05/13/24 15:26:36.912
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1556, will wait for the garbage collector to delete the pods @ 05/13/24 15:26:36.912
  May 13 15:26:36.975: INFO: Deleting DaemonSet.extensions daemon-set took: 10.664198ms
  May 13 15:26:37.077: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.805498ms
  E0513 15:26:37.841400      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:26:38.842375      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:26:39.842773      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:26:39.880: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 15:26:39.880: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  May 13 15:26:39.881: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"10974"},"items":null}

  May 13 15:26:39.882: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"10974"},"items":null}

  May 13 15:26:39.885: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1556" for this suite. @ 05/13/24 15:26:39.888
• [4.048 seconds]
------------------------------
S
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:572
  STEP: Creating a kubernetes client @ 05/13/24 15:26:39.892
  May 13 15:26:39.893: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename job @ 05/13/24 15:26:39.893
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:26:39.904
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:26:39.906
  STEP: Creating a job @ 05/13/24 15:26:39.907
  STEP: Ensuring job reaches completions @ 05/13/24 15:26:39.913
  E0513 15:26:40.843639      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:26:41.843718      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:26:42.844772      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:26:43.846000      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:26:44.845642      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:26:45.845515      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:26:46.845620      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:26:47.845870      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:26:48.846155      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:26:49.846841      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:26:49.920: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1012" for this suite. @ 05/13/24 15:26:49.93
• [10.044 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 05/13/24 15:26:49.939
  May 13 15:26:49.939: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename discovery @ 05/13/24 15:26:49.94
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:26:49.955
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:26:49.956
  STEP: Setting up server cert @ 05/13/24 15:26:49.958
  STEP: Requesting APIResourceList from "/api/v1" @ 05/13/24 15:26:50.388
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 05/13/24 15:26:50.39
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 05/13/24 15:26:50.39
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 05/13/24 15:26:50.391
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 05/13/24 15:26:50.391
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 05/13/24 15:26:50.392
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 05/13/24 15:26:50.392
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 05/13/24 15:26:50.392
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 05/13/24 15:26:50.393
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 05/13/24 15:26:50.393
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 05/13/24 15:26:50.394
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 05/13/24 15:26:50.394
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 05/13/24 15:26:50.395
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 05/13/24 15:26:50.395
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 05/13/24 15:26:50.396
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 05/13/24 15:26:50.396
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 05/13/24 15:26:50.397
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 05/13/24 15:26:50.397
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 05/13/24 15:26:50.398
  May 13 15:26:50.398: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-1919" for this suite. @ 05/13/24 15:26:50.4
• [0.464 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:100
  STEP: Creating a kubernetes client @ 05/13/24 15:26:50.404
  May 13 15:26:50.404: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename emptydir @ 05/13/24 15:26:50.404
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:26:50.414
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:26:50.415
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 05/13/24 15:26:50.417
  E0513 15:26:50.847626      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:26:51.848674      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:26:52.849373      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:26:53.849589      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:26:54.435
  May 13 15:26:54.438: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-215ee7ac-f822-414a-862e-6605c3d0cc97 container test-container: <nil>
  STEP: delete the pod @ 05/13/24 15:26:54.445
  May 13 15:26:54.457: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8075" for this suite. @ 05/13/24 15:26:54.482
• [4.107 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 05/13/24 15:26:54.523
  May 13 15:26:54.524: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename pods @ 05/13/24 15:26:54.527
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:26:54.552
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:26:54.558
  STEP: creating the pod @ 05/13/24 15:26:54.56
  STEP: setting up watch @ 05/13/24 15:26:54.56
  STEP: submitting the pod to kubernetes @ 05/13/24 15:26:54.662
  STEP: verifying the pod is in kubernetes @ 05/13/24 15:26:54.666
  STEP: verifying pod creation was observed @ 05/13/24 15:26:54.669
  E0513 15:26:54.850391      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:26:55.850191      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 05/13/24 15:26:56.681
  STEP: verifying pod deletion was observed @ 05/13/24 15:26:56.704
  E0513 15:26:56.850867      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:26:57.851726      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:26:58.852188      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:26:58.976: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6320" for this suite. @ 05/13/24 15:26:58.978
• [4.459 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:110
  STEP: Creating a kubernetes client @ 05/13/24 15:26:58.983
  May 13 15:26:58.983: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename emptydir @ 05/13/24 15:26:58.984
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:26:58.994
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:26:58.995
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 05/13/24 15:26:58.997
  E0513 15:26:59.852883      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:00.853978      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:01.854410      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:02.855122      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:03.855136      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:04.855482      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:27:05.018
  May 13 15:27:05.020: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-f0173399-b1e6-4b6b-8cba-a83eee3d6da0 container test-container: <nil>
  STEP: delete the pod @ 05/13/24 15:27:05.025
  May 13 15:27:05.037: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6502" for this suite. @ 05/13/24 15:27:05.041
• [6.061 seconds]
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:505
  STEP: Creating a kubernetes client @ 05/13/24 15:27:05.045
  May 13 15:27:05.045: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename configmap @ 05/13/24 15:27:05.046
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:27:05.057
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:27:05.059
  May 13 15:27:05.075: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9407" for this suite. @ 05/13/24 15:27:05.077
• [0.035 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:442
  STEP: Creating a kubernetes client @ 05/13/24 15:27:05.085
  May 13 15:27:05.085: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/13/24 15:27:05.086
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:27:05.097
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:27:05.098
  STEP: set up a multi version CRD @ 05/13/24 15:27:05.099
  May 13 15:27:05.100: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 15:27:05.856299      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:06.857458      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:07.862559      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mark a version not serverd @ 05/13/24 15:27:08.638
  STEP: check the unserved version gets removed @ 05/13/24 15:27:08.648
  E0513 15:27:08.863059      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 05/13/24 15:27:09.593
  E0513 15:27:09.864219      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:10.864803      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:11.866287      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:27:12.347: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2475" for this suite. @ 05/13/24 15:27:12.35
• [7.269 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 05/13/24 15:27:12.355
  May 13 15:27:12.355: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename deployment @ 05/13/24 15:27:12.356
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:27:12.365
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:27:12.367
  May 13 15:27:12.370: INFO: Creating deployment "webserver-deployment"
  May 13 15:27:12.372: INFO: Waiting for observed generation 1
  E0513 15:27:12.867785      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:13.867966      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:27:14.380: INFO: Waiting for all required pods to come up
  May 13 15:27:14.393: INFO: Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 05/13/24 15:27:14.393
  May 13 15:27:14.394: INFO: Waiting for deployment "webserver-deployment" to complete
  May 13 15:27:14.402: INFO: Updating deployment "webserver-deployment" with a non-existent image
  May 13 15:27:14.406: INFO: Updating deployment webserver-deployment
  May 13 15:27:14.407: INFO: Waiting for observed generation 2
  E0513 15:27:14.868520      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:15.868677      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:27:16.411: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  May 13 15:27:16.412: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
  May 13 15:27:16.414: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  May 13 15:27:16.417: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  May 13 15:27:16.417: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
  May 13 15:27:16.418: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  May 13 15:27:16.420: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  May 13 15:27:16.420: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
  May 13 15:27:16.425: INFO: Updating deployment webserver-deployment
  May 13 15:27:16.425: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  May 13 15:27:16.431: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
  May 13 15:27:16.461: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
  May 13 15:27:16.535: INFO: Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "77b12b2e-4cc4-4670-bfb6-a2cd3ab52a52",
      ResourceVersion: (string) (len=5) "11719",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210832,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 3,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 25,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=59) "ReplicaSet \"webserver-deployment-9b4f5bf69\" is progressing."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  May 13 15:27:16.560: INFO: New ReplicaSet "webserver-deployment-9b4f5bf69" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f00feae8-1ee9-40e2-a90e-1d7dd5cb145b",
      ResourceVersion: (string) (len=5) "11776",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210834,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "77b12b2e-4cc4-4670-bfb6-a2cd3ab52a52",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 37 37 62 31 32 62  32 65 2d 34 63 63 34 2d  |\"77b12b2e-4cc4-|
              00000120  34 36 37 30 2d 62 66 62  36 2d 61 32 63 64 33 61  |4670-bfb6-a2cd3a|
              00000130  62 35 32 61 35 32 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |b52a52\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 13,
      FullyLabeledReplicas: (int32) 13,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 3,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 13 15:27:16.561: INFO: All old ReplicaSets of Deployment "webserver-deployment":
  May 13 15:27:16.561: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
      ResourceVersion: (string) (len=5) "11778",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210832,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "77b12b2e-4cc4-4670-bfb6-a2cd3ab52a52",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 37 37 62 31 32 62  32 65 2d 34 63 63 34 2d  |\"77b12b2e-4cc4-|
              00000120  34 36 37 30 2d 62 66 62  36 2d 61 32 63 64 33 61  |4670-bfb6-a2cd3a|
              00000130  62 35 32 61 35 32 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |b52a52\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 20,
      FullyLabeledReplicas: (int32) 20,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 3,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 13 15:27:16.572: INFO: Pod "webserver-deployment-557759b7c7-2blsm" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-2blsm",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2f4a4deb-ded1-423c-9e6d-0822139a5b18",
      ResourceVersion: (string) (len=5) "11585",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210832,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=4) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "e329259c25bb2948ab2cfb0d00324b6230bd9fd7c3f18833a4ecd605ffc7445c",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=13) "10.42.3.39/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=13) "10.42.3.39/32",
        (string) (len=33) "k8s.v1.cni.cncf.io/network-status": (string) (len=112) "[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.3.39\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=4) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 39  37 65 33 36 66 66 2d 35  |d\":\"c97e36ff-5|
              00000090  62 38 61 2d 34 63 35 34  2d 61 39 61 33 2d 30 31  |b8a-4c54-a9a3-01|
              000000a0  65 34 38 66 63 65 62 37  36 63 5c 22 7d 22 3a 7b  |e48fceb76c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "multus",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=75) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 6b 38 73 2e 76  31 2e 63 6e 69 2e 63 6e  |"f:k8s.v1.cni.cn|
              00000030  63 66 2e 69 6f 2f 6e 65  74 77 6f 72 6b 2d 73 74  |cf.io/network-st|
              00000040  61 74 75 73 22 3a 7b 7d  7d 7d 7d                 |atus":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=659) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 34 32 2e 33 2e 33 39  5c 22 7d 22 3a 7b 22 2e  |.42.3.39\"}":{".|
              00000270  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              00000280  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              00000290  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-wmvz7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-wmvz7",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.7",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.7"
        }
      },
      PodIP: (string) (len=10) "10.42.3.39",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.42.3.39"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210832,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851210833,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://c0ab54c6f8b3b2a629cffb08b64327692f1279a85952600c6fc11c70043d685e",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.587: INFO: Pod "webserver-deployment-557759b7c7-4j9lz" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-4j9lz",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d1b7b439-a4ca-47f0-8ec7-8f4b4eba89c3",
      ResourceVersion: (string) (len=5) "11753",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 39  37 65 33 36 66 66 2d 35  |d\":\"c97e36ff-5|
              00000090  62 38 61 2d 34 63 35 34  2d 61 39 61 33 2d 30 31  |b8a-4c54-a9a3-01|
              000000a0  65 34 38 66 63 65 62 37  36 63 5c 22 7d 22 3a 7b  |e48fceb76c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6wx8d",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6wx8d",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.594: INFO: Pod "webserver-deployment-557759b7c7-4zd4f" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-4zd4f",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9e8c67ac-6643-4860-b28d-f88ca0c15bfe",
      ResourceVersion: (string) (len=5) "11780",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 39  37 65 33 36 66 66 2d 35  |d\":\"c97e36ff-5|
              00000090  62 38 61 2d 34 63 35 34  2d 61 39 61 33 2d 30 31  |b8a-4c54-a9a3-01|
              000000a0  65 34 38 66 63 65 62 37  36 63 5c 22 7d 22 3a 7b  |e48fceb76c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-s76cq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-s76cq",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.5",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.5"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.645: INFO: Pod "webserver-deployment-557759b7c7-c7hbd" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-c7hbd",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6baac151-7cc2-4aa2-8d6e-080326d49231",
      ResourceVersion: (string) (len=5) "11774",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 39  37 65 33 36 66 66 2d 35  |d\":\"c97e36ff-5|
              00000090  62 38 61 2d 34 63 35 34  2d 61 39 61 33 2d 30 31  |b8a-4c54-a9a3-01|
              000000a0  65 34 38 66 63 65 62 37  36 63 5c 22 7d 22 3a 7b  |e48fceb76c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-kzr6m",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-kzr6m",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.7",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.7"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.664: INFO: Pod "webserver-deployment-557759b7c7-czfdw" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-czfdw",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3a540da7-2107-4012-a840-36c1fa63258a",
      ResourceVersion: (string) (len=5) "11570",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210832,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=4) {
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=13) "10.42.1.50/32",
        (string) (len=33) "k8s.v1.cni.cncf.io/network-status": (string) (len=112) "[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.1.50\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "ebd10c4395e6054ca8eee63ffdefa07b71426b552200790a5a882607a0582d1f",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=13) "10.42.1.50/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=4) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 39  37 65 33 36 66 66 2d 35  |d\":\"c97e36ff-5|
              00000090  62 38 61 2d 34 63 35 34  2d 61 39 61 33 2d 30 31  |b8a-4c54-a9a3-01|
              000000a0  65 34 38 66 63 65 62 37  36 63 5c 22 7d 22 3a 7b  |e48fceb76c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "multus",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=75) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 6b 38 73 2e 76  31 2e 63 6e 69 2e 63 6e  |"f:k8s.v1.cni.cn|
              00000030  63 66 2e 69 6f 2f 6e 65  74 77 6f 72 6b 2d 73 74  |cf.io/network-st|
              00000040  61 74 75 73 22 3a 7b 7d  7d 7d 7d                 |atus":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=659) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 34 32 2e 31 2e 35 30  5c 22 7d 22 3a 7b 22 2e  |.42.1.50\"}":{".|
              00000270  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              00000280  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              00000290  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-hn9f6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-hn9f6",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.5",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.5"
        }
      },
      PodIP: (string) (len=10) "10.42.1.50",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.42.1.50"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210832,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851210833,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://5a4e21746da2ea7abb9c04d2122fb933f875d3f13b54be467c9e81455bb1ab07",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.688: INFO: Pod "webserver-deployment-557759b7c7-dvzrw" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-dvzrw",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9d66d359-2865-4257-9c14-80d69f79f801",
      ResourceVersion: (string) (len=5) "11740",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 39  37 65 33 36 66 66 2d 35  |d\":\"c97e36ff-5|
              00000090  62 38 61 2d 34 63 35 34  2d 61 39 61 33 2d 30 31  |b8a-4c54-a9a3-01|
              000000a0  65 34 38 66 63 65 62 37  36 63 5c 22 7d 22 3a 7b  |e48fceb76c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dlsx8",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dlsx8",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.694: INFO: Pod "webserver-deployment-557759b7c7-ffkh2" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-ffkh2",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2ae2bd55-bea7-45bf-8641-cae938a1397d",
      ResourceVersion: (string) (len=5) "11754",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 39  37 65 33 36 66 66 2d 35  |d\":\"c97e36ff-5|
              00000090  62 38 61 2d 34 63 35 34  2d 61 39 61 33 2d 30 31  |b8a-4c54-a9a3-01|
              000000a0  65 34 38 66 63 65 62 37  36 63 5c 22 7d 22 3a 7b  |e48fceb76c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-psxb6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-psxb6",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.709: INFO: Pod "webserver-deployment-557759b7c7-g7mwc" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-g7mwc",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "efa77f3d-607d-490d-99b9-935f4c4afe35",
      ResourceVersion: (string) (len=5) "11581",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210832,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=4) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "0b5597ae78892777e198fbb1da1974fcf22bd65657dc69efedae2e5fdc7035bf",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=13) "10.42.3.42/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=13) "10.42.3.42/32",
        (string) (len=33) "k8s.v1.cni.cncf.io/network-status": (string) (len=112) "[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.3.42\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=4) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 39  37 65 33 36 66 66 2d 35  |d\":\"c97e36ff-5|
              00000090  62 38 61 2d 34 63 35 34  2d 61 39 61 33 2d 30 31  |b8a-4c54-a9a3-01|
              000000a0  65 34 38 66 63 65 62 37  36 63 5c 22 7d 22 3a 7b  |e48fceb76c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "multus",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=75) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 6b 38 73 2e 76  31 2e 63 6e 69 2e 63 6e  |"f:k8s.v1.cni.cn|
              00000030  63 66 2e 69 6f 2f 6e 65  74 77 6f 72 6b 2d 73 74  |cf.io/network-st|
              00000040  61 74 75 73 22 3a 7b 7d  7d 7d 7d                 |atus":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=659) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 34 32 2e 33 2e 34 32  5c 22 7d 22 3a 7b 22 2e  |.42.3.42\"}":{".|
              00000270  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              00000280  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              00000290  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-tfpgq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-tfpgq",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.7",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.7"
        }
      },
      PodIP: (string) (len=10) "10.42.3.42",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.42.3.42"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210832,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851210833,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://72f2212706f0d1e3843c299f38420e25a359b8bf5d3cfd7a3092a119ec0a44a3",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.717: INFO: Pod "webserver-deployment-557759b7c7-jdsnj" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-jdsnj",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0e7448c0-5883-4199-9aef-c05b6004f694",
      ResourceVersion: (string) (len=5) "11716",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 39  37 65 33 36 66 66 2d 35  |d\":\"c97e36ff-5|
              00000090  62 38 61 2d 34 63 35 34  2d 61 39 61 33 2d 30 31  |b8a-4c54-a9a3-01|
              000000a0  65 34 38 66 63 65 62 37  36 63 5c 22 7d 22 3a 7b  |e48fceb76c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dsl4f",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dsl4f",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.725: INFO: Pod "webserver-deployment-557759b7c7-krbpl" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-krbpl",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "36d61b60-2acb-42af-9130-58e772cdc98c",
      ResourceVersion: (string) (len=5) "11565",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210832,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=4) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "9d20e881f48107722f712e645d2639094afe3a2ac431292b37954eb4599d7972",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=13) "10.42.1.54/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=13) "10.42.1.54/32",
        (string) (len=33) "k8s.v1.cni.cncf.io/network-status": (string) (len=112) "[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.1.54\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=4) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 39  37 65 33 36 66 66 2d 35  |d\":\"c97e36ff-5|
              00000090  62 38 61 2d 34 63 35 34  2d 61 39 61 33 2d 30 31  |b8a-4c54-a9a3-01|
              000000a0  65 34 38 66 63 65 62 37  36 63 5c 22 7d 22 3a 7b  |e48fceb76c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=659) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 34 32 2e 31 2e 35 34  5c 22 7d 22 3a 7b 22 2e  |.42.1.54\"}":{".|
              00000270  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              00000280  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              00000290  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "multus",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=75) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 6b 38 73 2e 76  31 2e 63 6e 69 2e 63 6e  |"f:k8s.v1.cni.cn|
              00000030  63 66 2e 69 6f 2f 6e 65  74 77 6f 72 6b 2d 73 74  |cf.io/network-st|
              00000040  61 74 75 73 22 3a 7b 7d  7d 7d 7d                 |atus":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-tz7pp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-tz7pp",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.5",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.5"
        }
      },
      PodIP: (string) (len=10) "10.42.1.54",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.42.1.54"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210832,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851210833,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://ace75a6c60cc88a472f7a57c708b1eebacc4471a8e9255c4e71ad3432bfb05c8",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.741: INFO: Pod "webserver-deployment-557759b7c7-njfhx" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-njfhx",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3c9b0639-ee80-4fc1-808b-e97663580ebe",
      ResourceVersion: (string) (len=5) "11737",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 39  37 65 33 36 66 66 2d 35  |d\":\"c97e36ff-5|
              00000090  62 38 61 2d 34 63 35 34  2d 61 39 61 33 2d 30 31  |b8a-4c54-a9a3-01|
              000000a0  65 34 38 66 63 65 62 37  36 63 5c 22 7d 22 3a 7b  |e48fceb76c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-r9k7l",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-r9k7l",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.744: INFO: Pod "webserver-deployment-557759b7c7-njlhr" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-njlhr",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c1ae9125-2065-41b5-9fb2-f1700dc048c8",
      ResourceVersion: (string) (len=5) "11739",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 39  37 65 33 36 66 66 2d 35  |d\":\"c97e36ff-5|
              00000090  62 38 61 2d 34 63 35 34  2d 61 39 61 33 2d 30 31  |b8a-4c54-a9a3-01|
              000000a0  65 34 38 66 63 65 62 37  36 63 5c 22 7d 22 3a 7b  |e48fceb76c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4vd6q",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4vd6q",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.751: INFO: Pod "webserver-deployment-557759b7c7-rqgbd" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-rqgbd",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "00fdcc9d-8247-4647-aefd-bf57c117cfa8",
      ResourceVersion: (string) (len=5) "11742",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 39  37 65 33 36 66 66 2d 35  |d\":\"c97e36ff-5|
              00000090  62 38 61 2d 34 63 35 34  2d 61 39 61 33 2d 30 31  |b8a-4c54-a9a3-01|
              000000a0  65 34 38 66 63 65 62 37  36 63 5c 22 7d 22 3a 7b  |e48fceb76c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-p2c6m",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-p2c6m",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.755: INFO: Pod "webserver-deployment-557759b7c7-skgf9" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-skgf9",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "98f69fc0-b746-4df2-9934-ed05df13a1b1",
      ResourceVersion: (string) (len=5) "11738",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 39  37 65 33 36 66 66 2d 35  |d\":\"c97e36ff-5|
              00000090  62 38 61 2d 34 63 35 34  2d 61 39 61 33 2d 30 31  |b8a-4c54-a9a3-01|
              000000a0  65 34 38 66 63 65 62 37  36 63 5c 22 7d 22 3a 7b  |e48fceb76c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gmwfk",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gmwfk",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.761: INFO: Pod "webserver-deployment-557759b7c7-slfsh" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-slfsh",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3d3a627f-86e0-4ac8-b8f7-d8940ee3c677",
      ResourceVersion: (string) (len=5) "11755",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 39  37 65 33 36 66 66 2d 35  |d\":\"c97e36ff-5|
              00000090  62 38 61 2d 34 63 35 34  2d 61 39 61 33 2d 30 31  |b8a-4c54-a9a3-01|
              000000a0  65 34 38 66 63 65 62 37  36 63 5c 22 7d 22 3a 7b  |e48fceb76c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dhk5s",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dhk5s",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.7",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.7"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.778: INFO: Pod "webserver-deployment-557759b7c7-txzzv" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-txzzv",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "67653371-ef24-47b2-bc42-b95de2d33202",
      ResourceVersion: (string) (len=5) "11748",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 39  37 65 33 36 66 66 2d 35  |d\":\"c97e36ff-5|
              00000090  62 38 61 2d 34 63 35 34  2d 61 39 61 33 2d 30 31  |b8a-4c54-a9a3-01|
              000000a0  65 34 38 66 63 65 62 37  36 63 5c 22 7d 22 3a 7b  |e48fceb76c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-sldlx",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-sldlx",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.784: INFO: Pod "webserver-deployment-557759b7c7-vgfrh" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-vgfrh",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "11bea0da-005c-4b29-9dfb-f788dc589037",
      ResourceVersion: (string) (len=5) "11573",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210832,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=4) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "cc23b9aeee8c55eb57bb7965f19d748666c017a001ca5bcac1b8d8b45e65bc40",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=13) "10.42.1.51/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=13) "10.42.1.51/32",
        (string) (len=33) "k8s.v1.cni.cncf.io/network-status": (string) (len=112) "[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.1.51\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=4) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 39  37 65 33 36 66 66 2d 35  |d\":\"c97e36ff-5|
              00000090  62 38 61 2d 34 63 35 34  2d 61 39 61 33 2d 30 31  |b8a-4c54-a9a3-01|
              000000a0  65 34 38 66 63 65 62 37  36 63 5c 22 7d 22 3a 7b  |e48fceb76c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "multus",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=75) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 6b 38 73 2e 76  31 2e 63 6e 69 2e 63 6e  |"f:k8s.v1.cni.cn|
              00000030  63 66 2e 69 6f 2f 6e 65  74 77 6f 72 6b 2d 73 74  |cf.io/network-st|
              00000040  61 74 75 73 22 3a 7b 7d  7d 7d 7d                 |atus":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=659) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 34 32 2e 31 2e 35 31  5c 22 7d 22 3a 7b 22 2e  |.42.1.51\"}":{".|
              00000270  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              00000280  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              00000290  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4bjtf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4bjtf",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.5",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.5"
        }
      },
      PodIP: (string) (len=10) "10.42.1.51",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.42.1.51"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210832,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851210833,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://d62d77acde53dbf2662e9048e39d7dcff9f4864cccfe97d015a9a73d66fd9b5f",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.796: INFO: Pod "webserver-deployment-557759b7c7-vgtnq" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-vgtnq",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "74e8b903-31f9-43d8-bed0-f74e08011d6a",
      ResourceVersion: (string) (len=5) "11562",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210832,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=4) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "58779ba836833c9e82cf12db038f0066efdad85e4c247cc8d2f6014b08149462",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=13) "10.42.1.53/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=13) "10.42.1.53/32",
        (string) (len=33) "k8s.v1.cni.cncf.io/network-status": (string) (len=112) "[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.1.53\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=4) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 39  37 65 33 36 66 66 2d 35  |d\":\"c97e36ff-5|
              00000090  62 38 61 2d 34 63 35 34  2d 61 39 61 33 2d 30 31  |b8a-4c54-a9a3-01|
              000000a0  65 34 38 66 63 65 62 37  36 63 5c 22 7d 22 3a 7b  |e48fceb76c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=659) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 34 32 2e 31 2e 35 33  5c 22 7d 22 3a 7b 22 2e  |.42.1.53\"}":{".|
              00000270  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              00000280  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              00000290  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "multus",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=75) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 6b 38 73 2e 76  31 2e 63 6e 69 2e 63 6e  |"f:k8s.v1.cni.cn|
              00000030  63 66 2e 69 6f 2f 6e 65  74 77 6f 72 6b 2d 73 74  |cf.io/network-st|
              00000040  61 74 75 73 22 3a 7b 7d  7d 7d 7d                 |atus":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-w7b2j",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-w7b2j",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.5",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.5"
        }
      },
      PodIP: (string) (len=10) "10.42.1.53",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.42.1.53"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210832,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851210833,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://0f37050cef6e5753568f847ac528bb2266e315ec919de3077b072eb8ec92c6e7",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.806: INFO: Pod "webserver-deployment-557759b7c7-wmbjq" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-wmbjq",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ee203b86-c772-4da7-8220-7dd601166fd4",
      ResourceVersion: (string) (len=5) "11559",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210832,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=4) {
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=13) "10.42.1.52/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=13) "10.42.1.52/32",
        (string) (len=33) "k8s.v1.cni.cncf.io/network-status": (string) (len=112) "[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.1.52\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "a22761906c2048b8e4fa97858155c3a5c57acfec33831bc89b4aac8c1978eac9"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=4) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 39  37 65 33 36 66 66 2d 35  |d\":\"c97e36ff-5|
              00000090  62 38 61 2d 34 63 35 34  2d 61 39 61 33 2d 30 31  |b8a-4c54-a9a3-01|
              000000a0  65 34 38 66 63 65 62 37  36 63 5c 22 7d 22 3a 7b  |e48fceb76c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=659) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 34 32 2e 31 2e 35 32  5c 22 7d 22 3a 7b 22 2e  |.42.1.52\"}":{".|
              00000270  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              00000280  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              00000290  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "multus",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=75) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 6b 38 73 2e 76  31 2e 63 6e 69 2e 63 6e  |"f:k8s.v1.cni.cn|
              00000030  63 66 2e 69 6f 2f 6e 65  74 77 6f 72 6b 2d 73 74  |cf.io/network-st|
              00000040  61 74 75 73 22 3a 7b 7d  7d 7d 7d                 |atus":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xsldk",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xsldk",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.5",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.5"
        }
      },
      PodIP: (string) (len=10) "10.42.1.52",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.42.1.52"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210832,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851210833,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://0b53f13d5c7d7df4c76bb0bd61240f7a84b4f10d16a2a7b9a1e1aa4912178062",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.816: INFO: Pod "webserver-deployment-557759b7c7-zqd8p" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-zqd8p",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b7156358-18db-4010-b328-40906bee668f",
      ResourceVersion: (string) (len=5) "11579",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210832,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=4) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "7975eb9c9e248f8a59eacf118bb432b1712117e8d457fb2b4a2cb3f82c7f2182",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=13) "10.42.3.40/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=13) "10.42.3.40/32",
        (string) (len=33) "k8s.v1.cni.cncf.io/network-status": (string) (len=112) "[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.3.40\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "c97e36ff-5b8a-4c54-a9a3-01e48fceb76c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=4) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 39  37 65 33 36 66 66 2d 35  |d\":\"c97e36ff-5|
              00000090  62 38 61 2d 34 63 35 34  2d 61 39 61 33 2d 30 31  |b8a-4c54-a9a3-01|
              000000a0  65 34 38 66 63 65 62 37  36 63 5c 22 7d 22 3a 7b  |e48fceb76c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "multus",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=75) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 6b 38 73 2e 76  31 2e 63 6e 69 2e 63 6e  |"f:k8s.v1.cni.cn|
              00000030  63 66 2e 69 6f 2f 6e 65  74 77 6f 72 6b 2d 73 74  |cf.io/network-st|
              00000040  61 74 75 73 22 3a 7b 7d  7d 7d 7d                 |atus":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=659) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 34 32 2e 33 2e 34 30  5c 22 7d 22 3a 7b 22 2e  |.42.3.40\"}":{".|
              00000270  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              00000280  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              00000290  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-8tlwm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-8tlwm",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.7",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.7"
        }
      },
      PodIP: (string) (len=10) "10.42.3.40",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.42.3.40"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210832,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851210833,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://d1afad8c9b7d19075e406b90f7d117632103fb057eef39ba2c5f7e00ec5aa590",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.826: INFO: Pod "webserver-deployment-9b4f5bf69-4jclg" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-4jclg",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "cd91a506-2bb0-4f4c-910d-ad95a573dfc1",
      ResourceVersion: (string) (len=5) "11677",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210834,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=4) {
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=13) "10.42.1.55/32",
        (string) (len=33) "k8s.v1.cni.cncf.io/network-status": (string) (len=112) "[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.1.55\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "b9f944740db05aab49bf3345cdb103e1b2acd6b55c13b7035d37b2cf85ee462f",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=13) "10.42.1.55/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "f00feae8-1ee9-40e2-a90e-1d7dd5cb145b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=4) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 30  30 66 65 61 65 38 2d 31  |d\":\"f00feae8-1|
              00000090  65 65 39 2d 34 30 65 32  2d 61 39 30 65 2d 31 64  |ee9-40e2-a90e-1d|
              000000a0  37 64 64 35 63 62 31 34  35 62 5c 22 7d 22 3a 7b  |7dd5cb145b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "multus",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=75) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 6b 38 73 2e 76  31 2e 63 6e 69 2e 63 6e  |"f:k8s.v1.cni.cn|
              00000030  63 66 2e 69 6f 2f 6e 65  74 77 6f 72 6b 2d 73 74  |cf.io/network-st|
              00000040  61 74 75 73 22 3a 7b 7d  7d 7d 7d                 |atus":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210835,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=704) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 30 2e 34 32  |:{\"ip\":\"10.42|
              00000290  2e 31 2e 35 35 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |.1.55\"}":{".":{|
              000002a0  7d 2c 22 66 3a 69 70 22  3a 7b 7d 7d 7d 2c 22 66  |},"f:ip":{}}},"f|
              000002b0  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-5rj9g",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-5rj9g",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210835,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.5",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.5"
        }
      },
      PodIP: (string) (len=10) "10.42.1.55",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.42.1.55"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210834,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.838: INFO: Pod "webserver-deployment-9b4f5bf69-4x6vp" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-4x6vp",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b089637d-1970-4852-a4e9-dfc878bb601d",
      ResourceVersion: (string) (len=5) "11764",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "f00feae8-1ee9-40e2-a90e-1d7dd5cb145b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 30  30 66 65 61 65 38 2d 31  |d\":\"f00feae8-1|
              00000090  65 65 39 2d 34 30 65 32  2d 61 39 30 65 2d 31 64  |ee9-40e2-a90e-1d|
              000000a0  37 64 64 35 63 62 31 34  35 62 5c 22 7d 22 3a 7b  |7dd5cb145b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9xfbw",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9xfbw",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.5",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.5"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.851: INFO: Pod "webserver-deployment-9b4f5bf69-6nfjk" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-6nfjk",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "de62528f-6ccb-438a-a2e4-37ca3b2d4bc4",
      ResourceVersion: (string) (len=5) "11747",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "f00feae8-1ee9-40e2-a90e-1d7dd5cb145b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 30  30 66 65 61 65 38 2d 31  |d\":\"f00feae8-1|
              00000090  65 65 39 2d 34 30 65 32  2d 61 39 30 65 2d 31 64  |ee9-40e2-a90e-1d|
              000000a0  37 64 64 35 63 62 31 34  35 62 5c 22 7d 22 3a 7b  |7dd5cb145b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-m8wtn",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-m8wtn",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.857: INFO: Pod "webserver-deployment-9b4f5bf69-9qpgq" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-9qpgq",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ef1cc3c4-e924-417e-9705-2b3606a00d5b",
      ResourceVersion: (string) (len=5) "11749",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "f00feae8-1ee9-40e2-a90e-1d7dd5cb145b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 30  30 66 65 61 65 38 2d 31  |d\":\"f00feae8-1|
              00000090  65 65 39 2d 34 30 65 32  2d 61 39 30 65 2d 31 64  |ee9-40e2-a90e-1d|
              000000a0  37 64 64 35 63 62 31 34  35 62 5c 22 7d 22 3a 7b  |7dd5cb145b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-thkr8",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-thkr8",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.862: INFO: Pod "webserver-deployment-9b4f5bf69-dkv4b" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-dkv4b",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a9bf151b-275a-45f4-9f82-5222d8cad535",
      ResourceVersion: (string) (len=5) "11750",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "f00feae8-1ee9-40e2-a90e-1d7dd5cb145b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 30  30 66 65 61 65 38 2d 31  |d\":\"f00feae8-1|
              00000090  65 65 39 2d 34 30 65 32  2d 61 39 30 65 2d 31 64  |ee9-40e2-a90e-1d|
              000000a0  37 64 64 35 63 62 31 34  35 62 5c 22 7d 22 3a 7b  |7dd5cb145b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ssdzq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ssdzq",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.868: INFO: Pod "webserver-deployment-9b4f5bf69-hdcnm" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-hdcnm",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "92005a2c-4839-4cbd-a1d7-6ec1189b8007",
      ResourceVersion: (string) (len=5) "11689",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210834,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=4) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "233158dbcaca7f6f95fb05440ae1a3e43eed30e289e4dd916eacb8ebbcb25e76",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=13) "10.42.3.43/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=13) "10.42.3.43/32",
        (string) (len=33) "k8s.v1.cni.cncf.io/network-status": (string) (len=112) "[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.3.43\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "f00feae8-1ee9-40e2-a90e-1d7dd5cb145b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=4) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 30  30 66 65 61 65 38 2d 31  |d\":\"f00feae8-1|
              00000090  65 65 39 2d 34 30 65 32  2d 61 39 30 65 2d 31 64  |ee9-40e2-a90e-1d|
              000000a0  37 64 64 35 63 62 31 34  35 62 5c 22 7d 22 3a 7b  |7dd5cb145b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "multus",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=75) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 6b 38 73 2e 76  31 2e 63 6e 69 2e 63 6e  |"f:k8s.v1.cni.cn|
              00000030  63 66 2e 69 6f 2f 6e 65  74 77 6f 72 6b 2d 73 74  |cf.io/network-st|
              00000040  61 74 75 73 22 3a 7b 7d  7d 7d 7d                 |atus":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=704) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 30 2e 34 32  |:{\"ip\":\"10.42|
              00000290  2e 33 2e 34 33 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |.3.43\"}":{".":{|
              000002a0  7d 2c 22 66 3a 69 70 22  3a 7b 7d 7d 7d 2c 22 66  |},"f:ip":{}}},"f|
              000002b0  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-n2pfd",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-n2pfd",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.7",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.7"
        }
      },
      PodIP: (string) (len=10) "10.42.3.43",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.42.3.43"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210834,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  E0513 15:27:16.868814      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:27:16.882: INFO: Pod "webserver-deployment-9b4f5bf69-lb5hs" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-lb5hs",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "406353e4-a2a8-4333-9616-72ee59b33fb6",
      ResourceVersion: (string) (len=5) "11751",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "f00feae8-1ee9-40e2-a90e-1d7dd5cb145b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 30  30 66 65 61 65 38 2d 31  |d\":\"f00feae8-1|
              00000090  65 65 39 2d 34 30 65 32  2d 61 39 30 65 2d 31 64  |ee9-40e2-a90e-1d|
              000000a0  37 64 64 35 63 62 31 34  35 62 5c 22 7d 22 3a 7b  |7dd5cb145b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vtnqh",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vtnqh",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.888: INFO: Pod "webserver-deployment-9b4f5bf69-pjhxn" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-pjhxn",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "842b2996-7fc9-4c6b-9ccb-b06430c56f7f",
      ResourceVersion: (string) (len=5) "11684",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210834,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=4) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "0bd87e9bf7ae8bab720c58b51b2ef3ea0728d7302ba04d53f9bc986bc8ed50fa",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=13) "10.42.3.45/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=13) "10.42.3.45/32",
        (string) (len=33) "k8s.v1.cni.cncf.io/network-status": (string) (len=112) "[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.3.45\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "f00feae8-1ee9-40e2-a90e-1d7dd5cb145b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=4) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 30  30 66 65 61 65 38 2d 31  |d\":\"f00feae8-1|
              00000090  65 65 39 2d 34 30 65 32  2d 61 39 30 65 2d 31 64  |ee9-40e2-a90e-1d|
              000000a0  37 64 64 35 63 62 31 34  35 62 5c 22 7d 22 3a 7b  |7dd5cb145b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210835,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "multus",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210835,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=75) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 6b 38 73 2e 76  31 2e 63 6e 69 2e 63 6e  |"f:k8s.v1.cni.cn|
              00000030  63 66 2e 69 6f 2f 6e 65  74 77 6f 72 6b 2d 73 74  |cf.io/network-st|
              00000040  61 74 75 73 22 3a 7b 7d  7d 7d 7d                 |atus":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=704) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 30 2e 34 32  |:{\"ip\":\"10.42|
              00000290  2e 33 2e 34 35 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |.3.45\"}":{".":{|
              000002a0  7d 2c 22 66 3a 69 70 22  3a 7b 7d 7d 7d 2c 22 66  |},"f:ip":{}}},"f|
              000002b0  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7595f",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7595f",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.7",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.7"
        }
      },
      PodIP: (string) (len=10) "10.42.3.45",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.42.3.45"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210834,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.896: INFO: Pod "webserver-deployment-9b4f5bf69-qrmd8" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-qrmd8",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d026d71c-da8b-4995-b894-b493084a9138",
      ResourceVersion: (string) (len=5) "11734",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "f00feae8-1ee9-40e2-a90e-1d7dd5cb145b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 30  30 66 65 61 65 38 2d 31  |d\":\"f00feae8-1|
              00000090  65 65 39 2d 34 30 65 32  2d 61 39 30 65 2d 31 64  |ee9-40e2-a90e-1d|
              000000a0  37 64 64 35 63 62 31 34  35 62 5c 22 7d 22 3a 7b  |7dd5cb145b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-985qz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-985qz",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.5",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.5"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.906: INFO: Pod "webserver-deployment-9b4f5bf69-rv5fm" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-rv5fm",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "493e1130-8fd5-4d39-a457-daa6477c3c97",
      ResourceVersion: (string) (len=5) "11761",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "f00feae8-1ee9-40e2-a90e-1d7dd5cb145b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 30  30 66 65 61 65 38 2d 31  |d\":\"f00feae8-1|
              00000090  65 65 39 2d 34 30 65 32  2d 61 39 30 65 2d 31 64  |ee9-40e2-a90e-1d|
              000000a0  37 64 64 35 63 62 31 34  35 62 5c 22 7d 22 3a 7b  |7dd5cb145b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-rrxp9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-rrxp9",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.913: INFO: Pod "webserver-deployment-9b4f5bf69-sqt5v" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-sqt5v",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7a083852-1123-40ad-add9-0e69b4e0132a",
      ResourceVersion: (string) (len=5) "11692",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210834,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=4) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "f8837f251a0d5a803591f7a56bcdb99f1dbd7081e019504f86226902bebe1b45",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=13) "10.42.3.44/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=13) "10.42.3.44/32",
        (string) (len=33) "k8s.v1.cni.cncf.io/network-status": (string) (len=112) "[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.3.44\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "f00feae8-1ee9-40e2-a90e-1d7dd5cb145b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=4) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 30  30 66 65 61 65 38 2d 31  |d\":\"f00feae8-1|
              00000090  65 65 39 2d 34 30 65 32  2d 61 39 30 65 2d 31 64  |ee9-40e2-a90e-1d|
              000000a0  37 64 64 35 63 62 31 34  35 62 5c 22 7d 22 3a 7b  |7dd5cb145b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "multus",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210835,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=75) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 6b 38 73 2e 76  31 2e 63 6e 69 2e 63 6e  |"f:k8s.v1.cni.cn|
              00000030  63 66 2e 69 6f 2f 6e 65  74 77 6f 72 6b 2d 73 74  |cf.io/network-st|
              00000040  61 74 75 73 22 3a 7b 7d  7d 7d 7d                 |atus":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=704) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 30 2e 34 32  |:{\"ip\":\"10.42|
              00000290  2e 33 2e 34 34 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |.3.44\"}":{".":{|
              000002a0  7d 2c 22 66 3a 69 70 22  3a 7b 7d 7d 7d 2c 22 66  |},"f:ip":{}}},"f|
              000002b0  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2dcqj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2dcqj",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.7",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.7"
        }
      },
      PodIP: (string) (len=10) "10.42.3.44",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.42.3.44"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210834,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.919: INFO: Pod "webserver-deployment-9b4f5bf69-x6gng" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-x6gng",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9e056434-0255-4ed1-b506-7f3e15b78658",
      ResourceVersion: (string) (len=5) "11681",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210834,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=4) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "28eec9ff5c97de4dc293914eeee377f65d8183f1d9440498c6e51c2842d33e2d",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=13) "10.42.1.56/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=13) "10.42.1.56/32",
        (string) (len=33) "k8s.v1.cni.cncf.io/network-status": (string) (len=112) "[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.1.56\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "f00feae8-1ee9-40e2-a90e-1d7dd5cb145b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=4) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 30  30 66 65 61 65 38 2d 31  |d\":\"f00feae8-1|
              00000090  65 65 39 2d 34 30 65 32  2d 61 39 30 65 2d 31 64  |ee9-40e2-a90e-1d|
              000000a0  37 64 64 35 63 62 31 34  35 62 5c 22 7d 22 3a 7b  |7dd5cb145b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210835,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=704) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 30 2e 34 32  |:{\"ip\":\"10.42|
              00000290  2e 31 2e 35 36 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |.1.56\"}":{".":{|
              000002a0  7d 2c 22 66 3a 69 70 22  3a 7b 7d 7d 7d 2c 22 66  |},"f:ip":{}}},"f|
              000002b0  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "multus",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210835,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=75) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 6b 38 73 2e 76  31 2e 63 6e 69 2e 63 6e  |"f:k8s.v1.cni.cn|
              00000030  63 66 2e 69 6f 2f 6e 65  74 77 6f 72 6b 2d 73 74  |cf.io/network-st|
              00000040  61 74 75 73 22 3a 7b 7d  7d 7d 7d                 |atus":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-k92bm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-k92bm",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210835,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.5",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.5"
        }
      },
      PodIP: (string) (len=10) "10.42.1.56",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.42.1.56"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210834,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.929: INFO: Pod "webserver-deployment-9b4f5bf69-zvbbh" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-zvbbh",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6322",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8ae03c92-9e82-4cd4-a83b-756f3f15a84b",
      ResourceVersion: (string) (len=5) "11730",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851210836,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "f00feae8-1ee9-40e2-a90e-1d7dd5cb145b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 30  30 66 65 61 65 38 2d 31  |d\":\"f00feae8-1|
              00000090  65 65 39 2d 34 30 65 32  2d 61 39 30 65 2d 31 64  |ee9-40e2-a90e-1d|
              000000a0  37 64 64 35 63 62 31 34  35 62 5c 22 7d 22 3a 7b  |7dd5cb145b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jqfcp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jqfcp",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851210836,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:27:16.942: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6322" for this suite. @ 05/13/24 15:27:16.947
• [4.598 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 05/13/24 15:27:16.953
  May 13 15:27:16.953: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename deployment @ 05/13/24 15:27:16.954
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:27:16.97
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:27:16.973
  STEP: creating a Deployment @ 05/13/24 15:27:16.976
  STEP: waiting for Deployment to be created @ 05/13/24 15:27:16.98
  STEP: waiting for all Replicas to be Ready @ 05/13/24 15:27:16.987
  May 13 15:27:16.995: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May 13 15:27:16.995: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May 13 15:27:16.995: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May 13 15:27:16.996: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May 13 15:27:16.996: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May 13 15:27:16.996: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May 13 15:27:17.597: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May 13 15:27:17.597: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E0513 15:27:17.870961      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:18.871391      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:19.871473      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:27:20.093: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  May 13 15:27:20.093: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  May 13 15:27:20.286: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 05/13/24 15:27:20.286
  May 13 15:27:20.303: INFO: observed event type ADDED
  STEP: waiting for Replicas to scale @ 05/13/24 15:27:20.303
  May 13 15:27:20.306: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 0
  May 13 15:27:20.306: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 0
  May 13 15:27:20.307: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 0
  May 13 15:27:20.307: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 0
  May 13 15:27:20.308: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 0
  May 13 15:27:20.308: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 0
  May 13 15:27:20.308: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 0
  May 13 15:27:20.308: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 0
  May 13 15:27:20.309: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 1
  May 13 15:27:20.309: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 1
  May 13 15:27:20.309: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 2
  May 13 15:27:20.309: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 2
  May 13 15:27:20.309: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 2
  May 13 15:27:20.310: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 2
  May 13 15:27:20.318: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 2
  May 13 15:27:20.318: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 2
  May 13 15:27:20.340: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 2
  May 13 15:27:20.340: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 2
  May 13 15:27:20.347: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 1
  May 13 15:27:20.347: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 1
  May 13 15:27:20.354: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 1
  May 13 15:27:20.354: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 1
  E0513 15:27:20.871572      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:27:21.092: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 2
  May 13 15:27:21.092: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 2
  May 13 15:27:21.113: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 1
  STEP: listing Deployments @ 05/13/24 15:27:21.113
  May 13 15:27:21.115: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 05/13/24 15:27:21.115
  May 13 15:27:21.123: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 05/13/24 15:27:21.123
  May 13 15:27:21.136: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  May 13 15:27:21.144: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  May 13 15:27:21.155: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  May 13 15:27:21.167: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  May 13 15:27:21.173: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0513 15:27:21.871942      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:27:22.301: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  May 13 15:27:22.354: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  May 13 15:27:22.393: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  May 13 15:27:22.400: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0513 15:27:22.872103      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:23.873008      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:24.873280      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:25.873587      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:27:26.208: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 05/13/24 15:27:26.228
  STEP: fetching the DeploymentStatus @ 05/13/24 15:27:26.235
  May 13 15:27:26.239: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 1
  May 13 15:27:26.239: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 1
  May 13 15:27:26.239: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 1
  May 13 15:27:26.239: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 1
  May 13 15:27:26.239: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 1
  May 13 15:27:26.239: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 2
  May 13 15:27:26.240: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 3
  May 13 15:27:26.240: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 2
  May 13 15:27:26.240: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 2
  May 13 15:27:26.240: INFO: observed Deployment test-deployment in namespace deployment-2525 with ReadyReplicas 3
  STEP: deleting the Deployment @ 05/13/24 15:27:26.24
  May 13 15:27:26.244: INFO: observed event type MODIFIED
  May 13 15:27:26.244: INFO: observed event type MODIFIED
  May 13 15:27:26.244: INFO: observed event type MODIFIED
  May 13 15:27:26.244: INFO: observed event type MODIFIED
  May 13 15:27:26.244: INFO: observed event type MODIFIED
  May 13 15:27:26.244: INFO: observed event type MODIFIED
  May 13 15:27:26.244: INFO: observed event type MODIFIED
  May 13 15:27:26.244: INFO: observed event type MODIFIED
  May 13 15:27:26.244: INFO: observed event type MODIFIED
  May 13 15:27:26.244: INFO: observed event type MODIFIED
  May 13 15:27:26.244: INFO: observed event type MODIFIED
  May 13 15:27:26.244: INFO: observed event type MODIFIED
  May 13 15:27:26.244: INFO: observed event type MODIFIED
  May 13 15:27:26.247: INFO: Log out all the ReplicaSets if there is no deployment created
  May 13 15:27:26.249: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2525" for this suite. @ 05/13/24 15:27:26.252
• [9.305 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:146
  STEP: Creating a kubernetes client @ 05/13/24 15:27:26.258
  May 13 15:27:26.259: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/13/24 15:27:26.263
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:27:26.276
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:27:26.279
  May 13 15:27:26.281: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 15:27:26.823: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-8400" for this suite. @ 05/13/24 15:27:26.834
• [0.580 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:270
  STEP: Creating a kubernetes client @ 05/13/24 15:27:26.84
  May 13 15:27:26.840: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/13/24 15:27:26.841
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:27:26.851
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:27:26.853
  May 13 15:27:26.854: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 15:27:26.874015      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:27.874234      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:28.874813      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:29.874933      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:27:29.906: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-6852" for this suite. @ 05/13/24 15:27:29.909
• [3.074 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:208
  STEP: Creating a kubernetes client @ 05/13/24 15:27:29.915
  May 13 15:27:29.915: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename endpointslice @ 05/13/24 15:27:29.916
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:27:29.928
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:27:29.93
  E0513 15:27:30.875900      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:31.876617      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:32.876796      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:33.877624      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:34.878702      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 05/13/24 15:27:34.997
  E0513 15:27:35.878966      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:36.879725      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:37.880997      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:38.881449      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:39.881979      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing matching pods with named port @ 05/13/24 15:27:40.006
  E0513 15:27:40.882722      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:41.883649      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:42.883657      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:43.883786      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:44.884941      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 05/13/24 15:27:45.021
  E0513 15:27:45.884990      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:46.885265      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:47.885477      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:48.885545      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:49.885998      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: recreating EndpointSlices after they've been deleted @ 05/13/24 15:27:50.034
  May 13 15:27:50.044: INFO: EndpointSlice for Service endpointslice-8491/example-named-port not found
  E0513 15:27:50.887135      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:51.887675      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:52.888364      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:53.889242      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:54.889863      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:55.893310      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:56.891748      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:57.891427      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:58.891537      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:27:59.892517      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:28:00.052: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-8491" for this suite. @ 05/13/24 15:28:00.054
• [30.144 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 05/13/24 15:28:00.064
  May 13 15:28:00.064: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename daemonsets @ 05/13/24 15:28:00.065
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:28:00.075
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:28:00.077
  STEP: Creating a simple DaemonSet "daemon-set" @ 05/13/24 15:28:00.087
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/13/24 15:28:00.094
  May 13 15:28:00.104: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 15:28:00.104: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 15:28:00.122: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 15:28:00.123: INFO: Node oneke-ip-172-16-100-5 is running 0 daemon pod, expected 1
  E0513 15:28:00.892802      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:28:01.099: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 15:28:01.099: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 15:28:01.101: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 15:28:01.101: INFO: Node oneke-ip-172-16-100-5 is running 0 daemon pod, expected 1
  E0513 15:28:01.892862      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:28:02.097: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 15:28:02.097: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 15:28:02.099: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May 13 15:28:02.099: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 05/13/24 15:28:02.1
  May 13 15:28:02.110: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 15:28:02.110: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 15:28:02.114: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May 13 15:28:02.114: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 05/13/24 15:28:02.114
  E0513 15:28:02.893862      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting DaemonSet "daemon-set" @ 05/13/24 15:28:03.118
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7565, will wait for the garbage collector to delete the pods @ 05/13/24 15:28:03.118
  May 13 15:28:03.175: INFO: Deleting DaemonSet.extensions daemon-set took: 5.096802ms
  May 13 15:28:03.276: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.210682ms
  E0513 15:28:03.894882      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:04.896197      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:28:05.479: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 15:28:05.479: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  May 13 15:28:05.481: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"12768"},"items":null}

  May 13 15:28:05.484: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"12768"},"items":null}

  May 13 15:28:05.510: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7565" for this suite. @ 05/13/24 15:28:05.513
• [5.454 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 05/13/24 15:28:05.519
  May 13 15:28:05.519: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename sysctl @ 05/13/24 15:28:05.52
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:28:05.538
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:28:05.541
  STEP: Creating a pod with one valid and two invalid sysctls @ 05/13/24 15:28:05.543
  May 13 15:28:05.547: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-9011" for this suite. @ 05/13/24 15:28:05.55
• [0.036 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 05/13/24 15:28:05.556
  May 13 15:28:05.556: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename server-version @ 05/13/24 15:28:05.557
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:28:05.569
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:28:05.571
  STEP: Request ServerVersion @ 05/13/24 15:28:05.572
  STEP: Confirm major version @ 05/13/24 15:28:05.572
  May 13 15:28:05.573: INFO: Major version: 1
  STEP: Confirm minor version @ 05/13/24 15:28:05.573
  May 13 15:28:05.573: INFO: cleanMinorVersion: 29
  May 13 15:28:05.573: INFO: Minor version: 29
  May 13 15:28:05.573: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-6893" for this suite. @ 05/13/24 15:28:05.575
• [0.023 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:639
  STEP: Creating a kubernetes client @ 05/13/24 15:28:05.58
  May 13 15:28:05.580: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename gc @ 05/13/24 15:28:05.581
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:28:05.591
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:28:05.593
  STEP: create the rc @ 05/13/24 15:28:05.597
  W0513 15:28:05.600462      17 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0513 15:28:05.896253      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:06.896483      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:07.899158      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:08.905533      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:09.906504      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:10.906831      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 05/13/24 15:28:11.603
  STEP: wait for the rc to be deleted @ 05/13/24 15:28:11.609
  E0513 15:28:11.906985      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:28:12.617: INFO: 80 pods remaining
  May 13 15:28:12.618: INFO: 80 pods has nil DeletionTimestamp
  May 13 15:28:12.618: INFO: 
  E0513 15:28:12.907701      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:28:13.629: INFO: 70 pods remaining
  May 13 15:28:13.629: INFO: 70 pods has nil DeletionTimestamp
  May 13 15:28:13.629: INFO: 
  E0513 15:28:13.909837      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:28:14.620: INFO: 60 pods remaining
  May 13 15:28:14.620: INFO: 60 pods has nil DeletionTimestamp
  May 13 15:28:14.620: INFO: 
  E0513 15:28:14.909909      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:28:15.620: INFO: 40 pods remaining
  May 13 15:28:15.620: INFO: 40 pods has nil DeletionTimestamp
  May 13 15:28:15.620: INFO: 
  E0513 15:28:15.910075      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:28:16.621: INFO: 30 pods remaining
  May 13 15:28:16.622: INFO: 30 pods has nil DeletionTimestamp
  May 13 15:28:16.622: INFO: 
  E0513 15:28:16.910542      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:28:17.615: INFO: 20 pods remaining
  May 13 15:28:17.615: INFO: 20 pods has nil DeletionTimestamp
  May 13 15:28:17.615: INFO: 
  E0513 15:28:17.912249      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/13/24 15:28:18.613
  May 13 15:28:18.785: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  May 13 15:28:18.801: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1515" for this suite. @ 05/13/24 15:28:18.808
• [13.235 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:237
  STEP: Creating a kubernetes client @ 05/13/24 15:28:18.817
  May 13 15:28:18.817: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 15:28:18.82
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:28:18.833
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:28:18.837
  STEP: Creating a pod to test downward API volume plugin @ 05/13/24 15:28:18.84
  E0513 15:28:18.911253      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:19.911258      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:20.911940      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:21.912074      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:22.913281      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:23.913229      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:24.913878      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:25.914014      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:26.914782      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:27.914937      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:28:28.86
  May 13 15:28:28.862: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod downwardapi-volume-f0de779f-ee63-4252-a329-bdbb01c9fdd3 container client-container: <nil>
  STEP: delete the pod @ 05/13/24 15:28:28.882
  May 13 15:28:28.897: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2929" for this suite. @ 05/13/24 15:28:28.902
• [10.087 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:170
  STEP: Creating a kubernetes client @ 05/13/24 15:28:28.906
  May 13 15:28:28.907: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename configmap @ 05/13/24 15:28:28.908
  E0513 15:28:28.916671      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:28:28.92
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:28:28.923
  STEP: creating a ConfigMap @ 05/13/24 15:28:28.925
  STEP: fetching the ConfigMap @ 05/13/24 15:28:28.928
  STEP: patching the ConfigMap @ 05/13/24 15:28:28.929
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 05/13/24 15:28:28.933
  STEP: deleting the ConfigMap by collection with a label selector @ 05/13/24 15:28:28.94
  STEP: listing all ConfigMaps in test namespace @ 05/13/24 15:28:28.946
  May 13 15:28:28.947: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2945" for this suite. @ 05/13/24 15:28:28.95
• [0.049 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 05/13/24 15:28:28.96
  May 13 15:28:28.960: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename pods @ 05/13/24 15:28:28.961
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:28:28.971
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:28:28.974
  May 13 15:28:28.975: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: creating the pod @ 05/13/24 15:28:28.976
  STEP: submitting the pod to kubernetes @ 05/13/24 15:28:28.976
  E0513 15:28:29.917648      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:30.917723      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:28:31.018: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8738" for this suite. @ 05/13/24 15:28:31.023
• [2.069 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:221
  STEP: Creating a kubernetes client @ 05/13/24 15:28:31.03
  May 13 15:28:31.030: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename webhook @ 05/13/24 15:28:31.031
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:28:31.039
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:28:31.042
  STEP: Setting up server cert @ 05/13/24 15:28:31.062
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/13/24 15:28:31.273
  STEP: Deploying the webhook pod @ 05/13/24 15:28:31.276
  STEP: Wait for the deployment to be ready @ 05/13/24 15:28:31.287
  May 13 15:28:31.294: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0513 15:28:31.918205      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:32.918310      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/13/24 15:28:33.314
  STEP: Verifying the service has paired with the endpoint @ 05/13/24 15:28:33.324
  E0513 15:28:33.919145      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:28:34.325: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  May 13 15:28:34.327: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 05/13/24 15:28:34.834
  STEP: Creating a custom resource that should be denied by the webhook @ 05/13/24 15:28:34.862
  E0513 15:28:34.920257      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:35.924547      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 05/13/24 15:28:36.906
  STEP: Updating the custom resource with disallowed data should be denied @ 05/13/24 15:28:36.924
  E0513 15:28:36.932211      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the custom resource should be denied @ 05/13/24 15:28:36.936
  STEP: Remove the offending key and value from the custom resource data @ 05/13/24 15:28:36.943
  STEP: Deleting the updated custom resource should be successful @ 05/13/24 15:28:36.949
  May 13 15:28:37.538: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2390" for this suite. @ 05/13/24 15:28:37.544
  STEP: Destroying namespace "webhook-markers-8535" for this suite. @ 05/13/24 15:28:37.549
• [6.523 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 05/13/24 15:28:37.553
  May 13 15:28:37.553: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename dns @ 05/13/24 15:28:37.554
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:28:37.565
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:28:37.567
  STEP: Creating a test externalName service @ 05/13/24 15:28:37.568
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-794.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-794.svc.cluster.local; sleep 1; done
   @ 05/13/24 15:28:37.572
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-794.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-794.svc.cluster.local; sleep 1; done
   @ 05/13/24 15:28:37.572
  STEP: creating a pod to probe DNS @ 05/13/24 15:28:37.572
  STEP: submitting the pod to kubernetes @ 05/13/24 15:28:37.572
  E0513 15:28:37.933282      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:38.933808      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:39.934401      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:40.934537      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:41.934657      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:42.935733      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/13/24 15:28:43.598
  STEP: looking for the results for each expected name from probers @ 05/13/24 15:28:43.599
  May 13 15:28:43.609: INFO: DNS probes using dns-test-4d787807-5354-4f71-9e2f-dde84cc6849d succeeded

  STEP: changing the externalName to bar.example.com @ 05/13/24 15:28:43.609
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-794.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-794.svc.cluster.local; sleep 1; done
   @ 05/13/24 15:28:43.615
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-794.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-794.svc.cluster.local; sleep 1; done
   @ 05/13/24 15:28:43.615
  STEP: creating a second pod to probe DNS @ 05/13/24 15:28:43.615
  STEP: submitting the pod to kubernetes @ 05/13/24 15:28:43.615
  E0513 15:28:43.936456      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:44.937302      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/13/24 15:28:45.63
  STEP: looking for the results for each expected name from probers @ 05/13/24 15:28:45.631
  May 13 15:28:45.636: INFO: File wheezy_udp@dns-test-service-3.dns-794.svc.cluster.local from pod  dns-794/dns-test-62704113-e301-41d5-80ad-a068c24e67dc contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May 13 15:28:45.638: INFO: File jessie_udp@dns-test-service-3.dns-794.svc.cluster.local from pod  dns-794/dns-test-62704113-e301-41d5-80ad-a068c24e67dc contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May 13 15:28:45.638: INFO: Lookups using dns-794/dns-test-62704113-e301-41d5-80ad-a068c24e67dc failed for: [wheezy_udp@dns-test-service-3.dns-794.svc.cluster.local jessie_udp@dns-test-service-3.dns-794.svc.cluster.local]

  May 13 15:28:45.642: INFO: Pod client logs for webserver: 
  May 13 15:28:45.646: INFO: Pod client logs for querier: 
  May 13 15:28:45.649: INFO: Pod client logs for jessie-querier: 
  E0513 15:28:45.938218      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:46.939151      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:47.939174      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:48.939303      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:49.940227      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:28:50.638: INFO: File wheezy_udp@dns-test-service-3.dns-794.svc.cluster.local from pod  dns-794/dns-test-62704113-e301-41d5-80ad-a068c24e67dc contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May 13 15:28:50.643: INFO: File jessie_udp@dns-test-service-3.dns-794.svc.cluster.local from pod  dns-794/dns-test-62704113-e301-41d5-80ad-a068c24e67dc contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May 13 15:28:50.644: INFO: Lookups using dns-794/dns-test-62704113-e301-41d5-80ad-a068c24e67dc failed for: [wheezy_udp@dns-test-service-3.dns-794.svc.cluster.local jessie_udp@dns-test-service-3.dns-794.svc.cluster.local]

  May 13 15:28:50.651: INFO: Pod client logs for webserver: 
  May 13 15:28:50.656: INFO: Pod client logs for querier: 
  May 13 15:28:50.660: INFO: Pod client logs for jessie-querier: 
  E0513 15:28:50.941111      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:51.941057      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:52.941180      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:53.941629      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:54.942696      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:28:55.633: INFO: File wheezy_udp@dns-test-service-3.dns-794.svc.cluster.local from pod  dns-794/dns-test-62704113-e301-41d5-80ad-a068c24e67dc contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May 13 15:28:55.635: INFO: File jessie_udp@dns-test-service-3.dns-794.svc.cluster.local from pod  dns-794/dns-test-62704113-e301-41d5-80ad-a068c24e67dc contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May 13 15:28:55.635: INFO: Lookups using dns-794/dns-test-62704113-e301-41d5-80ad-a068c24e67dc failed for: [wheezy_udp@dns-test-service-3.dns-794.svc.cluster.local jessie_udp@dns-test-service-3.dns-794.svc.cluster.local]

  May 13 15:28:55.638: INFO: Pod client logs for webserver: 
  May 13 15:28:55.641: INFO: Pod client logs for querier: 
  May 13 15:28:55.643: INFO: Pod client logs for jessie-querier: 
  E0513 15:28:55.943938      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:56.944044      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:57.944162      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:58.944459      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:28:59.944771      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:00.634: INFO: File wheezy_udp@dns-test-service-3.dns-794.svc.cluster.local from pod  dns-794/dns-test-62704113-e301-41d5-80ad-a068c24e67dc contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May 13 15:29:00.636: INFO: File jessie_udp@dns-test-service-3.dns-794.svc.cluster.local from pod  dns-794/dns-test-62704113-e301-41d5-80ad-a068c24e67dc contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May 13 15:29:00.636: INFO: Lookups using dns-794/dns-test-62704113-e301-41d5-80ad-a068c24e67dc failed for: [wheezy_udp@dns-test-service-3.dns-794.svc.cluster.local jessie_udp@dns-test-service-3.dns-794.svc.cluster.local]

  May 13 15:29:00.640: INFO: Pod client logs for webserver: 
  May 13 15:29:00.643: INFO: Pod client logs for querier: 
  May 13 15:29:00.646: INFO: Pod client logs for jessie-querier: 
  E0513 15:29:00.946181      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:01.946366      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:02.946572      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:03.947234      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:04.948000      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:05.634: INFO: File wheezy_udp@dns-test-service-3.dns-794.svc.cluster.local from pod  dns-794/dns-test-62704113-e301-41d5-80ad-a068c24e67dc contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May 13 15:29:05.636: INFO: File jessie_udp@dns-test-service-3.dns-794.svc.cluster.local from pod  dns-794/dns-test-62704113-e301-41d5-80ad-a068c24e67dc contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May 13 15:29:05.636: INFO: Lookups using dns-794/dns-test-62704113-e301-41d5-80ad-a068c24e67dc failed for: [wheezy_udp@dns-test-service-3.dns-794.svc.cluster.local jessie_udp@dns-test-service-3.dns-794.svc.cluster.local]

  May 13 15:29:05.640: INFO: Pod client logs for webserver: 
  May 13 15:29:05.644: INFO: Pod client logs for querier: 
  May 13 15:29:05.647: INFO: Pod client logs for jessie-querier: 
  E0513 15:29:05.948770      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:06.949652      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:07.950450      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:08.951195      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:09.951299      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:10.636: INFO: File jessie_udp@dns-test-service-3.dns-794.svc.cluster.local from pod  dns-794/dns-test-62704113-e301-41d5-80ad-a068c24e67dc contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May 13 15:29:10.636: INFO: Lookups using dns-794/dns-test-62704113-e301-41d5-80ad-a068c24e67dc failed for: [jessie_udp@dns-test-service-3.dns-794.svc.cluster.local]

  May 13 15:29:10.640: INFO: Pod client logs for webserver: 
  May 13 15:29:10.643: INFO: Pod client logs for querier: 
  May 13 15:29:10.646: INFO: Pod client logs for jessie-querier: 
  E0513 15:29:10.951379      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:11.951523      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:12.951874      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:13.951899      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:14.953108      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:15.638: INFO: DNS probes using dns-test-62704113-e301-41d5-80ad-a068c24e67dc succeeded

  STEP: changing the service to type=ClusterIP @ 05/13/24 15:29:15.638
  W0513 15:29:15.646035      17 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-794.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-794.svc.cluster.local; sleep 1; done
   @ 05/13/24 15:29:15.646
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-794.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-794.svc.cluster.local; sleep 1; done
   @ 05/13/24 15:29:15.646
  STEP: creating a third pod to probe DNS @ 05/13/24 15:29:15.646
  STEP: submitting the pod to kubernetes @ 05/13/24 15:29:15.648
  E0513 15:29:15.953289      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:16.953590      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/13/24 15:29:17.659
  STEP: looking for the results for each expected name from probers @ 05/13/24 15:29:17.66
  May 13 15:29:17.666: INFO: DNS probes using dns-test-99067ce7-6c38-4fba-979a-3c8d6058b376 succeeded

  STEP: deleting the pod @ 05/13/24 15:29:17.666
  STEP: deleting the pod @ 05/13/24 15:29:17.675
  STEP: deleting the pod @ 05/13/24 15:29:17.687
  STEP: deleting the test externalName service @ 05/13/24 15:29:17.699
  May 13 15:29:17.723: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-794" for this suite. @ 05/13/24 15:29:17.725
• [40.176 seconds]
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:98
  STEP: Creating a kubernetes client @ 05/13/24 15:29:17.729
  May 13 15:29:17.729: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename aggregator @ 05/13/24 15:29:17.732
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:29:17.743
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:29:17.745
  May 13 15:29:17.746: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Registering the sample API server. @ 05/13/24 15:29:17.747
  E0513 15:29:17.953565      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:18.110: INFO: Found ClusterRoles; assuming RBAC is enabled.
  May 13 15:29:18.138: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
  E0513 15:29:18.954153      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:19.954943      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:20.163: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0513 15:29:20.955737      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:21.955838      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:22.166: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0513 15:29:22.956845      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:23.957893      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:24.166: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0513 15:29:24.958420      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:25.958645      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:26.165: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0513 15:29:26.958792      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:27.959814      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:28.166: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0513 15:29:28.960797      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:29.960959      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:30.165: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0513 15:29:30.961870      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:31.962951      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:32.165: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0513 15:29:32.963981      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:33.964586      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:34.167: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0513 15:29:34.964778      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:35.965185      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:36.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0513 15:29:36.965637      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:37.966343      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:38.165: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0513 15:29:38.966492      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:39.967736      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:40.169: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0513 15:29:40.967886      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:41.968573      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:42.309: INFO: Waited 113.756859ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 05/13/24 15:29:42.361
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 05/13/24 15:29:42.363
  STEP: List APIServices @ 05/13/24 15:29:42.37
  May 13 15:29:42.374: INFO: Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 05/13/24 15:29:42.374
  May 13 15:29:42.385: INFO: APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 05/13/24 15:29:42.385
  May 13 15:29:42.393: INFO: updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2024, time.May, 13, 15, 29, 42, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 05/13/24 15:29:42.395
  May 13 15:29:42.397: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2024-05-13 15:29:42 +0000 UTC Passed all checks passed}
  May 13 15:29:42.397: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  May 13 15:29:42.397: INFO: Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 05/13/24 15:29:42.397
  May 13 15:29:42.403: INFO: Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-123479949" @ 05/13/24 15:29:42.403
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 05/13/24 15:29:42.414
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 05/13/24 15:29:42.419
  STEP: Patch APIService Status @ 05/13/24 15:29:42.421
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 05/13/24 15:29:42.424
  May 13 15:29:42.427: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2024-05-13 15:29:42 +0000 UTC Passed all checks passed}
  May 13 15:29:42.427: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  May 13 15:29:42.427: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  May 13 15:29:42.427: INFO: Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 05/13/24 15:29:42.428
  STEP: Confirm that the generated APIService has been deleted @ 05/13/24 15:29:42.433
  May 13 15:29:42.433: INFO: Requesting list of APIServices to confirm quantity
  May 13 15:29:42.435: INFO: Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  May 13 15:29:42.436: INFO: APIService v1alpha1.wardle.example.com has been deleted.
  May 13 15:29:42.510: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-1639" for this suite. @ 05/13/24 15:29:42.513
• [24.797 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2214
  STEP: Creating a kubernetes client @ 05/13/24 15:29:42.527
  May 13 15:29:42.527: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename services @ 05/13/24 15:29:42.528
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:29:42.539
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:29:42.541
  STEP: creating service in namespace services-7186 @ 05/13/24 15:29:42.543
  STEP: creating service affinity-nodeport in namespace services-7186 @ 05/13/24 15:29:42.543
  STEP: creating replication controller affinity-nodeport in namespace services-7186 @ 05/13/24 15:29:42.557
  I0513 15:29:42.561887      17 runners.go:197] Created replication controller with name: affinity-nodeport, namespace: services-7186, replica count: 3
  E0513 15:29:42.969557      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:43.970845      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:44.970106      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0513 15:29:45.613241      17 runners.go:197] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May 13 15:29:45.632: INFO: Creating new exec pod
  E0513 15:29:45.970702      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:46.970893      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:47.971814      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:48.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-7186 exec execpod-affinityb4r5w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  May 13 15:29:48.778: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  May 13 15:29:48.778: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 13 15:29:48.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-7186 exec execpod-affinityb4r5w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.28.49 80'
  May 13 15:29:48.884: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.28.49 80\nConnection to 10.43.28.49 80 port [tcp/http] succeeded!\n"
  May 13 15:29:48.884: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 13 15:29:48.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-7186 exec execpod-affinityb4r5w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.16.100.5 30567'
  E0513 15:29:48.972757      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:49.013: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.16.100.5 30567\nConnection to 172.16.100.5 30567 port [tcp/*] succeeded!\n"
  May 13 15:29:49.013: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 13 15:29:49.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-7186 exec execpod-affinityb4r5w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.16.100.7 30567'
  May 13 15:29:49.124: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.16.100.7 30567\nConnection to 172.16.100.7 30567 port [tcp/*] succeeded!\n"
  May 13 15:29:49.124: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 13 15:29:49.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-7186 exec execpod-affinityb4r5w -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.16.100.5:30567/ ; done'
  May 13 15:29:49.284: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:30567/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:30567/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:30567/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:30567/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:30567/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:30567/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:30567/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:30567/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:30567/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:30567/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:30567/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:30567/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:30567/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:30567/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:30567/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.16.100.5:30567/\n"
  May 13 15:29:49.284: INFO: stdout: "\naffinity-nodeport-4bf84\naffinity-nodeport-4bf84\naffinity-nodeport-4bf84\naffinity-nodeport-4bf84\naffinity-nodeport-4bf84\naffinity-nodeport-4bf84\naffinity-nodeport-4bf84\naffinity-nodeport-4bf84\naffinity-nodeport-4bf84\naffinity-nodeport-4bf84\naffinity-nodeport-4bf84\naffinity-nodeport-4bf84\naffinity-nodeport-4bf84\naffinity-nodeport-4bf84\naffinity-nodeport-4bf84\naffinity-nodeport-4bf84"
  May 13 15:29:49.284: INFO: Received response from host: affinity-nodeport-4bf84
  May 13 15:29:49.284: INFO: Received response from host: affinity-nodeport-4bf84
  May 13 15:29:49.284: INFO: Received response from host: affinity-nodeport-4bf84
  May 13 15:29:49.284: INFO: Received response from host: affinity-nodeport-4bf84
  May 13 15:29:49.284: INFO: Received response from host: affinity-nodeport-4bf84
  May 13 15:29:49.284: INFO: Received response from host: affinity-nodeport-4bf84
  May 13 15:29:49.284: INFO: Received response from host: affinity-nodeport-4bf84
  May 13 15:29:49.284: INFO: Received response from host: affinity-nodeport-4bf84
  May 13 15:29:49.284: INFO: Received response from host: affinity-nodeport-4bf84
  May 13 15:29:49.284: INFO: Received response from host: affinity-nodeport-4bf84
  May 13 15:29:49.284: INFO: Received response from host: affinity-nodeport-4bf84
  May 13 15:29:49.284: INFO: Received response from host: affinity-nodeport-4bf84
  May 13 15:29:49.284: INFO: Received response from host: affinity-nodeport-4bf84
  May 13 15:29:49.284: INFO: Received response from host: affinity-nodeport-4bf84
  May 13 15:29:49.284: INFO: Received response from host: affinity-nodeport-4bf84
  May 13 15:29:49.284: INFO: Received response from host: affinity-nodeport-4bf84
  May 13 15:29:49.284: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-7186, will wait for the garbage collector to delete the pods @ 05/13/24 15:29:49.296
  May 13 15:29:49.352: INFO: Deleting ReplicationController affinity-nodeport took: 3.242855ms
  May 13 15:29:49.453: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.934937ms
  E0513 15:29:49.973982      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:50.974807      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:51.975680      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:52.668: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7186" for this suite. @ 05/13/24 15:29:52.67
• [10.146 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 05/13/24 15:29:52.674
  May 13 15:29:52.674: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename disruption @ 05/13/24 15:29:52.674
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:29:52.684
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:29:52.686
  STEP: Waiting for the pdb to be processed @ 05/13/24 15:29:52.692
  STEP: Waiting for all pods to be running @ 05/13/24 15:29:52.725
  May 13 15:29:52.729: INFO: running pods: 0 < 3
  E0513 15:29:52.975832      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:53.976751      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:54.728: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-7537" for this suite. @ 05/13/24 15:29:54.73
• [2.062 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:793
  STEP: Creating a kubernetes client @ 05/13/24 15:29:54.737
  May 13 15:29:54.737: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename statefulset @ 05/13/24 15:29:54.738
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:29:54.747
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:29:54.748
  STEP: Creating service test in namespace statefulset-4691 @ 05/13/24 15:29:54.75
  STEP: Looking for a node to schedule stateful set and pod @ 05/13/24 15:29:54.755
  STEP: Creating pod with conflicting port in namespace statefulset-4691 @ 05/13/24 15:29:54.762
  STEP: Waiting until pod test-pod will start running in namespace statefulset-4691 @ 05/13/24 15:29:54.767
  E0513 15:29:54.976813      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:55.977468      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-4691 @ 05/13/24 15:29:56.772
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4691 @ 05/13/24 15:29:56.774
  May 13 15:29:56.787: INFO: Observed stateful pod in namespace: statefulset-4691, name: ss-0, uid: 24fe7aa7-879b-4809-8826-368201512e64, status phase: Pending. Waiting for statefulset controller to delete.
  May 13 15:29:56.792: INFO: Observed stateful pod in namespace: statefulset-4691, name: ss-0, uid: 24fe7aa7-879b-4809-8826-368201512e64, status phase: Failed. Waiting for statefulset controller to delete.
  May 13 15:29:56.800: INFO: Observed stateful pod in namespace: statefulset-4691, name: ss-0, uid: 24fe7aa7-879b-4809-8826-368201512e64, status phase: Failed. Waiting for statefulset controller to delete.
  May 13 15:29:56.801: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-4691
  STEP: Removing pod with conflicting port in namespace statefulset-4691 @ 05/13/24 15:29:56.802
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4691 and will be in running state @ 05/13/24 15:29:56.815
  E0513 15:29:56.977569      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:57.977546      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:29:58.820: INFO: Deleting all statefulset in ns statefulset-4691
  May 13 15:29:58.821: INFO: Scaling statefulset ss to 0
  E0513 15:29:58.978101      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:29:59.978133      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:00.978868      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:01.979531      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:02.979716      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:03.980134      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:04.980866      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:05.980894      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:06.981510      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:07.982258      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:30:08.830: INFO: Waiting for statefulset status.replicas updated to 0
  May 13 15:30:08.833: INFO: Deleting statefulset ss
  May 13 15:30:08.846: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4691" for this suite. @ 05/13/24 15:30:08.85
• [14.116 seconds]
------------------------------
S
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingress.go:558
  STEP: Creating a kubernetes client @ 05/13/24 15:30:08.854
  May 13 15:30:08.854: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename ingress @ 05/13/24 15:30:08.855
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:30:08.865
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:30:08.866
  STEP: getting /apis @ 05/13/24 15:30:08.868
  STEP: getting /apis/networking.k8s.io @ 05/13/24 15:30:08.872
  STEP: getting /apis/networking.k8s.iov1 @ 05/13/24 15:30:08.872
  STEP: creating @ 05/13/24 15:30:08.873
  STEP: getting @ 05/13/24 15:30:08.886
  STEP: listing @ 05/13/24 15:30:08.888
  STEP: watching @ 05/13/24 15:30:08.889
  May 13 15:30:08.889: INFO: starting watch
  STEP: cluster-wide listing @ 05/13/24 15:30:08.889
  STEP: cluster-wide watching @ 05/13/24 15:30:08.89
  May 13 15:30:08.890: INFO: starting watch
  STEP: patching @ 05/13/24 15:30:08.891
  STEP: updating @ 05/13/24 15:30:08.894
  May 13 15:30:08.900: INFO: waiting for watch events with expected annotations
  May 13 15:30:08.901: INFO: saw patched and updated annotations
  STEP: patching /status @ 05/13/24 15:30:08.901
  STEP: updating /status @ 05/13/24 15:30:08.905
  STEP: get /status @ 05/13/24 15:30:08.909
  STEP: deleting @ 05/13/24 15:30:08.911
  STEP: deleting a collection @ 05/13/24 15:30:08.915
  May 13 15:30:08.922: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-316" for this suite. @ 05/13/24 15:30:08.925
• [0.076 seconds]
------------------------------
SS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 05/13/24 15:30:08.93
  May 13 15:30:08.931: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename deployment @ 05/13/24 15:30:08.931
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:30:08.942
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:30:08.943
  May 13 15:30:08.945: INFO: Creating deployment "test-recreate-deployment"
  May 13 15:30:08.947: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
  May 13 15:30:08.957: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
  E0513 15:30:08.982585      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:09.982993      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:30:10.970: INFO: Waiting deployment "test-recreate-deployment" to complete
  May 13 15:30:10.977: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
  E0513 15:30:10.983792      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:30:10.996: INFO: Updating deployment test-recreate-deployment
  May 13 15:30:11.004: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  May 13 15:30:11.057: INFO: Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-275",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "80b4eee7-dd22-41a6-ae3b-9212d3447e33",
      ResourceVersion: (string) (len=5) "15834",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851211008,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851211010,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851211011,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851211011,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851211011,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851211011,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851211008,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=63) "ReplicaSet \"test-recreate-deployment-76fb77d45\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  May 13 15:30:11.083: INFO: New ReplicaSet "test-recreate-deployment-76fb77d45" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-275",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "038be546-91d2-4289-8276-0bc299d3c866",
      ResourceVersion: (string) (len=5) "15832",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851211011,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "80b4eee7-dd22-41a6-ae3b-9212d3447e33",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851211011,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 38 30 62 34 65 65  65 37 2d 64 64 32 32 2d  |\"80b4eee7-dd22-|
              00000120  34 31 61 36 2d 61 65 33  62 2d 39 32 31 32 64 33  |41a6-ae3b-9212d3|
              00000130  34 34 37 65 33 33 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |447e33\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851211011,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 13 15:30:11.088: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
  May 13 15:30:11.088: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-5cf87b5b86",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-275",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "bab08429-c9b3-46f9-93bf-33cf5761f329",
      ResourceVersion: (string) (len=5) "15822",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851211008,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "80b4eee7-dd22-41a6-ae3b-9212d3447e33",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851211010,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 38 30 62 34 65 65  65 37 2d 64 64 32 32 2d  |\"80b4eee7-dd22-|
              00000120  34 31 61 36 2d 61 65 33  62 2d 39 32 31 32 64 33  |41a6-ae3b-9212d3|
              00000130  34 34 37 65 33 33 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |447e33\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851211011,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86",
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86",
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 13 15:30:11.093: INFO: Pod "test-recreate-deployment-76fb77d45-7tdx9" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-recreate-deployment-76fb77d45-7tdx9",
      GenerateName: (string) (len=35) "test-recreate-deployment-76fb77d45-",
      Namespace: (string) (len=14) "deployment-275",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0d8f2074-844e-4cdd-ad53-fbe7e107316e",
      ResourceVersion: (string) (len=5) "15833",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851211011,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
          UID: (types.UID) (len=36) "038be546-91d2-4289-8276-0bc299d3c866",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851211011,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 33  38 62 65 35 34 36 2d 39  |d\":\"038be546-9|
              00000090  31 64 32 2d 34 32 38 39  2d 38 32 37 36 2d 30 62  |1d2-4289-8276-0b|
              000000a0  63 32 39 39 64 33 63 38  36 36 5c 22 7d 22 3a 7b  |c299d3c866\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851211011,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2m25n",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2m25n",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851211011,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851211011,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851211011,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851211011,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851211011,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.5",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.5"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851211011,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:30:11.095: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-275" for this suite. @ 05/13/24 15:30:11.098
• [2.171 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:104
  STEP: Creating a kubernetes client @ 05/13/24 15:30:11.103
  May 13 15:30:11.103: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename replication-controller @ 05/13/24 15:30:11.104
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:30:11.115
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:30:11.117
  STEP: Given a ReplicationController is created @ 05/13/24 15:30:11.118
  STEP: When the matched label of one of its pods change @ 05/13/24 15:30:11.12
  May 13 15:30:11.122: INFO: Pod name pod-release: Found 0 pods out of 1
  E0513 15:30:11.984122      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:12.984468      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:13.985101      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:14.985552      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:15.986183      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:30:16.147: INFO: Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 05/13/24 15:30:16.163
  E0513 15:30:16.986125      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:30:17.170: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-8788" for this suite. @ 05/13/24 15:30:17.173
• [6.074 seconds]
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 05/13/24 15:30:17.177
  May 13 15:30:17.177: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename subjectreview @ 05/13/24 15:30:17.177
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:30:17.188
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:30:17.19
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-9201" @ 05/13/24 15:30:17.191
  May 13 15:30:17.194: INFO: saUsername: "system:serviceaccount:subjectreview-9201:e2e"
  May 13 15:30:17.194: INFO: saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-9201"}
  May 13 15:30:17.194: INFO: saUID: "cbbbdfba-74dd-4145-9f29-0e21c87cd0a5"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-9201:e2e" @ 05/13/24 15:30:17.194
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-9201:e2e" @ 05/13/24 15:30:17.194
  May 13 15:30:17.196: INFO: sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-9201:e2e" api 'list' configmaps in "subjectreview-9201" namespace @ 05/13/24 15:30:17.196
  May 13 15:30:17.198: INFO: SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-9201:e2e" @ 05/13/24 15:30:17.198
  May 13 15:30:17.201: INFO: lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  May 13 15:30:17.201: INFO: LocalSubjectAccessReview has been verified
  May 13 15:30:17.201: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-9201" for this suite. @ 05/13/24 15:30:17.203
• [0.029 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 05/13/24 15:30:17.208
  May 13 15:30:17.208: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename sched-preemption @ 05/13/24 15:30:17.208
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:30:17.218
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:30:17.22
  May 13 15:30:17.228: INFO: Waiting up to 1m0s for all nodes to be ready
  E0513 15:30:17.986840      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:18.987208      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:19.988012      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:20.989006      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:21.989899      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:22.991310      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:23.991754      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:24.992179      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:25.993049      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:26.993282      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:27.994174      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:28.994423      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:29.995169      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:30.995613      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:31.997002      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:32.997465      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:33.997512      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:34.998321      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:35.998637      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:36.999523      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:37.999691      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:39.000558      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:40.000696      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:41.001674      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:42.002179      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:43.002286      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:44.003049      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:45.003759      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:46.004219      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:47.004150      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:48.004408      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:49.004360      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:50.005038      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:51.005245      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:52.005913      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:53.006624      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:54.006792      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:55.007796      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:56.008794      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:57.008823      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:58.009430      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:30:59.010287      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:00.011129      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:01.012611      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:02.012960      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:03.013273      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:04.013737      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:05.014002      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:06.015796      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:07.016019      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:08.016035      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:09.016892      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:10.017743      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:11.018635      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:12.019683      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:13.020012      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:14.021085      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:15.022098      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:16.022986      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:17.023218      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:31:17.242: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 05/13/24 15:31:17.244
  May 13 15:31:17.244: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename sched-preemption-path @ 05/13/24 15:31:17.244
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:31:17.253
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:31:17.256
  May 13 15:31:17.263: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  May 13 15:31:17.265: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  May 13 15:31:17.299: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-4233" for this suite. @ 05/13/24 15:31:17.301
  May 13 15:31:17.304: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-1064" for this suite. @ 05/13/24 15:31:17.308
• [60.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:199
  STEP: Creating a kubernetes client @ 05/13/24 15:31:17.314
  May 13 15:31:17.314: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename webhook @ 05/13/24 15:31:17.315
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:31:17.325
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:31:17.326
  STEP: Setting up server cert @ 05/13/24 15:31:17.342
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/13/24 15:31:17.703
  STEP: Deploying the webhook pod @ 05/13/24 15:31:17.708
  STEP: Wait for the deployment to be ready @ 05/13/24 15:31:17.716
  May 13 15:31:17.737: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0513 15:31:18.024504      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:19.024845      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/13/24 15:31:19.759
  STEP: Verifying the service has paired with the endpoint @ 05/13/24 15:31:19.779
  E0513 15:31:20.024907      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:31:20.780: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 05/13/24 15:31:20.793
  STEP: create a pod that should be denied by the webhook @ 05/13/24 15:31:20.82
  STEP: create a pod that causes the webhook to hang @ 05/13/24 15:31:20.83
  E0513 15:31:21.025625      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:22.027708      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:23.026582      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:24.027301      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:25.027177      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:26.027914      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:27.027960      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:28.028177      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:29.029238      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:30.029411      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create a configmap that should be denied by the webhook @ 05/13/24 15:31:30.835
  STEP: create a configmap that should be admitted by the webhook @ 05/13/24 15:31:30.983
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 05/13/24 15:31:30.991
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 05/13/24 15:31:30.995
  STEP: create a namespace that bypass the webhook @ 05/13/24 15:31:30.998
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 05/13/24 15:31:31.009
  E0513 15:31:31.030703      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:31:31.064: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2097" for this suite. @ 05/13/24 15:31:31.126
  STEP: Destroying namespace "webhook-markers-4266" for this suite. @ 05/13/24 15:31:31.169
  STEP: Destroying namespace "exempted-namespace-5182" for this suite. @ 05/13/24 15:31:31.174
• [13.868 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:131
  STEP: Creating a kubernetes client @ 05/13/24 15:31:31.182
  May 13 15:31:31.182: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename runtimeclass @ 05/13/24 15:31:31.184
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:31:31.196
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:31:31.197
  E0513 15:31:32.031246      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:33.031812      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:31:33.215: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-822" for this suite. @ 05/13/24 15:31:33.218
• [2.040 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:199
  STEP: Creating a kubernetes client @ 05/13/24 15:31:33.222
  May 13 15:31:33.222: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/13/24 15:31:33.223
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:31:33.235
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:31:33.236
  STEP: fetching the /apis discovery document @ 05/13/24 15:31:33.238
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 05/13/24 15:31:33.239
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 05/13/24 15:31:33.239
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 05/13/24 15:31:33.239
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 05/13/24 15:31:33.239
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 05/13/24 15:31:33.24
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 05/13/24 15:31:33.24
  May 13 15:31:33.240: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-778" for this suite. @ 05/13/24 15:31:33.243
• [0.025 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:234
  STEP: Creating a kubernetes client @ 05/13/24 15:31:33.248
  May 13 15:31:33.248: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename resourcequota @ 05/13/24 15:31:33.249
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:31:33.26
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:31:33.261
  STEP: Counting existing ResourceQuota @ 05/13/24 15:31:33.262
  E0513 15:31:34.032785      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:35.034190      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:36.034983      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:37.035651      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:38.036367      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/13/24 15:31:38.269
  STEP: Ensuring resource quota status is calculated @ 05/13/24 15:31:38.277
  E0513 15:31:39.036302      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:40.037008      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 05/13/24 15:31:40.28
  STEP: Ensuring ResourceQuota status captures the pod usage @ 05/13/24 15:31:40.289
  E0513 15:31:41.037423      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:42.038300      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 05/13/24 15:31:42.291
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 05/13/24 15:31:42.293
  STEP: Ensuring a pod cannot update its resource requirements @ 05/13/24 15:31:42.294
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 05/13/24 15:31:42.295
  E0513 15:31:43.038264      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:44.038541      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/13/24 15:31:44.297
  STEP: Ensuring resource quota status released the pod usage @ 05/13/24 15:31:44.307
  E0513 15:31:45.039004      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:46.040154      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:31:46.314: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5431" for this suite. @ 05/13/24 15:31:46.327
• [13.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:168
  STEP: Creating a kubernetes client @ 05/13/24 15:31:46.345
  May 13 15:31:46.345: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename downward-api @ 05/13/24 15:31:46.346
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:31:46.356
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:31:46.357
  STEP: Creating a pod to test downward api env vars @ 05/13/24 15:31:46.359
  E0513 15:31:47.040182      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:48.040961      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:49.041593      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:50.042160      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:31:50.371
  May 13 15:31:50.373: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod downward-api-b1650426-d2c4-47f2-8282-a0fbbe3f869c container dapi-container: <nil>
  STEP: delete the pod @ 05/13/24 15:31:50.382
  May 13 15:31:50.395: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8564" for this suite. @ 05/13/24 15:31:50.398
• [4.057 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:110
  STEP: Creating a kubernetes client @ 05/13/24 15:31:50.407
  May 13 15:31:50.407: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename configmap @ 05/13/24 15:31:50.408
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:31:50.419
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:31:50.421
  STEP: Creating configMap with name configmap-test-volume-map-403a30e4-e579-4c19-b9a4-5b20519f9397 @ 05/13/24 15:31:50.423
  STEP: Creating a pod to test consume configMaps @ 05/13/24 15:31:50.425
  E0513 15:31:51.042568      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:52.042673      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:53.042809      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:54.043019      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:31:54.438
  May 13 15:31:54.439: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-configmaps-e7e8f958-540c-4059-b121-1780b11d7e7d container agnhost-container: <nil>
  STEP: delete the pod @ 05/13/24 15:31:54.448
  May 13 15:31:54.467: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9212" for this suite. @ 05/13/24 15:31:54.473
• [4.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:223
  STEP: Creating a kubernetes client @ 05/13/24 15:31:54.477
  May 13 15:31:54.477: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename downward-api @ 05/13/24 15:31:54.477
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:31:54.496
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:31:54.514
  STEP: Creating a pod to test downward API volume plugin @ 05/13/24 15:31:54.544
  E0513 15:31:55.043999      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:56.044908      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:57.044779      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:31:58.044906      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:31:58.591
  May 13 15:31:58.593: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod downwardapi-volume-3ddb16a4-72af-42fa-9486-00acfc6d2800 container client-container: <nil>
  STEP: delete the pod @ 05/13/24 15:31:58.596
  May 13 15:31:58.606: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6788" for this suite. @ 05/13/24 15:31:58.608
• [4.135 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 05/13/24 15:31:58.613
  May 13 15:31:58.613: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename container-runtime @ 05/13/24 15:31:58.614
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:31:58.626
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:31:58.627
  STEP: create the container @ 05/13/24 15:31:58.628
  W0513 15:31:58.631522      17 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 05/13/24 15:31:58.631
  E0513 15:31:59.045803      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:00.046827      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:01.047144      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/13/24 15:32:01.642
  STEP: the container should be terminated @ 05/13/24 15:32:01.643
  STEP: the termination message should be set @ 05/13/24 15:32:01.643
  May 13 15:32:01.643: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 05/13/24 15:32:01.643
  May 13 15:32:01.651: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-4167" for this suite. @ 05/13/24 15:32:01.654
• [3.045 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 05/13/24 15:32:01.659
  May 13 15:32:01.659: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename dns @ 05/13/24 15:32:01.659
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:32:01.67
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:32:01.672
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5003.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-5003.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 05/13/24 15:32:01.673
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5003.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-5003.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 05/13/24 15:32:01.674
  STEP: creating a pod to probe /etc/hosts @ 05/13/24 15:32:01.674
  STEP: submitting the pod to kubernetes @ 05/13/24 15:32:01.674
  E0513 15:32:02.047693      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:03.048307      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/13/24 15:32:03.695
  STEP: looking for the results for each expected name from probers @ 05/13/24 15:32:03.699
  May 13 15:32:03.711: INFO: DNS probes using dns-5003/dns-test-5a2083a2-466f-4c08-ac37-feb986bf5a48 succeeded

  STEP: deleting the pod @ 05/13/24 15:32:03.711
  May 13 15:32:03.724: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-5003" for this suite. @ 05/13/24 15:32:03.726
• [2.072 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:263
  STEP: Creating a kubernetes client @ 05/13/24 15:32:03.733
  May 13 15:32:03.733: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 15:32:03.735
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:32:03.752
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:32:03.756
  STEP: Creating a pod to test downward API volume plugin @ 05/13/24 15:32:03.76
  E0513 15:32:04.049178      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:05.049967      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:06.050116      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:07.050336      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:32:07.781
  May 13 15:32:07.782: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod downwardapi-volume-f9d66f7f-bc18-4dc2-b114-34d476ff8974 container client-container: <nil>
  STEP: delete the pod @ 05/13/24 15:32:07.786
  May 13 15:32:07.798: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2612" for this suite. @ 05/13/24 15:32:07.837
• [4.174 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:784
  STEP: Creating a kubernetes client @ 05/13/24 15:32:07.907
  May 13 15:32:07.907: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename job @ 05/13/24 15:32:07.907
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:32:07.922
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:32:07.925
  STEP: Creating a job @ 05/13/24 15:32:07.926
  STEP: Ensure pods equal to parallelism count is attached to the job @ 05/13/24 15:32:07.931
  E0513 15:32:08.050766      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:09.050902      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 05/13/24 15:32:09.933
  STEP: updating /status @ 05/13/24 15:32:09.937
  STEP: get /status @ 05/13/24 15:32:09.94
  May 13 15:32:09.941: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8960" for this suite. @ 05/13/24 15:32:09.943
• [2.039 seconds]
------------------------------
SS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 05/13/24 15:32:09.946
  May 13 15:32:09.946: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename init-container @ 05/13/24 15:32:09.947
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:32:09.958
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:32:09.96
  STEP: creating the pod @ 05/13/24 15:32:09.961
  May 13 15:32:09.961: INFO: PodSpec: initContainers in spec.initContainers
  E0513 15:32:10.051580      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:11.052544      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:12.052600      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:13.053277      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:14.053626      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:15.054220      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:16.058549      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:17.054493      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:18.054639      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:19.054800      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:20.055777      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:21.055821      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:22.056661      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:23.056711      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:24.058937      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:25.059859      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:26.059878      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:27.060757      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:28.060832      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:29.062330      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:30.062678      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:31.063099      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:32.063478      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:33.064697      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:34.065828      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:35.066585      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:36.066889      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:37.067386      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:38.067650      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:39.068309      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:40.069678      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:41.070093      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:42.071264      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:43.071728      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:44.072275      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:45.072609      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:46.072242      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:47.072485      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:48.073109      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:49.072892      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:50.073936      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:51.074421      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:52.074290      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:53.074619      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:54.075033      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:32:54.183: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-7855c3da-7cbb-43c6-b7ef-f176e95d2594", GenerateName:"", Namespace:"init-container-8798", SelfLink:"", UID:"38e422f6-7b75-416a-8006-49b0ce0cbd3c", ResourceVersion:"17092", Generation:0, CreationTimestamp:time.Date(2024, time.May, 13, 15, 32, 9, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"961257237"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"87f1ba4c2bb14ed72bdb21c488241b305fcc2d9a13ff1c882847173176938de2", "cni.projectcalico.org/podIP":"10.42.1.137/32", "cni.projectcalico.org/podIPs":"10.42.1.137/32", "k8s.v1.cni.cncf.io/network-status":"[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.1.137\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 15, 32, 9, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001011f38), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 15, 32, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001011f68), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"multus", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 15, 32, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001011fb0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 15, 32, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004fe2000), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-c2l5n", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0039da740), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-c2l5n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-c2l5n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-c2l5n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000d1da18), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"oneke-ip-172-16-100-5", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0002a88c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000d1db10)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000d1db30)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc000d1db38), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc000d1db3c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc003eb09c0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 13, 15, 32, 11, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 13, 15, 32, 9, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 13, 15, 32, 9, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 13, 15, 32, 9, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 13, 15, 32, 9, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.16.100.5", HostIPs:[]v1.HostIP{v1.HostIP{IP:"172.16.100.5"}}, PodIP:"10.42.1.137", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.42.1.137"}}, StartTime:time.Date(2024, time.May, 13, 15, 32, 9, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0002a89a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0002a8a80)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9", ContainerID:"containerd://6b56c8f3529461dfb484179285d86488bbaa2ddc767f74d69d94e7ebcbcb3aba", Started:(*bool)(0xc000d1dbda), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0039da7a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc000d1dbef), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0039da780), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc000d1dbbf), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  May 13 15:32:54.183: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-8798" for this suite. @ 05/13/24 15:32:54.186
• [44.244 seconds]
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:46
  STEP: Creating a kubernetes client @ 05/13/24 15:32:54.191
  May 13 15:32:54.191: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename downward-api @ 05/13/24 15:32:54.191
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:32:54.201
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:32:54.202
  STEP: Creating a pod to test downward api env vars @ 05/13/24 15:32:54.203
  E0513 15:32:55.075847      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:56.076154      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:57.076414      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:32:58.077004      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:32:58.214
  May 13 15:32:58.216: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod downward-api-13b39ca3-3ff9-40ed-8f89-e1005cca4d7e container dapi-container: <nil>
  STEP: delete the pod @ 05/13/24 15:32:58.219
  May 13 15:32:58.230: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4221" for this suite. @ 05/13/24 15:32:58.235
• [4.049 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:135
  STEP: Creating a kubernetes client @ 05/13/24 15:32:58.241
  May 13 15:32:58.241: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename security-context @ 05/13/24 15:32:58.241
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:32:58.25
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:32:58.251
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 05/13/24 15:32:58.253
  E0513 15:32:59.077153      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:00.077473      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:01.078542      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:02.079118      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:33:02.27
  May 13 15:33:02.273: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod security-context-0cd150f9-8344-4a84-ad65-c0371f6f01bb container test-container: <nil>
  STEP: delete the pod @ 05/13/24 15:33:02.281
  May 13 15:33:02.292: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-4532" for this suite. @ 05/13/24 15:33:02.295
• [4.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:160
  STEP: Creating a kubernetes client @ 05/13/24 15:33:02.307
  May 13 15:33:02.307: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename emptydir @ 05/13/24 15:33:02.308
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:33:02.32
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:33:02.327
  STEP: Creating a pod to test emptydir volume type on node default medium @ 05/13/24 15:33:02.328
  E0513 15:33:03.078936      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:04.080288      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:05.080149      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:06.080752      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:33:06.354
  May 13 15:33:06.360: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-a3735f5c-2b20-41f3-b8ef-966520e7cdb6 container test-container: <nil>
  STEP: delete the pod @ 05/13/24 15:33:06.375
  May 13 15:33:06.387: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1409" for this suite. @ 05/13/24 15:33:06.389
• [4.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 05/13/24 15:33:06.394
  May 13 15:33:06.394: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename disruption @ 05/13/24 15:33:06.395
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:33:06.406
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:33:06.407
  STEP: Creating a kubernetes client @ 05/13/24 15:33:06.408
  May 13 15:33:06.408: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename disruption-2 @ 05/13/24 15:33:06.409
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:33:06.419
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:33:06.421
  STEP: Waiting for the pdb to be processed @ 05/13/24 15:33:06.424
  E0513 15:33:07.080887      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:08.081309      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 05/13/24 15:33:08.434
  STEP: Waiting for the pdb to be processed @ 05/13/24 15:33:08.446
  STEP: listing a collection of PDBs across all namespaces @ 05/13/24 15:33:08.449
  STEP: listing a collection of PDBs in namespace disruption-9077 @ 05/13/24 15:33:08.451
  STEP: deleting a collection of PDBs @ 05/13/24 15:33:08.452
  STEP: Waiting for the PDB collection to be deleted @ 05/13/24 15:33:08.456
  May 13 15:33:08.457: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-9480" for this suite. @ 05/13/24 15:33:08.459
  May 13 15:33:08.463: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9077" for this suite. @ 05/13/24 15:33:08.465
• [2.074 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 05/13/24 15:33:08.469
  May 13 15:33:08.469: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename proxy @ 05/13/24 15:33:08.47
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:33:08.479
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:33:08.481
  May 13 15:33:08.483: INFO: Creating pod...
  E0513 15:33:09.081312      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:10.082049      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:33:10.500: INFO: Creating service...
  May 13 15:33:10.522: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-4383/pods/agnhost/proxy/some/path/with/DELETE
  May 13 15:33:10.529: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  May 13 15:33:10.530: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-4383/pods/agnhost/proxy/some/path/with/GET
  May 13 15:33:10.533: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  May 13 15:33:10.533: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-4383/pods/agnhost/proxy/some/path/with/HEAD
  May 13 15:33:10.535: INFO: http.Client request:HEAD | StatusCode:200
  May 13 15:33:10.535: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-4383/pods/agnhost/proxy/some/path/with/OPTIONS
  May 13 15:33:10.537: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  May 13 15:33:10.537: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-4383/pods/agnhost/proxy/some/path/with/PATCH
  May 13 15:33:10.538: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  May 13 15:33:10.538: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-4383/pods/agnhost/proxy/some/path/with/POST
  May 13 15:33:10.540: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  May 13 15:33:10.541: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-4383/pods/agnhost/proxy/some/path/with/PUT
  May 13 15:33:10.542: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  May 13 15:33:10.542: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-4383/services/test-service/proxy/some/path/with/DELETE
  May 13 15:33:10.546: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  May 13 15:33:10.546: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-4383/services/test-service/proxy/some/path/with/GET
  May 13 15:33:10.547: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  May 13 15:33:10.547: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-4383/services/test-service/proxy/some/path/with/HEAD
  May 13 15:33:10.549: INFO: http.Client request:HEAD | StatusCode:200
  May 13 15:33:10.550: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-4383/services/test-service/proxy/some/path/with/OPTIONS
  May 13 15:33:10.552: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  May 13 15:33:10.552: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-4383/services/test-service/proxy/some/path/with/PATCH
  May 13 15:33:10.554: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  May 13 15:33:10.554: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-4383/services/test-service/proxy/some/path/with/POST
  May 13 15:33:10.556: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  May 13 15:33:10.556: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-4383/services/test-service/proxy/some/path/with/PUT
  May 13 15:33:10.558: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  May 13 15:33:10.558: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-4383" for this suite. @ 05/13/24 15:33:10.561
• [2.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 05/13/24 15:33:10.565
  May 13 15:33:10.565: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename secrets @ 05/13/24 15:33:10.565
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:33:10.577
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:33:10.578
  May 13 15:33:10.611: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1626" for this suite. @ 05/13/24 15:33:10.614
• [0.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:254
  STEP: Creating a kubernetes client @ 05/13/24 15:33:10.618
  May 13 15:33:10.618: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename namespaces @ 05/13/24 15:33:10.618
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:33:10.627
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:33:10.628
  STEP: Creating a test namespace @ 05/13/24 15:33:10.63
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:33:10.638
  STEP: Creating a service in the namespace @ 05/13/24 15:33:10.64
  STEP: Deleting the namespace @ 05/13/24 15:33:10.646
  STEP: Waiting for the namespace to be removed. @ 05/13/24 15:33:10.656
  E0513 15:33:11.083085      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:12.083536      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:13.083519      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:14.083892      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:15.084825      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:16.085067      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 05/13/24 15:33:16.663
  STEP: Verifying there is no service in the namespace @ 05/13/24 15:33:16.678
  May 13 15:33:16.680: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-2150" for this suite. @ 05/13/24 15:33:16.682
  STEP: Destroying namespace "nsdeletetest-7336" for this suite. @ 05/13/24 15:33:16.686
  May 13 15:33:16.688: INFO: Namespace nsdeletetest-7336 was already deleted
  STEP: Destroying namespace "nsdeletetest-2467" for this suite. @ 05/13/24 15:33:16.688
• [6.075 seconds]
------------------------------
SS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 05/13/24 15:33:16.693
  May 13 15:33:16.693: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename endpointslicemirroring @ 05/13/24 15:33:16.693
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:33:16.704
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:33:16.705
  STEP: mirroring a new custom Endpoint @ 05/13/24 15:33:16.713
  May 13 15:33:16.718: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
  E0513 15:33:17.085790      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:18.086066      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 05/13/24 15:33:18.721
  May 13 15:33:18.727: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  E0513 15:33:19.086871      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:20.086863      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring deletion of a custom Endpoint @ 05/13/24 15:33:20.739
  May 13 15:33:20.763: INFO: Waiting for 0 EndpointSlices to exist, got 1
  E0513 15:33:21.087435      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:22.087751      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:33:22.766: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-3803" for this suite. @ 05/13/24 15:33:22.768
• [6.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:90
  STEP: Creating a kubernetes client @ 05/13/24 15:33:22.773
  May 13 15:33:22.773: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 15:33:22.773
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:33:22.785
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:33:22.786
  STEP: Creating configMap with name projected-configmap-test-volume-map-91d75184-67ce-4182-9604-2b2fd111d6cc @ 05/13/24 15:33:22.788
  STEP: Creating a pod to test consume configMaps @ 05/13/24 15:33:22.79
  E0513 15:33:23.087916      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:24.088123      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:25.088321      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:26.088625      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:33:26.81
  May 13 15:33:26.811: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-projected-configmaps-d50357ae-f65d-4cdf-8e56-0aa6d8e8a74f container agnhost-container: <nil>
  STEP: delete the pod @ 05/13/24 15:33:26.815
  May 13 15:33:26.824: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5909" for this suite. @ 05/13/24 15:33:26.828
• [4.059 seconds]
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 05/13/24 15:33:26.831
  May 13 15:33:26.831: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename dns @ 05/13/24 15:33:26.832
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:33:26.844
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:33:26.845
  STEP: Creating a test headless service @ 05/13/24 15:33:26.847
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-228 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-228;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-228 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-228;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-228.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-228.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-228.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-228.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-228.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-228.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-228.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-228.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-228.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-228.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-228.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-228.svc;check="$$(dig +notcp +noall +answer +search 124.237.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.237.124_udp@PTR;check="$$(dig +tcp +noall +answer +search 124.237.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.237.124_tcp@PTR;sleep 1; done
   @ 05/13/24 15:33:26.862
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-228 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-228;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-228 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-228;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-228.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-228.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-228.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-228.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-228.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-228.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-228.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-228.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-228.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-228.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-228.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-228.svc;check="$$(dig +notcp +noall +answer +search 124.237.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.237.124_udp@PTR;check="$$(dig +tcp +noall +answer +search 124.237.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.237.124_tcp@PTR;sleep 1; done
   @ 05/13/24 15:33:26.863
  STEP: creating a pod to probe DNS @ 05/13/24 15:33:26.863
  STEP: submitting the pod to kubernetes @ 05/13/24 15:33:26.863
  E0513 15:33:27.089701      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:28.090658      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/13/24 15:33:28.88
  STEP: looking for the results for each expected name from probers @ 05/13/24 15:33:28.881
  May 13 15:33:28.888: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:28.893: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:28.899: INFO: Unable to read wheezy_udp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:28.901: INFO: Unable to read wheezy_tcp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:28.904: INFO: Unable to read wheezy_udp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:28.906: INFO: Unable to read wheezy_tcp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:28.908: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:28.911: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:28.925: INFO: Unable to read jessie_udp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:28.927: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:28.929: INFO: Unable to read jessie_udp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:28.931: INFO: Unable to read jessie_tcp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:28.933: INFO: Unable to read jessie_udp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:28.935: INFO: Unable to read jessie_tcp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:28.937: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:28.939: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:28.949: INFO: Lookups using dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-228 wheezy_tcp@dns-test-service.dns-228 wheezy_udp@dns-test-service.dns-228.svc wheezy_tcp@dns-test-service.dns-228.svc wheezy_udp@_http._tcp.dns-test-service.dns-228.svc wheezy_tcp@_http._tcp.dns-test-service.dns-228.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-228 jessie_tcp@dns-test-service.dns-228 jessie_udp@dns-test-service.dns-228.svc jessie_tcp@dns-test-service.dns-228.svc jessie_udp@_http._tcp.dns-test-service.dns-228.svc jessie_tcp@_http._tcp.dns-test-service.dns-228.svc]

  May 13 15:33:28.961: INFO: Pod client logs for webserver: 
  May 13 15:33:28.966: INFO: Pod client logs for querier: 
  May 13 15:33:28.975: INFO: Pod client logs for jessie-querier: 
  E0513 15:33:29.091661      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:30.092077      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:31.092483      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:32.093861      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:33.093762      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:33:33.884: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:33.886: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:33.888: INFO: Unable to read wheezy_udp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:33.889: INFO: Unable to read wheezy_tcp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:33.890: INFO: Unable to read wheezy_udp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:33.892: INFO: Unable to read wheezy_tcp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:33.893: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:33.894: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:33.904: INFO: Unable to read jessie_udp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:33.905: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:33.907: INFO: Unable to read jessie_udp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:33.910: INFO: Unable to read jessie_tcp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:33.911: INFO: Unable to read jessie_udp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:33.912: INFO: Unable to read jessie_tcp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:33.914: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:33.915: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:33.920: INFO: Lookups using dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-228 wheezy_tcp@dns-test-service.dns-228 wheezy_udp@dns-test-service.dns-228.svc wheezy_tcp@dns-test-service.dns-228.svc wheezy_udp@_http._tcp.dns-test-service.dns-228.svc wheezy_tcp@_http._tcp.dns-test-service.dns-228.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-228 jessie_tcp@dns-test-service.dns-228 jessie_udp@dns-test-service.dns-228.svc jessie_tcp@dns-test-service.dns-228.svc jessie_udp@_http._tcp.dns-test-service.dns-228.svc jessie_tcp@_http._tcp.dns-test-service.dns-228.svc]

  May 13 15:33:33.924: INFO: Pod client logs for webserver: 
  May 13 15:33:33.926: INFO: Pod client logs for querier: 
  May 13 15:33:33.929: INFO: Pod client logs for jessie-querier: 
  E0513 15:33:34.094870      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:35.094923      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:36.095115      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:37.095442      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:38.095538      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:33:38.884: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:38.886: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:38.887: INFO: Unable to read wheezy_udp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:38.889: INFO: Unable to read wheezy_tcp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:38.890: INFO: Unable to read wheezy_udp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:38.891: INFO: Unable to read wheezy_tcp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:38.893: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:38.894: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:38.904: INFO: Unable to read jessie_udp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:38.905: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:38.907: INFO: Unable to read jessie_udp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:38.908: INFO: Unable to read jessie_tcp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:38.909: INFO: Unable to read jessie_udp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:38.911: INFO: Unable to read jessie_tcp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:38.912: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:38.914: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:38.919: INFO: Lookups using dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-228 wheezy_tcp@dns-test-service.dns-228 wheezy_udp@dns-test-service.dns-228.svc wheezy_tcp@dns-test-service.dns-228.svc wheezy_udp@_http._tcp.dns-test-service.dns-228.svc wheezy_tcp@_http._tcp.dns-test-service.dns-228.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-228 jessie_tcp@dns-test-service.dns-228 jessie_udp@dns-test-service.dns-228.svc jessie_tcp@dns-test-service.dns-228.svc jessie_udp@_http._tcp.dns-test-service.dns-228.svc jessie_tcp@_http._tcp.dns-test-service.dns-228.svc]

  May 13 15:33:38.922: INFO: Pod client logs for webserver: 
  May 13 15:33:38.925: INFO: Pod client logs for querier: 
  May 13 15:33:38.928: INFO: Pod client logs for jessie-querier: 
  E0513 15:33:39.095973      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:40.096396      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:41.097336      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:42.097271      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:43.097634      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:33:43.884: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:43.885: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:43.887: INFO: Unable to read wheezy_udp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:43.888: INFO: Unable to read wheezy_tcp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:43.889: INFO: Unable to read wheezy_udp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:43.891: INFO: Unable to read wheezy_tcp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:43.892: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:43.893: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:43.902: INFO: Unable to read jessie_udp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:43.904: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:43.906: INFO: Unable to read jessie_udp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:43.907: INFO: Unable to read jessie_tcp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:43.910: INFO: Unable to read jessie_udp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:43.911: INFO: Unable to read jessie_tcp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:43.913: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:43.914: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:43.919: INFO: Lookups using dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-228 wheezy_tcp@dns-test-service.dns-228 wheezy_udp@dns-test-service.dns-228.svc wheezy_tcp@dns-test-service.dns-228.svc wheezy_udp@_http._tcp.dns-test-service.dns-228.svc wheezy_tcp@_http._tcp.dns-test-service.dns-228.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-228 jessie_tcp@dns-test-service.dns-228 jessie_udp@dns-test-service.dns-228.svc jessie_tcp@dns-test-service.dns-228.svc jessie_udp@_http._tcp.dns-test-service.dns-228.svc jessie_tcp@_http._tcp.dns-test-service.dns-228.svc]

  May 13 15:33:43.922: INFO: Pod client logs for webserver: 
  May 13 15:33:43.926: INFO: Pod client logs for querier: 
  May 13 15:33:43.929: INFO: Pod client logs for jessie-querier: 
  E0513 15:33:44.097793      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:45.099071      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:46.098879      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:47.099650      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:48.099859      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:33:48.885: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:48.886: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:48.887: INFO: Unable to read wheezy_udp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:48.889: INFO: Unable to read wheezy_tcp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:48.890: INFO: Unable to read wheezy_udp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:48.891: INFO: Unable to read wheezy_tcp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:48.892: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:48.894: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:48.905: INFO: Unable to read jessie_udp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:48.907: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:48.908: INFO: Unable to read jessie_udp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:48.910: INFO: Unable to read jessie_tcp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:48.911: INFO: Unable to read jessie_udp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:48.918: INFO: Unable to read jessie_tcp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:48.920: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:48.926: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:48.934: INFO: Lookups using dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-228 wheezy_tcp@dns-test-service.dns-228 wheezy_udp@dns-test-service.dns-228.svc wheezy_tcp@dns-test-service.dns-228.svc wheezy_udp@_http._tcp.dns-test-service.dns-228.svc wheezy_tcp@_http._tcp.dns-test-service.dns-228.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-228 jessie_tcp@dns-test-service.dns-228 jessie_udp@dns-test-service.dns-228.svc jessie_tcp@dns-test-service.dns-228.svc jessie_udp@_http._tcp.dns-test-service.dns-228.svc jessie_tcp@_http._tcp.dns-test-service.dns-228.svc]

  May 13 15:33:48.937: INFO: Pod client logs for webserver: 
  May 13 15:33:48.941: INFO: Pod client logs for querier: 
  May 13 15:33:48.945: INFO: Pod client logs for jessie-querier: 
  E0513 15:33:49.100386      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:50.100970      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:51.101455      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:52.103184      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:53.103328      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:33:53.885: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:53.887: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:53.888: INFO: Unable to read wheezy_udp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:53.890: INFO: Unable to read wheezy_tcp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:53.891: INFO: Unable to read wheezy_udp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:53.893: INFO: Unable to read wheezy_tcp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:53.894: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:53.896: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:53.906: INFO: Unable to read jessie_udp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:53.910: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:53.912: INFO: Unable to read jessie_udp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:53.914: INFO: Unable to read jessie_tcp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:53.915: INFO: Unable to read jessie_udp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:53.917: INFO: Unable to read jessie_tcp@dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:53.919: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:53.921: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:53.927: INFO: Lookups using dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-228 wheezy_tcp@dns-test-service.dns-228 wheezy_udp@dns-test-service.dns-228.svc wheezy_tcp@dns-test-service.dns-228.svc wheezy_udp@_http._tcp.dns-test-service.dns-228.svc wheezy_tcp@_http._tcp.dns-test-service.dns-228.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-228 jessie_tcp@dns-test-service.dns-228 jessie_udp@dns-test-service.dns-228.svc jessie_tcp@dns-test-service.dns-228.svc jessie_udp@_http._tcp.dns-test-service.dns-228.svc jessie_tcp@_http._tcp.dns-test-service.dns-228.svc]

  May 13 15:33:53.930: INFO: Pod client logs for webserver: 
  May 13 15:33:53.933: INFO: Pod client logs for querier: 
  May 13 15:33:53.936: INFO: Pod client logs for jessie-querier: 
  E0513 15:33:54.103916      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:55.103813      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:56.104835      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:57.105881      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:33:58.106267      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:33:58.890: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:58.918: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:58.936: INFO: Unable to read wheezy_udp@dns-test-service.dns-228 from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:58.992: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:58.994: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-228.svc from pod dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f: the server could not find the requested resource (get pods dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f)
  May 13 15:33:59.029: INFO: Lookups using dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-228 wheezy_udp@_http._tcp.dns-test-service.dns-228.svc wheezy_tcp@_http._tcp.dns-test-service.dns-228.svc]

  May 13 15:33:59.033: INFO: Pod client logs for webserver: 
  May 13 15:33:59.036: INFO: Pod client logs for querier: 
  May 13 15:33:59.039: INFO: Pod client logs for jessie-querier: 
  E0513 15:33:59.106573      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:00.106925      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:01.107032      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:02.107330      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:03.107525      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:34:03.929: INFO: DNS probes using dns-228/dns-test-c3d0bac7-493e-43fe-abe3-5153610e046f succeeded

  STEP: deleting the pod @ 05/13/24 15:34:03.929
  STEP: deleting the test service @ 05/13/24 15:34:03.954
  STEP: deleting the test headless service @ 05/13/24 15:34:03.976
  May 13 15:34:03.989: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-228" for this suite. @ 05/13/24 15:34:03.994
• [37.166 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:230
  STEP: Creating a kubernetes client @ 05/13/24 15:34:04.001
  May 13 15:34:04.001: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename emptydir @ 05/13/24 15:34:04.002
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:34:04.012
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:34:04.014
  STEP: Creating Pod @ 05/13/24 15:34:04.015
  E0513 15:34:04.108553      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:05.111227      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 05/13/24 15:34:06.027
  May 13 15:34:06.027: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-389 PodName:pod-sharedvolume-4905d998-277a-4ab7-9f0f-a29b25c1fb44 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 15:34:06.027: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 15:34:06.028: INFO: ExecWithOptions: Clientset creation
  May 13 15:34:06.028: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/emptydir-389/pods/pod-sharedvolume-4905d998-277a-4ab7-9f0f-a29b25c1fb44/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  May 13 15:34:06.092: INFO: Exec stderr: ""
  May 13 15:34:06.093: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-389" for this suite. @ 05/13/24 15:34:06.096
• [2.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:166
  STEP: Creating a kubernetes client @ 05/13/24 15:34:06.105
  May 13 15:34:06.105: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename replicaset @ 05/13/24 15:34:06.106
  E0513 15:34:06.125037      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:34:06.13
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:34:06.135
  STEP: Create a ReplicaSet @ 05/13/24 15:34:06.137
  STEP: Verify that the required pods have come up @ 05/13/24 15:34:06.142
  May 13 15:34:06.145: INFO: Pod name sample-pod: Found 0 pods out of 3
  E0513 15:34:07.113038      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:08.113820      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:09.114024      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:10.114715      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:11.115497      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:34:11.148: INFO: Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 05/13/24 15:34:11.15
  May 13 15:34:11.156: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 05/13/24 15:34:11.156
  STEP: DeleteCollection of the ReplicaSets @ 05/13/24 15:34:11.158
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 05/13/24 15:34:11.165
  May 13 15:34:11.174: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3323" for this suite. @ 05/13/24 15:34:11.19
• [5.090 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 05/13/24 15:34:11.196
  May 13 15:34:11.196: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename secrets @ 05/13/24 15:34:11.197
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:34:11.21
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:34:11.212
  STEP: Creating secret with name secret-test-ae66927e-f6e9-4c93-b620-1dd9f881d49b @ 05/13/24 15:34:11.216
  STEP: Creating a pod to test consume secrets @ 05/13/24 15:34:11.22
  E0513 15:34:12.116206      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:13.116463      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:14.117355      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:15.118416      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:34:15.236
  May 13 15:34:15.238: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-secrets-e93451a9-cf6a-4abe-90a8-e384d4aaef73 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/13/24 15:34:15.241
  May 13 15:34:15.251: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-640" for this suite. @ 05/13/24 15:34:15.253
• [4.062 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1533
  STEP: Creating a kubernetes client @ 05/13/24 15:34:15.26
  May 13 15:34:15.260: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename services @ 05/13/24 15:34:15.261
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:34:15.273
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:34:15.275
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-6329 @ 05/13/24 15:34:15.277
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 05/13/24 15:34:15.283
  STEP: creating service externalsvc in namespace services-6329 @ 05/13/24 15:34:15.283
  STEP: creating replication controller externalsvc in namespace services-6329 @ 05/13/24 15:34:15.304
  I0513 15:34:15.314342      17 runners.go:197] Created replication controller with name: externalsvc, namespace: services-6329, replica count: 2
  E0513 15:34:16.119306      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:17.119537      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:18.119631      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0513 15:34:18.374722      17 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 05/13/24 15:34:18.379
  May 13 15:34:18.393: INFO: Creating new exec pod
  E0513 15:34:19.120684      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:20.122370      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:34:20.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-6329 exec execpodvwspp -- /bin/sh -x -c nslookup nodeport-service.services-6329.svc.cluster.local'
  May 13 15:34:20.627: INFO: stderr: "+ nslookup nodeport-service.services-6329.svc.cluster.local\n"
  May 13 15:34:20.627: INFO: stdout: "Server:\t\t10.43.0.10\nAddress:\t10.43.0.10#53\n\nnodeport-service.services-6329.svc.cluster.local\tcanonical name = externalsvc.services-6329.svc.cluster.local.\nName:\texternalsvc.services-6329.svc.cluster.local\nAddress: 10.43.176.139\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-6329, will wait for the garbage collector to delete the pods @ 05/13/24 15:34:20.627
  May 13 15:34:20.683: INFO: Deleting ReplicationController externalsvc took: 3.693028ms
  May 13 15:34:20.784: INFO: Terminating ReplicationController externalsvc pods took: 101.255084ms
  E0513 15:34:21.121522      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:22.122679      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:23.122810      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:34:23.607: INFO: Cleaning up the NodePort to ExternalName test service
  May 13 15:34:23.618: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6329" for this suite. @ 05/13/24 15:34:23.623
• [8.370 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:112
  STEP: Creating a kubernetes client @ 05/13/24 15:34:23.631
  May 13 15:34:23.631: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename replicaset @ 05/13/24 15:34:23.632
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:34:23.689
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:34:23.692
  May 13 15:34:23.695: INFO: Creating ReplicaSet my-hostname-basic-71905791-bb52-4588-bccf-66090758ca23
  May 13 15:34:23.702: INFO: Pod name my-hostname-basic-71905791-bb52-4588-bccf-66090758ca23: Found 0 pods out of 1
  E0513 15:34:24.123780      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:25.124413      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:26.125577      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:27.126158      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:28.126295      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:34:28.705: INFO: Pod name my-hostname-basic-71905791-bb52-4588-bccf-66090758ca23: Found 1 pods out of 1
  May 13 15:34:28.706: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-71905791-bb52-4588-bccf-66090758ca23" is running
  May 13 15:34:28.714: INFO: Pod "my-hostname-basic-71905791-bb52-4588-bccf-66090758ca23-4rnsd" is running (conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-13 15:34:24 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-13 15:34:23 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-13 15:34:24 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-13 15:34:24 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-13 15:34:23 +0000 UTC Reason: Message:}])
  May 13 15:34:28.716: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 05/13/24 15:34:28.716
  May 13 15:34:28.727: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-8393" for this suite. @ 05/13/24 15:34:28.731
• [5.104 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:150
  STEP: Creating a kubernetes client @ 05/13/24 15:34:28.735
  May 13 15:34:28.735: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename emptydir @ 05/13/24 15:34:28.736
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:34:28.748
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:34:28.757
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 05/13/24 15:34:28.765
  E0513 15:34:29.127414      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:30.127621      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:31.128431      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:32.128634      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:34:32.788
  May 13 15:34:32.795: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-d6588caf-99cd-4069-81ae-37ca49459608 container test-container: <nil>
  STEP: delete the pod @ 05/13/24 15:34:32.799
  May 13 15:34:32.809: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9084" for this suite. @ 05/13/24 15:34:32.812
• [4.081 seconds]
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 05/13/24 15:34:32.816
  May 13 15:34:32.816: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename csiinlinevolumes @ 05/13/24 15:34:32.817
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:34:32.83
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:34:32.831
  STEP: Creating two CSIDrivers @ 05/13/24 15:34:32.833
  STEP: Getting "inline-driver-80fc1522-1c54-4c3a-8ef4-ae5bbb68424a" & "inline-driver-b0e33bd0-5e8b-4d82-b80e-c7fac1e1c17d" @ 05/13/24 15:34:32.843
  STEP: Patching the CSIDriver "inline-driver-b0e33bd0-5e8b-4d82-b80e-c7fac1e1c17d" @ 05/13/24 15:34:32.845
  STEP: Updating the CSIDriver "inline-driver-b0e33bd0-5e8b-4d82-b80e-c7fac1e1c17d" @ 05/13/24 15:34:32.849
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-5254" @ 05/13/24 15:34:32.855
  STEP: Deleting CSIDriver "inline-driver-80fc1522-1c54-4c3a-8ef4-ae5bbb68424a" @ 05/13/24 15:34:32.856
  STEP: Confirm deletion of CSIDriver "inline-driver-80fc1522-1c54-4c3a-8ef4-ae5bbb68424a" @ 05/13/24 15:34:32.859
  STEP: Deleting CSIDriver "inline-driver-b0e33bd0-5e8b-4d82-b80e-c7fac1e1c17d" via DeleteCollection @ 05/13/24 15:34:32.86
  STEP: Confirm deletion of CSIDriver "inline-driver-b0e33bd0-5e8b-4d82-b80e-c7fac1e1c17d" @ 05/13/24 15:34:32.862
  May 13 15:34:32.864: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-5254" for this suite. @ 05/13/24 15:34:32.867
• [0.054 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:189
  STEP: Creating a kubernetes client @ 05/13/24 15:34:32.871
  May 13 15:34:32.871: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename var-expansion @ 05/13/24 15:34:32.871
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:34:32.881
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:34:32.882
  E0513 15:34:33.129028      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:34.129833      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:34:34.895: INFO: Deleting pod "var-expansion-ac3cf635-a3f0-47ea-b16f-385ba4f78620" in namespace "var-expansion-7602"
  May 13 15:34:34.901: INFO: Wait up to 5m0s for pod "var-expansion-ac3cf635-a3f0-47ea-b16f-385ba4f78620" to be fully deleted
  E0513 15:34:35.130903      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:36.131162      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:34:36.908: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7602" for this suite. @ 05/13/24 15:34:36.917
• [4.068 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:209
  STEP: Creating a kubernetes client @ 05/13/24 15:34:36.943
  May 13 15:34:36.943: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename downward-api @ 05/13/24 15:34:36.944
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:34:36.959
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:34:36.96
  STEP: Creating a pod to test downward API volume plugin @ 05/13/24 15:34:36.962
  E0513 15:34:37.131885      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:38.131908      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:39.132595      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:40.133137      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:34:40.98
  May 13 15:34:40.985: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod downwardapi-volume-c232f3b6-7f08-43a5-8a1f-471ff78ad714 container client-container: <nil>
  STEP: delete the pod @ 05/13/24 15:34:40.996
  May 13 15:34:41.012: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2461" for this suite. @ 05/13/24 15:34:41.014
• [4.074 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:539
  STEP: Creating a kubernetes client @ 05/13/24 15:34:41.021
  May 13 15:34:41.021: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename gc @ 05/13/24 15:34:41.021
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:34:41.031
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:34:41.032
  STEP: create the deployment @ 05/13/24 15:34:41.034
  W0513 15:34:41.038705      17 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 05/13/24 15:34:41.038
  E0513 15:34:41.134018      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 05/13/24 15:34:41.546
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 05/13/24 15:34:41.555
  STEP: Gathering metrics @ 05/13/24 15:34:42.065
  E0513 15:34:42.143374      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:34:42.151: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  May 13 15:34:42.160: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-2398" for this suite. @ 05/13/24 15:34:42.163
• [1.145 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:132
  STEP: Creating a kubernetes client @ 05/13/24 15:34:42.166
  May 13 15:34:42.166: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename replicaset @ 05/13/24 15:34:42.167
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:34:42.178
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:34:42.18
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 05/13/24 15:34:42.181
  E0513 15:34:43.144500      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:44.144981      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 05/13/24 15:34:44.203
  STEP: Then the orphan pod is adopted @ 05/13/24 15:34:44.215
  STEP: When the matched label of one of its pods change @ 05/13/24 15:34:44.229
  May 13 15:34:44.232: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 05/13/24 15:34:44.241
  May 13 15:34:44.248: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-2638" for this suite. @ 05/13/24 15:34:44.254
• [2.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:70
  STEP: Creating a kubernetes client @ 05/13/24 15:34:44.264
  May 13 15:34:44.264: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 15:34:44.267
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:34:44.277
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:34:44.279
  STEP: Creating a pod to test downward API volume plugin @ 05/13/24 15:34:44.28
  E0513 15:34:45.145853      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:46.145651      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:47.146027      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:48.146305      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:34:48.298
  May 13 15:34:48.300: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod downwardapi-volume-abdbf3df-fb22-4433-916e-b9e1902b29b9 container client-container: <nil>
  STEP: delete the pod @ 05/13/24 15:34:48.303
  May 13 15:34:48.314: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2180" for this suite. @ 05/13/24 15:34:48.317
• [4.060 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:100
  STEP: Creating a kubernetes client @ 05/13/24 15:34:48.323
  May 13 15:34:48.323: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 15:34:48.324
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:34:48.334
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:34:48.335
  STEP: Creating configMap with name projected-configmap-test-volume-map-de8044e8-298c-4098-96cb-7997244bbd40 @ 05/13/24 15:34:48.337
  STEP: Creating a pod to test consume configMaps @ 05/13/24 15:34:48.339
  E0513 15:34:49.146664      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:50.147666      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:51.148216      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:52.148290      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:34:52.359
  May 13 15:34:52.361: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-projected-configmaps-0a92712e-6007-4165-89eb-e10360e9194c container agnhost-container: <nil>
  STEP: delete the pod @ 05/13/24 15:34:52.365
  May 13 15:34:52.375: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8236" for this suite. @ 05/13/24 15:34:52.378
• [4.062 seconds]
------------------------------
SSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:105
  STEP: Creating a kubernetes client @ 05/13/24 15:34:52.385
  May 13 15:34:52.385: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename endpointslice @ 05/13/24 15:34:52.387
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:34:52.399
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:34:52.401
  May 13 15:34:52.436: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-7291" for this suite. @ 05/13/24 15:34:52.439
• [0.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:210
  STEP: Creating a kubernetes client @ 05/13/24 15:34:52.449
  May 13 15:34:52.449: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename webhook @ 05/13/24 15:34:52.45
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:34:52.461
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:34:52.463
  STEP: Setting up server cert @ 05/13/24 15:34:52.477
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/13/24 15:34:52.779
  STEP: Deploying the webhook pod @ 05/13/24 15:34:52.783
  STEP: Wait for the deployment to be ready @ 05/13/24 15:34:52.792
  May 13 15:34:52.797: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0513 15:34:53.148416      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:54.149567      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/13/24 15:34:54.82
  STEP: Verifying the service has paired with the endpoint @ 05/13/24 15:34:54.833
  E0513 15:34:55.150970      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:34:55.833: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 05/13/24 15:34:55.836
  STEP: create a pod @ 05/13/24 15:34:55.847
  E0513 15:34:56.150965      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:57.151436      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 05/13/24 15:34:57.864
  May 13 15:34:57.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=webhook-4229 attach --namespace=webhook-4229 to-be-attached-pod -i -c=container1'
  May 13 15:34:57.964: INFO: rc: 1
  May 13 15:34:58.006: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4229" for this suite. @ 05/13/24 15:34:58.014
  STEP: Destroying namespace "webhook-markers-9218" for this suite. @ 05/13/24 15:34:58.019
• [5.573 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:70
  STEP: Creating a kubernetes client @ 05/13/24 15:34:58.037
  May 13 15:34:58.037: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename replication-controller @ 05/13/24 15:34:58.038
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:34:58.049
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:34:58.051
  STEP: Creating replication controller my-hostname-basic-e7a05217-96fa-4119-a4b3-fbafa3e33d7b @ 05/13/24 15:34:58.053
  May 13 15:34:58.060: INFO: Pod name my-hostname-basic-e7a05217-96fa-4119-a4b3-fbafa3e33d7b: Found 0 pods out of 1
  E0513 15:34:58.151714      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:34:59.151998      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:00.152637      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:01.152705      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:02.153381      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:03.063: INFO: Pod name my-hostname-basic-e7a05217-96fa-4119-a4b3-fbafa3e33d7b: Found 1 pods out of 1
  May 13 15:35:03.065: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-e7a05217-96fa-4119-a4b3-fbafa3e33d7b" are running
  May 13 15:35:03.067: INFO: Pod "my-hostname-basic-e7a05217-96fa-4119-a4b3-fbafa3e33d7b-wtqdd" is running and ready(conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-13 15:34:59 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-13 15:34:58 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-13 15:34:59 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-13 15:34:59 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-13 15:34:58 +0000 UTC Reason: Message:}])
  May 13 15:35:03.067: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 05/13/24 15:35:03.067
  May 13 15:35:03.078: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-2079" for this suite. @ 05/13/24 15:35:03.081
• [5.050 seconds]
------------------------------
SSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2199
  STEP: Creating a kubernetes client @ 05/13/24 15:35:03.087
  May 13 15:35:03.087: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename services @ 05/13/24 15:35:03.087
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:35:03.111
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:35:03.119
  STEP: creating service in namespace services-4745 @ 05/13/24 15:35:03.122
  STEP: creating service affinity-clusterip-transition in namespace services-4745 @ 05/13/24 15:35:03.125
  STEP: creating replication controller affinity-clusterip-transition in namespace services-4745 @ 05/13/24 15:35:03.138
  I0513 15:35:03.146441      17 runners.go:197] Created replication controller with name: affinity-clusterip-transition, namespace: services-4745, replica count: 3
  E0513 15:35:03.153610      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:04.154217      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:05.154667      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:06.154746      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0513 15:35:06.199307      17 runners.go:197] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May 13 15:35:06.210: INFO: Creating new exec pod
  E0513 15:35:07.154728      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:08.155035      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:09.155192      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:09.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-4745 exec execpod-affinitygtm2r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  May 13 15:35:09.370: INFO: stderr: "+ + nc -v -t -w 2 affinity-clusterip-transition 80\necho hostName\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  May 13 15:35:09.370: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 13 15:35:09.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-4745 exec execpod-affinitygtm2r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.152.13 80'
  May 13 15:35:09.467: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.152.13 80\nConnection to 10.43.152.13 80 port [tcp/http] succeeded!\n"
  May 13 15:35:09.467: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 13 15:35:09.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-4745 exec execpod-affinitygtm2r -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.43.152.13:80/ ; done'
  May 13 15:35:09.699: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n"
  May 13 15:35:09.699: INFO: stdout: "\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-tjnlx\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-5bz6s\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-tjnlx\naffinity-clusterip-transition-tjnlx\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-5bz6s\naffinity-clusterip-transition-5bz6s\naffinity-clusterip-transition-tjnlx\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-5bz6s\naffinity-clusterip-transition-5bz6s"
  May 13 15:35:09.699: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.699: INFO: Received response from host: affinity-clusterip-transition-tjnlx
  May 13 15:35:09.699: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.699: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.699: INFO: Received response from host: affinity-clusterip-transition-5bz6s
  May 13 15:35:09.699: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.699: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.699: INFO: Received response from host: affinity-clusterip-transition-tjnlx
  May 13 15:35:09.699: INFO: Received response from host: affinity-clusterip-transition-tjnlx
  May 13 15:35:09.699: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.699: INFO: Received response from host: affinity-clusterip-transition-5bz6s
  May 13 15:35:09.699: INFO: Received response from host: affinity-clusterip-transition-5bz6s
  May 13 15:35:09.699: INFO: Received response from host: affinity-clusterip-transition-tjnlx
  May 13 15:35:09.699: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.699: INFO: Received response from host: affinity-clusterip-transition-5bz6s
  May 13 15:35:09.699: INFO: Received response from host: affinity-clusterip-transition-5bz6s
  May 13 15:35:09.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-4745 exec execpod-affinitygtm2r -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.43.152.13:80/ ; done'
  May 13 15:35:09.869: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.152.13:80/\n"
  May 13 15:35:09.869: INFO: stdout: "\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-chgvw\naffinity-clusterip-transition-chgvw"
  May 13 15:35:09.869: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.869: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.869: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.869: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.869: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.869: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.869: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.869: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.869: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.869: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.869: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.869: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.869: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.869: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.869: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.869: INFO: Received response from host: affinity-clusterip-transition-chgvw
  May 13 15:35:09.869: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-4745, will wait for the garbage collector to delete the pods @ 05/13/24 15:35:09.878
  May 13 15:35:09.933: INFO: Deleting ReplicationController affinity-clusterip-transition took: 3.189881ms
  May 13 15:35:10.033: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.434295ms
  E0513 15:35:10.155434      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:11.155952      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:12.156850      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:12.749: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4745" for this suite. @ 05/13/24 15:35:12.751
• [9.674 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:550
  STEP: Creating a kubernetes client @ 05/13/24 15:35:12.765
  May 13 15:35:12.766: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename container-probe @ 05/13/24 15:35:12.766
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:35:12.775
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:35:12.777
  STEP: Creating pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803 @ 05/13/24 15:35:12.779
  E0513 15:35:13.157056      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:14.157116      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/13/24 15:35:14.789
  May 13 15:35:14.792: INFO: Initial restart count of pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 is 0
  May 13 15:35:14.793: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:15.158354      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:16.158973      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:16.801: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:17.159449      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:18.160452      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:18.805: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:19.160566      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:20.161454      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:20.808: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:21.161825      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:22.161868      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:22.812: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:23.165647      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:24.164479      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:24.820: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:25.164432      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:26.165553      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:26.824: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:27.166075      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:28.166135      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:28.827: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:29.166256      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:30.166683      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:30.844: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:31.166894      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:32.166892      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:32.853: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:33.167641      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:34.168050      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:34.856: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:35.168470      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:36.169169      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:36.865: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:37.171820      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:38.171980      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:38.869: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:39.172635      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:40.172721      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:40.872: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:41.173097      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:42.173320      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:42.874: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:43.173365      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:44.174136      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:44.881: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:45.175167      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:46.175881      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:46.884: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:47.176514      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:48.176574      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:48.887: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:49.176796      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:50.177013      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:50.894: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:51.177085      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:52.178081      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:52.897: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:53.178186      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:54.178920      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:54.899: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:55.179366      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:56.180462      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:56.907: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:57.181169      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:35:58.181754      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:35:58.915: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:35:59.182035      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:00.182201      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:36:00.917: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:36:01.182204      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:02.183183      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:36:02.919: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:36:03.183329      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:04.184004      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:36:04.923: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:36:05.184961      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:06.185071      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:36:06.925: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:36:07.185551      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:08.186449      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:36:08.927: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:36:09.186899      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:10.187218      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:36:10.934: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:36:11.187796      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:12.189097      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:36:12.939: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:36:13.188873      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:14.189344      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:36:14.945: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:36:15.189504      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:16.189826      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:36:16.950: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  E0513 15:36:17.189763      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:18.189836      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:36:18.953: INFO: Get pod test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 in namespace container-probe-2803
  May 13 15:36:18.953: INFO: Restart count of pod container-probe-2803/test-grpc-5c0146e5-b4ef-4007-aaba-181b5aee3bd4 is now 1 (1m4.161177359s elapsed)
  STEP: deleting the pod @ 05/13/24 15:36:18.953
  May 13 15:36:18.961: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2803" for this suite. @ 05/13/24 15:36:18.964
• [66.202 seconds]
------------------------------
S
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:96
  STEP: Creating a kubernetes client @ 05/13/24 15:36:18.969
  May 13 15:36:18.969: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename secrets @ 05/13/24 15:36:18.969
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:36:18.98
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:36:18.982
  STEP: creating secret secrets-6954/secret-test-72f1638c-405f-46ba-a330-9cdbfc006233 @ 05/13/24 15:36:18.983
  STEP: Creating a pod to test consume secrets @ 05/13/24 15:36:18.986
  E0513 15:36:19.190711      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:20.190743      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:21.192007      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:22.193196      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:36:23.001
  May 13 15:36:23.003: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-configmaps-7440d6b4-2b9e-4b47-b223-c5c7bfdd3b80 container env-test: <nil>
  STEP: delete the pod @ 05/13/24 15:36:23.024
  May 13 15:36:23.037: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6954" for this suite. @ 05/13/24 15:36:23.04
• [4.075 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:46
  STEP: Creating a kubernetes client @ 05/13/24 15:36:23.044
  May 13 15:36:23.044: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename configmap @ 05/13/24 15:36:23.044
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:36:23.053
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:36:23.054
  STEP: Creating configMap configmap-5978/configmap-test-bb97e9b9-9e39-4626-bc5b-6e915a21e878 @ 05/13/24 15:36:23.055
  STEP: Creating a pod to test consume configMaps @ 05/13/24 15:36:23.057
  E0513 15:36:23.193094      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:24.193830      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:36:25.065
  May 13 15:36:25.066: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-configmaps-3dde40b3-078c-4a3f-a06d-87bdc9b71b4c container env-test: <nil>
  STEP: delete the pod @ 05/13/24 15:36:25.069
  May 13 15:36:25.081: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5978" for this suite. @ 05/13/24 15:36:25.083
• [2.043 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 05/13/24 15:36:25.088
  May 13 15:36:25.088: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename pod-network-test @ 05/13/24 15:36:25.089
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:36:25.1
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:36:25.101
  STEP: Performing setup for networking test in namespace pod-network-test-7435 @ 05/13/24 15:36:25.102
  STEP: creating a selector @ 05/13/24 15:36:25.102
  STEP: Creating the service pods in kubernetes @ 05/13/24 15:36:25.103
  May 13 15:36:25.103: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0513 15:36:25.194487      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:26.195182      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:27.195149      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:28.195208      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:29.210672      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:30.196205      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:31.197725      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:32.198071      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:33.198349      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:34.199159      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:35.199378      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:36.199563      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 05/13/24 15:36:37.197
  E0513 15:36:37.201101      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:38.201134      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:39.201223      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:36:39.210: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  May 13 15:36:39.210: INFO: Breadth first check of 10.42.1.155 on host 172.16.100.5...
  May 13 15:36:39.211: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.156:9080/dial?request=hostname&protocol=udp&host=10.42.1.155&port=8081&tries=1'] Namespace:pod-network-test-7435 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 15:36:39.211: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 15:36:39.212: INFO: ExecWithOptions: Clientset creation
  May 13 15:36:39.212: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-7435/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.1.156%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.42.1.155%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  May 13 15:36:39.267: INFO: Waiting for responses: map[]
  May 13 15:36:39.267: INFO: reached 10.42.1.155 after 0/1 tries
  May 13 15:36:39.267: INFO: Breadth first check of 10.42.3.136 on host 172.16.100.7...
  May 13 15:36:39.269: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.156:9080/dial?request=hostname&protocol=udp&host=10.42.3.136&port=8081&tries=1'] Namespace:pod-network-test-7435 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 15:36:39.269: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 15:36:39.269: INFO: ExecWithOptions: Clientset creation
  May 13 15:36:39.269: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-7435/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.1.156%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.42.3.136%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  May 13 15:36:39.321: INFO: Waiting for responses: map[]
  May 13 15:36:39.321: INFO: reached 10.42.3.136 after 0/1 tries
  May 13 15:36:39.321: INFO: Going to retry 0 out of 2 pods....
  May 13 15:36:39.321: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-7435" for this suite. @ 05/13/24 15:36:39.323
• [14.239 seconds]
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 05/13/24 15:36:39.328
  May 13 15:36:39.328: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename emptydir-wrapper @ 05/13/24 15:36:39.328
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:36:39.338
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:36:39.339
  E0513 15:36:40.201323      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:41.201929      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the secret @ 05/13/24 15:36:41.371
  STEP: Cleaning up the configmap @ 05/13/24 15:36:41.381
  STEP: Cleaning up the pod @ 05/13/24 15:36:41.39
  May 13 15:36:41.401: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-5271" for this suite. @ 05/13/24 15:36:41.404
• [2.081 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:214
  STEP: Creating a kubernetes client @ 05/13/24 15:36:41.409
  May 13 15:36:41.409: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename container-probe @ 05/13/24 15:36:41.41
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:36:41.423
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:36:41.425
  STEP: Creating pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062 @ 05/13/24 15:36:41.426
  E0513 15:36:42.202645      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:43.203315      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/13/24 15:36:43.441
  May 13 15:36:43.443: INFO: Initial restart count of pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 is 0
  May 13 15:36:43.443: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:36:44.203971      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:45.204138      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:36:45.446: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:36:46.205186      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:47.205515      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:36:47.448: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:36:48.205545      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:49.206029      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:36:49.454: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:36:50.206270      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:51.206893      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:36:51.463: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:36:52.208666      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:53.208931      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:36:53.466: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:36:54.209963      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:55.210955      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:36:55.474: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:36:56.211371      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:57.211617      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:36:57.478: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:36:58.211721      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:36:59.211793      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:36:59.496: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:00.213060      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:01.213660      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:01.499: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:02.214217      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:03.214785      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:03.501: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:04.215993      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:05.216048      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:05.504: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:06.217488      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:07.217874      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:07.506: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:08.218091      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:09.218412      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:09.509: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:10.219462      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:11.219783      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:11.512: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:12.220730      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:13.220830      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:13.513: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:14.221272      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:15.221323      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:15.516: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:16.221637      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:17.221731      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:17.522: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:18.222712      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:19.223116      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:19.526: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:20.223390      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:21.224025      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:21.529: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:22.224682      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:23.224886      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:23.532: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:24.224964      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:25.225543      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:25.535: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:26.225699      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:27.226052      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:27.541: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:28.225986      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:29.226200      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:29.544: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:30.227271      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:31.227526      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:31.546: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:32.227182      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:33.227961      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:33.549: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:34.228715      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:35.229223      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:35.551: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:36.229820      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:37.230675      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:37.557: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:38.230495      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:39.230995      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:39.562: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:40.231396      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:41.232206      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:41.569: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:42.232724      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:43.232719      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:43.571: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:44.233825      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:45.234532      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:45.573: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:46.235423      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:47.236340      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:47.577: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:48.237136      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:49.237801      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:49.580: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:50.238309      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:51.239892      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:51.582: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:52.240247      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:53.240516      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:53.584: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:54.240682      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:55.241307      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:55.587: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:56.241556      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:57.242042      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:57.589: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:37:58.242104      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:37:59.242667      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:37:59.593: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:00.243689      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:01.243778      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:01.595: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:02.244672      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:03.244794      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:03.598: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:04.245323      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:05.245432      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:05.600: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:06.245946      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:07.246766      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:07.602: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:08.246636      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:09.246847      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:09.615: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:10.247710      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:11.248645      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:11.619: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:12.248345      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:13.248605      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:13.627: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:14.249434      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:15.249660      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:15.630: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:16.250578      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:17.250753      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:17.632: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:18.250881      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:19.251147      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:19.634: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:20.252143      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:21.252593      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:21.636: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:22.253454      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:23.254420      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:23.638: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:24.254668      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:25.255274      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:25.641: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:26.255988      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:27.256148      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:27.646: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:28.256835      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:29.257052      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:29.652: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:30.258082      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:31.258889      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:31.656: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:32.259667      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:33.260295      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:33.664: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:34.260395      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:35.261009      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:35.668: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:36.261642      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:37.261988      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:37.678: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:38.262276      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:39.262648      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:39.686: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:40.263125      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:41.263721      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:41.696: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:42.263535      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:43.264608      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:43.699: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:44.265841      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:45.266589      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:45.701: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:46.267738      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:47.268465      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:47.703: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:48.268621      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:49.269146      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:49.712: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:50.269718      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:51.269811      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:51.714: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:52.269916      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:53.270044      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:53.719: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:54.270856      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:55.271045      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:55.722: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:56.271465      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:57.271519      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:57.727: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:38:58.272054      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:38:59.272911      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:38:59.736: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:00.273109      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:01.273472      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:01.745: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:02.274168      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:03.274587      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:03.751: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:04.275582      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:05.276473      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:05.753: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:06.277461      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:07.277636      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:07.757: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:08.278601      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:09.278963      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:09.763: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:10.279666      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:11.280003      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:11.769: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:12.280879      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:13.281328      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:13.771: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:14.281876      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:15.282423      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:15.777: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:16.284167      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:17.284233      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:17.782: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:18.284699      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:19.285017      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:19.788: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:20.285942      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:21.286380      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:21.791: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:22.287202      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:23.288178      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:23.795: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:24.288710      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:25.289211      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:25.798: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:26.289832      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:27.290731      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:27.809: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:28.291189      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:29.291769      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:29.819: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:30.291745      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:31.292855      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:31.823: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:32.292838      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:33.293046      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:33.830: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:34.294293      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:35.294693      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:35.835: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:36.295696      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:37.296472      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:37.842: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:38.297075      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:39.297324      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:39.850: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:40.298401      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:41.298504      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:41.856: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:42.299573      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:43.300408      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:43.858: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:44.301457      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:45.301485      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:45.865: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:46.302664      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:47.303260      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:47.868: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:48.303691      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:49.304251      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:49.874: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:50.305167      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:51.305574      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:51.881: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:52.306790      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:53.306921      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:53.885: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:54.308137      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:55.309056      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:55.887: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:56.309154      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:57.309281      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:57.889: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:39:58.310066      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:39:59.310927      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:39:59.896: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:00.311929      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:01.312024      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:01.897: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:02.312160      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:03.312296      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:03.901: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:04.312965      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:05.313798      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:05.911: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:06.314614      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:07.314870      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:07.915: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:08.314916      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:09.315957      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:09.925: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:10.315907      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:11.316643      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:11.929: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:12.316522      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:13.316565      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:13.931: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:14.317761      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:15.317740      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:15.935: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:16.318554      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:17.318366      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:17.937: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:18.318347      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:19.318715      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:19.945: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:20.319284      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:21.319992      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:21.949: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:22.320740      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:23.321076      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:23.951: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:24.321548      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:25.322144      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:25.954: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:26.323733      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:27.324073      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:27.957: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:28.324337      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:29.324545      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:29.959: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:30.325498      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:31.325608      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:31.961: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:32.326936      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:33.326815      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:33.964: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:34.327412      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:35.328572      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:35.967: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:36.328560      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:37.328645      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:37.969: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:38.328831      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:39.331002      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:39.978: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:40.330882      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:41.332472      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:40:41.982: INFO: Get pod test-webserver-6c9247f0-76c9-445f-969e-76d23f914c22 in namespace container-probe-6062
  E0513 15:40:42.336646      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:43.336712      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 05/13/24 15:40:43.983
  May 13 15:40:44.002: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6062" for this suite. @ 05/13/24 15:40:44.005
• [242.600 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:94
  STEP: Creating a kubernetes client @ 05/13/24 15:40:44.013
  May 13 15:40:44.013: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename configmap @ 05/13/24 15:40:44.014
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:40:44.025
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:40:44.027
  STEP: Creating configMap configmap-8533/configmap-test-e08afbaa-6c88-440f-9fcb-798bb8a43a55 @ 05/13/24 15:40:44.028
  STEP: Creating a pod to test consume configMaps @ 05/13/24 15:40:44.03
  E0513 15:40:44.336837      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:45.337251      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:46.337995      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:47.338772      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:40:48.051
  May 13 15:40:48.058: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-configmaps-cebc51ed-5108-477a-a68b-9716bf77df13 container env-test: <nil>
  STEP: delete the pod @ 05/13/24 15:40:48.09
  May 13 15:40:48.099: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8533" for this suite. @ 05/13/24 15:40:48.102
• [4.093 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1838
  STEP: Creating a kubernetes client @ 05/13/24 15:40:48.107
  May 13 15:40:48.107: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubectl @ 05/13/24 15:40:48.107
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:40:48.124
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:40:48.125
  STEP: starting the proxy server @ 05/13/24 15:40:48.127
  May 13 15:40:48.127: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5501 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 05/13/24 15:40:48.163
  May 13 15:40:48.168: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5501" for this suite. @ 05/13/24 15:40:48.17
• [0.072 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 05/13/24 15:40:48.182
  May 13 15:40:48.182: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename cronjob @ 05/13/24 15:40:48.183
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:40:48.192
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:40:48.195
  STEP: Creating a ForbidConcurrent cronjob @ 05/13/24 15:40:48.197
  STEP: Ensuring a job is scheduled @ 05/13/24 15:40:48.2
  E0513 15:40:48.339364      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:49.339742      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:50.339897      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:51.340401      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:52.341409      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:53.343324      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:54.344214      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:55.345425      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:56.345910      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:57.347244      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:58.347068      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:40:59.347249      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 05/13/24 15:41:00.203
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 05/13/24 15:41:00.206
  STEP: Ensuring no more jobs are scheduled @ 05/13/24 15:41:00.209
  E0513 15:41:00.347318      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:01.347619      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:02.348102      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:03.348423      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:04.348520      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:05.349415      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:06.351966      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:07.351141      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:08.351505      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:09.351933      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:10.352623      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:11.353234      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:12.353962      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:13.355120      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:14.355464      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:15.355821      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:16.356974      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:17.357089      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:18.358098      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:19.359113      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:20.360262      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:21.360597      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:22.361699      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:23.361791      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:24.362754      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:25.363548      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:26.364339      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:27.364627      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:28.364653      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:29.366143      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:30.366740      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:31.367760      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:32.368221      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:33.368494      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:34.368667      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:35.368764      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:36.369588      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:37.370646      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:38.371213      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:39.371737      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:40.371970      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:41.374171      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:42.374869      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:43.376638      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:44.376691      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:45.376956      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:46.377918      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:47.378799      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:48.379745      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:49.380307      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:50.380636      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:51.381321      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:52.381866      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:53.381978      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:54.382372      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:55.382170      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:56.383167      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:57.383801      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:58.384361      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:41:59.384777      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:00.385103      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:01.385265      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:02.386242      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:03.386561      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:04.387497      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:05.388373      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:06.389348      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:07.390063      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:08.390628      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:09.391298      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:10.391777      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:11.392919      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:12.393238      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:13.393781      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:14.394535      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:15.395320      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:16.395896      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:17.396151      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:18.396374      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:19.397299      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:20.397398      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:21.398299      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:22.399080      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:23.398595      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:24.398991      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:25.399262      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:26.399214      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:27.399641      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:28.399763      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:29.400063      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:30.400612      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:31.400761      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:32.401000      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:33.401010      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:34.401309      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:35.401565      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:36.401980      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:37.402699      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:38.402811      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:39.402953      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:40.403929      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:41.404128      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:42.404616      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:43.404788      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:44.405354      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:45.405910      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:46.406204      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:47.407164      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:48.407711      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:49.408266      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:50.409212      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:51.409206      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:52.410233      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:53.410503      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:54.411181      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:55.411509      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:56.411690      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:57.412476      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:58.413515      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:42:59.414016      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:00.414881      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:01.415909      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:02.415952      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:03.416005      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:04.417437      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:05.418081      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:06.418074      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:07.418928      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:08.419218      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:09.419926      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:10.420134      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:11.420552      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:12.421329      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:13.421454      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:14.421581      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:15.422579      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:16.423882      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:17.434669      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:18.432185      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:19.433463      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:20.434431      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:21.444677      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:22.445894      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:23.446219      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:24.446860      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:25.447626      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:26.448364      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:27.449410      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:28.450219      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:29.451093      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:30.451605      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:31.452696      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:32.453476      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:33.453778      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:34.454599      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:35.455655      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:36.455679      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:37.455993      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:38.456376      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:39.456666      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:40.456635      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:41.456895      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:42.457047      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:43.457126      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:44.463988      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:45.462099      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:46.462346      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:47.462440      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:48.462640      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:49.462818      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:50.463513      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:51.464110      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:52.464686      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:53.464488      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:54.470654      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:55.471044      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:56.471320      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:57.472473      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:58.474332      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:43:59.474716      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:00.475151      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:01.478625      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:02.479158      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:03.480321      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:04.480478      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:05.480705      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:06.481602      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:07.482289      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:08.482945      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:09.483640      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:10.484426      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:11.485144      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:12.485329      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:13.485395      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:14.486620      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:15.487340      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:16.488279      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:17.488386      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:18.489431      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:19.489492      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:20.490304      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:21.490613      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:22.491540      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:23.492273      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:24.493314      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:25.493517      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:26.494087      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:27.494706      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:28.494492      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:29.494615      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:30.495529      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:31.495640      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:32.496686      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:33.496838      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:34.498079      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:35.499664      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:36.499627      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:37.500051      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:38.501382      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:39.501030      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:40.501397      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:41.501517      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:42.503182      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:43.501908      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:44.503312      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:45.504363      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:46.505341      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:47.505676      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:48.506807      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:49.508730      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:50.508899      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:51.508949      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:52.509821      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:53.509933      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:54.510611      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:55.511530      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:56.511983      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:57.512621      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:58.513352      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:44:59.513384      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:00.515538      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:01.514650      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:02.516079      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:03.515951      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:04.517600      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:05.518271      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:06.519222      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:07.519550      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:08.520322      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:09.521399      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:10.522281      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:11.522605      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:12.523220      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:13.523275      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:14.524441      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:15.524128      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:16.524855      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:17.524940      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:18.525722      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:19.530562      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:20.531450      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:21.535205      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:22.535608      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:23.535659      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:24.536542      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:25.537097      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:26.538180      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:27.539014      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:28.540038      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:29.539788      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:30.540073      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:31.541445      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:32.541569      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:33.541552      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:34.542065      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:35.542334      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:36.543409      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:37.543684      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:38.543972      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:39.544662      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:40.545969      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:41.546340      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:42.547041      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:43.546888      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:44.547156      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:45.547278      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:46.547838      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:47.547687      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:48.547889      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:49.549639      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:50.550700      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:51.550902      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:52.551622      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:53.551927      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:54.552370      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:55.553238      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:56.553513      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:57.553511      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:58.553637      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:45:59.554217      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 05/13/24 15:46:00.212
  May 13 15:46:00.215: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-3661" for this suite. @ 05/13/24 15:46:00.223
• [312.055 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 05/13/24 15:46:00.248
  May 13 15:46:00.249: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename events @ 05/13/24 15:46:00.25
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:46:00.264
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:46:00.265
  STEP: Create set of events @ 05/13/24 15:46:00.267
  May 13 15:46:00.269: INFO: created test-event-1
  May 13 15:46:00.271: INFO: created test-event-2
  May 13 15:46:00.273: INFO: created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 05/13/24 15:46:00.273
  STEP: delete collection of events @ 05/13/24 15:46:00.275
  May 13 15:46:00.275: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 05/13/24 15:46:00.281
  May 13 15:46:00.281: INFO: requesting list of events to confirm quantity
  May 13 15:46:00.282: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-3304" for this suite. @ 05/13/24 15:46:00.284
• [0.039 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:301
  STEP: Creating a kubernetes client @ 05/13/24 15:46:00.287
  May 13 15:46:00.287: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename webhook @ 05/13/24 15:46:00.288
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:46:00.299
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:46:00.301
  STEP: Setting up server cert @ 05/13/24 15:46:00.315
  E0513 15:46:00.555022      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/13/24 15:46:00.675
  STEP: Deploying the webhook pod @ 05/13/24 15:46:00.678
  STEP: Wait for the deployment to be ready @ 05/13/24 15:46:00.69
  May 13 15:46:00.711: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0513 15:46:01.555143      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:02.555234      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/13/24 15:46:02.715
  STEP: Verifying the service has paired with the endpoint @ 05/13/24 15:46:02.724
  E0513 15:46:03.555401      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:46:03.725: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 05/13/24 15:46:03.728
  STEP: Creating a custom resource definition that should be denied by the webhook @ 05/13/24 15:46:03.743
  May 13 15:46:03.744: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 15:46:03.787: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6497" for this suite. @ 05/13/24 15:46:03.793
  STEP: Destroying namespace "webhook-markers-6687" for this suite. @ 05/13/24 15:46:03.799
• [3.516 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:120
  STEP: Creating a kubernetes client @ 05/13/24 15:46:03.804
  May 13 15:46:03.805: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename emptydir @ 05/13/24 15:46:03.806
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:46:03.816
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:46:03.818
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 05/13/24 15:46:03.822
  E0513 15:46:04.556114      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:05.557205      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:46:05.837
  May 13 15:46:05.838: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-40cbff26-17a9-463f-9ce1-d6c761165277 container test-container: <nil>
  STEP: delete the pod @ 05/13/24 15:46:05.846
  May 13 15:46:05.854: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9925" for this suite. @ 05/13/24 15:46:05.856
• [2.055 seconds]
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:163
  STEP: Creating a kubernetes client @ 05/13/24 15:46:05.859
  May 13 15:46:05.860: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename svcaccounts @ 05/13/24 15:46:05.861
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:46:05.87
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:46:05.872
  May 13 15:46:05.884: INFO: created pod pod-service-account-defaultsa
  May 13 15:46:05.884: INFO: pod pod-service-account-defaultsa service account token volume mount: true
  May 13 15:46:05.892: INFO: created pod pod-service-account-mountsa
  May 13 15:46:05.892: INFO: pod pod-service-account-mountsa service account token volume mount: true
  May 13 15:46:05.917: INFO: created pod pod-service-account-nomountsa
  May 13 15:46:05.918: INFO: pod pod-service-account-nomountsa service account token volume mount: false
  May 13 15:46:05.929: INFO: created pod pod-service-account-defaultsa-mountspec
  May 13 15:46:05.929: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  May 13 15:46:05.936: INFO: created pod pod-service-account-mountsa-mountspec
  May 13 15:46:05.936: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
  May 13 15:46:05.940: INFO: created pod pod-service-account-nomountsa-mountspec
  May 13 15:46:05.940: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  May 13 15:46:05.952: INFO: created pod pod-service-account-defaultsa-nomountspec
  May 13 15:46:05.952: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  May 13 15:46:05.964: INFO: created pod pod-service-account-mountsa-nomountspec
  May 13 15:46:05.965: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  May 13 15:46:05.977: INFO: created pod pod-service-account-nomountsa-nomountspec
  May 13 15:46:05.977: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  May 13 15:46:05.978: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-3412" for this suite. @ 05/13/24 15:46:05.985
• [0.137 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:344
  STEP: Creating a kubernetes client @ 05/13/24 15:46:05.997
  May 13 15:46:05.997: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubectl @ 05/13/24 15:46:05.998
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:46:06.012
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:46:06.014
  STEP: creating a replication controller @ 05/13/24 15:46:06.016
  May 13 15:46:06.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-7099 create -f -'
  May 13 15:46:06.202: INFO: stderr: ""
  May 13 15:46:06.202: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/13/24 15:46:06.202
  May 13 15:46:06.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-7099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May 13 15:46:06.297: INFO: stderr: ""
  May 13 15:46:06.297: INFO: stdout: "update-demo-nautilus-nwvbx update-demo-nautilus-xkl72 "
  May 13 15:46:06.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-7099 get pods update-demo-nautilus-nwvbx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 13 15:46:06.352: INFO: stderr: ""
  May 13 15:46:06.352: INFO: stdout: ""
  May 13 15:46:06.352: INFO: update-demo-nautilus-nwvbx is created but not running
  E0513 15:46:06.557385      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:07.558036      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:08.558591      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:09.560999      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:10.561682      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:46:11.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-7099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May 13 15:46:11.408: INFO: stderr: ""
  May 13 15:46:11.408: INFO: stdout: "update-demo-nautilus-nwvbx update-demo-nautilus-xkl72 "
  May 13 15:46:11.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-7099 get pods update-demo-nautilus-nwvbx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 13 15:46:11.485: INFO: stderr: ""
  May 13 15:46:11.485: INFO: stdout: "true"
  May 13 15:46:11.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-7099 get pods update-demo-nautilus-nwvbx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  E0513 15:46:11.562132      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:46:11.565: INFO: stderr: ""
  May 13 15:46:11.565: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May 13 15:46:11.565: INFO: validating pod update-demo-nautilus-nwvbx
  May 13 15:46:11.570: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May 13 15:46:11.570: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May 13 15:46:11.570: INFO: update-demo-nautilus-nwvbx is verified up and running
  May 13 15:46:11.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-7099 get pods update-demo-nautilus-xkl72 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 13 15:46:11.638: INFO: stderr: ""
  May 13 15:46:11.638: INFO: stdout: "true"
  May 13 15:46:11.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-7099 get pods update-demo-nautilus-xkl72 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  May 13 15:46:11.714: INFO: stderr: ""
  May 13 15:46:11.714: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May 13 15:46:11.714: INFO: validating pod update-demo-nautilus-xkl72
  May 13 15:46:11.719: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May 13 15:46:11.719: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May 13 15:46:11.719: INFO: update-demo-nautilus-xkl72 is verified up and running
  STEP: using delete to clean up resources @ 05/13/24 15:46:11.719
  May 13 15:46:11.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-7099 delete --grace-period=0 --force -f -'
  May 13 15:46:11.782: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May 13 15:46:11.782: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  May 13 15:46:11.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-7099 get rc,svc -l name=update-demo --no-headers'
  May 13 15:46:11.852: INFO: stderr: "No resources found in kubectl-7099 namespace.\n"
  May 13 15:46:11.852: INFO: stdout: ""
  May 13 15:46:11.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-7099 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  May 13 15:46:11.906: INFO: stderr: ""
  May 13 15:46:11.906: INFO: stdout: ""
  May 13 15:46:11.906: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7099" for this suite. @ 05/13/24 15:46:11.909
• [5.915 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3154
  STEP: Creating a kubernetes client @ 05/13/24 15:46:11.912
  May 13 15:46:11.912: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename services @ 05/13/24 15:46:11.914
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:46:11.927
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:46:11.929
  STEP: creating an Endpoint @ 05/13/24 15:46:11.931
  STEP: waiting for available Endpoint @ 05/13/24 15:46:11.934
  STEP: listing all Endpoints @ 05/13/24 15:46:11.935
  STEP: updating the Endpoint @ 05/13/24 15:46:11.937
  STEP: fetching the Endpoint @ 05/13/24 15:46:11.94
  STEP: patching the Endpoint @ 05/13/24 15:46:11.942
  STEP: fetching the Endpoint @ 05/13/24 15:46:11.947
  STEP: deleting the Endpoint by Collection @ 05/13/24 15:46:11.949
  STEP: waiting for Endpoint deletion @ 05/13/24 15:46:11.953
  STEP: fetching the Endpoint @ 05/13/24 15:46:11.954
  May 13 15:46:11.956: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8938" for this suite. @ 05/13/24 15:46:11.959
• [0.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 05/13/24 15:46:11.962
  May 13 15:46:11.962: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 05/13/24 15:46:11.963
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:46:11.973
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:46:11.975
  STEP: creating a target pod @ 05/13/24 15:46:11.977
  E0513 15:46:12.563074      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:13.563145      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 05/13/24 15:46:13.989
  E0513 15:46:14.563215      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:15.563795      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:16.564387      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:17.564656      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 05/13/24 15:46:18.022
  May 13 15:46:18.023: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-5221 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 15:46:18.023: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 15:46:18.025: INFO: ExecWithOptions: Clientset creation
  May 13 15:46:18.026: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/ephemeral-containers-test-5221/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  May 13 15:46:18.103: INFO: Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 05/13/24 15:46:18.112
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 05/13/24 15:46:18.114
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 05/13/24 15:46:18.12
  May 13 15:46:18.128: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-5221" for this suite. @ 05/13/24 15:46:18.134
• [6.176 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 05/13/24 15:46:18.14
  May 13 15:46:18.140: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename pods @ 05/13/24 15:46:18.141
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:46:18.15
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:46:18.152
  STEP: creating the pod @ 05/13/24 15:46:18.154
  STEP: submitting the pod to kubernetes @ 05/13/24 15:46:18.154
  W0513 15:46:18.160194      17 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E0513 15:46:18.565171      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:19.565872      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 05/13/24 15:46:20.171
  STEP: updating the pod @ 05/13/24 15:46:20.173
  E0513 15:46:20.567849      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:46:20.696: INFO: Successfully updated pod "pod-update-activedeadlineseconds-61f02369-05d4-49e1-9ba2-e065937fc3d4"
  E0513 15:46:21.567823      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:22.568844      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:23.568248      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:24.572712      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:25.572873      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:26.573465      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:46:26.708: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1971" for this suite. @ 05/13/24 15:46:26.71
• [8.574 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:356
  STEP: Creating a kubernetes client @ 05/13/24 15:46:26.715
  May 13 15:46:26.715: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename endpointslice @ 05/13/24 15:46:26.715
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:46:26.727
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:46:26.728
  STEP: getting /apis @ 05/13/24 15:46:26.73
  STEP: getting /apis/discovery.k8s.io @ 05/13/24 15:46:26.734
  STEP: getting /apis/discovery.k8s.iov1 @ 05/13/24 15:46:26.734
  STEP: creating @ 05/13/24 15:46:26.735
  STEP: getting @ 05/13/24 15:46:26.748
  STEP: listing @ 05/13/24 15:46:26.749
  STEP: watching @ 05/13/24 15:46:26.751
  May 13 15:46:26.751: INFO: starting watch
  STEP: cluster-wide listing @ 05/13/24 15:46:26.751
  STEP: cluster-wide watching @ 05/13/24 15:46:26.752
  May 13 15:46:26.753: INFO: starting watch
  STEP: patching @ 05/13/24 15:46:26.753
  STEP: updating @ 05/13/24 15:46:26.757
  May 13 15:46:26.763: INFO: waiting for watch events with expected annotations
  May 13 15:46:26.764: INFO: saw patched and updated annotations
  STEP: deleting @ 05/13/24 15:46:26.764
  STEP: deleting a collection @ 05/13/24 15:46:26.77
  May 13 15:46:26.777: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-8628" for this suite. @ 05/13/24 15:46:26.78
• [0.068 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:572
  STEP: Creating a kubernetes client @ 05/13/24 15:46:26.784
  May 13 15:46:26.784: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename webhook @ 05/13/24 15:46:26.785
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:46:26.795
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:46:26.796
  STEP: Setting up server cert @ 05/13/24 15:46:26.81
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/13/24 15:46:27.233
  STEP: Deploying the webhook pod @ 05/13/24 15:46:27.236
  STEP: Wait for the deployment to be ready @ 05/13/24 15:46:27.245
  May 13 15:46:27.251: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0513 15:46:27.574018      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:28.574374      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/13/24 15:46:29.269
  STEP: Verifying the service has paired with the endpoint @ 05/13/24 15:46:29.285
  E0513 15:46:29.574699      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:46:30.287: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 05/13/24 15:46:30.322
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/13/24 15:46:30.353
  STEP: Deleting the collection of validation webhooks @ 05/13/24 15:46:30.398
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/13/24 15:46:30.413
  May 13 15:46:30.450: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4160" for this suite. @ 05/13/24 15:46:30.456
  STEP: Destroying namespace "webhook-markers-8466" for this suite. @ 05/13/24 15:46:30.465
• [3.686 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:251
  STEP: Creating a kubernetes client @ 05/13/24 15:46:30.471
  May 13 15:46:30.471: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 15:46:30.472
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:46:30.482
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:46:30.484
  STEP: Creating a pod to test downward API volume plugin @ 05/13/24 15:46:30.486
  E0513 15:46:30.575316      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:31.575455      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:32.576295      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:33.576444      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:46:34.511
  May 13 15:46:34.521: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod downwardapi-volume-20af9097-e583-47c8-9853-573febc11fa7 container client-container: <nil>
  STEP: delete the pod @ 05/13/24 15:46:34.534
  May 13 15:46:34.567: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4569" for this suite. @ 05/13/24 15:46:34.574
  E0513 15:46:34.577440      17 retrywatcher.go:129] "Watch failed" err="context canceled"
• [4.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:430
  STEP: Creating a kubernetes client @ 05/13/24 15:46:34.584
  May 13 15:46:34.585: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename pv @ 05/13/24 15:46:34.585
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:46:34.596
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:46:34.598
  STEP: Creating initial PV and PVC @ 05/13/24 15:46:34.599
  May 13 15:46:34.599: INFO: Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-6975" @ 05/13/24 15:46:34.611
  STEP: Listing PVCs in namespace "pv-6975" @ 05/13/24 15:46:34.613
  STEP: Patching the PV "pv-6975-5xm4k" @ 05/13/24 15:46:34.617
  STEP: Patching the PVC "pvc-8wklg" @ 05/13/24 15:46:34.627
  STEP: Getting PV "pv-6975-5xm4k" @ 05/13/24 15:46:34.632
  STEP: Getting PVC "pvc-8wklg" @ 05/13/24 15:46:34.633
  STEP: Deleting PVC "pvc-8wklg" @ 05/13/24 15:46:34.634
  STEP: Confirm deletion of PVC "pvc-8wklg" @ 05/13/24 15:46:34.642
  E0513 15:46:35.579157      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:36.578993      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-6975-5xm4k" @ 05/13/24 15:46:36.652
  STEP: Confirm deletion of PV "pv-6975-5xm4k" @ 05/13/24 15:46:36.675
  E0513 15:46:37.579394      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:38.579568      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating another PV & PVC @ 05/13/24 15:46:38.688
  May 13 15:46:38.688: INFO: Creating a PV followed by a PVC
  STEP: Updating the PV "pv-6975-2wrzl" @ 05/13/24 15:46:38.705
  STEP: Updating the PVC "pvc-x8g8w" @ 05/13/24 15:46:38.716
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-x8g8w=updated" @ 05/13/24 15:46:38.723
  STEP: Deleting PVC "pvc-x8g8w" via DeleteCollection @ 05/13/24 15:46:38.725
  STEP: Confirm deletion of PVC "pvc-x8g8w" @ 05/13/24 15:46:38.729
  E0513 15:46:39.579763      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:40.580555      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-6975-2wrzl" via DeleteCollection @ 05/13/24 15:46:40.738
  STEP: Confirm deletion of PV "pv-6975-2wrzl" @ 05/13/24 15:46:40.757
  May 13 15:46:40.767: INFO: AfterEach: deleting 1 PVCs and 1 PVs...
  May 13 15:46:40.767: INFO: Deleting PersistentVolumeClaim "pvc-x8g8w"
  May 13 15:46:40.770: INFO: Deleting PersistentVolume "pv-6975-2wrzl"
  May 13 15:46:40.772: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-6975" for this suite. @ 05/13/24 15:46:40.776
• [6.197 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:48
  STEP: Creating a kubernetes client @ 05/13/24 15:46:40.785
  May 13 15:46:40.785: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename configmap @ 05/13/24 15:46:40.786
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:46:40.8
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:46:40.81
  STEP: Creating configMap with name configmap-test-volume-c599d3af-1481-484a-b9e9-43c03e527476 @ 05/13/24 15:46:40.813
  STEP: Creating a pod to test consume configMaps @ 05/13/24 15:46:40.82
  E0513 15:46:41.580453      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:42.582022      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:43.582135      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:44.582579      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:46:44.841
  May 13 15:46:44.843: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-configmaps-1ace0df6-2b29-4840-9f67-661140a592ce container agnhost-container: <nil>
  STEP: delete the pod @ 05/13/24 15:46:44.85
  May 13 15:46:44.867: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3559" for this suite. @ 05/13/24 15:46:44.872
• [4.091 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:78
  STEP: Creating a kubernetes client @ 05/13/24 15:46:44.876
  May 13 15:46:44.876: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename resourcequota @ 05/13/24 15:46:44.878
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:46:44.895
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:46:44.896
  STEP: Counting existing ResourceQuota @ 05/13/24 15:46:44.898
  E0513 15:46:45.582675      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:46.583250      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:47.583952      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:48.583892      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:49.584183      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/13/24 15:46:49.913
  STEP: Ensuring resource quota status is calculated @ 05/13/24 15:46:49.924
  E0513 15:46:50.584391      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:51.584615      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:46:51.931: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4658" for this suite. @ 05/13/24 15:46:51.942
• [7.079 seconds]
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:277
  STEP: Creating a kubernetes client @ 05/13/24 15:46:51.958
  May 13 15:46:51.959: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename svcaccounts @ 05/13/24 15:46:51.961
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:46:51.977
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:46:51.979
  STEP: Creating a pod to test service account token:  @ 05/13/24 15:46:51.98
  E0513 15:46:52.585649      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:53.585928      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:54.595910      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:55.595960      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:46:56.001
  May 13 15:46:56.002: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod test-pod-a8076b69-105d-4399-b7ea-36ea3563205f container agnhost-container: <nil>
  STEP: delete the pod @ 05/13/24 15:46:56.006
  May 13 15:46:56.020: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2202" for this suite. @ 05/13/24 15:46:56.021
• [4.068 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:47
  STEP: Creating a kubernetes client @ 05/13/24 15:46:56.033
  May 13 15:46:56.033: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename secrets @ 05/13/24 15:46:56.034
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:46:56.046
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:46:56.048
  STEP: Creating secret with name secret-test-5bbcb68d-efd7-4385-86a1-007b506f835f @ 05/13/24 15:46:56.051
  STEP: Creating a pod to test consume secrets @ 05/13/24 15:46:56.055
  E0513 15:46:56.595978      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:57.596081      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:58.596707      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:46:59.597099      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:47:00.073
  May 13 15:47:00.075: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-secrets-f607cea9-49b4-464f-bcc0-64bbb1a0197b container secret-env-test: <nil>
  STEP: delete the pod @ 05/13/24 15:47:00.085
  May 13 15:47:00.097: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8413" for this suite. @ 05/13/24 15:47:00.1
• [4.072 seconds]
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:836
  STEP: Creating a kubernetes client @ 05/13/24 15:47:00.106
  May 13 15:47:00.106: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename daemonsets @ 05/13/24 15:47:00.107
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:47:00.116
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:47:00.118
  STEP: Creating simple DaemonSet "daemon-set" @ 05/13/24 15:47:00.128
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/13/24 15:47:00.131
  May 13 15:47:00.140: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 15:47:00.140: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 15:47:00.145: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 15:47:00.145: INFO: Node oneke-ip-172-16-100-5 is running 0 daemon pod, expected 1
  E0513 15:47:00.598174      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:47:01.135: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 15:47:01.136: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 15:47:01.138: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 15:47:01.138: INFO: Node oneke-ip-172-16-100-5 is running 0 daemon pod, expected 1
  E0513 15:47:01.598988      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:47:02.134: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 15:47:02.134: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 15:47:02.136: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May 13 15:47:02.136: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: listing all DaemonSets @ 05/13/24 15:47:02.137
  STEP: DeleteCollection of the DaemonSets @ 05/13/24 15:47:02.139
  STEP: Verify that ReplicaSets have been deleted @ 05/13/24 15:47:02.142
  May 13 15:47:02.149: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22937"},"items":null}

  May 13 15:47:02.154: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22937"},"items":[{"metadata":{"name":"daemon-set-2qs74","generateName":"daemon-set-","namespace":"daemonsets-3803","uid":"21115e22-cc38-450c-8b25-112a7037cef3","resourceVersion":"22932","creationTimestamp":"2024-05-13T15:47:00Z","labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"9e8b9a2918196fe6dd57fbcedb3649d2e2e3fb3880b668f05a6c4c021d74b765","cni.projectcalico.org/podIP":"10.42.3.147/32","cni.projectcalico.org/podIPs":"10.42.3.147/32","k8s.v1.cni.cncf.io/network-status":"[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.3.147\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"590e3138-6dc5-4261-a612-7ea6e35578a5","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2024-05-13T15:47:00Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-05-13T15:47:00Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"590e3138-6dc5-4261-a612-7ea6e35578a5\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"multus","operation":"Update","apiVersion":"v1","time":"2024-05-13T15:47:00Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{"f:k8s.v1.cni.cncf.io/network-status":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-05-13T15:47:01Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.3.147\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-nzbmg","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-nzbmg","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"oneke-ip-172-16-100-7","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["oneke-ip-172-16-100-7"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-13T15:47:01Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-13T15:47:00Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-13T15:47:01Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-13T15:47:01Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-13T15:47:00Z"}],"hostIP":"172.16.100.7","hostIPs":[{"ip":"172.16.100.7"}],"podIP":"10.42.3.147","podIPs":[{"ip":"10.42.3.147"}],"startTime":"2024-05-13T15:47:00Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-05-13T15:47:00Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://f4d377f4ff053190e49a785dfaa83898a45883423302d0ce10bd540bef262ff3","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-b5bg8","generateName":"daemon-set-","namespace":"daemonsets-3803","uid":"4d6b43cd-feab-46ba-810a-49655ee8a804","resourceVersion":"22935","creationTimestamp":"2024-05-13T15:47:00Z","labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"6cb926958206340b1952fb7ed2a9a9cb91037b5ebe997835cbafcd83483e9352","cni.projectcalico.org/podIP":"10.42.1.166/32","cni.projectcalico.org/podIPs":"10.42.1.166/32","k8s.v1.cni.cncf.io/network-status":"[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.1.166\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"590e3138-6dc5-4261-a612-7ea6e35578a5","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2024-05-13T15:47:00Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-05-13T15:47:00Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"590e3138-6dc5-4261-a612-7ea6e35578a5\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"multus","operation":"Update","apiVersion":"v1","time":"2024-05-13T15:47:00Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{"f:k8s.v1.cni.cncf.io/network-status":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-05-13T15:47:01Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.166\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-zhsjf","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-zhsjf","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"oneke-ip-172-16-100-5","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["oneke-ip-172-16-100-5"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-13T15:47:01Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-13T15:47:00Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-13T15:47:01Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-13T15:47:01Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-13T15:47:00Z"}],"hostIP":"172.16.100.5","hostIPs":[{"ip":"172.16.100.5"}],"podIP":"10.42.1.166","podIPs":[{"ip":"10.42.1.166"}],"startTime":"2024-05-13T15:47:00Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-05-13T15:47:00Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://7f7779dbcf7c8bb4ecc4f527006dc17ca4b2ec181fde0d03ec624617fff2e011","started":true}],"qosClass":"BestEffort"}}]}

  May 13 15:47:02.163: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3803" for this suite. @ 05/13/24 15:47:02.166
• [2.063 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:219
  STEP: Creating a kubernetes client @ 05/13/24 15:47:02.172
  May 13 15:47:02.172: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename downward-api @ 05/13/24 15:47:02.172
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:47:02.184
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:47:02.185
  STEP: Creating a pod to test downward api env vars @ 05/13/24 15:47:02.187
  E0513 15:47:02.599855      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:03.600327      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:04.600530      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:05.600936      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:47:06.201
  May 13 15:47:06.202: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod downward-api-99b71797-d607-446c-a4be-fcef82444f1c container dapi-container: <nil>
  STEP: delete the pod @ 05/13/24 15:47:06.206
  May 13 15:47:06.214: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7873" for this suite. @ 05/13/24 15:47:06.217
• [4.051 seconds]
------------------------------
SSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1280
  STEP: Creating a kubernetes client @ 05/13/24 15:47:06.224
  May 13 15:47:06.224: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename services @ 05/13/24 15:47:06.225
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:47:06.234
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:47:06.237
  STEP: creating service nodeport-test with type=NodePort in namespace services-3042 @ 05/13/24 15:47:06.238
  STEP: creating replication controller nodeport-test in namespace services-3042 @ 05/13/24 15:47:06.249
  I0513 15:47:06.258722      17 runners.go:197] Created replication controller with name: nodeport-test, namespace: services-3042, replica count: 2
  E0513 15:47:06.600989      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:07.601631      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:08.602114      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0513 15:47:09.309811      17 runners.go:197] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May 13 15:47:09.309: INFO: Creating new exec pod
  E0513 15:47:09.602406      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:10.602850      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:11.603576      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:47:12.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-3042 exec execpodtc5lm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  May 13 15:47:12.464: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  May 13 15:47:12.464: INFO: stdout: "nodeport-test-9fqp2"
  May 13 15:47:12.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-3042 exec execpodtc5lm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.15.113 80'
  May 13 15:47:12.569: INFO: stderr: "+ nc -v -t -w 2 10.43.15.113 80\nConnection to 10.43.15.113 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  May 13 15:47:12.569: INFO: stdout: "nodeport-test-qtcjq"
  May 13 15:47:12.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-3042 exec execpodtc5lm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.16.100.5 32228'
  E0513 15:47:12.604293      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:47:12.670: INFO: stderr: "+ nc -v -t -w 2 172.16.100.5 32228\n+ echo hostName\nConnection to 172.16.100.5 32228 port [tcp/*] succeeded!\n"
  May 13 15:47:12.670: INFO: stdout: "nodeport-test-qtcjq"
  May 13 15:47:12.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-3042 exec execpodtc5lm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.16.100.7 32228'
  May 13 15:47:12.761: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.16.100.7 32228\nConnection to 172.16.100.7 32228 port [tcp/*] succeeded!\n"
  May 13 15:47:12.762: INFO: stdout: "nodeport-test-qtcjq"
  May 13 15:47:12.762: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3042" for this suite. @ 05/13/24 15:47:12.764
• [6.544 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:200
  STEP: Creating a kubernetes client @ 05/13/24 15:47:12.768
  May 13 15:47:12.768: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename emptydir @ 05/13/24 15:47:12.769
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:47:12.783
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:47:12.785
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 05/13/24 15:47:12.786
  E0513 15:47:13.604439      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:14.604882      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:15.605717      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:16.606180      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:47:16.806
  May 13 15:47:16.811: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-69afa102-ac72-4821-bde0-2815d68c8092 container test-container: <nil>
  STEP: delete the pod @ 05/13/24 15:47:16.823
  May 13 15:47:16.838: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2005" for this suite. @ 05/13/24 15:47:16.842
• [4.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:71
  STEP: Creating a kubernetes client @ 05/13/24 15:47:16.847
  May 13 15:47:16.847: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename container-probe @ 05/13/24 15:47:16.848
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:47:16.857
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:47:16.859
  E0513 15:47:17.606582      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:18.606758      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:19.607266      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:20.607839      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:21.608144      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:22.609245      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:23.609960      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:24.609739      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:25.610306      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:26.611425      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:27.612035      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:28.612551      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:29.612968      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:30.613384      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:31.613549      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:32.613757      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:33.613951      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:34.614166      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:35.615486      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:36.615720      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:37.615811      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:38.615913      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:47:38.922: INFO: Container started at 2024-05-13 15:47:17 +0000 UTC, pod became ready at 2024-05-13 15:47:37 +0000 UTC
  May 13 15:47:38.922: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8772" for this suite. @ 05/13/24 15:47:38.924
• [22.082 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/controller_revision.go:126
  STEP: Creating a kubernetes client @ 05/13/24 15:47:38.93
  May 13 15:47:38.930: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename controllerrevisions @ 05/13/24 15:47:38.93
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:47:38.94
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:47:38.943
  STEP: Creating DaemonSet "e2e-m2n8l-daemon-set" @ 05/13/24 15:47:38.953
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/13/24 15:47:38.956
  May 13 15:47:38.959: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 15:47:38.959: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 15:47:38.963: INFO: Number of nodes with available pods controlled by daemonset e2e-m2n8l-daemon-set: 0
  May 13 15:47:38.963: INFO: Node oneke-ip-172-16-100-5 is running 0 daemon pod, expected 1
  E0513 15:47:39.616994      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:47:39.966: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 15:47:39.966: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 15:47:39.968: INFO: Number of nodes with available pods controlled by daemonset e2e-m2n8l-daemon-set: 1
  May 13 15:47:39.968: INFO: Node oneke-ip-172-16-100-7 is running 0 daemon pod, expected 1
  E0513 15:47:40.617433      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:47:40.965: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 15:47:40.966: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 15:47:40.973: INFO: Number of nodes with available pods controlled by daemonset e2e-m2n8l-daemon-set: 2
  May 13 15:47:40.973: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset e2e-m2n8l-daemon-set
  STEP: Confirm DaemonSet "e2e-m2n8l-daemon-set" successfully created with "daemonset-name=e2e-m2n8l-daemon-set" label @ 05/13/24 15:47:40.981
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-m2n8l-daemon-set" @ 05/13/24 15:47:40.993
  May 13 15:47:40.997: INFO: Located ControllerRevision: "e2e-m2n8l-daemon-set-65d55c8dd8"
  STEP: Patching ControllerRevision "e2e-m2n8l-daemon-set-65d55c8dd8" @ 05/13/24 15:47:41
  May 13 15:47:41.007: INFO: e2e-m2n8l-daemon-set-65d55c8dd8 has been patched
  STEP: Create a new ControllerRevision @ 05/13/24 15:47:41.007
  May 13 15:47:41.010: INFO: Created ControllerRevision: e2e-m2n8l-daemon-set-6f4f9777b6
  STEP: Confirm that there are two ControllerRevisions @ 05/13/24 15:47:41.01
  May 13 15:47:41.010: INFO: Requesting list of ControllerRevisions to confirm quantity
  May 13 15:47:41.012: INFO: Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-m2n8l-daemon-set-65d55c8dd8" @ 05/13/24 15:47:41.012
  STEP: Confirm that there is only one ControllerRevision @ 05/13/24 15:47:41.014
  May 13 15:47:41.015: INFO: Requesting list of ControllerRevisions to confirm quantity
  May 13 15:47:41.016: INFO: Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-m2n8l-daemon-set-6f4f9777b6" @ 05/13/24 15:47:41.017
  May 13 15:47:41.021: INFO: e2e-m2n8l-daemon-set-6f4f9777b6 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 05/13/24 15:47:41.021
  W0513 15:47:41.024373      17 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 05/13/24 15:47:41.024
  May 13 15:47:41.024: INFO: Requesting list of ControllerRevisions to confirm quantity
  E0513 15:47:41.617524      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:47:42.025: INFO: Requesting list of ControllerRevisions to confirm quantity
  May 13 15:47:42.029: INFO: Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-m2n8l-daemon-set-6f4f9777b6=updated" @ 05/13/24 15:47:42.03
  STEP: Confirm that there is only one ControllerRevision @ 05/13/24 15:47:42.034
  May 13 15:47:42.034: INFO: Requesting list of ControllerRevisions to confirm quantity
  May 13 15:47:42.036: INFO: Found 1 ControllerRevisions
  May 13 15:47:42.037: INFO: ControllerRevision "e2e-m2n8l-daemon-set-bfc47ddbc" has revision 3
  STEP: Deleting DaemonSet "e2e-m2n8l-daemon-set" @ 05/13/24 15:47:42.039
  STEP: deleting DaemonSet.extensions e2e-m2n8l-daemon-set in namespace controllerrevisions-6552, will wait for the garbage collector to delete the pods @ 05/13/24 15:47:42.039
  May 13 15:47:42.094: INFO: Deleting DaemonSet.extensions e2e-m2n8l-daemon-set took: 3.103578ms
  May 13 15:47:42.194: INFO: Terminating DaemonSet.extensions e2e-m2n8l-daemon-set pods took: 100.78226ms
  E0513 15:47:42.617974      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:47:43.497: INFO: Number of nodes with available pods controlled by daemonset e2e-m2n8l-daemon-set: 0
  May 13 15:47:43.497: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-m2n8l-daemon-set
  May 13 15:47:43.498: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"23381"},"items":null}

  May 13 15:47:43.499: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"23381"},"items":null}

  May 13 15:47:43.504: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-6552" for this suite. @ 05/13/24 15:47:43.506
• [4.580 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:300
  STEP: Creating a kubernetes client @ 05/13/24 15:47:43.518
  May 13 15:47:43.519: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename var-expansion @ 05/13/24 15:47:43.519
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:47:43.528
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:47:43.529
  STEP: creating the pod @ 05/13/24 15:47:43.531
  STEP: waiting for pod running @ 05/13/24 15:47:43.537
  E0513 15:47:43.618982      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:44.619102      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 05/13/24 15:47:45.543
  May 13 15:47:45.545: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-7047 PodName:var-expansion-8784d4a8-fdc9-40e3-8dba-5a111a9fec2e ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 15:47:45.546: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 15:47:45.546: INFO: ExecWithOptions: Clientset creation
  May 13 15:47:45.546: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/var-expansion-7047/pods/var-expansion-8784d4a8-fdc9-40e3-8dba-5a111a9fec2e/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  E0513 15:47:45.619322      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: test for file in mounted path @ 05/13/24 15:47:45.619
  May 13 15:47:45.621: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-7047 PodName:var-expansion-8784d4a8-fdc9-40e3-8dba-5a111a9fec2e ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 15:47:45.621: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 15:47:45.622: INFO: ExecWithOptions: Clientset creation
  May 13 15:47:45.622: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/var-expansion-7047/pods/var-expansion-8784d4a8-fdc9-40e3-8dba-5a111a9fec2e/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 05/13/24 15:47:45.67
  May 13 15:47:46.195: INFO: Successfully updated pod "var-expansion-8784d4a8-fdc9-40e3-8dba-5a111a9fec2e"
  STEP: waiting for annotated pod running @ 05/13/24 15:47:46.195
  STEP: deleting the pod gracefully @ 05/13/24 15:47:46.199
  May 13 15:47:46.199: INFO: Deleting pod "var-expansion-8784d4a8-fdc9-40e3-8dba-5a111a9fec2e" in namespace "var-expansion-7047"
  May 13 15:47:46.208: INFO: Wait up to 5m0s for pod "var-expansion-8784d4a8-fdc9-40e3-8dba-5a111a9fec2e" to be fully deleted
  E0513 15:47:46.619702      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:47.620868      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:48.620249      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:49.620847      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:50.621877      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:51.622381      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:52.623377      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:53.624398      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:54.624995      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:55.625365      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:56.625762      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:57.626709      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:58.626664      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:47:59.626819      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:00.627577      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:01.629228      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:02.629561      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:03.629970      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:04.630542      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:05.630782      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:06.631151      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:07.631263      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:08.632050      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:09.632829      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:10.632983      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:11.634055      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:12.634312      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:13.634955      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:14.635081      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:15.635589      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:16.636453      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:17.637781      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:18.637800      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:19.637915      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:48:20.273: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7047" for this suite. @ 05/13/24 15:48:20.275
• [36.759 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:220
  STEP: Creating a kubernetes client @ 05/13/24 15:48:20.281
  May 13 15:48:20.281: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename emptydir @ 05/13/24 15:48:20.281
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:48:20.29
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:48:20.292
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 05/13/24 15:48:20.294
  E0513 15:48:20.638701      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:21.640648      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:22.641175      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:23.641390      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:48:24.31
  May 13 15:48:24.312: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-ee68a3b8-1dd9-443e-ae96-0057fb8bf1ca container test-container: <nil>
  STEP: delete the pod @ 05/13/24 15:48:24.315
  May 13 15:48:24.324: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4095" for this suite. @ 05/13/24 15:48:24.327
• [4.051 seconds]
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:153
  STEP: Creating a kubernetes client @ 05/13/24 15:48:24.332
  May 13 15:48:24.332: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/13/24 15:48:24.333
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:48:24.343
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:48:24.346
  May 13 15:48:24.347: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 15:48:24.641633      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:25.672273      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 05/13/24 15:48:25.811
  May 13 15:48:25.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-9766 --namespace=crd-publish-openapi-9766 create -f -'
  E0513 15:48:26.673247      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:27.673237      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:48:27.874: INFO: stderr: ""
  May 13 15:48:27.874: INFO: stdout: "e2e-test-crd-publish-openapi-4805-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  May 13 15:48:27.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-9766 --namespace=crd-publish-openapi-9766 delete e2e-test-crd-publish-openapi-4805-crds test-cr'
  May 13 15:48:27.928: INFO: stderr: ""
  May 13 15:48:27.928: INFO: stdout: "e2e-test-crd-publish-openapi-4805-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  May 13 15:48:27.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-9766 --namespace=crd-publish-openapi-9766 apply -f -'
  May 13 15:48:27.977: INFO: stderr: ""
  May 13 15:48:27.977: INFO: stdout: "e2e-test-crd-publish-openapi-4805-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  May 13 15:48:27.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-9766 --namespace=crd-publish-openapi-9766 delete e2e-test-crd-publish-openapi-4805-crds test-cr'
  May 13 15:48:28.023: INFO: stderr: ""
  May 13 15:48:28.023: INFO: stdout: "e2e-test-crd-publish-openapi-4805-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 05/13/24 15:48:28.023
  May 13 15:48:28.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-9766 explain e2e-test-crd-publish-openapi-4805-crds'
  May 13 15:48:28.073: INFO: stderr: ""
  May 13 15:48:28.073: INFO: stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-4805-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E0513 15:48:28.674843      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:48:29.624: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9766" for this suite. @ 05/13/24 15:48:29.627
• [5.299 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:134
  STEP: Creating a kubernetes client @ 05/13/24 15:48:29.631
  May 13 15:48:29.631: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubelet-test @ 05/13/24 15:48:29.633
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:48:29.645
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:48:29.647
  May 13 15:48:29.664: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-5524" for this suite. @ 05/13/24 15:48:29.667
  E0513 15:48:29.675496      17 retrywatcher.go:129] "Watch failed" err="context canceled"
• [0.044 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:55
  STEP: Creating a kubernetes client @ 05/13/24 15:48:29.675
  May 13 15:48:29.675: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 15:48:29.676
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:48:29.693
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:48:29.694
  STEP: Creating a pod to test downward API volume plugin @ 05/13/24 15:48:29.695
  E0513 15:48:30.676394      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:31.677958      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:32.677637      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:33.678392      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:48:33.716
  May 13 15:48:33.718: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod downwardapi-volume-df3b7c30-b4e3-45d1-809b-63ecf206e212 container client-container: <nil>
  STEP: delete the pod @ 05/13/24 15:48:33.722
  May 13 15:48:33.731: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-647" for this suite. @ 05/13/24 15:48:33.734
• [4.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:125
  STEP: Creating a kubernetes client @ 05/13/24 15:48:33.74
  May 13 15:48:33.740: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename configmap @ 05/13/24 15:48:33.742
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:48:33.757
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:48:33.758
  STEP: Creating configMap with name configmap-test-upd-9b022f91-d319-434e-af86-e661f2bbb5ef @ 05/13/24 15:48:33.761
  STEP: Creating the pod @ 05/13/24 15:48:33.763
  E0513 15:48:34.677855      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:35.677980      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap configmap-test-upd-9b022f91-d319-434e-af86-e661f2bbb5ef @ 05/13/24 15:48:35.781
  STEP: waiting to observe update in volume @ 05/13/24 15:48:35.786
  E0513 15:48:36.678711      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:37.679546      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:38.680904      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:39.681079      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:40.682118      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:41.682262      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:42.683217      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:43.683363      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:44.683431      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:45.683700      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:46.683985      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:47.684341      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:48.684852      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:49.685374      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:50.685826      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:51.687077      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:52.687518      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:53.687930      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:54.688078      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:55.688481      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:56.689284      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:57.689394      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:58.690874      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:48:59.692692      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:00.692899      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:01.692927      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:02.693244      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:03.693525      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:04.694644      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:05.694824      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:06.696091      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:07.696159      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:08.696241      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:09.696563      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:10.696770      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:11.696917      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:49:12.004: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9405" for this suite. @ 05/13/24 15:49:12.01
• [38.276 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 05/13/24 15:49:12.016
  May 13 15:49:12.016: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename init-container @ 05/13/24 15:49:12.017
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:49:12.031
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:49:12.032
  STEP: creating the pod @ 05/13/24 15:49:12.033
  May 13 15:49:12.033: INFO: PodSpec: initContainers in spec.initContainers
  E0513 15:49:12.697285      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:13.698201      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:14.698686      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:15.710576      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:16.711473      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:49:16.928: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-6064" for this suite. @ 05/13/24 15:49:16.931
• [4.919 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 05/13/24 15:49:16.936
  May 13 15:49:16.936: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename cronjob @ 05/13/24 15:49:16.937
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:49:16.947
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:49:16.949
  STEP: Creating a suspended cronjob @ 05/13/24 15:49:16.95
  STEP: Ensuring no jobs are scheduled @ 05/13/24 15:49:16.953
  E0513 15:49:17.711658      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:18.712292      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:19.712385      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:20.712657      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:21.713476      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:22.713954      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:23.714059      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:24.714629      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:25.715202      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:26.715870      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:27.716025      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:28.716513      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:29.717292      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:30.717744      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:31.718096      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:32.719062      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:33.719108      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:34.720044      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:35.720536      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:36.720757      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:37.720883      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:38.721418      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:39.721623      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:40.721932      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:41.722294      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:42.723897      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:43.724661      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:44.725048      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:45.725162      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:46.725768      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:47.726143      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:48.727025      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:49.727164      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:50.727288      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:51.727681      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:52.727976      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:53.728299      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:54.728979      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:55.730135      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:56.730782      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:57.731751      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:58.732200      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:49:59.732564      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:00.732566      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:01.732709      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:02.732720      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:03.733291      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:04.733458      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:05.734024      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:06.734530      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:07.734470      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:08.734758      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:09.735368      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:10.735806      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:11.735448      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:12.736249      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:13.736816      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:14.737153      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:15.737871      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:16.737644      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:17.738775      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:18.741609      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:19.741708      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:20.741480      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:21.741643      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:22.742308      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:23.743261      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:24.746632      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:25.746798      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:26.747293      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:27.748348      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:28.749077      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:29.749454      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:30.749856      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:31.749964      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:32.750397      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:33.751421      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:34.752119      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:35.752417      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:36.752557      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:37.753596      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:38.753750      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:39.753810      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:40.755087      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:41.755843      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:42.756062      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:43.756897      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:44.757505      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:45.758113      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:46.758887      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:47.759451      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:48.759950      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:49.760285      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:50.761433      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:51.761507      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:52.762057      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:53.763171      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:54.763162      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:55.763756      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:56.763990      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:57.764572      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:58.764323      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:50:59.764613      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:00.765645      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:01.765749      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:02.766536      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:03.766716      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:04.767995      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:05.768004      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:06.769039      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:07.771192      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:08.770129      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:09.770988      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:10.772212      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:11.773103      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:12.773990      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:13.774248      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:14.774901      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:15.775668      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:16.776342      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:17.776551      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:18.777771      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:19.777807      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:20.778857      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:21.778983      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:22.779720      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:23.779700      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:24.780674      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:25.782614      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:26.782764      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:27.783673      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:28.783800      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:29.786671      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:30.785582      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:31.785778      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:32.787663      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:33.787407      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:34.788198      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:35.788558      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:36.788542      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:37.789432      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:38.789471      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:39.790761      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:40.790853      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:41.791364      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:42.792296      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:43.793183      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:44.793020      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:45.793965      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:46.794268      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:47.795280      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:48.796139      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:49.796617      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:50.796658      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:51.796693      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:52.803180      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:53.803642      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:54.806126      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:55.806345      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:56.806395      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:57.806585      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:58.806857      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:51:59.807064      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:00.807586      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:01.808413      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:02.808826      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:03.809196      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:04.810455      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:05.810477      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:06.811011      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:07.811958      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:08.811819      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:09.813258      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:10.813045      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:11.813067      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:12.813469      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:13.814412      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:14.815000      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:15.815145      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:16.815639      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:17.816071      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:18.816282      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:19.816384      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:20.816639      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:21.817490      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:22.817740      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:23.817870      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:24.818283      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:25.818384      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:26.818675      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:27.819238      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:28.819753      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:29.822855      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:30.820761      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:31.821026      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:32.821031      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:33.821871      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:34.822148      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:35.823341      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:36.823652      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:37.824513      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:38.824919      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:39.825248      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:40.825536      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:41.825821      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:42.826312      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:43.827531      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:44.830097      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:45.830739      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:46.831883      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:47.832186      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:48.832388      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:49.832466      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:50.832637      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:51.832796      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:52.833186      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:53.833295      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:54.833880      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:55.834046      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:56.834581      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:57.834938      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:58.834767      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:52:59.835101      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:00.835143      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:01.835617      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:02.835972      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:03.835979      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:04.837206      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:05.837212      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:06.838005      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:07.838597      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:08.839583      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:09.840885      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:10.841311      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:11.841669      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:12.841740      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:13.841839      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:14.842246      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:15.843045      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:16.843420      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:17.843758      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:18.843780      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:19.845032      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:20.845411      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:21.846170      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:22.847091      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:23.846953      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:24.847619      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:25.847929      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:26.848206      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:27.848616      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:28.848781      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:29.849248      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:30.850241      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:31.850662      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:32.851819      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:33.851775      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:34.852411      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:35.852479      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:36.853120      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:37.853270      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:38.853259      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:39.853560      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:40.853707      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:41.853818      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:42.853882      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:43.854166      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:44.855304      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:45.855600      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:46.856147      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:47.855417      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:48.855521      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:49.855901      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:50.856930      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:51.856512      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:52.857937      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:53.857643      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:54.857917      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:55.857897      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:56.858452      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:57.859215      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:58.859572      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:53:59.860563      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:00.860352      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:01.860875      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:02.860966      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:03.861738      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:04.862308      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:05.862663      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:06.864163      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:07.864713      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:08.865762      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:09.866668      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:10.867522      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:11.867667      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:12.867810      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:13.867904      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:14.868102      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:15.868486      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:16.868860      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 05/13/24 15:54:16.964
  STEP: Removing cronjob @ 05/13/24 15:54:16.969
  May 13 15:54:16.979: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-3062" for this suite. @ 05/13/24 15:54:16.985
• [300.068 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 05/13/24 15:54:17.006
  May 13 15:54:17.006: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename svc-latency @ 05/13/24 15:54:17.007
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:54:17.021
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:54:17.024
  May 13 15:54:17.025: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-3334 @ 05/13/24 15:54:17.026
  I0513 15:54:17.030206      17 runners.go:197] Created replication controller with name: svc-latency-rc, namespace: svc-latency-3334, replica count: 1
  E0513 15:54:17.868931      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0513 15:54:18.081946      17 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0513 15:54:18.869446      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0513 15:54:19.083069      17 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May 13 15:54:19.196: INFO: Created: latency-svc-gmmhk
  May 13 15:54:19.206: INFO: Got endpoints: latency-svc-gmmhk [22.795791ms]
  May 13 15:54:19.220: INFO: Created: latency-svc-qsftp
  May 13 15:54:19.234: INFO: Created: latency-svc-cjnr7
  May 13 15:54:19.235: INFO: Created: latency-svc-6bn29
  May 13 15:54:19.238: INFO: Got endpoints: latency-svc-qsftp [30.325698ms]
  May 13 15:54:19.240: INFO: Got endpoints: latency-svc-6bn29 [32.197378ms]
  May 13 15:54:19.241: INFO: Got endpoints: latency-svc-cjnr7 [32.489593ms]
  May 13 15:54:19.243: INFO: Created: latency-svc-kzfxb
  May 13 15:54:19.250: INFO: Got endpoints: latency-svc-kzfxb [42.064471ms]
  May 13 15:54:19.267: INFO: Created: latency-svc-cbc7q
  May 13 15:54:19.268: INFO: Created: latency-svc-2rmw9
  May 13 15:54:19.268: INFO: Got endpoints: latency-svc-cbc7q [60.036826ms]
  May 13 15:54:19.279: INFO: Created: latency-svc-phs7t
  May 13 15:54:19.270: INFO: Got endpoints: latency-svc-2rmw9 [61.628359ms]
  May 13 15:54:19.270: INFO: Created: latency-svc-mvw4x
  May 13 15:54:19.282: INFO: Got endpoints: latency-svc-mvw4x [74.506167ms]
  May 13 15:54:19.284: INFO: Created: latency-svc-9qncg
  May 13 15:54:19.289: INFO: Got endpoints: latency-svc-phs7t [80.724279ms]
  May 13 15:54:19.292: INFO: Got endpoints: latency-svc-9qncg [83.806647ms]
  May 13 15:54:19.297: INFO: Created: latency-svc-zl4kg
  May 13 15:54:19.299: INFO: Got endpoints: latency-svc-zl4kg [89.03228ms]
  May 13 15:54:19.303: INFO: Created: latency-svc-f6ljv
  May 13 15:54:19.309: INFO: Got endpoints: latency-svc-f6ljv [98.343897ms]
  May 13 15:54:19.319: INFO: Created: latency-svc-hvwgr
  May 13 15:54:19.320: INFO: Got endpoints: latency-svc-hvwgr [108.1592ms]
  May 13 15:54:19.320: INFO: Created: latency-svc-nxhmd
  May 13 15:54:19.325: INFO: Got endpoints: latency-svc-nxhmd [113.575224ms]
  May 13 15:54:19.343: INFO: Created: latency-svc-48vdv
  May 13 15:54:19.351: INFO: Created: latency-svc-hxm2w
  May 13 15:54:19.350: INFO: Created: latency-svc-bclg9
  May 13 15:54:19.352: INFO: Got endpoints: latency-svc-48vdv [143.099029ms]
  May 13 15:54:19.356: INFO: Created: latency-svc-vnn6x
  May 13 15:54:19.361: INFO: Created: latency-svc-kh66z
  May 13 15:54:19.361: INFO: Got endpoints: latency-svc-hxm2w [120.932296ms]
  May 13 15:54:19.366: INFO: Created: latency-svc-h9rq9
  May 13 15:54:19.370: INFO: Got endpoints: latency-svc-bclg9 [159.172743ms]
  May 13 15:54:19.378: INFO: Got endpoints: latency-svc-kh66z [137.049269ms]
  May 13 15:54:19.379: INFO: Got endpoints: latency-svc-vnn6x [140.729599ms]
  May 13 15:54:19.380: INFO: Created: latency-svc-frs7c
  May 13 15:54:19.387: INFO: Got endpoints: latency-svc-frs7c [114.269142ms]
  May 13 15:54:19.380: INFO: Got endpoints: latency-svc-h9rq9 [129.42857ms]
  May 13 15:54:19.382: INFO: Created: latency-svc-wcnfg
  May 13 15:54:19.393: INFO: Created: latency-svc-qc4xn
  May 13 15:54:19.393: INFO: Got endpoints: latency-svc-wcnfg [110.662891ms]
  May 13 15:54:19.402: INFO: Got endpoints: latency-svc-qc4xn [119.269098ms]
  May 13 15:54:19.404: INFO: Created: latency-svc-hjkfl
  May 13 15:54:19.411: INFO: Got endpoints: latency-svc-hjkfl [121.429104ms]
  May 13 15:54:19.416: INFO: Created: latency-svc-4qzmv
  May 13 15:54:19.423: INFO: Got endpoints: latency-svc-4qzmv [130.22078ms]
  May 13 15:54:19.425: INFO: Created: latency-svc-lnz7c
  May 13 15:54:19.425: INFO: Got endpoints: latency-svc-lnz7c [125.337079ms]
  May 13 15:54:19.433: INFO: Created: latency-svc-7q5fb
  May 13 15:54:19.437: INFO: Got endpoints: latency-svc-7q5fb [128.029675ms]
  May 13 15:54:19.442: INFO: Created: latency-svc-qks9d
  May 13 15:54:19.442: INFO: Got endpoints: latency-svc-qks9d [122.727018ms]
  May 13 15:54:19.447: INFO: Created: latency-svc-chwpd
  May 13 15:54:19.454: INFO: Got endpoints: latency-svc-chwpd [128.744781ms]
  May 13 15:54:19.503: INFO: Created: latency-svc-rndm4
  May 13 15:54:19.504: INFO: Created: latency-svc-zxmdq
  May 13 15:54:19.504: INFO: Created: latency-svc-p6pvr
  May 13 15:54:19.504: INFO: Created: latency-svc-7cqsk
  May 13 15:54:19.504: INFO: Created: latency-svc-qnkq9
  May 13 15:54:19.504: INFO: Got endpoints: latency-svc-7cqsk [117.79116ms]
  May 13 15:54:19.505: INFO: Got endpoints: latency-svc-rndm4 [133.170906ms]
  May 13 15:54:19.505: INFO: Got endpoints: latency-svc-zxmdq [128.179522ms]
  May 13 15:54:19.505: INFO: Got endpoints: latency-svc-p6pvr [125.938897ms]
  May 13 15:54:19.516: INFO: Got endpoints: latency-svc-qnkq9 [129.004414ms]
  May 13 15:54:19.517: INFO: Created: latency-svc-d5flb
  May 13 15:54:19.530: INFO: Got endpoints: latency-svc-d5flb [142.992911ms]
  May 13 15:54:19.521: INFO: Created: latency-svc-57mw4
  May 13 15:54:19.546: INFO: Created: latency-svc-w8nvh
  May 13 15:54:19.546: INFO: Created: latency-svc-sprqd
  May 13 15:54:19.546: INFO: Got endpoints: latency-svc-57mw4 [160.116493ms]
  May 13 15:54:19.556: INFO: Created: latency-svc-smqbm
  May 13 15:54:19.560: INFO: Created: latency-svc-v9zs5
  May 13 15:54:19.563: INFO: Created: latency-svc-x9qg9
  May 13 15:54:19.570: INFO: Got endpoints: latency-svc-w8nvh [176.708037ms]
  May 13 15:54:19.574: INFO: Created: latency-svc-tsnzs
  May 13 15:54:19.585: INFO: Created: latency-svc-zjkck
  May 13 15:54:19.591: INFO: Created: latency-svc-9hcgv
  May 13 15:54:19.602: INFO: Created: latency-svc-9pfff
  May 13 15:54:19.609: INFO: Got endpoints: latency-svc-sprqd [207.01056ms]
  May 13 15:54:19.615: INFO: Created: latency-svc-nkbh5
  May 13 15:54:19.620: INFO: Created: latency-svc-xqkxr
  May 13 15:54:19.623: INFO: Created: latency-svc-j5kvt
  May 13 15:54:19.628: INFO: Created: latency-svc-f6lq5
  May 13 15:54:19.633: INFO: Created: latency-svc-99dhp
  May 13 15:54:19.640: INFO: Created: latency-svc-xn2hq
  May 13 15:54:19.640: INFO: Created: latency-svc-qzsd9
  May 13 15:54:19.647: INFO: Created: latency-svc-fcc5s
  May 13 15:54:19.647: INFO: Got endpoints: latency-svc-smqbm [236.354484ms]
  May 13 15:54:19.655: INFO: Created: latency-svc-d5cvl
  May 13 15:54:19.697: INFO: Got endpoints: latency-svc-v9zs5 [273.907812ms]
  May 13 15:54:19.704: INFO: Created: latency-svc-9czmc
  May 13 15:54:19.746: INFO: Got endpoints: latency-svc-x9qg9 [321.403371ms]
  May 13 15:54:19.753: INFO: Created: latency-svc-gsrb5
  May 13 15:54:19.799: INFO: Got endpoints: latency-svc-tsnzs [360.551132ms]
  May 13 15:54:19.807: INFO: Created: latency-svc-j6llj
  May 13 15:54:19.845: INFO: Got endpoints: latency-svc-zjkck [402.769747ms]
  May 13 15:54:19.854: INFO: Created: latency-svc-dkq2x
  E0513 15:54:19.870233      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:54:19.898: INFO: Got endpoints: latency-svc-9hcgv [443.544066ms]
  May 13 15:54:19.911: INFO: Created: latency-svc-wdfg8
  May 13 15:54:19.944: INFO: Got endpoints: latency-svc-9pfff [440.15639ms]
  May 13 15:54:19.951: INFO: Created: latency-svc-knrf9
  May 13 15:54:19.997: INFO: Got endpoints: latency-svc-nkbh5 [492.074205ms]
  May 13 15:54:20.004: INFO: Created: latency-svc-pjmvn
  May 13 15:54:20.049: INFO: Got endpoints: latency-svc-xqkxr [544.373772ms]
  May 13 15:54:20.057: INFO: Created: latency-svc-mm6f4
  May 13 15:54:20.096: INFO: Got endpoints: latency-svc-j5kvt [591.498786ms]
  May 13 15:54:20.103: INFO: Created: latency-svc-xsft8
  May 13 15:54:20.147: INFO: Got endpoints: latency-svc-f6lq5 [616.370091ms]
  May 13 15:54:20.154: INFO: Created: latency-svc-wxt89
  May 13 15:54:20.197: INFO: Got endpoints: latency-svc-99dhp [666.536616ms]
  May 13 15:54:20.210: INFO: Created: latency-svc-nxkbx
  May 13 15:54:20.246: INFO: Got endpoints: latency-svc-xn2hq [699.395539ms]
  May 13 15:54:20.255: INFO: Created: latency-svc-fpkr6
  May 13 15:54:20.301: INFO: Got endpoints: latency-svc-qzsd9 [731.032408ms]
  May 13 15:54:20.310: INFO: Created: latency-svc-g54zf
  May 13 15:54:20.346: INFO: Got endpoints: latency-svc-fcc5s [735.87325ms]
  May 13 15:54:20.362: INFO: Created: latency-svc-q552p
  May 13 15:54:20.397: INFO: Got endpoints: latency-svc-d5cvl [748.316295ms]
  May 13 15:54:20.405: INFO: Created: latency-svc-9b7hs
  May 13 15:54:20.450: INFO: Got endpoints: latency-svc-9czmc [753.640242ms]
  May 13 15:54:20.462: INFO: Created: latency-svc-6v44m
  May 13 15:54:20.499: INFO: Got endpoints: latency-svc-gsrb5 [752.540078ms]
  May 13 15:54:20.506: INFO: Created: latency-svc-875vx
  May 13 15:54:20.552: INFO: Got endpoints: latency-svc-j6llj [753.245471ms]
  May 13 15:54:20.567: INFO: Created: latency-svc-lvsjf
  May 13 15:54:20.595: INFO: Got endpoints: latency-svc-dkq2x [749.507624ms]
  May 13 15:54:20.607: INFO: Created: latency-svc-pfl4b
  May 13 15:54:20.646: INFO: Got endpoints: latency-svc-wdfg8 [748.206683ms]
  May 13 15:54:20.654: INFO: Created: latency-svc-6nnf2
  May 13 15:54:20.696: INFO: Got endpoints: latency-svc-knrf9 [752.067564ms]
  May 13 15:54:20.706: INFO: Created: latency-svc-4p9hc
  May 13 15:54:20.748: INFO: Got endpoints: latency-svc-pjmvn [750.667912ms]
  May 13 15:54:20.756: INFO: Created: latency-svc-rm9zp
  May 13 15:54:20.801: INFO: Got endpoints: latency-svc-mm6f4 [752.048985ms]
  May 13 15:54:20.808: INFO: Created: latency-svc-4mvhk
  May 13 15:54:20.847: INFO: Got endpoints: latency-svc-xsft8 [750.364602ms]
  May 13 15:54:20.855: INFO: Created: latency-svc-mbbrp
  E0513 15:54:20.870721      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:54:20.897: INFO: Got endpoints: latency-svc-wxt89 [749.935449ms]
  May 13 15:54:20.905: INFO: Created: latency-svc-dm7vp
  May 13 15:54:20.959: INFO: Got endpoints: latency-svc-nxkbx [761.866789ms]
  May 13 15:54:20.968: INFO: Created: latency-svc-vmn99
  May 13 15:54:20.998: INFO: Got endpoints: latency-svc-fpkr6 [751.608095ms]
  May 13 15:54:21.005: INFO: Created: latency-svc-6l7zt
  May 13 15:54:21.049: INFO: Got endpoints: latency-svc-g54zf [747.596693ms]
  May 13 15:54:21.056: INFO: Created: latency-svc-cqvnf
  May 13 15:54:21.097: INFO: Got endpoints: latency-svc-q552p [750.782163ms]
  May 13 15:54:21.106: INFO: Created: latency-svc-mkdl9
  May 13 15:54:21.147: INFO: Got endpoints: latency-svc-9b7hs [749.872468ms]
  May 13 15:54:21.155: INFO: Created: latency-svc-vgpph
  May 13 15:54:21.211: INFO: Got endpoints: latency-svc-6v44m [760.203591ms]
  May 13 15:54:21.220: INFO: Created: latency-svc-nsdkv
  May 13 15:54:21.248: INFO: Got endpoints: latency-svc-875vx [748.476292ms]
  May 13 15:54:21.255: INFO: Created: latency-svc-bcjvs
  May 13 15:54:21.296: INFO: Got endpoints: latency-svc-lvsjf [742.008165ms]
  May 13 15:54:21.303: INFO: Created: latency-svc-f6hjv
  May 13 15:54:21.346: INFO: Got endpoints: latency-svc-pfl4b [748.559633ms]
  May 13 15:54:21.354: INFO: Created: latency-svc-f78p7
  May 13 15:54:21.398: INFO: Got endpoints: latency-svc-6nnf2 [752.041909ms]
  May 13 15:54:21.407: INFO: Created: latency-svc-9bvrg
  May 13 15:54:21.453: INFO: Got endpoints: latency-svc-4p9hc [756.656951ms]
  May 13 15:54:21.461: INFO: Created: latency-svc-d6rhl
  May 13 15:54:21.497: INFO: Got endpoints: latency-svc-rm9zp [749.464705ms]
  May 13 15:54:21.514: INFO: Created: latency-svc-w97jt
  May 13 15:54:21.547: INFO: Got endpoints: latency-svc-4mvhk [745.452182ms]
  May 13 15:54:21.553: INFO: Created: latency-svc-zmnvg
  May 13 15:54:21.596: INFO: Got endpoints: latency-svc-mbbrp [749.280552ms]
  May 13 15:54:21.605: INFO: Created: latency-svc-svshd
  May 13 15:54:21.644: INFO: Got endpoints: latency-svc-dm7vp [747.467927ms]
  May 13 15:54:21.652: INFO: Created: latency-svc-fptpd
  May 13 15:54:21.698: INFO: Got endpoints: latency-svc-vmn99 [738.085554ms]
  May 13 15:54:21.706: INFO: Created: latency-svc-g67x7
  May 13 15:54:21.746: INFO: Got endpoints: latency-svc-6l7zt [747.856185ms]
  May 13 15:54:21.757: INFO: Created: latency-svc-n5fgr
  May 13 15:54:21.798: INFO: Got endpoints: latency-svc-cqvnf [748.558415ms]
  May 13 15:54:21.807: INFO: Created: latency-svc-tt9kc
  May 13 15:54:21.845: INFO: Got endpoints: latency-svc-mkdl9 [747.784004ms]
  May 13 15:54:21.852: INFO: Created: latency-svc-w4hcw
  E0513 15:54:21.871380      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:54:21.897: INFO: Got endpoints: latency-svc-vgpph [750.075264ms]
  May 13 15:54:21.909: INFO: Created: latency-svc-pw46p
  May 13 15:54:21.948: INFO: Got endpoints: latency-svc-nsdkv [736.695877ms]
  May 13 15:54:21.955: INFO: Created: latency-svc-mg8sh
  May 13 15:54:21.998: INFO: Got endpoints: latency-svc-bcjvs [749.779503ms]
  May 13 15:54:22.004: INFO: Created: latency-svc-rfvsn
  May 13 15:54:22.047: INFO: Got endpoints: latency-svc-f6hjv [750.609702ms]
  May 13 15:54:22.056: INFO: Created: latency-svc-x8d64
  May 13 15:54:22.103: INFO: Got endpoints: latency-svc-f78p7 [756.652627ms]
  May 13 15:54:22.112: INFO: Created: latency-svc-pgtkv
  May 13 15:54:22.149: INFO: Got endpoints: latency-svc-9bvrg [749.883634ms]
  May 13 15:54:22.157: INFO: Created: latency-svc-d6hgj
  May 13 15:54:22.203: INFO: Got endpoints: latency-svc-d6rhl [749.405776ms]
  May 13 15:54:22.210: INFO: Created: latency-svc-xw84g
  May 13 15:54:22.247: INFO: Got endpoints: latency-svc-w97jt [748.965628ms]
  May 13 15:54:22.255: INFO: Created: latency-svc-kw2br
  May 13 15:54:22.302: INFO: Got endpoints: latency-svc-zmnvg [755.452954ms]
  May 13 15:54:22.316: INFO: Created: latency-svc-7wd75
  May 13 15:54:22.348: INFO: Got endpoints: latency-svc-svshd [751.426676ms]
  May 13 15:54:22.357: INFO: Created: latency-svc-w2grd
  May 13 15:54:22.397: INFO: Got endpoints: latency-svc-fptpd [751.874037ms]
  May 13 15:54:22.405: INFO: Created: latency-svc-5bzp8
  May 13 15:54:22.456: INFO: Got endpoints: latency-svc-g67x7 [758.226662ms]
  May 13 15:54:22.468: INFO: Created: latency-svc-7j8gc
  May 13 15:54:22.495: INFO: Got endpoints: latency-svc-n5fgr [748.548002ms]
  May 13 15:54:22.505: INFO: Created: latency-svc-ftclk
  May 13 15:54:22.547: INFO: Got endpoints: latency-svc-tt9kc [748.355987ms]
  May 13 15:54:22.555: INFO: Created: latency-svc-2q6q4
  May 13 15:54:22.598: INFO: Got endpoints: latency-svc-w4hcw [750.742287ms]
  May 13 15:54:22.604: INFO: Created: latency-svc-42jj8
  May 13 15:54:22.648: INFO: Got endpoints: latency-svc-pw46p [750.768571ms]
  May 13 15:54:22.656: INFO: Created: latency-svc-475b7
  May 13 15:54:22.698: INFO: Got endpoints: latency-svc-mg8sh [750.241011ms]
  May 13 15:54:22.705: INFO: Created: latency-svc-522bx
  May 13 15:54:22.748: INFO: Got endpoints: latency-svc-rfvsn [750.491925ms]
  May 13 15:54:22.763: INFO: Created: latency-svc-5mdh8
  May 13 15:54:22.797: INFO: Got endpoints: latency-svc-x8d64 [749.35732ms]
  May 13 15:54:22.806: INFO: Created: latency-svc-cw6j7
  May 13 15:54:22.847: INFO: Got endpoints: latency-svc-pgtkv [743.370902ms]
  May 13 15:54:22.853: INFO: Created: latency-svc-9ww5b
  E0513 15:54:22.872045      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:54:22.898: INFO: Got endpoints: latency-svc-d6hgj [748.334611ms]
  May 13 15:54:22.905: INFO: Created: latency-svc-zhbkj
  May 13 15:54:22.947: INFO: Got endpoints: latency-svc-xw84g [744.223736ms]
  May 13 15:54:22.952: INFO: Created: latency-svc-j69lb
  May 13 15:54:22.997: INFO: Got endpoints: latency-svc-kw2br [750.367538ms]
  May 13 15:54:23.005: INFO: Created: latency-svc-hxn8m
  May 13 15:54:23.047: INFO: Got endpoints: latency-svc-7wd75 [744.584062ms]
  May 13 15:54:23.054: INFO: Created: latency-svc-nlvqr
  May 13 15:54:23.098: INFO: Got endpoints: latency-svc-w2grd [749.495482ms]
  May 13 15:54:23.106: INFO: Created: latency-svc-g6dmc
  May 13 15:54:23.149: INFO: Got endpoints: latency-svc-5bzp8 [751.922142ms]
  May 13 15:54:23.157: INFO: Created: latency-svc-vh6wl
  May 13 15:54:23.197: INFO: Got endpoints: latency-svc-7j8gc [739.832645ms]
  May 13 15:54:23.210: INFO: Created: latency-svc-xdmmp
  May 13 15:54:23.250: INFO: Got endpoints: latency-svc-ftclk [754.519667ms]
  May 13 15:54:23.258: INFO: Created: latency-svc-6hrt9
  May 13 15:54:23.297: INFO: Got endpoints: latency-svc-2q6q4 [749.834873ms]
  May 13 15:54:23.305: INFO: Created: latency-svc-f2xch
  May 13 15:54:23.346: INFO: Got endpoints: latency-svc-42jj8 [748.292039ms]
  May 13 15:54:23.358: INFO: Created: latency-svc-ltj4k
  May 13 15:54:23.395: INFO: Got endpoints: latency-svc-475b7 [746.59118ms]
  May 13 15:54:23.403: INFO: Created: latency-svc-qgntt
  May 13 15:54:23.447: INFO: Got endpoints: latency-svc-522bx [748.164456ms]
  May 13 15:54:23.455: INFO: Created: latency-svc-5n2rd
  May 13 15:54:23.496: INFO: Got endpoints: latency-svc-5mdh8 [746.200166ms]
  May 13 15:54:23.503: INFO: Created: latency-svc-6lddh
  May 13 15:54:23.548: INFO: Got endpoints: latency-svc-cw6j7 [751.743198ms]
  May 13 15:54:23.556: INFO: Created: latency-svc-m6tz7
  May 13 15:54:23.598: INFO: Got endpoints: latency-svc-9ww5b [750.901242ms]
  May 13 15:54:23.606: INFO: Created: latency-svc-xdcxl
  May 13 15:54:23.647: INFO: Got endpoints: latency-svc-zhbkj [748.710987ms]
  May 13 15:54:23.654: INFO: Created: latency-svc-6nfqn
  May 13 15:54:23.697: INFO: Got endpoints: latency-svc-j69lb [750.03738ms]
  May 13 15:54:23.706: INFO: Created: latency-svc-lhm8x
  May 13 15:54:23.744: INFO: Got endpoints: latency-svc-hxn8m [746.843044ms]
  May 13 15:54:23.753: INFO: Created: latency-svc-n8dxx
  May 13 15:54:23.798: INFO: Got endpoints: latency-svc-nlvqr [751.123788ms]
  May 13 15:54:23.806: INFO: Created: latency-svc-vs82r
  May 13 15:54:23.849: INFO: Got endpoints: latency-svc-g6dmc [750.577655ms]
  May 13 15:54:23.857: INFO: Created: latency-svc-59dkl
  E0513 15:54:23.872955      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:54:23.895: INFO: Got endpoints: latency-svc-vh6wl [745.382604ms]
  May 13 15:54:23.906: INFO: Created: latency-svc-8mx42
  May 13 15:54:23.947: INFO: Got endpoints: latency-svc-xdmmp [749.969436ms]
  May 13 15:54:23.954: INFO: Created: latency-svc-2x22h
  May 13 15:54:23.999: INFO: Got endpoints: latency-svc-6hrt9 [748.482287ms]
  May 13 15:54:24.006: INFO: Created: latency-svc-4lv25
  May 13 15:54:24.048: INFO: Got endpoints: latency-svc-f2xch [750.519045ms]
  May 13 15:54:24.055: INFO: Created: latency-svc-ms5q8
  May 13 15:54:24.097: INFO: Got endpoints: latency-svc-ltj4k [750.921825ms]
  May 13 15:54:24.107: INFO: Created: latency-svc-shzbc
  May 13 15:54:24.145: INFO: Got endpoints: latency-svc-qgntt [749.609093ms]
  May 13 15:54:24.155: INFO: Created: latency-svc-5wlk9
  May 13 15:54:24.214: INFO: Got endpoints: latency-svc-5n2rd [767.076692ms]
  May 13 15:54:24.237: INFO: Created: latency-svc-j8bg2
  May 13 15:54:24.247: INFO: Got endpoints: latency-svc-6lddh [751.244339ms]
  May 13 15:54:24.258: INFO: Created: latency-svc-bjjcx
  May 13 15:54:24.298: INFO: Got endpoints: latency-svc-m6tz7 [749.305896ms]
  May 13 15:54:24.306: INFO: Created: latency-svc-bqwh6
  May 13 15:54:24.347: INFO: Got endpoints: latency-svc-xdcxl [748.252023ms]
  May 13 15:54:24.355: INFO: Created: latency-svc-g9l4k
  May 13 15:54:24.395: INFO: Got endpoints: latency-svc-6nfqn [747.802056ms]
  May 13 15:54:24.404: INFO: Created: latency-svc-rzd5k
  May 13 15:54:24.459: INFO: Got endpoints: latency-svc-lhm8x [761.56415ms]
  May 13 15:54:24.478: INFO: Created: latency-svc-7pq6p
  May 13 15:54:24.502: INFO: Got endpoints: latency-svc-n8dxx [757.539343ms]
  May 13 15:54:24.538: INFO: Created: latency-svc-rzdq9
  May 13 15:54:24.557: INFO: Got endpoints: latency-svc-vs82r [758.145642ms]
  May 13 15:54:24.574: INFO: Created: latency-svc-lbg7q
  May 13 15:54:24.601: INFO: Got endpoints: latency-svc-59dkl [752.582689ms]
  May 13 15:54:24.616: INFO: Created: latency-svc-9jmrs
  May 13 15:54:24.646: INFO: Got endpoints: latency-svc-8mx42 [751.076165ms]
  May 13 15:54:24.655: INFO: Created: latency-svc-phfbc
  May 13 15:54:24.699: INFO: Got endpoints: latency-svc-2x22h [751.32689ms]
  May 13 15:54:24.706: INFO: Created: latency-svc-zhgd2
  May 13 15:54:24.748: INFO: Got endpoints: latency-svc-4lv25 [748.197228ms]
  May 13 15:54:24.755: INFO: Created: latency-svc-pxb5z
  May 13 15:54:24.798: INFO: Got endpoints: latency-svc-ms5q8 [749.50919ms]
  May 13 15:54:24.804: INFO: Created: latency-svc-44grb
  May 13 15:54:24.845: INFO: Got endpoints: latency-svc-shzbc [747.070536ms]
  May 13 15:54:24.856: INFO: Created: latency-svc-flgjf
  E0513 15:54:24.873238      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:54:24.897: INFO: Got endpoints: latency-svc-5wlk9 [752.436573ms]
  May 13 15:54:24.906: INFO: Created: latency-svc-lc9qm
  May 13 15:54:24.949: INFO: Got endpoints: latency-svc-j8bg2 [732.618369ms]
  May 13 15:54:24.958: INFO: Created: latency-svc-lhr5j
  May 13 15:54:24.995: INFO: Got endpoints: latency-svc-bjjcx [747.775311ms]
  May 13 15:54:25.006: INFO: Created: latency-svc-jx8xk
  May 13 15:54:25.044: INFO: Got endpoints: latency-svc-bqwh6 [746.172996ms]
  May 13 15:54:25.053: INFO: Created: latency-svc-gbhbg
  May 13 15:54:25.096: INFO: Got endpoints: latency-svc-g9l4k [749.71334ms]
  May 13 15:54:25.104: INFO: Created: latency-svc-jkcmc
  May 13 15:54:25.147: INFO: Got endpoints: latency-svc-rzd5k [751.176868ms]
  May 13 15:54:25.155: INFO: Created: latency-svc-nj5c4
  May 13 15:54:25.198: INFO: Got endpoints: latency-svc-7pq6p [739.511794ms]
  May 13 15:54:25.212: INFO: Created: latency-svc-5rq97
  May 13 15:54:25.246: INFO: Got endpoints: latency-svc-rzdq9 [744.141423ms]
  May 13 15:54:25.255: INFO: Created: latency-svc-jv5kx
  May 13 15:54:25.297: INFO: Got endpoints: latency-svc-lbg7q [740.627178ms]
  May 13 15:54:25.305: INFO: Created: latency-svc-7c5t6
  May 13 15:54:25.346: INFO: Got endpoints: latency-svc-9jmrs [739.74252ms]
  May 13 15:54:25.354: INFO: Created: latency-svc-bnd7h
  May 13 15:54:25.396: INFO: Got endpoints: latency-svc-phfbc [749.893468ms]
  May 13 15:54:25.407: INFO: Created: latency-svc-n548m
  May 13 15:54:25.448: INFO: Got endpoints: latency-svc-zhgd2 [749.366788ms]
  May 13 15:54:25.456: INFO: Created: latency-svc-cxlwp
  May 13 15:54:25.497: INFO: Got endpoints: latency-svc-pxb5z [749.092365ms]
  May 13 15:54:25.504: INFO: Created: latency-svc-mrslj
  May 13 15:54:25.545: INFO: Got endpoints: latency-svc-44grb [747.879069ms]
  May 13 15:54:25.555: INFO: Created: latency-svc-sfjsn
  May 13 15:54:25.596: INFO: Got endpoints: latency-svc-flgjf [751.432632ms]
  May 13 15:54:25.603: INFO: Created: latency-svc-mw2lg
  May 13 15:54:25.645: INFO: Got endpoints: latency-svc-lc9qm [747.940887ms]
  May 13 15:54:25.653: INFO: Created: latency-svc-sdf7w
  May 13 15:54:25.696: INFO: Got endpoints: latency-svc-lhr5j [746.333668ms]
  May 13 15:54:25.704: INFO: Created: latency-svc-jvkfq
  May 13 15:54:25.757: INFO: Got endpoints: latency-svc-jx8xk [761.341185ms]
  May 13 15:54:25.768: INFO: Created: latency-svc-hbsxx
  May 13 15:54:25.800: INFO: Got endpoints: latency-svc-gbhbg [755.220757ms]
  May 13 15:54:25.807: INFO: Created: latency-svc-wfdzm
  May 13 15:54:25.846: INFO: Got endpoints: latency-svc-jkcmc [749.341998ms]
  May 13 15:54:25.855: INFO: Created: latency-svc-d6pn6
  E0513 15:54:25.873685      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:54:25.895: INFO: Got endpoints: latency-svc-nj5c4 [747.807439ms]
  May 13 15:54:25.906: INFO: Created: latency-svc-bdsqf
  May 13 15:54:25.951: INFO: Got endpoints: latency-svc-5rq97 [752.440416ms]
  May 13 15:54:25.964: INFO: Created: latency-svc-twt62
  May 13 15:54:25.997: INFO: Got endpoints: latency-svc-jv5kx [748.931929ms]
  May 13 15:54:26.006: INFO: Created: latency-svc-crdbv
  May 13 15:54:26.045: INFO: Got endpoints: latency-svc-7c5t6 [747.501588ms]
  May 13 15:54:26.054: INFO: Created: latency-svc-gqrkv
  May 13 15:54:26.098: INFO: Got endpoints: latency-svc-bnd7h [751.298479ms]
  May 13 15:54:26.108: INFO: Created: latency-svc-8t22z
  May 13 15:54:26.149: INFO: Got endpoints: latency-svc-n548m [752.967789ms]
  May 13 15:54:26.157: INFO: Created: latency-svc-6kj4f
  May 13 15:54:26.199: INFO: Got endpoints: latency-svc-cxlwp [751.073818ms]
  May 13 15:54:26.210: INFO: Created: latency-svc-6q72n
  May 13 15:54:26.248: INFO: Got endpoints: latency-svc-mrslj [750.341706ms]
  May 13 15:54:26.256: INFO: Created: latency-svc-6cfvq
  May 13 15:54:26.296: INFO: Got endpoints: latency-svc-sfjsn [750.559977ms]
  May 13 15:54:26.304: INFO: Created: latency-svc-bfl75
  May 13 15:54:26.348: INFO: Got endpoints: latency-svc-mw2lg [751.030504ms]
  May 13 15:54:26.356: INFO: Created: latency-svc-d6zx4
  May 13 15:54:26.406: INFO: Got endpoints: latency-svc-sdf7w [760.897782ms]
  May 13 15:54:26.415: INFO: Created: latency-svc-p57ln
  May 13 15:54:26.445: INFO: Got endpoints: latency-svc-jvkfq [749.818789ms]
  May 13 15:54:26.453: INFO: Created: latency-svc-dl4ft
  May 13 15:54:26.497: INFO: Got endpoints: latency-svc-hbsxx [740.537727ms]
  May 13 15:54:26.504: INFO: Created: latency-svc-ngv6b
  May 13 15:54:26.554: INFO: Got endpoints: latency-svc-wfdzm [753.526015ms]
  May 13 15:54:26.566: INFO: Created: latency-svc-ctb2t
  May 13 15:54:26.597: INFO: Got endpoints: latency-svc-d6pn6 [750.472491ms]
  May 13 15:54:26.617: INFO: Created: latency-svc-khj6l
  May 13 15:54:26.645: INFO: Got endpoints: latency-svc-bdsqf [750.103643ms]
  May 13 15:54:26.653: INFO: Created: latency-svc-xcgxp
  May 13 15:54:26.708: INFO: Got endpoints: latency-svc-twt62 [756.784403ms]
  May 13 15:54:26.721: INFO: Created: latency-svc-jdskn
  May 13 15:54:26.747: INFO: Got endpoints: latency-svc-crdbv [749.309491ms]
  May 13 15:54:26.754: INFO: Created: latency-svc-95dhh
  May 13 15:54:26.795: INFO: Got endpoints: latency-svc-gqrkv [749.118968ms]
  May 13 15:54:26.804: INFO: Created: latency-svc-chfm8
  May 13 15:54:26.849: INFO: Got endpoints: latency-svc-8t22z [750.669075ms]
  May 13 15:54:26.856: INFO: Created: latency-svc-qdpjb
  E0513 15:54:26.874583      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:54:26.897: INFO: Got endpoints: latency-svc-6kj4f [747.244908ms]
  May 13 15:54:26.908: INFO: Created: latency-svc-vbbml
  May 13 15:54:26.945: INFO: Got endpoints: latency-svc-6q72n [745.720545ms]
  May 13 15:54:26.954: INFO: Created: latency-svc-jwlws
  May 13 15:54:26.999: INFO: Got endpoints: latency-svc-6cfvq [750.905332ms]
  May 13 15:54:27.008: INFO: Created: latency-svc-fn6bt
  May 13 15:54:27.048: INFO: Got endpoints: latency-svc-bfl75 [750.9224ms]
  May 13 15:54:27.098: INFO: Got endpoints: latency-svc-d6zx4 [749.529959ms]
  May 13 15:54:27.152: INFO: Got endpoints: latency-svc-p57ln [746.176579ms]
  May 13 15:54:27.202: INFO: Got endpoints: latency-svc-dl4ft [756.96075ms]
  May 13 15:54:27.247: INFO: Got endpoints: latency-svc-ngv6b [749.845483ms]
  May 13 15:54:27.300: INFO: Got endpoints: latency-svc-ctb2t [746.103518ms]
  May 13 15:54:27.348: INFO: Got endpoints: latency-svc-khj6l [751.218795ms]
  May 13 15:54:27.399: INFO: Got endpoints: latency-svc-xcgxp [754.057862ms]
  May 13 15:54:27.458: INFO: Got endpoints: latency-svc-jdskn [749.540567ms]
  May 13 15:54:27.499: INFO: Got endpoints: latency-svc-95dhh [751.680813ms]
  May 13 15:54:27.546: INFO: Got endpoints: latency-svc-chfm8 [751.678213ms]
  May 13 15:54:27.596: INFO: Got endpoints: latency-svc-qdpjb [747.087374ms]
  May 13 15:54:27.646: INFO: Got endpoints: latency-svc-vbbml [748.833377ms]
  May 13 15:54:27.699: INFO: Got endpoints: latency-svc-jwlws [754.331533ms]
  May 13 15:54:27.752: INFO: Got endpoints: latency-svc-fn6bt [753.179584ms]
  May 13 15:54:27.753: INFO: Latencies: [30.325698ms 32.197378ms 32.489593ms 42.064471ms 60.036826ms 61.628359ms 74.506167ms 80.724279ms 83.806647ms 89.03228ms 98.343897ms 108.1592ms 110.662891ms 113.575224ms 114.269142ms 117.79116ms 119.269098ms 120.932296ms 121.429104ms 122.727018ms 125.337079ms 125.938897ms 128.029675ms 128.179522ms 128.744781ms 129.004414ms 129.42857ms 130.22078ms 133.170906ms 137.049269ms 140.729599ms 142.992911ms 143.099029ms 159.172743ms 160.116493ms 176.708037ms 207.01056ms 236.354484ms 273.907812ms 321.403371ms 360.551132ms 402.769747ms 440.15639ms 443.544066ms 492.074205ms 544.373772ms 591.498786ms 616.370091ms 666.536616ms 699.395539ms 731.032408ms 732.618369ms 735.87325ms 736.695877ms 738.085554ms 739.511794ms 739.74252ms 739.832645ms 740.537727ms 740.627178ms 742.008165ms 743.370902ms 744.141423ms 744.223736ms 744.584062ms 745.382604ms 745.452182ms 745.720545ms 746.103518ms 746.172996ms 746.176579ms 746.200166ms 746.333668ms 746.59118ms 746.843044ms 747.070536ms 747.087374ms 747.244908ms 747.467927ms 747.501588ms 747.596693ms 747.775311ms 747.784004ms 747.802056ms 747.807439ms 747.856185ms 747.879069ms 747.940887ms 748.164456ms 748.197228ms 748.206683ms 748.252023ms 748.292039ms 748.316295ms 748.334611ms 748.355987ms 748.476292ms 748.482287ms 748.548002ms 748.558415ms 748.559633ms 748.710987ms 748.833377ms 748.931929ms 748.965628ms 749.092365ms 749.118968ms 749.280552ms 749.305896ms 749.309491ms 749.341998ms 749.35732ms 749.366788ms 749.405776ms 749.464705ms 749.495482ms 749.507624ms 749.50919ms 749.529959ms 749.540567ms 749.609093ms 749.71334ms 749.779503ms 749.818789ms 749.834873ms 749.845483ms 749.872468ms 749.883634ms 749.893468ms 749.935449ms 749.969436ms 750.03738ms 750.075264ms 750.103643ms 750.241011ms 750.341706ms 750.364602ms 750.367538ms 750.472491ms 750.491925ms 750.519045ms 750.559977ms 750.577655ms 750.609702ms 750.667912ms 750.669075ms 750.742287ms 750.768571ms 750.782163ms 750.901242ms 750.905332ms 750.921825ms 750.9224ms 751.030504ms 751.073818ms 751.076165ms 751.123788ms 751.176868ms 751.218795ms 751.244339ms 751.298479ms 751.32689ms 751.426676ms 751.432632ms 751.608095ms 751.678213ms 751.680813ms 751.743198ms 751.874037ms 751.922142ms 752.041909ms 752.048985ms 752.067564ms 752.436573ms 752.440416ms 752.540078ms 752.582689ms 752.967789ms 753.179584ms 753.245471ms 753.526015ms 753.640242ms 754.057862ms 754.331533ms 754.519667ms 755.220757ms 755.452954ms 756.652627ms 756.656951ms 756.784403ms 756.96075ms 757.539343ms 758.145642ms 758.226662ms 760.203591ms 760.897782ms 761.341185ms 761.56415ms 761.866789ms 767.076692ms]
  May 13 15:54:27.754: INFO: 50 %ile: 748.559633ms
  May 13 15:54:27.755: INFO: 90 %ile: 753.526015ms
  May 13 15:54:27.755: INFO: 99 %ile: 761.866789ms
  May 13 15:54:27.755: INFO: Total sample count: 200
  May 13 15:54:27.756: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-3334" for this suite. @ 05/13/24 15:54:27.766
• [10.765 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:742
  STEP: Creating a kubernetes client @ 05/13/24 15:54:27.775
  May 13 15:54:27.775: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename svcaccounts @ 05/13/24 15:54:27.776
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:54:27.791
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:54:27.792
  May 13 15:54:27.795: INFO: Got root ca configmap in namespace "svcaccounts-6422"
  May 13 15:54:27.797: INFO: Deleted root ca configmap in namespace "svcaccounts-6422"
  E0513 15:54:27.875595      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for a new root ca configmap created @ 05/13/24 15:54:28.298
  May 13 15:54:28.300: INFO: Recreated root ca configmap in namespace "svcaccounts-6422"
  May 13 15:54:28.305: INFO: Updated root ca configmap in namespace "svcaccounts-6422"
  STEP: waiting for the root ca configmap reconciled @ 05/13/24 15:54:28.806
  May 13 15:54:28.808: INFO: Reconciled root ca configmap in namespace "svcaccounts-6422"
  May 13 15:54:28.808: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6422" for this suite. @ 05/13/24 15:54:28.81
• [1.039 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 05/13/24 15:54:28.815
  May 13 15:54:28.815: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename deployment @ 05/13/24 15:54:28.815
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:54:28.825
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:54:28.827
  May 13 15:54:28.829: INFO: Creating simple deployment test-new-deployment
  May 13 15:54:28.834: INFO: new replicaset for deployment "test-new-deployment" is yet to be created
  E0513 15:54:28.876011      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:29.876453      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 05/13/24 15:54:30.85
  STEP: updating a scale subresource @ 05/13/24 15:54:30.854
  STEP: verifying the deployment Spec.Replicas was modified @ 05/13/24 15:54:30.861
  STEP: Patch a scale subresource @ 05/13/24 15:54:30.864
  E0513 15:54:30.876568      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:54:30.887: INFO: Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7304",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "cd0b91b6-0510-45d0-8916-6dc0b1eecab3",
      ResourceVersion: (string) (len=5) "26259",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851212468,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212468,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212468,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-557759b7c7\" has successfully progressed."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  May 13 15:54:30.917: INFO: New ReplicaSet "test-new-deployment-557759b7c7" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7304",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "cfe2d367-40ac-4233-b87b-c4c4e3ccf33f",
      ResourceVersion: (string) (len=5) "26265",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851212468,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "4",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "5"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "cd0b91b6-0510-45d0-8916-6dc0b1eecab3",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 63 64 30 62 39 31  62 36 2d 30 35 31 30 2d  |\"cd0b91b6-0510-|
              00000120  34 35 64 30 2d 38 39 31  36 2d 36 64 63 30 62 31  |45d0-8916-6dc0b1|
              00000130  65 65 63 61 62 33 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |eecab3\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(4),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 2,
      FullyLabeledReplicas: (int32) 2,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 13 15:54:30.934: INFO: Pod "test-new-deployment-557759b7c7-7klrm" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-7klrm",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-7304",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5f9ee175-890a-48ad-bfe5-947f616d8086",
      ResourceVersion: (string) (len=5) "26275",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851212470,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "cfe2d367-40ac-4233-b87b-c4c4e3ccf33f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 66  65 32 64 33 36 37 2d 34  |d\":\"cfe2d367-4|
              00000090  30 61 63 2d 34 32 33 33  2d 62 38 37 62 2d 63 34  |0ac-4233-b87b-c4|
              000000a0  63 34 65 33 63 63 66 33  33 66 5c 22 7d 22 3a 7b  |c4e3ccf33f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jkmqs",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jkmqs",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:54:30.943: INFO: Pod "test-new-deployment-557759b7c7-ddfcz" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-ddfcz",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-7304",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "feee1cd2-b874-4c2c-aa02-65a8f63d7049",
      ResourceVersion: (string) (len=5) "26248",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851212468,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=4) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "215e1d96e4026313683a8e02f84138a0f1facf62b5b0d5998124599d75eca5a9",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.42.1.173/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.42.1.173/32",
        (string) (len=33) "k8s.v1.cni.cncf.io/network-status": (string) (len=113) "[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.1.173\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "cfe2d367-40ac-4233-b87b-c4c4e3ccf33f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=4) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212468,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 66  65 32 64 33 36 37 2d 34  |d\":\"cfe2d367-4|
              00000090  30 61 63 2d 34 32 33 33  2d 62 38 37 62 2d 63 34  |0ac-4233-b87b-c4|
              000000a0  63 34 65 33 63 63 66 33  33 66 5c 22 7d 22 3a 7b  |c4e3ccf33f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212469,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "multus",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212469,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=75) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 6b 38 73 2e 76  31 2e 63 6e 69 2e 63 6e  |"f:k8s.v1.cni.cn|
              00000030  63 66 2e 69 6f 2f 6e 65  74 77 6f 72 6b 2d 73 74  |cf.io/network-st|
              00000040  61 74 75 73 22 3a 7b 7d  7d 7d 7d                 |atus":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 34 32 2e 31 2e 31 37  33 5c 22 7d 22 3a 7b 22  |.42.1.173\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-67chh",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-67chh",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212468,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212468,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.5",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.5"
        }
      },
      PodIP: (string) (len=11) "10.42.1.173",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.42.1.173"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851212468,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851212469,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://60b1cdf92da25a8d4560bea8691e09618503e112fa6d7e2bf95ea3e2a36a7ae7",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:54:30.959: INFO: Pod "test-new-deployment-557759b7c7-lzl64" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-lzl64",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-7304",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "076f620b-95b7-4ba4-a50a-129ff5c3cea1",
      ResourceVersion: (string) (len=5) "26266",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851212470,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "cfe2d367-40ac-4233-b87b-c4c4e3ccf33f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 66  65 32 64 33 36 37 2d 34  |d\":\"cfe2d367-4|
              00000090  30 61 63 2d 34 32 33 33  2d 62 38 37 62 2d 63 34  |0ac-4233-b87b-c4|
              000000a0  63 34 65 33 63 63 66 33  33 66 5c 22 7d 22 3a 7b  |c4e3ccf33f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-678vr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-678vr",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.7",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.7"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851212470,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:54:30.965: INFO: Pod "test-new-deployment-557759b7c7-xc29q" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-xc29q",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-7304",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2c48579b-5e5d-4daa-b637-634caef2a820",
      ResourceVersion: (string) (len=5) "26270",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851212470,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "cfe2d367-40ac-4233-b87b-c4c4e3ccf33f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 66  65 32 64 33 36 37 2d 34  |d\":\"cfe2d367-4|
              00000090  30 61 63 2d 34 32 33 33  2d 62 38 37 62 2d 63 34  |0ac-4233-b87b-c4|
              000000a0  63 34 65 33 63 63 66 33  33 66 5c 22 7d 22 3a 7b  |c4e3ccf33f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-w8fn5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-w8fn5",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851212470,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 15:54:30.975: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7304" for this suite. @ 05/13/24 15:54:30.977
• [2.165 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:58
  STEP: Creating a kubernetes client @ 05/13/24 15:54:30.98
  May 13 15:54:30.980: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename configmap @ 05/13/24 15:54:30.981
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:54:30.991
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:54:30.992
  STEP: Creating configMap with name configmap-test-volume-35dc7fe5-75a7-4b42-adf5-271bdd67f8bc @ 05/13/24 15:54:30.994
  STEP: Creating a pod to test consume configMaps @ 05/13/24 15:54:30.996
  E0513 15:54:31.876682      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:32.878004      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:33.878823      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:34.880689      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:54:35.008
  May 13 15:54:35.013: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-configmaps-1356dcae-0bff-4bea-bc1d-1ac3a9e19a23 container agnhost-container: <nil>
  STEP: delete the pod @ 05/13/24 15:54:35.025
  May 13 15:54:35.041: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4232" for this suite. @ 05/13/24 15:54:35.045
• [4.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lease.go:73
  STEP: Creating a kubernetes client @ 05/13/24 15:54:35.053
  May 13 15:54:35.053: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename lease-test @ 05/13/24 15:54:35.055
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:54:35.072
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:54:35.076
  May 13 15:54:35.130: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-6907" for this suite. @ 05/13/24 15:54:35.136
• [0.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 05/13/24 15:54:35.151
  May 13 15:54:35.151: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename dns @ 05/13/24 15:54:35.155
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:54:35.168
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:54:35.17
  STEP: Creating a test headless service @ 05/13/24 15:54:35.179
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3040.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-3040.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3040.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-3040.svc.cluster.local;sleep 1; done
   @ 05/13/24 15:54:35.188
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3040.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-3040.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3040.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-3040.svc.cluster.local;sleep 1; done
   @ 05/13/24 15:54:35.188
  STEP: creating a pod to probe DNS @ 05/13/24 15:54:35.188
  STEP: submitting the pod to kubernetes @ 05/13/24 15:54:35.188
  E0513 15:54:35.880176      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:36.880569      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/13/24 15:54:37.204
  STEP: looking for the results for each expected name from probers @ 05/13/24 15:54:37.207
  May 13 15:54:37.217: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:37.220: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:37.224: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:37.227: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:37.230: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:37.234: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:37.238: INFO: Unable to read jessie_udp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:37.241: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:37.241: INFO: Lookups using dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local wheezy_udp@dns-test-service-2.dns-3040.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-3040.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local jessie_udp@dns-test-service-2.dns-3040.svc.cluster.local jessie_tcp@dns-test-service-2.dns-3040.svc.cluster.local]

  May 13 15:54:37.246: INFO: Pod client logs for webserver: 
  May 13 15:54:37.249: INFO: Pod client logs for querier: 
  May 13 15:54:37.252: INFO: Pod client logs for jessie-querier: 
  E0513 15:54:37.881617      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:38.881739      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:39.882133      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:40.883426      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:41.883986      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:54:42.211: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:42.214: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:42.217: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:42.219: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:42.221: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:42.223: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:42.225: INFO: Unable to read jessie_udp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:42.227: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:42.227: INFO: Lookups using dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local wheezy_udp@dns-test-service-2.dns-3040.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-3040.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local jessie_udp@dns-test-service-2.dns-3040.svc.cluster.local jessie_tcp@dns-test-service-2.dns-3040.svc.cluster.local]

  May 13 15:54:42.231: INFO: Pod client logs for webserver: 
  May 13 15:54:42.235: INFO: Pod client logs for querier: 
  May 13 15:54:42.239: INFO: Pod client logs for jessie-querier: 
  E0513 15:54:42.884047      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:43.884320      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:44.884668      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:45.885016      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:46.885166      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:54:47.219: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:47.222: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:47.225: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:47.230: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:47.233: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:47.237: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:47.239: INFO: Unable to read jessie_udp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:47.241: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:47.241: INFO: Lookups using dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local wheezy_udp@dns-test-service-2.dns-3040.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-3040.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local jessie_udp@dns-test-service-2.dns-3040.svc.cluster.local jessie_tcp@dns-test-service-2.dns-3040.svc.cluster.local]

  May 13 15:54:47.245: INFO: Pod client logs for webserver: 
  May 13 15:54:47.248: INFO: Pod client logs for querier: 
  May 13 15:54:47.251: INFO: Pod client logs for jessie-querier: 
  E0513 15:54:47.885440      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:48.885665      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:49.886738      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:50.893220      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:51.887482      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:54:52.218: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:52.229: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:52.241: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:52.247: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:52.251: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:52.255: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:52.258: INFO: Unable to read jessie_udp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:52.260: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:52.260: INFO: Lookups using dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local wheezy_udp@dns-test-service-2.dns-3040.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-3040.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local jessie_udp@dns-test-service-2.dns-3040.svc.cluster.local jessie_tcp@dns-test-service-2.dns-3040.svc.cluster.local]

  May 13 15:54:52.265: INFO: Pod client logs for webserver: 
  May 13 15:54:52.268: INFO: Pod client logs for querier: 
  May 13 15:54:52.271: INFO: Pod client logs for jessie-querier: 
  E0513 15:54:52.887408      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:53.887740      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:54.888139      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:55.888410      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:56.889021      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:54:57.212: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:57.216: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:57.219: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:57.222: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:57.226: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:57.231: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:57.239: INFO: Unable to read jessie_udp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:57.243: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:54:57.243: INFO: Lookups using dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local wheezy_udp@dns-test-service-2.dns-3040.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-3040.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local jessie_udp@dns-test-service-2.dns-3040.svc.cluster.local jessie_tcp@dns-test-service-2.dns-3040.svc.cluster.local]

  May 13 15:54:57.248: INFO: Pod client logs for webserver: 
  May 13 15:54:57.252: INFO: Pod client logs for querier: 
  May 13 15:54:57.255: INFO: Pod client logs for jessie-querier: 
  E0513 15:54:57.888785      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:58.889295      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:54:59.889949      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:00.890430      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:01.890738      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:55:02.212: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:55:02.214: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:55:02.217: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:55:02.220: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:55:02.223: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:55:02.226: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:55:02.229: INFO: Unable to read jessie_udp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:55:02.232: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-3040.svc.cluster.local from pod dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72: the server could not find the requested resource (get pods dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72)
  May 13 15:55:02.233: INFO: Lookups using dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local wheezy_udp@dns-test-service-2.dns-3040.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-3040.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3040.svc.cluster.local jessie_udp@dns-test-service-2.dns-3040.svc.cluster.local jessie_tcp@dns-test-service-2.dns-3040.svc.cluster.local]

  May 13 15:55:02.238: INFO: Pod client logs for webserver: 
  May 13 15:55:02.245: INFO: Pod client logs for querier: 
  May 13 15:55:02.253: INFO: Pod client logs for jessie-querier: 
  E0513 15:55:02.891162      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:03.891571      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:04.891818      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:05.891753      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:06.892417      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:55:07.219: INFO: DNS probes using dns-3040/dns-test-bcab45e3-0f78-45a8-94fd-f62dd81d9c72 succeeded

  STEP: deleting the pod @ 05/13/24 15:55:07.22
  STEP: deleting the test headless service @ 05/13/24 15:55:07.237
  May 13 15:55:07.251: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-3040" for this suite. @ 05/13/24 15:55:07.257
• [32.109 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1731
  STEP: Creating a kubernetes client @ 05/13/24 15:55:07.263
  May 13 15:55:07.263: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubectl @ 05/13/24 15:55:07.264
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:55:07.274
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:55:07.276
  May 13 15:55:07.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-9656 version'
  May 13 15:55:07.319: INFO: stderr: ""
  May 13 15:55:07.319: INFO: stdout: "Client Version: v1.29.4\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nServer Version: v1.29.4+rke2r1\n"
  May 13 15:55:07.320: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9656" for this suite. @ 05/13/24 15:55:07.323
• [0.063 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 05/13/24 15:55:07.327
  May 13 15:55:07.327: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename dns @ 05/13/24 15:55:07.327
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:55:07.339
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:55:07.34
  STEP: Creating a test headless service @ 05/13/24 15:55:07.342
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4922.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-4922.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 05/13/24 15:55:07.35
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4922.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-4922.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 05/13/24 15:55:07.351
  STEP: creating a pod to probe DNS @ 05/13/24 15:55:07.351
  STEP: submitting the pod to kubernetes @ 05/13/24 15:55:07.351
  E0513 15:55:07.892573      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:08.892708      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/13/24 15:55:09.36
  STEP: looking for the results for each expected name from probers @ 05/13/24 15:55:09.362
  May 13 15:55:09.371: INFO: DNS probes using dns-4922/dns-test-e6d9ef76-a39c-43c0-9138-8830a2e077e3 succeeded

  STEP: deleting the pod @ 05/13/24 15:55:09.371
  STEP: deleting the test headless service @ 05/13/24 15:55:09.385
  May 13 15:55:09.393: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-4922" for this suite. @ 05/13/24 15:55:09.397
• [2.074 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3565
  STEP: Creating a kubernetes client @ 05/13/24 15:55:09.403
  May 13 15:55:09.403: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename services @ 05/13/24 15:55:09.404
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:55:09.413
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:55:09.415
  STEP: creating a collection of services @ 05/13/24 15:55:09.416
  May 13 15:55:09.416: INFO: Creating e2e-svc-a-tncvh
  May 13 15:55:09.423: INFO: Creating e2e-svc-b-4tnwk
  May 13 15:55:09.436: INFO: Creating e2e-svc-c-5m6cd
  STEP: deleting service collection @ 05/13/24 15:55:09.45
  May 13 15:55:09.488: INFO: Collection of services has been deleted
  May 13 15:55:09.488: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-869" for this suite. @ 05/13/24 15:55:09.492
• [0.094 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:818
  STEP: Creating a kubernetes client @ 05/13/24 15:55:09.498
  May 13 15:55:09.498: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename gc @ 05/13/24 15:55:09.498
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:55:09.513
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:55:09.515
  May 13 15:55:09.570: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"ba53b460-d508-4c67-8d44-8931347f7861", Controller:(*bool)(0xc002d59da6), BlockOwnerDeletion:(*bool)(0xc002d59da7)}}
  May 13 15:55:09.578: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"54a6fbaf-4495-49fa-9ad0-81279b6eddeb", Controller:(*bool)(0xc00382433e), BlockOwnerDeletion:(*bool)(0xc00382433f)}}
  May 13 15:55:09.586: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"83462797-2e92-41ef-9ff9-cbc69a182059", Controller:(*bool)(0xc004a69466), BlockOwnerDeletion:(*bool)(0xc004a69467)}}
  E0513 15:55:09.898379      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:10.898894      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:11.900680      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:12.900447      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:13.900913      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:55:14.598: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3645" for this suite. @ 05/13/24 15:55:14.625
• [5.133 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:649
  STEP: Creating a kubernetes client @ 05/13/24 15:55:14.631
  May 13 15:55:14.631: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename svcaccounts @ 05/13/24 15:55:14.631
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:55:14.691
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:55:14.693
  STEP: creating a ServiceAccount @ 05/13/24 15:55:14.695
  STEP: watching for the ServiceAccount to be added @ 05/13/24 15:55:14.7
  STEP: patching the ServiceAccount @ 05/13/24 15:55:14.701
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 05/13/24 15:55:14.711
  STEP: deleting the ServiceAccount @ 05/13/24 15:55:14.713
  May 13 15:55:14.725: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7871" for this suite. @ 05/13/24 15:55:14.731
• [0.106 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:62
  STEP: Creating a kubernetes client @ 05/13/24 15:55:14.737
  May 13 15:55:14.737: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename limitrange @ 05/13/24 15:55:14.739
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:55:14.753
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:55:14.756
  STEP: Creating a LimitRange @ 05/13/24 15:55:14.757
  STEP: Setting up watch @ 05/13/24 15:55:14.758
  STEP: Submitting a LimitRange @ 05/13/24 15:55:14.862
  STEP: Verifying LimitRange creation was observed @ 05/13/24 15:55:14.866
  STEP: Fetching the LimitRange to ensure it has proper values @ 05/13/24 15:55:14.866
  May 13 15:55:14.867: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  May 13 15:55:14.867: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 05/13/24 15:55:14.867
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 05/13/24 15:55:14.872
  May 13 15:55:14.875: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  May 13 15:55:14.875: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 05/13/24 15:55:14.875
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 05/13/24 15:55:14.881
  May 13 15:55:14.885: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  May 13 15:55:14.885: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 05/13/24 15:55:14.885
  STEP: Failing to create a Pod with more than max resources @ 05/13/24 15:55:14.887
  STEP: Updating a LimitRange @ 05/13/24 15:55:14.888
  STEP: Verifying LimitRange updating is effective @ 05/13/24 15:55:14.891
  E0513 15:55:14.901439      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:15.901803      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 05/13/24 15:55:16.9
  E0513 15:55:16.906574      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Failing to create a Pod with more than max resources @ 05/13/24 15:55:16.916
  STEP: Deleting a LimitRange @ 05/13/24 15:55:16.921
  STEP: Verifying the LimitRange was deleted @ 05/13/24 15:55:16.924
  E0513 15:55:17.901915      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:18.902067      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:19.905038      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:20.904082      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:21.907047      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:55:21.926: INFO: limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 05/13/24 15:55:21.926
  May 13 15:55:21.934: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-7571" for this suite. @ 05/13/24 15:55:21.943
• [7.209 seconds]
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:855
  STEP: Creating a kubernetes client @ 05/13/24 15:55:21.946
  May 13 15:55:21.946: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename job @ 05/13/24 15:55:21.946
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:55:21.955
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:55:21.957
  STEP: Creating a suspended job @ 05/13/24 15:55:21.959
  STEP: Patching the Job @ 05/13/24 15:55:21.962
  STEP: Watching for Job to be patched @ 05/13/24 15:55:21.968
  May 13 15:55:21.971: INFO: Event ADDED observed for Job e2e-2fmd9 in namespace job-7294 with labels: map[e2e-job-label:e2e-2fmd9] and annotations: map[]
  May 13 15:55:21.971: INFO: Event MODIFIED found for Job e2e-2fmd9 in namespace job-7294 with labels: map[e2e-2fmd9:patched e2e-job-label:e2e-2fmd9] and annotations: map[]
  STEP: Updating the job @ 05/13/24 15:55:21.971
  STEP: Watching for Job to be updated @ 05/13/24 15:55:21.977
  May 13 15:55:21.978: INFO: Event MODIFIED found for Job e2e-2fmd9 in namespace job-7294 with labels: map[e2e-2fmd9:patched e2e-job-label:e2e-2fmd9] and annotations: map[updated:true]
  May 13 15:55:21.978: INFO: Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 05/13/24 15:55:21.978
  May 13 15:55:21.986: INFO: Job: e2e-2fmd9 as labels: map[e2e-2fmd9:patched e2e-job-label:e2e-2fmd9]
  STEP: Waiting for job to complete @ 05/13/24 15:55:21.986
  E0513 15:55:22.906534      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:23.907103      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:24.908607      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:25.908111      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:26.908362      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:27.908521      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:28.908688      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:29.909373      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 05/13/24 15:55:29.99
  STEP: Watching for Job to be deleted @ 05/13/24 15:55:30
  May 13 15:55:30.004: INFO: Event MODIFIED observed for Job e2e-2fmd9 in namespace job-7294 with labels: map[e2e-2fmd9:patched e2e-job-label:e2e-2fmd9] and annotations: map[updated:true]
  May 13 15:55:30.011: INFO: Event MODIFIED observed for Job e2e-2fmd9 in namespace job-7294 with labels: map[e2e-2fmd9:patched e2e-job-label:e2e-2fmd9] and annotations: map[updated:true]
  May 13 15:55:30.012: INFO: Event MODIFIED observed for Job e2e-2fmd9 in namespace job-7294 with labels: map[e2e-2fmd9:patched e2e-job-label:e2e-2fmd9] and annotations: map[updated:true]
  May 13 15:55:30.013: INFO: Event MODIFIED observed for Job e2e-2fmd9 in namespace job-7294 with labels: map[e2e-2fmd9:patched e2e-job-label:e2e-2fmd9] and annotations: map[updated:true]
  May 13 15:55:30.013: INFO: Event MODIFIED observed for Job e2e-2fmd9 in namespace job-7294 with labels: map[e2e-2fmd9:patched e2e-job-label:e2e-2fmd9] and annotations: map[updated:true]
  May 13 15:55:30.014: INFO: Event MODIFIED observed for Job e2e-2fmd9 in namespace job-7294 with labels: map[e2e-2fmd9:patched e2e-job-label:e2e-2fmd9] and annotations: map[updated:true]
  May 13 15:55:30.014: INFO: Event MODIFIED observed for Job e2e-2fmd9 in namespace job-7294 with labels: map[e2e-2fmd9:patched e2e-job-label:e2e-2fmd9] and annotations: map[updated:true]
  May 13 15:55:30.014: INFO: Event DELETED found for Job e2e-2fmd9 in namespace job-7294 with labels: map[e2e-2fmd9:patched e2e-job-label:e2e-2fmd9] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 05/13/24 15:55:30.015
  May 13 15:55:30.031: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7294" for this suite. @ 05/13/24 15:55:30.037
• [8.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 05/13/24 15:55:30.045
  May 13 15:55:30.045: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename secrets @ 05/13/24 15:55:30.045
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:55:30.055
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:55:30.057
  STEP: Creating secret with name s-test-opt-del-52c74f44-b25e-4c91-a01b-5d794161e8ef @ 05/13/24 15:55:30.061
  STEP: Creating secret with name s-test-opt-upd-56225d79-68f9-4476-8b5f-410ad4bc8654 @ 05/13/24 15:55:30.064
  STEP: Creating the pod @ 05/13/24 15:55:30.067
  E0513 15:55:30.909457      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:31.910285      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-52c74f44-b25e-4c91-a01b-5d794161e8ef @ 05/13/24 15:55:32.09
  STEP: Updating secret s-test-opt-upd-56225d79-68f9-4476-8b5f-410ad4bc8654 @ 05/13/24 15:55:32.093
  STEP: Creating secret with name s-test-opt-create-b86cd5f8-be23-4cb1-b7cd-f97a357d0aa2 @ 05/13/24 15:55:32.097
  STEP: waiting to observe update in volume @ 05/13/24 15:55:32.099
  E0513 15:55:32.911005      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:33.911733      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:55:34.146: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1528" for this suite. @ 05/13/24 15:55:34.149
• [4.110 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:214
  STEP: Creating a kubernetes client @ 05/13/24 15:55:34.155
  May 13 15:55:34.155: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/13/24 15:55:34.156
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:55:34.166
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:55:34.168
  STEP: create the container to handle the HTTPGet hook request. @ 05/13/24 15:55:34.172
  E0513 15:55:34.912775      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:35.913731      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/13/24 15:55:36.189
  E0513 15:55:36.913602      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:37.913677      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 05/13/24 15:55:38.209
  E0513 15:55:38.913731      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:39.914302      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 05/13/24 15:55:40.219
  May 13 15:55:40.229: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-634" for this suite. @ 05/13/24 15:55:40.232
• [6.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:714
  STEP: Creating a kubernetes client @ 05/13/24 15:55:40.241
  May 13 15:55:40.241: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename gc @ 05/13/24 15:55:40.242
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:55:40.252
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:55:40.254
  STEP: create the rc1 @ 05/13/24 15:55:40.258
  STEP: create the rc2 @ 05/13/24 15:55:40.262
  E0513 15:55:40.915860      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:41.916670      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:42.918276      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:43.918592      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:44.918924      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:45.919767      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 05/13/24 15:55:46.273
  STEP: delete the rc simpletest-rc-to-be-deleted @ 05/13/24 15:55:46.752
  STEP: wait for the rc to be deleted @ 05/13/24 15:55:46.76
  E0513 15:55:46.920812      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:47.920871      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:48.921139      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:49.921332      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:50.922061      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:55:51.776: INFO: 70 pods remaining
  May 13 15:55:51.777: INFO: 70 pods has nil DeletionTimestamp
  May 13 15:55:51.777: INFO: 
  E0513 15:55:51.923081      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:52.924146      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:53.924296      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:54.924981      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:55.925240      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/13/24 15:55:56.77
  May 13 15:55:56.838: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  May 13 15:55:56.842: INFO: Deleting pod "simpletest-rc-to-be-deleted-2gz58" in namespace "gc-4780"
  May 13 15:55:56.852: INFO: Deleting pod "simpletest-rc-to-be-deleted-2nc4f" in namespace "gc-4780"
  May 13 15:55:56.863: INFO: Deleting pod "simpletest-rc-to-be-deleted-2szkt" in namespace "gc-4780"
  May 13 15:55:56.871: INFO: Deleting pod "simpletest-rc-to-be-deleted-2xkth" in namespace "gc-4780"
  May 13 15:55:56.877: INFO: Deleting pod "simpletest-rc-to-be-deleted-44vmd" in namespace "gc-4780"
  May 13 15:55:56.885: INFO: Deleting pod "simpletest-rc-to-be-deleted-4dsv2" in namespace "gc-4780"
  May 13 15:55:56.894: INFO: Deleting pod "simpletest-rc-to-be-deleted-4w4v7" in namespace "gc-4780"
  May 13 15:55:56.902: INFO: Deleting pod "simpletest-rc-to-be-deleted-526cf" in namespace "gc-4780"
  May 13 15:55:56.910: INFO: Deleting pod "simpletest-rc-to-be-deleted-5czvh" in namespace "gc-4780"
  May 13 15:55:56.919: INFO: Deleting pod "simpletest-rc-to-be-deleted-5gmpm" in namespace "gc-4780"
  May 13 15:55:56.929: INFO: Deleting pod "simpletest-rc-to-be-deleted-5kf6k" in namespace "gc-4780"
  E0513 15:55:56.929523      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:55:56.940: INFO: Deleting pod "simpletest-rc-to-be-deleted-5mc5v" in namespace "gc-4780"
  May 13 15:55:56.948: INFO: Deleting pod "simpletest-rc-to-be-deleted-5mlkg" in namespace "gc-4780"
  May 13 15:55:56.955: INFO: Deleting pod "simpletest-rc-to-be-deleted-5rxqj" in namespace "gc-4780"
  May 13 15:55:56.965: INFO: Deleting pod "simpletest-rc-to-be-deleted-5z4hj" in namespace "gc-4780"
  May 13 15:55:56.973: INFO: Deleting pod "simpletest-rc-to-be-deleted-6rfx8" in namespace "gc-4780"
  May 13 15:55:56.981: INFO: Deleting pod "simpletest-rc-to-be-deleted-7r8xv" in namespace "gc-4780"
  May 13 15:55:56.991: INFO: Deleting pod "simpletest-rc-to-be-deleted-7rn8s" in namespace "gc-4780"
  May 13 15:55:57.000: INFO: Deleting pod "simpletest-rc-to-be-deleted-7tm9q" in namespace "gc-4780"
  May 13 15:55:57.008: INFO: Deleting pod "simpletest-rc-to-be-deleted-7tnxl" in namespace "gc-4780"
  May 13 15:55:57.016: INFO: Deleting pod "simpletest-rc-to-be-deleted-8l4bc" in namespace "gc-4780"
  May 13 15:55:57.026: INFO: Deleting pod "simpletest-rc-to-be-deleted-8ncn9" in namespace "gc-4780"
  May 13 15:55:57.035: INFO: Deleting pod "simpletest-rc-to-be-deleted-8pvqj" in namespace "gc-4780"
  May 13 15:55:57.042: INFO: Deleting pod "simpletest-rc-to-be-deleted-92zvx" in namespace "gc-4780"
  May 13 15:55:57.051: INFO: Deleting pod "simpletest-rc-to-be-deleted-9hsnc" in namespace "gc-4780"
  May 13 15:55:57.061: INFO: Deleting pod "simpletest-rc-to-be-deleted-9n7fn" in namespace "gc-4780"
  May 13 15:55:57.071: INFO: Deleting pod "simpletest-rc-to-be-deleted-b6mfs" in namespace "gc-4780"
  May 13 15:55:57.082: INFO: Deleting pod "simpletest-rc-to-be-deleted-b6vz5" in namespace "gc-4780"
  May 13 15:55:57.094: INFO: Deleting pod "simpletest-rc-to-be-deleted-bqvdq" in namespace "gc-4780"
  May 13 15:55:57.106: INFO: Deleting pod "simpletest-rc-to-be-deleted-bx2f8" in namespace "gc-4780"
  May 13 15:55:57.113: INFO: Deleting pod "simpletest-rc-to-be-deleted-ckjqp" in namespace "gc-4780"
  May 13 15:55:57.123: INFO: Deleting pod "simpletest-rc-to-be-deleted-d4rl4" in namespace "gc-4780"
  May 13 15:55:57.131: INFO: Deleting pod "simpletest-rc-to-be-deleted-d5gfs" in namespace "gc-4780"
  May 13 15:55:57.139: INFO: Deleting pod "simpletest-rc-to-be-deleted-dl9dl" in namespace "gc-4780"
  May 13 15:55:57.146: INFO: Deleting pod "simpletest-rc-to-be-deleted-f4hnf" in namespace "gc-4780"
  May 13 15:55:57.154: INFO: Deleting pod "simpletest-rc-to-be-deleted-fb9xz" in namespace "gc-4780"
  May 13 15:55:57.162: INFO: Deleting pod "simpletest-rc-to-be-deleted-fjcmv" in namespace "gc-4780"
  May 13 15:55:57.169: INFO: Deleting pod "simpletest-rc-to-be-deleted-fl7hv" in namespace "gc-4780"
  May 13 15:55:57.177: INFO: Deleting pod "simpletest-rc-to-be-deleted-fr4s7" in namespace "gc-4780"
  May 13 15:55:57.187: INFO: Deleting pod "simpletest-rc-to-be-deleted-g2k4f" in namespace "gc-4780"
  May 13 15:55:57.195: INFO: Deleting pod "simpletest-rc-to-be-deleted-gq9gk" in namespace "gc-4780"
  May 13 15:55:57.204: INFO: Deleting pod "simpletest-rc-to-be-deleted-gsn9c" in namespace "gc-4780"
  May 13 15:55:57.212: INFO: Deleting pod "simpletest-rc-to-be-deleted-gxj5k" in namespace "gc-4780"
  May 13 15:55:57.219: INFO: Deleting pod "simpletest-rc-to-be-deleted-jjvj8" in namespace "gc-4780"
  May 13 15:55:57.227: INFO: Deleting pod "simpletest-rc-to-be-deleted-jmfzn" in namespace "gc-4780"
  May 13 15:55:57.238: INFO: Deleting pod "simpletest-rc-to-be-deleted-jpkph" in namespace "gc-4780"
  May 13 15:55:57.254: INFO: Deleting pod "simpletest-rc-to-be-deleted-jrlpj" in namespace "gc-4780"
  May 13 15:55:57.261: INFO: Deleting pod "simpletest-rc-to-be-deleted-k6vlq" in namespace "gc-4780"
  May 13 15:55:57.270: INFO: Deleting pod "simpletest-rc-to-be-deleted-k7vnj" in namespace "gc-4780"
  May 13 15:55:57.281: INFO: Deleting pod "simpletest-rc-to-be-deleted-kqh74" in namespace "gc-4780"
  May 13 15:55:57.289: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-4780" for this suite. @ 05/13/24 15:55:57.292
• [17.054 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:109
  STEP: Creating a kubernetes client @ 05/13/24 15:55:57.296
  May 13 15:55:57.296: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubelet-test @ 05/13/24 15:55:57.297
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:55:57.307
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:55:57.309
  E0513 15:55:57.929855      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:58.930073      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:55:59.930915      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:00.931987      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:01.932909      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:02.933442      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:03.933602      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:04.933628      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:05.933809      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:06.934576      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:07.934669      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:08.934873      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:56:09.329: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-8238" for this suite. @ 05/13/24 15:56:09.333
• [12.040 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:250
  STEP: Creating a kubernetes client @ 05/13/24 15:56:09.337
  May 13 15:56:09.337: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename webhook @ 05/13/24 15:56:09.339
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:56:09.351
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:56:09.352
  STEP: Setting up server cert @ 05/13/24 15:56:09.367
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/13/24 15:56:09.818
  STEP: Deploying the webhook pod @ 05/13/24 15:56:09.82
  STEP: Wait for the deployment to be ready @ 05/13/24 15:56:09.828
  May 13 15:56:09.833: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0513 15:56:09.935360      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:10.935809      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/13/24 15:56:11.846
  STEP: Verifying the service has paired with the endpoint @ 05/13/24 15:56:11.867
  E0513 15:56:11.935991      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:56:12.868: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 05/13/24 15:56:12.874
  STEP: create a configmap that should be updated by the webhook @ 05/13/24 15:56:12.895
  May 13 15:56:12.935: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1661" for this suite. @ 05/13/24 15:56:12.938
  E0513 15:56:12.938414      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-markers-6044" for this suite. @ 05/13/24 15:56:12.943
• [3.624 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:948
  STEP: Creating a kubernetes client @ 05/13/24 15:56:12.964
  May 13 15:56:12.964: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename resourcequota @ 05/13/24 15:56:12.965
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:56:12.982
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:56:12.983
  STEP: Creating a ResourceQuota @ 05/13/24 15:56:12.986
  STEP: Getting a ResourceQuota @ 05/13/24 15:56:12.988
  STEP: Listing all ResourceQuotas with LabelSelector @ 05/13/24 15:56:12.99
  STEP: Patching the ResourceQuota @ 05/13/24 15:56:12.992
  STEP: Deleting a Collection of ResourceQuotas @ 05/13/24 15:56:12.996
  STEP: Verifying the deleted ResourceQuota @ 05/13/24 15:56:12.999
  May 13 15:56:13.000: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8935" for this suite. @ 05/13/24 15:56:13.002
• [0.041 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:315
  STEP: Creating a kubernetes client @ 05/13/24 15:56:13.005
  May 13 15:56:13.005: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename webhook @ 05/13/24 15:56:13.006
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:56:13.014
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:56:13.017
  STEP: Setting up server cert @ 05/13/24 15:56:13.031
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/13/24 15:56:13.53
  STEP: Deploying the webhook pod @ 05/13/24 15:56:13.533
  STEP: Wait for the deployment to be ready @ 05/13/24 15:56:13.542
  May 13 15:56:13.546: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0513 15:56:13.938673      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:14.938958      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/13/24 15:56:15.55
  STEP: Verifying the service has paired with the endpoint @ 05/13/24 15:56:15.555
  E0513 15:56:15.939738      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:56:16.557: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  May 13 15:56:16.560: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 15:56:16.939960      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7994-crds.webhook.example.com via the AdmissionRegistration API @ 05/13/24 15:56:17.092
  STEP: Creating a custom resource while v1 is storage version @ 05/13/24 15:56:17.116
  E0513 15:56:17.940473      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:18.940604      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 05/13/24 15:56:19.148
  STEP: Patching the custom resource while v2 is storage version @ 05/13/24 15:56:19.166
  May 13 15:56:19.736: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1722" for this suite. @ 05/13/24 15:56:19.742
  STEP: Destroying namespace "webhook-markers-4279" for this suite. @ 05/13/24 15:56:19.75
• [6.749 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:86
  STEP: Creating a kubernetes client @ 05/13/24 15:56:19.755
  May 13 15:56:19.755: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 15:56:19.756
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:56:19.77
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:56:19.772
  STEP: Creating a pod to test downward API volume plugin @ 05/13/24 15:56:19.774
  E0513 15:56:19.941752      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:20.942563      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:21.942636      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:22.942930      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 15:56:23.789
  May 13 15:56:23.790: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod downwardapi-volume-9fda81b3-a579-4c4d-b522-b7e176762a33 container client-container: <nil>
  STEP: delete the pod @ 05/13/24 15:56:23.794
  May 13 15:56:23.804: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8113" for this suite. @ 05/13/24 15:56:23.807
• [4.056 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:245
  STEP: Creating a kubernetes client @ 05/13/24 15:56:23.813
  May 13 15:56:23.813: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename namespaces @ 05/13/24 15:56:23.814
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:56:23.873
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:56:23.875
  STEP: Creating a test namespace @ 05/13/24 15:56:23.876
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:56:23.886
  STEP: Creating a pod in the namespace @ 05/13/24 15:56:23.887
  STEP: Waiting for the pod to have running status @ 05/13/24 15:56:23.892
  E0513 15:56:23.943495      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:24.950662      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the namespace @ 05/13/24 15:56:25.897
  STEP: Waiting for the namespace to be removed. @ 05/13/24 15:56:25.902
  E0513 15:56:25.951454      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:26.952454      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:27.953365      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:28.953420      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:29.953458      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:30.953766      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:31.954675      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:32.954366      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:33.954958      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:34.955522      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:35.955703      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 05/13/24 15:56:36.909
  STEP: Verifying there are no pods in the namespace @ 05/13/24 15:56:36.926
  May 13 15:56:36.927: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-3146" for this suite. @ 05/13/24 15:56:36.929
  STEP: Destroying namespace "nsdeletetest-7509" for this suite. @ 05/13/24 15:56:36.933
  May 13 15:56:36.934: INFO: Namespace nsdeletetest-7509 was already deleted
  STEP: Destroying namespace "nsdeletetest-261" for this suite. @ 05/13/24 15:56:36.934
• [13.127 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:183
  STEP: Creating a kubernetes client @ 05/13/24 15:56:36.941
  May 13 15:56:36.941: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename container-probe @ 05/13/24 15:56:36.941
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 15:56:36.952
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 15:56:36.953
  STEP: Creating pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558 @ 05/13/24 15:56:36.955
  E0513 15:56:36.956081      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:37.956439      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:38.956398      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/13/24 15:56:38.965
  May 13 15:56:38.966: INFO: Initial restart count of pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 is 0
  May 13 15:56:38.967: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:56:39.956515      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:40.956696      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:56:40.969: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:56:41.966790      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:42.967329      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:56:42.978: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:56:43.967996      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:44.967907      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:56:44.986: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:56:45.968022      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:46.968746      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:56:46.988: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:56:47.968865      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:48.968961      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:56:48.990: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:56:49.970164      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:50.970156      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:56:50.993: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:56:51.970927      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:52.971358      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:56:53.000: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:56:53.971485      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:54.972919      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:56:55.009: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:56:55.973244      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:56.973631      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:56:57.011: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:56:57.974053      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:56:58.974767      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:56:59.013: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:56:59.975162      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:00.975288      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:01.020: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:01.975649      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:02.977034      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:03.028: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:03.977799      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:04.978169      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:05.030: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:05.979196      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:06.979914      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:07.032: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:07.980299      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:08.981255      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:09.039: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:09.982113      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:10.983245      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:11.045: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:11.983345      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:12.984205      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:13.048: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:13.985825      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:14.986947      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:15.055: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:15.987374      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:16.987575      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:17.065: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:17.987688      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:18.988044      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:19.068: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:19.988901      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:20.989092      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:21.071: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:21.990117      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:22.990012      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:23.077: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:23.991320      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:24.992312      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:25.084: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:25.993276      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:26.993883      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:27.091: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:27.994696      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:28.994719      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:29.095: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:29.995061      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:30.995196      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:31.098: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:31.995482      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:32.999176      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:33.104: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:33.999742      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:35.000531      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:35.114: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:36.000510      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:37.000736      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:37.121: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:38.001440      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:39.001588      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:39.123: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:40.002003      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:41.002566      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:41.130: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:42.002823      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:43.003211      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:43.137: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:44.003848      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:45.004145      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:45.145: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:46.004249      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:47.005413      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:47.154: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:48.005431      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:49.005617      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:49.159: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:50.006168      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:51.006266      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:51.164: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:52.007248      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:53.007504      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:53.172: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:54.007706      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:55.009272      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:55.180: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:56.009350      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:57.010831      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:57.188: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:57:58.010863      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:57:59.011075      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:57:59.190: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:00.011112      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:01.011224      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:01.192: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:02.011775      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:03.011904      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:03.195: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:04.012761      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:05.013842      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:05.196: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:06.014300      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:07.014830      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:07.208: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:08.014831      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:09.015333      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:09.215: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:10.015989      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:11.018686      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:11.220: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:12.019281      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:13.020181      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:13.223: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:14.020892      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:15.021703      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:15.225: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:16.022501      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:17.022961      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:17.233: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:18.023046      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:19.023852      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:19.242: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:20.024434      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:21.024979      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:21.246: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:22.026644      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:23.026802      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:23.248: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:24.027356      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:25.028076      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:25.251: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:26.028187      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:27.028249      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:27.260: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:28.028883      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:29.029242      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:29.265: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:30.029314      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:31.029270      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:31.272: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:32.031484      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:33.031655      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:33.275: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:34.032134      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:35.032299      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:35.276: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:36.032265      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:37.032720      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:37.278: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:38.033195      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:39.033334      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:39.285: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:40.034408      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:41.035008      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:41.295: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:42.036951      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:43.036717      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:43.298: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:44.037403      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:45.038106      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:45.304: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:46.038677      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:47.038638      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:47.308: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:48.039438      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:49.039956      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:49.313: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:50.040596      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:51.040540      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:51.317: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:52.040686      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:53.041099      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:53.319: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:54.041994      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:55.043116      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:55.321: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:56.043204      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:57.043224      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:57.324: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:58:58.043464      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:58:59.043543      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:58:59.330: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:00.044399      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:01.044680      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:01.337: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:02.045163      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:03.046062      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:03.340: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:04.046935      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:05.047329      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:05.344: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:06.047957      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:07.048131      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:07.347: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:08.049156      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:09.049528      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:09.350: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:10.049788      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:11.050758      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:11.355: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:12.050292      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:13.055702      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:13.358: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:14.055839      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:15.056712      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:15.370: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:16.057175      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:17.057481      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:17.381: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:18.057961      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:19.058007      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:19.386: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:20.058025      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:21.058403      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:21.389: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:22.058686      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:23.058995      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:23.398: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:24.059872      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:25.060759      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:25.409: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:26.061748      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:27.062800      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:27.413: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:28.063320      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:29.064204      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:29.420: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:30.065090      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:31.065315      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:31.427: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:32.065605      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:33.066179      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:33.431: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:34.066960      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:35.067444      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:35.437: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:36.067611      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:37.067925      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:37.441: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:38.068883      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:39.069250      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:39.450: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:40.069800      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:41.070199      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:41.455: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:42.070955      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:43.072017      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:43.457: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:44.072076      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:45.072921      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:45.469: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:46.074074      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:47.074572      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:47.474: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:48.075252      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:49.075389      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:49.488: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:50.075555      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:51.076087      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:51.493: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:52.076366      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:53.076570      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:53.495: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:54.077789      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:55.077928      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:55.501: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:56.079109      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:57.080452      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:57.505: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 15:59:58.080097      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 15:59:59.080165      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 15:59:59.508: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 16:00:00.080675      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:01.081745      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:00:01.512: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 16:00:02.081841      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:03.082149      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:00:03.514: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 16:00:04.083255      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:05.084341      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:00:05.521: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 16:00:06.085125      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:07.085334      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:00:07.524: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 16:00:08.086654      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:09.087096      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:00:09.532: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 16:00:10.087070      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:11.087485      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:00:11.534: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 16:00:12.087572      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:13.087788      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:00:13.536: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 16:00:14.088589      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:15.088949      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:00:15.538: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 16:00:16.089987      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:17.090160      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:00:17.541: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 16:00:18.090327      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:19.091093      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:00:19.544: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 16:00:20.091462      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:21.092227      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:00:21.546: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 16:00:22.092550      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:23.092730      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:00:23.550: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 16:00:24.094375      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:25.095157      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:00:25.552: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 16:00:26.095706      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:27.096408      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:00:27.564: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 16:00:28.097062      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:29.098081      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:00:29.569: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 16:00:30.098337      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:31.098873      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:00:31.581: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 16:00:32.100066      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:33.101056      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:00:33.596: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 16:00:34.102260      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:35.102351      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:00:35.609: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 16:00:36.102779      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:37.103714      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:00:37.612: INFO: Get pod liveness-2da40f04-58bd-47ec-a383-dd607f8df9f1 in namespace container-probe-7558
  E0513 16:00:38.104061      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:39.104647      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 05/13/24 16:00:39.613
  May 13 16:00:39.625: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7558" for this suite. @ 05/13/24 16:00:39.631
• [242.693 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 05/13/24 16:00:39.633
  May 13 16:00:39.633: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 16:00:39.635
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:00:39.655
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:00:39.657
  STEP: Creating configMap with name configmap-projected-all-test-volume-085b9300-720f-4d82-9f4b-41dac716291a @ 05/13/24 16:00:39.659
  STEP: Creating secret with name secret-projected-all-test-volume-714a9289-a6a6-4ec1-99a5-b89e5c5ade04 @ 05/13/24 16:00:39.662
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 05/13/24 16:00:39.664
  E0513 16:00:40.104802      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:41.105926      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:42.106440      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:43.107071      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:00:43.692
  May 13 16:00:43.693: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod projected-volume-54d19e2b-2f2a-4418-b2b2-4b67fa07308a container projected-all-volume-test: <nil>
  STEP: delete the pod @ 05/13/24 16:00:43.703
  May 13 16:00:43.713: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3340" for this suite. @ 05/13/24 16:00:43.716
• [4.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:158
  STEP: Creating a kubernetes client @ 05/13/24 16:00:43.721
  May 13 16:00:43.722: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename runtimeclass @ 05/13/24 16:00:43.723
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:00:43.734
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:00:43.735
  STEP: Deleting RuntimeClass runtimeclass-8125-delete-me @ 05/13/24 16:00:43.739
  STEP: Waiting for the RuntimeClass to disappear @ 05/13/24 16:00:43.742
  May 13 16:00:43.746: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8125" for this suite. @ 05/13/24 16:00:43.749
• [0.033 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 05/13/24 16:00:43.756
  May 13 16:00:43.756: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename events @ 05/13/24 16:00:43.756
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:00:43.768
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:00:43.769
  STEP: creating a test event @ 05/13/24 16:00:43.77
  STEP: listing all events in all namespaces @ 05/13/24 16:00:43.772
  STEP: patching the test event @ 05/13/24 16:00:43.786
  STEP: fetching the test event @ 05/13/24 16:00:43.789
  STEP: updating the test event @ 05/13/24 16:00:43.79
  STEP: getting the test event @ 05/13/24 16:00:43.794
  STEP: deleting the test event @ 05/13/24 16:00:43.796
  STEP: listing all events in all namespaces @ 05/13/24 16:00:43.798
  May 13 16:00:43.818: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-8390" for this suite. @ 05/13/24 16:00:43.821
• [0.070 seconds]
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:92
  STEP: Creating a kubernetes client @ 05/13/24 16:00:43.826
  May 13 16:00:43.826: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename downward-api @ 05/13/24 16:00:43.827
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:00:43.837
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:00:43.839
  STEP: Creating a pod to test downward api env vars @ 05/13/24 16:00:43.845
  E0513 16:00:44.108300      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:45.109195      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:46.110679      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:47.110250      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:00:47.86
  May 13 16:00:47.861: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod downward-api-b6a2a9d4-53bc-4d21-b6e5-faddd2b5cd55 container dapi-container: <nil>
  STEP: delete the pod @ 05/13/24 16:00:47.866
  May 13 16:00:47.876: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-14" for this suite. @ 05/13/24 16:00:47.879
• [4.056 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:372
  STEP: Creating a kubernetes client @ 05/13/24 16:00:47.883
  May 13 16:00:47.883: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename namespaces @ 05/13/24 16:00:47.884
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:00:47.895
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:00:47.896
  STEP: Updating Namespace "namespaces-9232" @ 05/13/24 16:00:47.898
  May 13 16:00:47.905: INFO: Namespace "namespaces-9232" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"50111627-8bdf-4f1e-a872-7707fb8f813f", "kubernetes.io/metadata.name":"namespaces-9232", "namespaces-9232":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  May 13 16:00:47.905: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-9232" for this suite. @ 05/13/24 16:00:47.907
• [0.028 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:47
  STEP: Creating a kubernetes client @ 05/13/24 16:00:47.913
  May 13 16:00:47.913: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename var-expansion @ 05/13/24 16:00:47.914
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:00:47.924
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:00:47.926
  STEP: Creating a pod to test env composition @ 05/13/24 16:00:47.928
  E0513 16:00:48.110773      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:49.111618      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:50.111821      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:51.112136      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:00:51.941
  May 13 16:00:51.943: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod var-expansion-f4a890f3-b885-4243-86bd-5203600b2b55 container dapi-container: <nil>
  STEP: delete the pod @ 05/13/24 16:00:51.952
  May 13 16:00:51.968: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5481" for this suite. @ 05/13/24 16:00:51.971
• [4.061 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 05/13/24 16:00:51.975
  May 13 16:00:51.975: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename taint-single-pod @ 05/13/24 16:00:51.976
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:00:51.987
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:00:51.989
  May 13 16:00:51.990: INFO: Waiting up to 1m0s for all nodes to be ready
  E0513 16:00:52.112420      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:53.112433      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:54.113059      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:55.113499      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:56.114735      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:57.114598      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:58.115692      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:00:59.115699      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:00.115780      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:01.116019      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:02.116783      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:03.118723      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:04.119440      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:05.119604      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:06.120357      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:07.120482      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:08.120763      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:09.121634      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:10.121724      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:11.123089      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:12.123704      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:13.124282      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:14.125957      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:15.126929      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:16.127240      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:17.127874      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:18.128665      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:19.128951      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:20.129672      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:21.129780      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:22.130437      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:23.130542      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:24.131520      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:25.132333      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:26.132712      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:27.133240      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:28.133673      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:29.133910      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:30.134888      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:31.135938      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:32.136197      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:33.136399      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:34.136712      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:35.138021      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:36.138886      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:37.139506      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:38.142782      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:39.139848      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:40.142135      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:41.140575      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:42.141378      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:43.141780      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:44.142053      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:45.142536      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:46.142928      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:47.143400      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:48.143547      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:49.143651      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:50.144071      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:51.144296      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:01:51.991: INFO: Waiting for terminating namespaces to be deleted...
  May 13 16:01:51.998: INFO: Starting informer...
  STEP: Starting pod... @ 05/13/24 16:01:51.998
  E0513 16:01:52.144627      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:01:52.221: INFO: Pod is running on oneke-ip-172-16-100-5. Tainting Node
  STEP: Trying to apply a taint on the Node @ 05/13/24 16:01:52.221
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/13/24 16:01:52.244
  STEP: Waiting short time to make sure Pod is queued for deletion @ 05/13/24 16:01:52.278
  May 13 16:01:52.279: INFO: Pod wasn't evicted. Proceeding
  May 13 16:01:52.279: INFO: Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/13/24 16:01:52.348
  STEP: Waiting some time to make sure that toleration time passed. @ 05/13/24 16:01:52.383
  E0513 16:01:53.144978      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:54.145069      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:55.146122      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:56.146682      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:57.147274      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:58.147089      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:01:59.147221      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:00.147272      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:01.147487      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:02.148282      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:03.148465      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:04.148640      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:05.149737      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:06.150101      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:07.150766      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:08.150682      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:09.150797      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:10.153914      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:11.154664      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:12.154538      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:13.154973      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:14.155386      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:15.156491      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:16.157584      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:17.158062      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:18.158803      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:19.159916      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:20.160224      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:21.160403      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:22.160774      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:23.160862      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:24.161869      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:25.162797      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:26.162891      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:27.163022      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:28.163158      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:29.163460      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:30.164596      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:31.165417      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:32.165657      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:33.165682      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:34.166658      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:35.167690      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:36.168048      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:37.168338      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:38.168317      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:39.168522      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:40.168944      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:41.169441      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:42.169840      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:43.170514      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:44.171069      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:45.172058      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:46.173281      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:47.173495      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:48.173615      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:49.173677      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:50.174368      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:51.175669      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:52.176195      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:53.176554      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:54.177968      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:55.178886      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:56.178892      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:57.179243      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:58.179351      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:02:59.179378      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:00.179883      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:01.180010      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:02.180370      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:03.181046      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:04.181873      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:05.182550      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:06.182618      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:07.182746      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:03:07.384: INFO: Pod wasn't evicted. Test successful
  May 13 16:03:07.384: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-1325" for this suite. @ 05/13/24 16:03:07.391
• [135.422 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:887
  STEP: Creating a kubernetes client @ 05/13/24 16:03:07.398
  May 13 16:03:07.398: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubectl @ 05/13/24 16:03:07.401
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:03:07.417
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:03:07.419
  STEP: validating api versions @ 05/13/24 16:03:07.421
  May 13 16:03:07.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-6434 api-versions'
  May 13 16:03:07.473: INFO: stderr: ""
  May 13 16:03:07.473: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta3\nhelm.cattle.io/v1\nk3s.cattle.io/v1\nk8s.cni.cncf.io/v1\nlonghorn.io/v1beta1\nlonghorn.io/v1beta2\nmetallb.io/v1beta1\nmetallb.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nsnapshot.storage.k8s.io/v1beta1\nstorage.k8s.io/v1\ntraefik.io/v1alpha1\nv1\nwhereabouts.cni.cncf.io/v1alpha1\n"
  May 13 16:03:07.473: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6434" for this suite. @ 05/13/24 16:03:07.475
• [0.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:195
  STEP: Creating a kubernetes client @ 05/13/24 16:03:07.483
  May 13 16:03:07.483: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 16:03:07.484
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:03:07.495
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:03:07.497
  STEP: Creating a pod to test downward API volume plugin @ 05/13/24 16:03:07.498
  E0513 16:03:08.183633      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:09.184314      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:10.184740      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:11.185022      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:03:11.513
  May 13 16:03:11.516: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod downwardapi-volume-08119468-e45b-4e17-8602-ab8410b63a7c container client-container: <nil>
  STEP: delete the pod @ 05/13/24 16:03:11.524
  May 13 16:03:11.535: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8176" for this suite. @ 05/13/24 16:03:11.539
• [4.061 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 05/13/24 16:03:11.544
  May 13 16:03:11.544: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 16:03:11.546
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:03:11.554
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:03:11.556
  STEP: Creating secret with name projected-secret-test-e251a75f-7acd-4396-b0c3-30e1f7e7fc44 @ 05/13/24 16:03:11.557
  STEP: Creating a pod to test consume secrets @ 05/13/24 16:03:11.561
  E0513 16:03:12.185105      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:13.185241      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:14.185813      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:15.185942      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:03:15.571
  May 13 16:03:15.572: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-projected-secrets-2ba18999-f8be-43bd-8af4-bcb0e7b8fd98 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/13/24 16:03:15.583
  May 13 16:03:15.592: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8932" for this suite. @ 05/13/24 16:03:15.594
• [4.053 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:309
  STEP: Creating a kubernetes client @ 05/13/24 16:03:15.598
  May 13 16:03:15.598: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/13/24 16:03:15.599
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:03:15.611
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:03:15.612
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 05/13/24 16:03:15.614
  May 13 16:03:15.614: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 16:03:16.186449      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:17.187234      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:18.186984      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:19.187761      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:20.187836      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 05/13/24 16:03:21.071
  May 13 16:03:21.072: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 16:03:21.188793      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:22.202622      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:03:22.536: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 16:03:23.202809      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:24.204266      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:25.204918      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:26.206739      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:27.206876      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:03:28.049: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2445" for this suite. @ 05/13/24 16:03:28.053
• [12.460 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:223
  STEP: Creating a kubernetes client @ 05/13/24 16:03:28.06
  May 13 16:03:28.060: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 16:03:28.061
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:03:28.07
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:03:28.073
  STEP: Creating a pod to test downward API volume plugin @ 05/13/24 16:03:28.081
  E0513 16:03:28.207805      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:29.208706      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:30.209957      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:31.210823      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:03:32.097
  May 13 16:03:32.098: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod downwardapi-volume-4a7bf911-7f75-41f7-8337-dc7f9c5d9824 container client-container: <nil>
  STEP: delete the pod @ 05/13/24 16:03:32.101
  May 13 16:03:32.111: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4418" for this suite. @ 05/13/24 16:03:32.113
• [4.058 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 05/13/24 16:03:32.117
  May 13 16:03:32.117: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename tables @ 05/13/24 16:03:32.118
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:03:32.128
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:03:32.13
  May 13 16:03:32.132: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-852" for this suite. @ 05/13/24 16:03:32.134
• [0.020 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 05/13/24 16:03:32.138
  May 13 16:03:32.138: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename secrets @ 05/13/24 16:03:32.138
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:03:32.148
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:03:32.149
  STEP: Creating secret with name secret-test-89eda169-4455-4184-b3af-a99c75e770d1 @ 05/13/24 16:03:32.151
  STEP: Creating a pod to test consume secrets @ 05/13/24 16:03:32.155
  E0513 16:03:32.211414      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:33.211919      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:34.212364      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:35.212920      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:03:36.172
  May 13 16:03:36.178: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-secrets-0a5aa2a3-58ad-4bfa-95cf-40367ba0bd7f container secret-volume-test: <nil>
  STEP: delete the pod @ 05/13/24 16:03:36.19
  May 13 16:03:36.212: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0513 16:03:36.212915      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "secrets-1965" for this suite. @ 05/13/24 16:03:36.215
• [4.082 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 05/13/24 16:03:36.22
  May 13 16:03:36.220: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename watch @ 05/13/24 16:03:36.22
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:03:36.23
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:03:36.232
  STEP: getting a starting resourceVersion @ 05/13/24 16:03:36.233
  STEP: starting a background goroutine to produce watch events @ 05/13/24 16:03:36.234
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 05/13/24 16:03:36.234
  E0513 16:03:37.213266      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:38.217066      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:03:39.024: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-8244" for this suite. @ 05/13/24 16:03:39.077
• [2.906 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3649
  STEP: Creating a kubernetes client @ 05/13/24 16:03:39.127
  May 13 16:03:39.127: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename services @ 05/13/24 16:03:39.128
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:03:39.139
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:03:39.14
  STEP: creating service multiprotocol-test in namespace services-3147 @ 05/13/24 16:03:39.141
  STEP: creating pod pod1 in namespace services-3147 @ 05/13/24 16:03:39.151
  STEP: Creating pod pod1 in namespace services-3147 @ 05/13/24 16:03:39.151
  E0513 16:03:39.217345      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:40.218523      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multiprotocol-test in namespace services-3147 to expose endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]] @ 05/13/24 16:03:41.173
  May 13 16:03:41.180: INFO: successfully validated that service multiprotocol-test in namespace services-3147 exposes endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 05/13/24 16:03:41.181
  May 13 16:03:41.181: INFO: Creating new exec pod
  E0513 16:03:41.219034      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:42.219582      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:03:43.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-3147 exec execpod7cz2l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.30.220 80'
  E0513 16:03:43.220383      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:03:43.302: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.30.220 80\nConnection to 10.43.30.220 80 port [tcp/http] succeeded!\n"
  May 13 16:03:43.302: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 13 16:03:43.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-3147 exec execpod7cz2l -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.43.30.220 80'
  E0513 16:03:44.221437      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:45.221465      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:46.221770      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:47.222654      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:03:47.427: INFO: stderr: "+ nc -v -u -w 2 10.43.30.220 80\n+ echo hostName\nConnection to 10.43.30.220 80 port [udp/*] succeeded!\n"
  May 13 16:03:47.427: INFO: stdout: "pod1"
  STEP: Checking if the Service forwards traffic to TCP only @ 05/13/24 16:03:47.427
  May 13 16:03:47.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-3147 exec execpod7cz2l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.30.220 80'
  May 13 16:03:47.574: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.30.220 80\nConnection to 10.43.30.220 80 port [tcp/http] succeeded!\n"
  May 13 16:03:47.574: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 13 16:03:47.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-3147 exec execpod7cz2l -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.43.30.220 80'
  E0513 16:03:48.223502      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:49.224999      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:50.225181      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:51.226024      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:03:51.697: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.43.30.220 80\nConnection to 10.43.30.220 80 port [udp/*] succeeded!\n"
  May 13 16:03:51.698: INFO: stdout: ""
  May 13 16:03:51.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-3147 exec execpod7cz2l -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.43.30.220 80'
  E0513 16:03:52.227014      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:53.227777      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:54.228645      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:55.228810      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:03:55.851: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.43.30.220 80\nConnection to 10.43.30.220 80 port [udp/*] succeeded!\n"
  May 13 16:03:55.851: INFO: stdout: ""
  STEP: Checking if the Service forwards traffic to UDP only @ 05/13/24 16:03:55.851
  May 13 16:03:55.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-3147 exec execpod7cz2l -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.43.30.220 80'
  E0513 16:03:56.229998      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:57.230775      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:58.230949      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:03:59.232101      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:04:00.027: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.43.30.220 80\nConnection to 10.43.30.220 80 port [udp/*] succeeded!\n"
  May 13 16:04:00.027: INFO: stdout: "pod1"
  May 13 16:04:00.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-3147 exec execpod7cz2l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.30.220 80'
  E0513 16:04:00.232971      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:01.233054      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:04:02.152: INFO: rc: 1
  May 13 16:04:02.152: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-3147 exec execpod7cz2l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.30.220 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.43.30.220 80
  nc: connect to 10.43.30.220 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  May 13 16:04:02.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-3147 exec execpod7cz2l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.30.220 80'
  E0513 16:04:02.233663      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:03.233773      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:04.233988      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:04:04.265: INFO: rc: 1
  May 13 16:04:04.265: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-3147 exec execpod7cz2l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.30.220 80:
  Command stdout:

  stderr:
  + + echonc hostName -v
   -t -w 2 10.43.30.220 80
  nc: connect to 10.43.30.220 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  May 13 16:04:04.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-3147 exec execpod7cz2l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.30.220 80'
  E0513 16:04:05.234742      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:06.234145      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:04:06.391: INFO: rc: 1
  May 13 16:04:06.391: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-3147 exec execpod7cz2l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.30.220 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 10.43.30.220 80
  + echo hostName
  nc: connect to 10.43.30.220 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  May 13 16:04:06.392: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3147" for this suite. @ 05/13/24 16:04:06.395
• [27.272 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3129
  STEP: Creating a kubernetes client @ 05/13/24 16:04:06.399
  May 13 16:04:06.399: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename services @ 05/13/24 16:04:06.4
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:04:06.412
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:04:06.413
  STEP: fetching services @ 05/13/24 16:04:06.415
  May 13 16:04:06.417: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1307" for this suite. @ 05/13/24 16:04:06.419
• [0.024 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:480
  STEP: Creating a kubernetes client @ 05/13/24 16:04:06.425
  May 13 16:04:06.425: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename gc @ 05/13/24 16:04:06.426
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:04:06.436
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:04:06.438
  STEP: create the deployment @ 05/13/24 16:04:06.439
  W0513 16:04:06.443053      17 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 05/13/24 16:04:06.443
  STEP: delete the deployment @ 05/13/24 16:04:06.446
  STEP: wait for all rs to be garbage collected @ 05/13/24 16:04:06.458
  STEP: expected 0 rs, got 1 rs @ 05/13/24 16:04:06.465
  STEP: expected 0 pods, got 2 pods @ 05/13/24 16:04:06.472
  STEP: Gathering metrics @ 05/13/24 16:04:06.972
  May 13 16:04:07.046: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  May 13 16:04:07.046: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-12" for this suite. @ 05/13/24 16:04:07.048
• [0.626 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 05/13/24 16:04:07.053
  May 13 16:04:07.053: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename pods @ 05/13/24 16:04:07.053
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:04:07.063
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:04:07.065
  STEP: Create set of pods @ 05/13/24 16:04:07.066
  May 13 16:04:07.072: INFO: created test-pod-1
  May 13 16:04:07.088: INFO: created test-pod-2
  May 13 16:04:07.096: INFO: created test-pod-3
  STEP: waiting for all 3 pods to be running @ 05/13/24 16:04:07.098
  E0513 16:04:07.235239      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:08.235398      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 05/13/24 16:04:09.135
  May 13 16:04:09.137: INFO: Pod quantity 3 is different from expected quantity 0
  E0513 16:04:09.235878      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:04:10.139: INFO: Pod quantity 3 is different from expected quantity 0
  E0513 16:04:10.236006      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:04:11.139: INFO: Pod quantity 3 is different from expected quantity 0
  E0513 16:04:11.237037      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:04:12.136: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3513" for this suite. @ 05/13/24 16:04:12.141
• [5.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 05/13/24 16:04:12.15
  May 13 16:04:12.150: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename csiinlinevolumes @ 05/13/24 16:04:12.154
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:04:12.165
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:04:12.169
  STEP: creating @ 05/13/24 16:04:12.171
  STEP: getting @ 05/13/24 16:04:12.183
  STEP: listing in namespace @ 05/13/24 16:04:12.187
  STEP: patching @ 05/13/24 16:04:12.199
  STEP: deleting @ 05/13/24 16:04:12.205
  May 13 16:04:12.213: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-7377" for this suite. @ 05/13/24 16:04:12.226
• [0.081 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 05/13/24 16:04:12.234
  May 13 16:04:12.234: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename init-container @ 05/13/24 16:04:12.235
  E0513 16:04:12.237064      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:04:12.244
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:04:12.246
  STEP: creating the pod @ 05/13/24 16:04:12.248
  May 13 16:04:12.249: INFO: PodSpec: initContainers in spec.initContainers
  E0513 16:04:13.238135      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:14.238824      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:15.239089      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:04:15.711: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-7618" for this suite. @ 05/13/24 16:04:15.719
• [3.490 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 05/13/24 16:04:15.724
  May 13 16:04:15.724: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename subpath @ 05/13/24 16:04:15.725
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:04:15.734
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:04:15.735
  STEP: Setting up data @ 05/13/24 16:04:15.736
  STEP: Creating pod pod-subpath-test-configmap-fcgw @ 05/13/24 16:04:15.742
  STEP: Creating a pod to test atomic-volume-subpath @ 05/13/24 16:04:15.742
  E0513 16:04:16.239087      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:17.239676      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:18.240647      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:19.241305      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:20.241055      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:21.241376      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:22.241369      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:23.241506      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:24.241913      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:25.242058      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:26.242694      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:27.242846      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:28.243639      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:29.243907      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:30.244288      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:31.244653      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:32.244660      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:33.244797      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:34.245978      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:35.246248      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:36.246498      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:37.246601      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:04:37.803
  May 13 16:04:37.805: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-subpath-test-configmap-fcgw container test-container-subpath-configmap-fcgw: <nil>
  STEP: delete the pod @ 05/13/24 16:04:37.809
  STEP: Deleting pod pod-subpath-test-configmap-fcgw @ 05/13/24 16:04:37.818
  May 13 16:04:37.819: INFO: Deleting pod "pod-subpath-test-configmap-fcgw" in namespace "subpath-9128"
  May 13 16:04:37.820: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-9128" for this suite. @ 05/13/24 16:04:37.823
• [22.103 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1455
  STEP: Creating a kubernetes client @ 05/13/24 16:04:37.828
  May 13 16:04:37.828: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename services @ 05/13/24 16:04:37.829
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:04:37.84
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:04:37.842
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-1282 @ 05/13/24 16:04:37.844
  STEP: changing the ExternalName service to type=NodePort @ 05/13/24 16:04:37.848
  STEP: creating replication controller externalname-service in namespace services-1282 @ 05/13/24 16:04:37.865
  I0513 16:04:37.874442      17 runners.go:197] Created replication controller with name: externalname-service, namespace: services-1282, replica count: 2
  E0513 16:04:38.247291      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:39.247945      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:40.248068      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0513 16:04:40.926326      17 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May 13 16:04:40.927: INFO: Creating new exec pod
  E0513 16:04:41.248375      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:42.248351      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:43.248871      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:04:43.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-1282 exec execpodvqj6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  May 13 16:04:44.085: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  May 13 16:04:44.085: INFO: stdout: "externalname-service-644vm"
  May 13 16:04:44.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-1282 exec execpodvqj6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.20.197 80'
  May 13 16:04:44.196: INFO: stderr: "+ nc -v -t -w 2 10.43.20.197 80\n+ echo hostName\nConnection to 10.43.20.197 80 port [tcp/http] succeeded!\n"
  May 13 16:04:44.196: INFO: stdout: ""
  E0513 16:04:44.258212      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:04:45.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-1282 exec execpodvqj6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.20.197 80'
  May 13 16:04:45.202: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.20.197 80\nConnection to 10.43.20.197 80 port [tcp/http] succeeded!\n"
  May 13 16:04:45.202: INFO: stdout: ""
  E0513 16:04:45.250002      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:04:46.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-1282 exec execpodvqj6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.20.197 80'
  May 13 16:04:46.222: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.20.197 80\nConnection to 10.43.20.197 80 port [tcp/http] succeeded!\n"
  May 13 16:04:46.222: INFO: stdout: ""
  E0513 16:04:46.250714      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:04:47.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-1282 exec execpodvqj6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.20.197 80'
  May 13 16:04:47.185: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.20.197 80\nConnection to 10.43.20.197 80 port [tcp/http] succeeded!\n"
  May 13 16:04:47.185: INFO: stdout: "externalname-service-ct7n6"
  May 13 16:04:47.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-1282 exec execpodvqj6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.16.100.5 30364'
  E0513 16:04:47.251224      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:04:47.289: INFO: stderr: "+ nc -v -t -w 2 172.16.100.5 30364\n+ echo hostName\nConnection to 172.16.100.5 30364 port [tcp/*] succeeded!\n"
  May 13 16:04:47.289: INFO: stdout: ""
  May 13 16:04:48.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-1282 exec execpodvqj6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.16.100.5 30364'
  E0513 16:04:48.252116      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:04:48.292: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.16.100.5 30364\nConnection to 172.16.100.5 30364 port [tcp/*] succeeded!\n"
  May 13 16:04:48.292: INFO: stdout: ""
  May 13 16:04:49.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-1282 exec execpodvqj6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.16.100.5 30364'
  E0513 16:04:49.252957      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:04:49.303: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.16.100.5 30364\nConnection to 172.16.100.5 30364 port [tcp/*] succeeded!\n"
  May 13 16:04:49.303: INFO: stdout: ""
  May 13 16:04:50.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-1282 exec execpodvqj6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.16.100.5 30364'
  E0513 16:04:50.253606      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:04:50.312: INFO: stderr: "+ nc -v -t -w 2 172.16.100.5 30364\n+ echo hostName\nConnection to 172.16.100.5 30364 port [tcp/*] succeeded!\n"
  May 13 16:04:50.312: INFO: stdout: ""
  May 13 16:04:51.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-1282 exec execpodvqj6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.16.100.5 30364'
  E0513 16:04:51.253861      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:04:51.311: INFO: stderr: "+ nc -v -t -w 2 172.16.100.5 30364\n+ echo hostName\nConnection to 172.16.100.5 30364 port [tcp/*] succeeded!\n"
  May 13 16:04:51.311: INFO: stdout: "externalname-service-ct7n6"
  May 13 16:04:51.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-1282 exec execpodvqj6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.16.100.7 30364'
  May 13 16:04:51.406: INFO: stderr: "+ nc -v -t -w 2 172.16.100.7 30364\n+ echo hostName\nConnection to 172.16.100.7 30364 port [tcp/*] succeeded!\n"
  May 13 16:04:51.406: INFO: stdout: ""
  E0513 16:04:52.254354      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:04:52.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-1282 exec execpodvqj6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.16.100.7 30364'
  May 13 16:04:52.407: INFO: stderr: "+ nc -v -t -w 2 172.16.100.7 30364\nConnection to 172.16.100.7 30364 port [tcp/*] succeeded!\n+ echo hostName\n"
  May 13 16:04:52.407: INFO: stdout: ""
  E0513 16:04:53.254604      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:04:53.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-1282 exec execpodvqj6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.16.100.7 30364'
  May 13 16:04:53.421: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.16.100.7 30364\nConnection to 172.16.100.7 30364 port [tcp/*] succeeded!\n"
  May 13 16:04:53.421: INFO: stdout: "externalname-service-644vm"
  May 13 16:04:53.421: INFO: Cleaning up the ExternalName to NodePort test service
  May 13 16:04:53.444: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1282" for this suite. @ 05/13/24 16:04:53.448
• [15.624 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:177
  STEP: Creating a kubernetes client @ 05/13/24 16:04:53.453
  May 13 16:04:53.453: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename podtemplate @ 05/13/24 16:04:53.454
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:04:53.468
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:04:53.469
  STEP: Create a pod template @ 05/13/24 16:04:53.471
  STEP: Replace a pod template @ 05/13/24 16:04:53.476
  May 13 16:04:53.481: INFO: Found updated podtemplate annotation: "true"

  May 13 16:04:53.481: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-7995" for this suite. @ 05/13/24 16:04:53.483
• [0.035 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:357
  STEP: Creating a kubernetes client @ 05/13/24 16:04:53.488
  May 13 16:04:53.488: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/13/24 16:04:53.489
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:04:53.499
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:04:53.5
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 05/13/24 16:04:53.502
  May 13 16:04:53.502: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 16:04:54.255086      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:04:54.927: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 16:04:55.255255      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:56.256145      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:57.256781      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:58.257648      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:04:59.257716      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:00.259445      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:05:00.439: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7038" for this suite. @ 05/13/24 16:05:00.442
• [6.957 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:76
  STEP: Creating a kubernetes client @ 05/13/24 16:05:00.446
  May 13 16:05:00.446: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename var-expansion @ 05/13/24 16:05:00.447
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:05:00.456
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:05:00.458
  STEP: Creating a pod to test substitution in container's command @ 05/13/24 16:05:00.459
  E0513 16:05:01.260114      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:02.261301      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:03.261223      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:04.262400      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:05:04.48
  May 13 16:05:04.485: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod var-expansion-3adb9f69-3780-4b7e-9a91-0035236a3d74 container dapi-container: <nil>
  STEP: delete the pod @ 05/13/24 16:05:04.503
  May 13 16:05:04.530: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8795" for this suite. @ 05/13/24 16:05:04.537
• [4.114 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 05/13/24 16:05:04.571
  May 13 16:05:04.571: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename watch @ 05/13/24 16:05:04.583
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:05:04.6
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:05:04.603
  STEP: creating a watch on configmaps with label A @ 05/13/24 16:05:04.604
  STEP: creating a watch on configmaps with label B @ 05/13/24 16:05:04.605
  STEP: creating a watch on configmaps with label A or B @ 05/13/24 16:05:04.605
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 05/13/24 16:05:04.606
  May 13 16:05:04.608: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9796  20fffaa0-98d9-4e7d-9c1a-5b769c91265a 33991 0 2024-05-13 16:05:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-13 16:05:04 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  May 13 16:05:04.608: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9796  20fffaa0-98d9-4e7d-9c1a-5b769c91265a 33991 0 2024-05-13 16:05:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-13 16:05:04 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 05/13/24 16:05:04.608
  May 13 16:05:04.611: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9796  20fffaa0-98d9-4e7d-9c1a-5b769c91265a 33992 0 2024-05-13 16:05:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-13 16:05:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 13 16:05:04.611: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9796  20fffaa0-98d9-4e7d-9c1a-5b769c91265a 33992 0 2024-05-13 16:05:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-13 16:05:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 05/13/24 16:05:04.612
  May 13 16:05:04.614: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9796  20fffaa0-98d9-4e7d-9c1a-5b769c91265a 33993 0 2024-05-13 16:05:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-13 16:05:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 13 16:05:04.615: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9796  20fffaa0-98d9-4e7d-9c1a-5b769c91265a 33993 0 2024-05-13 16:05:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-13 16:05:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 05/13/24 16:05:04.615
  May 13 16:05:04.617: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9796  20fffaa0-98d9-4e7d-9c1a-5b769c91265a 33994 0 2024-05-13 16:05:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-13 16:05:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 13 16:05:04.617: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9796  20fffaa0-98d9-4e7d-9c1a-5b769c91265a 33994 0 2024-05-13 16:05:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-13 16:05:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 05/13/24 16:05:04.617
  May 13 16:05:04.619: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9796  cfbbb41a-8913-4a2e-be6f-29e61a4f85cd 33995 0 2024-05-13 16:05:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-05-13 16:05:04 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  May 13 16:05:04.619: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9796  cfbbb41a-8913-4a2e-be6f-29e61a4f85cd 33995 0 2024-05-13 16:05:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-05-13 16:05:04 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0513 16:05:05.262858      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:06.262993      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:07.264040      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:08.264512      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:09.264855      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:10.264792      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:11.265697      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:12.266649      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:13.267350      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:14.268241      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 05/13/24 16:05:14.619
  May 13 16:05:14.623: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9796  cfbbb41a-8913-4a2e-be6f-29e61a4f85cd 34054 0 2024-05-13 16:05:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-05-13 16:05:04 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  May 13 16:05:14.623: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9796  cfbbb41a-8913-4a2e-be6f-29e61a4f85cd 34054 0 2024-05-13 16:05:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-05-13 16:05:04 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0513 16:05:15.268072      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:16.268780      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:17.269780      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:18.270565      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:19.271015      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:20.271048      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:21.271607      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:22.271696      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:23.271845      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:24.272274      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:05:24.624: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-9796" for this suite. @ 05/13/24 16:05:24.626
• [20.065 seconds]
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:75
  STEP: Creating a kubernetes client @ 05/13/24 16:05:24.63
  May 13 16:05:24.630: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename configmap @ 05/13/24 16:05:24.631
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:05:24.641
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:05:24.643
  STEP: Creating configMap with name configmap-test-volume-d409c690-89dc-4e37-a33c-790ba48c4ccc @ 05/13/24 16:05:24.644
  STEP: Creating a pod to test consume configMaps @ 05/13/24 16:05:24.647
  E0513 16:05:25.272940      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:26.273208      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:27.273205      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:28.273985      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:05:28.665
  May 13 16:05:28.670: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-configmaps-2b832585-957a-4ae3-bf0d-fc17a5899149 container agnhost-container: <nil>
  STEP: delete the pod @ 05/13/24 16:05:28.679
  May 13 16:05:28.691: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9818" for this suite. @ 05/13/24 16:05:28.693
• [4.067 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:261
  STEP: Creating a kubernetes client @ 05/13/24 16:05:28.697
  May 13 16:05:28.697: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename webhook @ 05/13/24 16:05:28.698
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:05:28.707
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:05:28.708
  STEP: Setting up server cert @ 05/13/24 16:05:28.723
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/13/24 16:05:29.083
  STEP: Deploying the webhook pod @ 05/13/24 16:05:29.086
  STEP: Wait for the deployment to be ready @ 05/13/24 16:05:29.097
  May 13 16:05:29.121: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 16, 5, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 16, 5, 29, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-7c55c7d74c\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 13, 16, 5, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 16, 5, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
  E0513 16:05:29.275544      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:30.276145      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/13/24 16:05:31.128
  STEP: Verifying the service has paired with the endpoint @ 05/13/24 16:05:31.142
  E0513 16:05:31.276869      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:05:32.144: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 05/13/24 16:05:32.155
  STEP: create a pod that should be updated by the webhook @ 05/13/24 16:05:32.181
  May 13 16:05:32.247: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1908" for this suite. @ 05/13/24 16:05:32.253
  STEP: Destroying namespace "webhook-markers-1124" for this suite. @ 05/13/24 16:05:32.257
• [3.565 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should provide secure master service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:775
  STEP: Creating a kubernetes client @ 05/13/24 16:05:32.266
  May 13 16:05:32.267: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename services @ 05/13/24 16:05:32.268
  E0513 16:05:32.277267      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:05:32.277
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:05:32.281
  May 13 16:05:32.284: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1155" for this suite. @ 05/13/24 16:05:32.287
• [0.024 seconds]
------------------------------
SSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:151
  STEP: Creating a kubernetes client @ 05/13/24 16:05:32.291
  May 13 16:05:32.291: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename container-probe @ 05/13/24 16:05:32.291
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:05:32.301
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:05:32.303
  STEP: Creating pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200 @ 05/13/24 16:05:32.305
  E0513 16:05:33.277958      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:34.279410      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/13/24 16:05:34.319
  May 13 16:05:34.326: INFO: Initial restart count of pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce is 0
  May 13 16:05:34.333: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:05:35.279045      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:36.279270      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:05:36.341: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:05:37.281488      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:38.282177      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:05:38.345: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:05:39.282903      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:40.282619      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:05:40.348: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:05:41.283304      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:42.283724      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:05:42.364: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:05:43.283735      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:44.284140      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:05:44.367: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:05:45.285133      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:46.286056      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:05:46.373: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:05:47.286835      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:48.286815      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:05:48.375: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:05:49.287721      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:50.288425      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:05:50.381: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:05:51.288726      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:52.292369      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:05:52.390: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:05:53.293328      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:54.293971      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:05:54.398: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:05:55.294380      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:56.295395      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:05:56.400: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:05:57.296075      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:05:58.296635      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:05:58.403: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:05:59.297716      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:00.298515      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:00.412: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:01.299046      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:02.299229      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:02.416: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:03.299987      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:04.301005      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:04.420: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:05.302056      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:06.302222      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:06.427: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:07.303254      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:08.303426      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:08.430: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:09.304702      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:10.305253      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:10.432: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:11.305735      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:12.306884      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:12.436: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:13.306913      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:14.308138      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:14.443: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:15.308016      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:16.308198      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:16.445: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:17.308222      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:18.308569      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:18.447: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:19.309235      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:20.310346      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:20.450: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:21.311155      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:22.311264      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:22.452: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:23.311324      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:24.311961      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:24.455: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:25.312111      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:26.312825      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:26.458: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:27.313477      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:28.313715      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:28.459: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:29.314794      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:30.315860      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:30.463: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:31.315932      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:32.316166      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:32.466: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:33.316297      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:34.317425      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:34.475: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:35.317407      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:36.317813      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:36.477: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:37.318543      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:38.318591      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:38.479: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:39.318659      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:40.319303      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:40.489: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:41.319722      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:42.320277      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:42.492: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:43.321023      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:44.321291      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:44.498: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:45.322166      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:46.322809      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:46.500: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:47.323736      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:48.323815      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:48.504: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:49.323957      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:50.324224      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:50.506: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:51.324573      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:52.324756      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:52.511: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:53.324873      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:54.325042      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:54.518: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:55.325139      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:56.325557      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:56.521: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:57.325545      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:06:58.325614      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:06:58.526: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:06:59.326052      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:00.326057      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:00.535: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:01.326733      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:02.326812      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:02.540: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:03.327551      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:04.327963      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:04.554: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:05.328926      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:06.329559      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:06.570: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:07.329842      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:08.330892      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:08.573: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:09.330823      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:10.331395      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:10.582: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:11.332364      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:12.332655      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:12.584: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:13.333451      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:14.334348      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:14.588: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:15.334564      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:16.334954      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:16.595: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:17.335652      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:18.335832      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:18.603: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:19.336380      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:20.337216      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:20.606: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:21.337411      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:22.337937      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:22.607: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:23.338593      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:24.339078      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:24.609: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:25.340050      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:26.340328      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:26.616: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:27.340824      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:28.340858      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:28.624: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:29.341481      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:30.342521      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:30.627: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:31.342630      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:32.342794      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:32.631: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:33.343755      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:34.344873      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:34.634: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:35.344799      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:36.345184      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:36.643: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:37.345437      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:38.345580      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:38.651: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:39.346181      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:40.347199      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:40.659: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:41.348086      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:42.348964      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:42.663: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:43.350130      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:44.349972      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:44.665: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:45.350134      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:46.350904      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:46.672: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:47.351266      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:48.351527      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:48.679: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:49.355360      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:50.355715      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:50.685: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:51.355913      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:52.355889      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:52.689: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:53.356991      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:54.357347      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:54.692: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:55.357447      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:56.357607      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:56.694: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:57.357629      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:07:58.358179      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:07:58.703: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:07:59.359006      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:00.358931      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:00.704: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:01.359751      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:02.359852      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:02.710: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:03.359945      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:04.360689      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:04.711: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:05.360760      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:06.361763      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:06.715: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:07.361989      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:08.361726      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:08.723: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:09.363214      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:10.362986      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:10.731: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:11.363728      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:12.364172      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:12.735: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:13.364349      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:14.364988      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:14.743: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:15.365474      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:16.365475      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:16.751: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:17.366511      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:18.367155      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:18.758: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:19.368209      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:20.368295      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:20.761: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:21.368359      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:22.370087      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:22.764: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:23.370178      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:24.370737      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:24.770: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:25.371851      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:26.371906      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:26.773: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:27.372072      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:28.372865      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:28.775: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:29.373687      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:30.373751      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:30.778: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:31.375797      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:32.376184      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:32.782: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:33.376302      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:34.377572      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:34.789: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:35.378112      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:36.378170      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:36.794: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:37.378748      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:38.379665      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:38.797: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:39.380654      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:40.380860      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:40.800: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:41.381728      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:42.382175      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:42.803: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:43.382258      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:44.383007      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:44.809: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:45.383591      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:46.384315      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:46.814: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:47.384314      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:48.384742      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:48.821: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:49.385775      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:50.385956      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:50.828: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:51.386944      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:52.387651      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:52.830: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:53.388278      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:54.389071      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:54.837: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:55.390413      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:56.390588      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:56.844: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:57.391815      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:08:58.391840      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:08:58.850: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:08:59.392853      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:00.393035      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:09:00.854: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:09:01.394633      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:02.395293      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:09:02.857: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:09:03.396318      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:04.397209      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:09:04.863: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:09:05.397312      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:06.398168      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:09:06.866: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:09:07.398904      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:08.398607      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:09:08.869: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:09:09.399026      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:10.399436      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:09:10.872: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:09:11.399630      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:12.400061      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:09:12.875: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:09:13.400780      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:14.401923      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:09:14.881: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:09:15.401984      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:16.403078      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:09:16.888: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:09:17.404084      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:18.404933      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:09:18.894: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:09:19.405879      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:20.406217      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:09:20.900: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:09:21.406761      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:22.406971      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:09:22.903: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:09:23.406989      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:24.407877      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:09:24.905: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:09:25.408174      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:26.408362      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:09:26.912: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:09:27.409112      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:28.409204      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:09:28.915: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:09:29.410256      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:30.410891      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:09:30.920: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:09:31.411165      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:32.412186      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:09:32.926: INFO: Get pod busybox-0c0a9621-4b07-40d3-a793-5865df18bcce in namespace container-probe-9200
  E0513 16:09:33.412643      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:34.413105      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 05/13/24 16:09:34.927
  May 13 16:09:34.939: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9200" for this suite. @ 05/13/24 16:09:34.943
• [242.657 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:488
  STEP: Creating a kubernetes client @ 05/13/24 16:09:34.948
  May 13 16:09:34.948: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename security-context-test @ 05/13/24 16:09:34.949
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:09:34.964
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:09:34.965
  E0513 16:09:35.413687      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:36.414320      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:37.415910      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:38.415918      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:09:38.984: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-7342" for this suite. @ 05/13/24 16:09:38.987
• [4.043 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:190
  STEP: Creating a kubernetes client @ 05/13/24 16:09:38.998
  May 13 16:09:38.998: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename emptydir @ 05/13/24 16:09:38.999
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:09:39.009
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:09:39.01
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 05/13/24 16:09:39.012
  E0513 16:09:39.416413      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:40.416651      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:41.417071      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:42.417627      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:09:43.028
  May 13 16:09:43.029: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-95570276-fa9d-44fd-a05f-e1f193e31c7a container test-container: <nil>
  STEP: delete the pod @ 05/13/24 16:09:43.039
  May 13 16:09:43.050: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6174" for this suite. @ 05/13/24 16:09:43.064
• [4.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:349
  STEP: Creating a kubernetes client @ 05/13/24 16:09:43.071
  May 13 16:09:43.071: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename disruption @ 05/13/24 16:09:43.071
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:09:43.082
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:09:43.084
  STEP: Creating a pdb that targets all three pods in a test replica set @ 05/13/24 16:09:43.085
  STEP: Waiting for the pdb to be processed @ 05/13/24 16:09:43.088
  STEP: First trying to evict a pod which shouldn't be evictable @ 05/13/24 16:09:43.093
  STEP: Waiting for all pods to be running @ 05/13/24 16:09:43.093
  May 13 16:09:43.095: INFO: pods: 0 < 3
  E0513 16:09:43.417626      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:44.418077      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 05/13/24 16:09:45.097
  STEP: Updating the pdb to allow a pod to be evicted @ 05/13/24 16:09:45.107
  STEP: Waiting for the pdb to be processed @ 05/13/24 16:09:45.113
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 05/13/24 16:09:45.119
  STEP: Waiting for all pods to be running @ 05/13/24 16:09:45.119
  STEP: Waiting for the pdb to observed all healthy pods @ 05/13/24 16:09:45.122
  STEP: Patching the pdb to disallow a pod to be evicted @ 05/13/24 16:09:45.139
  STEP: Waiting for the pdb to be processed @ 05/13/24 16:09:45.161
  STEP: Waiting for all pods to be running @ 05/13/24 16:09:45.178
  May 13 16:09:45.218: INFO: running pods: 2 < 3
  E0513 16:09:45.419194      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:46.419708      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 05/13/24 16:09:47.195
  STEP: Deleting the pdb to allow a pod to be evicted @ 05/13/24 16:09:47.208
  STEP: Waiting for the pdb to be deleted @ 05/13/24 16:09:47.213
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 05/13/24 16:09:47.216
  STEP: Waiting for all pods to be running @ 05/13/24 16:09:47.216
  May 13 16:09:47.228: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9939" for this suite. @ 05/13/24 16:09:47.234
• [4.180 seconds]
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 05/13/24 16:09:47.253
  May 13 16:09:47.254: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename subpath @ 05/13/24 16:09:47.256
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:09:47.272
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:09:47.273
  STEP: Setting up data @ 05/13/24 16:09:47.277
  STEP: Creating pod pod-subpath-test-secret-z8fw @ 05/13/24 16:09:47.284
  STEP: Creating a pod to test atomic-volume-subpath @ 05/13/24 16:09:47.284
  E0513 16:09:47.419799      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:48.419969      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:49.420367      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:50.421534      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:51.421774      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:52.423415      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:53.423329      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:54.424185      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:55.425389      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:56.425523      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:57.425970      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:58.426056      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:09:59.426895      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:00.427322      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:01.427565      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:02.427671      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:03.428282      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:04.428941      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:05.429329      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:06.429800      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:07.429908      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:08.430002      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:09.430873      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:10.431221      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:10:11.345
  May 13 16:10:11.353: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-subpath-test-secret-z8fw container test-container-subpath-secret-z8fw: <nil>
  STEP: delete the pod @ 05/13/24 16:10:11.371
  STEP: Deleting pod pod-subpath-test-secret-z8fw @ 05/13/24 16:10:11.385
  May 13 16:10:11.386: INFO: Deleting pod "pod-subpath-test-secret-z8fw" in namespace "subpath-4108"
  May 13 16:10:11.387: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-4108" for this suite. @ 05/13/24 16:10:11.391
• [24.141 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:408
  STEP: Creating a kubernetes client @ 05/13/24 16:10:11.397
  May 13 16:10:11.397: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename job @ 05/13/24 16:10:11.398
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:10:11.408
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:10:11.41
  STEP: Creating Indexed job @ 05/13/24 16:10:11.411
  STEP: Ensuring job reaches completions @ 05/13/24 16:10:11.416
  E0513 16:10:11.432000      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:12.432512      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:13.433190      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:14.433651      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:15.434205      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:16.434421      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:17.435585      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:18.435527      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 05/13/24 16:10:19.424
  May 13 16:10:19.434: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0513 16:10:19.436758      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "job-7615" for this suite. @ 05/13/24 16:10:19.452
• [8.064 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
k8s.io/kubernetes/test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 05/13/24 16:10:19.466
  May 13 16:10:19.466: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename conformance-tests @ 05/13/24 16:10:19.468
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:10:19.495
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:10:19.575
  STEP: Getting node addresses @ 05/13/24 16:10:19.623
  May 13 16:10:19.623: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  May 13 16:10:19.630: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-5927" for this suite. @ 05/13/24 16:10:19.634
• [0.172 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 05/13/24 16:10:19.638
  May 13 16:10:19.638: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename sysctl @ 05/13/24 16:10:19.639
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:10:19.648
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:10:19.649
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 05/13/24 16:10:19.651
  STEP: Watching for error events or started pod @ 05/13/24 16:10:19.656
  E0513 16:10:20.436742      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:21.439488      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 05/13/24 16:10:21.66
  E0513 16:10:22.439014      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:23.439454      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 05/13/24 16:10:23.667
  STEP: Getting logs from the pod @ 05/13/24 16:10:23.667
  STEP: Checking that the sysctl is actually updated @ 05/13/24 16:10:23.681
  May 13 16:10:23.681: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-9996" for this suite. @ 05/13/24 16:10:23.686
• [4.054 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 05/13/24 16:10:23.692
  May 13 16:10:23.693: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename emptydir-wrapper @ 05/13/24 16:10:23.693
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:10:23.707
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:10:23.709
  STEP: Creating 50 configmaps @ 05/13/24 16:10:23.711
  STEP: Creating RC which spawns configmap-volume pods @ 05/13/24 16:10:23.958
  May 13 16:10:24.111: INFO: Pod name wrapped-volume-race-0ad932f4-eec7-46af-aed2-265032db8c59: Found 3 pods out of 5
  E0513 16:10:24.440835      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:25.440515      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:26.440916      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:27.440888      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:28.440980      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:10:29.127: INFO: Pod name wrapped-volume-race-0ad932f4-eec7-46af-aed2-265032db8c59: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 05/13/24 16:10:29.13
  STEP: Creating RC which spawns configmap-volume pods @ 05/13/24 16:10:29.143
  May 13 16:10:29.164: INFO: Pod name wrapped-volume-race-0bea463f-e7a8-424d-9722-5c709f480542: Found 1 pods out of 5
  E0513 16:10:29.441383      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:30.441854      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:31.446194      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:32.446552      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:33.447209      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:10:34.201: INFO: Pod name wrapped-volume-race-0bea463f-e7a8-424d-9722-5c709f480542: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 05/13/24 16:10:34.202
  STEP: Creating RC which spawns configmap-volume pods @ 05/13/24 16:10:34.214
  May 13 16:10:34.235: INFO: Pod name wrapped-volume-race-ab10ddd3-ed72-447c-b26e-45db786504ae: Found 1 pods out of 5
  E0513 16:10:34.448117      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:35.448540      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:36.448698      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:37.449039      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:38.449493      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:10:39.241: INFO: Pod name wrapped-volume-race-ab10ddd3-ed72-447c-b26e-45db786504ae: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 05/13/24 16:10:39.241
  STEP: deleting ReplicationController wrapped-volume-race-ab10ddd3-ed72-447c-b26e-45db786504ae in namespace emptydir-wrapper-5266, will wait for the garbage collector to delete the pods @ 05/13/24 16:10:39.25
  May 13 16:10:39.312: INFO: Deleting ReplicationController wrapped-volume-race-ab10ddd3-ed72-447c-b26e-45db786504ae took: 8.798783ms
  May 13 16:10:39.412: INFO: Terminating ReplicationController wrapped-volume-race-ab10ddd3-ed72-447c-b26e-45db786504ae pods took: 100.811128ms
  E0513 16:10:39.450229      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:40.451110      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-0bea463f-e7a8-424d-9722-5c709f480542 in namespace emptydir-wrapper-5266, will wait for the garbage collector to delete the pods @ 05/13/24 16:10:41.314
  May 13 16:10:41.377: INFO: Deleting ReplicationController wrapped-volume-race-0bea463f-e7a8-424d-9722-5c709f480542 took: 9.688511ms
  E0513 16:10:41.451411      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:10:41.478: INFO: Terminating ReplicationController wrapped-volume-race-0bea463f-e7a8-424d-9722-5c709f480542 pods took: 101.637969ms
  E0513 16:10:42.474569      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-0ad932f4-eec7-46af-aed2-265032db8c59 in namespace emptydir-wrapper-5266, will wait for the garbage collector to delete the pods @ 05/13/24 16:10:43.179
  May 13 16:10:43.237: INFO: Deleting ReplicationController wrapped-volume-race-0ad932f4-eec7-46af-aed2-265032db8c59 took: 2.858569ms
  May 13 16:10:43.338: INFO: Terminating ReplicationController wrapped-volume-race-0ad932f4-eec7-46af-aed2-265032db8c59 pods took: 100.856822ms
  E0513 16:10:43.474724      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:44.480288      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 05/13/24 16:10:45.239
  May 13 16:10:45.349: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-5266" for this suite. @ 05/13/24 16:10:45.352
• [21.664 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:305
  STEP: Creating a kubernetes client @ 05/13/24 16:10:45.357
  May 13 16:10:45.357: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename namespaces @ 05/13/24 16:10:45.358
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:10:45.367
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:10:45.369
  STEP: Read namespace status @ 05/13/24 16:10:45.37
  May 13 16:10:45.372: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 05/13/24 16:10:45.372
  May 13 16:10:45.376: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 05/13/24 16:10:45.376
  May 13 16:10:45.382: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  May 13 16:10:45.382: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-9236" for this suite. @ 05/13/24 16:10:45.385
• [0.033 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
  STEP: Creating a kubernetes client @ 05/13/24 16:10:45.39
  May 13 16:10:45.390: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubectl @ 05/13/24 16:10:45.391
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:10:45.4
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:10:45.401
  May 13 16:10:45.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-561 create -f -'
  E0513 16:10:45.480800      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:10:45.508: INFO: stderr: ""
  May 13 16:10:45.508: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  May 13 16:10:45.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-561 create -f -'
  May 13 16:10:45.618: INFO: stderr: ""
  May 13 16:10:45.618: INFO: stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 05/13/24 16:10:45.618
  E0513 16:10:46.481476      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:10:46.621: INFO: Selector matched 1 pods for map[app:agnhost]
  May 13 16:10:46.621: INFO: Found 0 / 1
  E0513 16:10:47.481629      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:10:47.621: INFO: Selector matched 1 pods for map[app:agnhost]
  May 13 16:10:47.621: INFO: Found 1 / 1
  May 13 16:10:47.621: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  May 13 16:10:47.624: INFO: Selector matched 1 pods for map[app:agnhost]
  May 13 16:10:47.624: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  May 13 16:10:47.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-561 describe pod agnhost-primary-tls7l'
  May 13 16:10:47.702: INFO: stderr: ""
  May 13 16:10:47.702: INFO: stdout: "Name:             agnhost-primary-tls7l\nNamespace:        kubectl-561\nPriority:         0\nService Account:  default\nNode:             oneke-ip-172-16-100-5/172.16.100.5\nStart Time:       Mon, 13 May 2024 16:10:45 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 2773db1b8b6ff960fddb26a70c355fb92b54d272a8a3fb6d6543e9c9dc83d18d\n                  cni.projectcalico.org/podIP: 10.42.1.11/32\n                  cni.projectcalico.org/podIPs: 10.42.1.11/32\n                  k8s.v1.cni.cncf.io/network-status:\n                    [{\n                        \"name\": \"k8s-pod-network\",\n                        \"ips\": [\n                            \"10.42.1.11\"\n                        ],\n                        \"default\": true,\n                        \"dns\": {}\n                    }]\nStatus:           Running\nIP:               10.42.1.11\nIPs:\n  IP:           10.42.1.11\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://3a28e9ec8476412a0f313fd943696ff5d04747dc105c13ed10bed383136d2856\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.47\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 13 May 2024 16:10:46 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-7mnqv (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-7mnqv:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason          Age   From               Message\n  ----    ------          ----  ----               -------\n  Normal  Scheduled       2s    default-scheduler  Successfully assigned kubectl-561/agnhost-primary-tls7l to oneke-ip-172-16-100-5\n  Normal  AddedInterface  2s    multus             Add eth0 [10.42.1.11/32] from k8s-pod-network\n  Normal  Pulled          1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.47\" already present on machine\n  Normal  Created         1s    kubelet            Created container agnhost-primary\n  Normal  Started         1s    kubelet            Started container agnhost-primary\n"
  May 13 16:10:47.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-561 describe rc agnhost-primary'
  May 13 16:10:47.752: INFO: stderr: ""
  May 13 16:10:47.752: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-561\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.47\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-tls7l\n"
  May 13 16:10:47.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-561 describe service agnhost-primary'
  May 13 16:10:47.801: INFO: stderr: ""
  May 13 16:10:47.801: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-561\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.43.156.241\nIPs:               10.43.156.241\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.42.1.11:6379\nSession Affinity:  None\nEvents:            <none>\n"
  May 13 16:10:47.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-561 describe node oneke-ip-172-16-100-4'
  May 13 16:10:47.882: INFO: stderr: ""
  May 13 16:10:47.882: INFO: stdout: "Name:               oneke-ip-172-16-100-4\nRoles:              control-plane,etcd,master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=rke2\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=oneke-ip-172-16-100-4\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=true\n                    node-role.kubernetes.io/etcd=true\n                    node-role.kubernetes.io/master=true\n                    node.kubernetes.io/instance-type=rke2\nAnnotations:        alpha.kubernetes.io/provided-node-ip: 172.16.100.4\n                    etcd.rke2.cattle.io/local-snapshots-timestamp: 2024-05-13T15:01:33Z\n                    etcd.rke2.cattle.io/node-address: 172.16.100.4\n                    etcd.rke2.cattle.io/node-name: oneke-ip-172-16-100-4-a5cd628b\n                    flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"ba:6d:b5:88:73:7b\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 172.16.100.4\n                    node.alpha.kubernetes.io/ttl: 0\n                    rke2.io/encryption-config-hash: start-c83f3f4cfafdead9769a4ed4a2ff697e05d23d2c4cab492e7fcd5c373f5da10c\n                    rke2.io/hostname: oneke-ip-172-16-100-4\n                    rke2.io/internal-ip: 172.16.100.4\n                    rke2.io/node-args:\n                      [\"server\",\"--node-name\",\"oneke-ip-172-16-100-4\",\"--token\",\"********\",\"--tls-san\",\"localhost\",\"--tls-san\",\"127.0.0.1\",\"--tls-san\",\"ep0.eth0...\n                    rke2.io/node-config-hash: Q4CAJLYXUMQKEM3XGTCHLI3R6CVKASHX7EWYKJ5VZSE3IJHH2YGA====\n                    rke2.io/node-env: {}\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 13 May 2024 15:01:31 +0000\nTaints:             CriticalAddonsOnly=true:NoExecute\nUnschedulable:      false\nLease:\n  HolderIdentity:  oneke-ip-172-16-100-4\n  AcquireTime:     <unset>\n  RenewTime:       Mon, 13 May 2024 16:10:45 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 13 May 2024 15:02:13 +0000   Mon, 13 May 2024 15:02:13 +0000   FlannelIsUp                  Flannel is running on this node\n  EtcdIsVoter          True    Mon, 13 May 2024 16:06:41 +0000   Mon, 13 May 2024 15:01:41 +0000   MemberNotLearner             Node is a voting member of the etcd cluster\n  MemoryPressure       False   Mon, 13 May 2024 16:08:12 +0000   Mon, 13 May 2024 15:01:31 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 13 May 2024 16:08:12 +0000   Mon, 13 May 2024 15:01:31 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 13 May 2024 16:08:12 +0000   Mon, 13 May 2024 15:01:31 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 13 May 2024 16:08:12 +0000   Mon, 13 May 2024 15:02:05 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.16.100.4\n  Hostname:    oneke-ip-172-16-100-4\nCapacity:\n  cpu:                2\n  ephemeral-storage:  25215872Ki\n  hugepages-2Mi:      0\n  memory:             3039936Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  24530000263\n  hugepages-2Mi:      0\n  memory:             3039936Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 02a076a5668348a3b03821501bcd1c53\n  System UUID:                02a076a5-6683-48a3-b038-21501bcd1c53\n  Boot ID:                    38ca1281-ae80-4980-9bad-cd43bcdd6424\n  Kernel Version:             5.15.0-105-generic\n  OS Image:                   Ubuntu 22.04.4 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.7.11-k3s2\n  Kubelet Version:            v1.29.4+rke2r1\n  Kube-Proxy Version:         v1.29.4+rke2r1\nPodCIDR:                      10.42.0.0/24\nPodCIDRs:                     10.42.0.0/24\nProviderID:                   rke2://oneke-ip-172-16-100-4\nNon-terminated Pods:          (11 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 cloud-controller-manager-oneke-ip-172-16-100-4             100m (5%)     0 (0%)      128Mi (4%)       0 (0%)         69m\n  kube-system                 etcd-oneke-ip-172-16-100-4                                 200m (10%)    0 (0%)      512Mi (17%)      0 (0%)         68m\n  kube-system                 kube-apiserver-oneke-ip-172-16-100-4                       250m (12%)    0 (0%)      1Gi (34%)        0 (0%)         69m\n  kube-system                 kube-controller-manager-oneke-ip-172-16-100-4              200m (10%)    0 (0%)      256Mi (8%)       0 (0%)         69m\n  kube-system                 kube-proxy-oneke-ip-172-16-100-4                           250m (12%)    0 (0%)      128Mi (4%)       0 (0%)         69m\n  kube-system                 kube-scheduler-oneke-ip-172-16-100-4                       100m (5%)     0 (0%)      128Mi (4%)       0 (0%)         69m\n  kube-system                 rke2-canal-f5llm                                           250m (12%)    0 (0%)      0 (0%)           0 (0%)         68m\n  kube-system                 rke2-coredns-rke2-coredns-5b7d84d764-vjsxh                 100m (5%)     100m (5%)   128Mi (4%)       128Mi (4%)     68m\n  kube-system                 rke2-multus-cjz4t                                          250m (12%)    2 (100%)    128Mi (4%)       1Gi (34%)      68m\n  sonobuoy                    sonobuoy-e2e-job-115bc6212fad49d2                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         49m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-6a4de22bea6049d2-nbslt    0 (0%)        0 (0%)      0 (0%)           0 (0%)         49m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests      Limits\n  --------           --------      ------\n  cpu                1700m (85%)   2100m (105%)\n  memory             2432Mi (81%)  1152Mi (38%)\n  ephemeral-storage  0 (0%)        0 (0%)\n  hugepages-2Mi      0 (0%)        0 (0%)\nEvents:              <none>\n"
  May 13 16:10:47.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-561 describe namespace kubectl-561'
  May 13 16:10:47.935: INFO: stderr: ""
  May 13 16:10:47.935: INFO: stdout: "Name:         kubectl-561\nLabels:       e2e-framework=kubectl\n              e2e-run=50111627-8bdf-4f1e-a872-7707fb8f813f\n              kubernetes.io/metadata.name=kubectl-561\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  May 13 16:10:47.935: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-561" for this suite. @ 05/13/24 16:10:47.937
• [2.550 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 05/13/24 16:10:47.941
  May 13 16:10:47.941: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename crd-watch @ 05/13/24 16:10:47.942
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:10:47.953
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:10:47.955
  May 13 16:10:47.956: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 16:10:48.482340      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:49.482575      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:50.483359      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 05/13/24 16:10:50.487
  May 13 16:10:50.490: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-13T16:10:50Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-13T16:10:50Z]] name:name1 resourceVersion:36575 uid:78774b42-1659-4135-a9c7-cd0812d33ac1] num:map[num1:9223372036854775807 num2:1000000]]}
  E0513 16:10:51.486530      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:52.483592      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:53.483833      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:54.486661      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:55.486955      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:56.487096      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:57.487340      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:58.487345      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:10:59.487942      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:00.488230      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 05/13/24 16:11:00.49
  May 13 16:11:00.504: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-13T16:11:00Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-13T16:11:00Z]] name:name2 resourceVersion:36732 uid:f08ffcfc-9b87-4fb7-adf4-7b9b7e267530] num:map[num1:9223372036854775807 num2:1000000]]}
  E0513 16:11:01.503192      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:02.502877      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:03.503084      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:04.507185      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:05.507851      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:06.508066      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:07.508254      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:08.508379      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:09.514603      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 05/13/24 16:11:10.507
  E0513 16:11:10.515806      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:11:10.519: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-13T16:10:50Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-13T16:11:10Z]] name:name1 resourceVersion:36780 uid:78774b42-1659-4135-a9c7-cd0812d33ac1] num:map[num1:9223372036854775807 num2:1000000]]}
  E0513 16:11:11.515459      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:12.515599      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:13.515725      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:14.518601      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:15.519511      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:16.520915      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:17.521211      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:18.521604      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:19.521564      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:20.521701      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 05/13/24 16:11:20.521
  May 13 16:11:20.524: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-13T16:11:00Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-13T16:11:20Z]] name:name2 resourceVersion:36822 uid:f08ffcfc-9b87-4fb7-adf4-7b9b7e267530] num:map[num1:9223372036854775807 num2:1000000]]}
  E0513 16:11:21.521795      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:22.522198      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:23.524213      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:24.529639      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:25.530281      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:26.531358      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:27.532654      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:28.533558      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:29.539744      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 05/13/24 16:11:30.526
  May 13 16:11:30.533: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-13T16:10:50Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-13T16:11:10Z]] name:name1 resourceVersion:36865 uid:78774b42-1659-4135-a9c7-cd0812d33ac1] num:map[num1:9223372036854775807 num2:1000000]]}
  E0513 16:11:30.539910      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:31.539954      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:32.540706      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:33.540451      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:34.541947      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:35.542585      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:36.542806      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:37.543547      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:38.545459      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:39.546633      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 05/13/24 16:11:40.535
  E0513 16:11:40.548256      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:11:40.549: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-13T16:11:00Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-13T16:11:20Z]] name:name2 resourceVersion:36905 uid:f08ffcfc-9b87-4fb7-adf4-7b9b7e267530] num:map[num1:9223372036854775807 num2:1000000]]}
  E0513 16:11:41.547899      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:42.548393      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:43.548886      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:44.551864      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:45.552272      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:46.552412      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:47.552588      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:48.554394      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:49.553620      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:50.554126      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:11:51.083: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-3590" for this suite. @ 05/13/24 16:11:51.085
• [63.148 seconds]
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:962
  STEP: Creating a kubernetes client @ 05/13/24 16:11:51.089
  May 13 16:11:51.089: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename statefulset @ 05/13/24 16:11:51.09
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:11:51.1
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:11:51.101
  STEP: Creating service test in namespace statefulset-5752 @ 05/13/24 16:11:51.103
  May 13 16:11:51.117: INFO: Found 0 stateful pods, waiting for 1
  E0513 16:11:51.554231      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:52.555123      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:53.554949      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:54.559999      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:55.560210      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:56.560558      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:57.560960      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:58.561679      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:11:59.561748      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:00.562408      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:01.115: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 05/13/24 16:12:01.118
  W0513 16:12:01.133036      17 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  May 13 16:12:01.140: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  May 13 16:12:01.140: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Pending - Ready=false
  E0513 16:12:01.562894      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:02.563649      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:03.563738      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:04.565811      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:05.565854      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:06.565959      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:07.566140      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:08.566788      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:09.567418      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:10.568017      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:11.143: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  May 13 16:12:11.145: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 05/13/24 16:12:11.161
  STEP: Delete all of the StatefulSets @ 05/13/24 16:12:11.165
  STEP: Verify that StatefulSets have been deleted @ 05/13/24 16:12:11.174
  May 13 16:12:11.183: INFO: Deleting all statefulset in ns statefulset-5752
  May 13 16:12:11.202: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5752" for this suite. @ 05/13/24 16:12:11.207
• [20.125 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 05/13/24 16:12:11.215
  May 13 16:12:11.215: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 16:12:11.216
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:12:11.229
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:12:11.231
  STEP: Creating projection with secret that has name projected-secret-test-3bd71959-8897-4d50-9a24-c658dfdb043d @ 05/13/24 16:12:11.232
  STEP: Creating a pod to test consume secrets @ 05/13/24 16:12:11.236
  E0513 16:12:11.568099      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:12.568219      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:13.568987      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:14.570262      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:12:15.25
  May 13 16:12:15.251: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-projected-secrets-bf0f61a7-a6fe-465d-a111-dcb99873ee0d container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/13/24 16:12:15.26
  May 13 16:12:15.269: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5008" for this suite. @ 05/13/24 16:12:15.271
• [4.061 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 05/13/24 16:12:15.276
  May 13 16:12:15.276: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 16:12:15.277
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:12:15.287
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:12:15.288
  STEP: Creating secret with name s-test-opt-del-d2d392fe-94ef-458c-af5c-ff800ac81a7e @ 05/13/24 16:12:15.292
  STEP: Creating secret with name s-test-opt-upd-ebe9e498-d30e-4dfc-b7c3-157328eca122 @ 05/13/24 16:12:15.295
  STEP: Creating the pod @ 05/13/24 16:12:15.297
  E0513 16:12:15.571010      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:16.571542      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-d2d392fe-94ef-458c-af5c-ff800ac81a7e @ 05/13/24 16:12:17.318
  STEP: Updating secret s-test-opt-upd-ebe9e498-d30e-4dfc-b7c3-157328eca122 @ 05/13/24 16:12:17.323
  STEP: Creating secret with name s-test-opt-create-2ad905a5-4033-422a-ac34-838e91a25956 @ 05/13/24 16:12:17.327
  STEP: waiting to observe update in volume @ 05/13/24 16:12:17.33
  E0513 16:12:17.571496      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:18.571848      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:19.345: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9399" for this suite. @ 05/13/24 16:12:19.348
• [4.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:198
  STEP: Creating a kubernetes client @ 05/13/24 16:12:19.354
  May 13 16:12:19.355: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename container-probe @ 05/13/24 16:12:19.355
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:12:19.366
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:12:19.368
  STEP: Creating pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019 @ 05/13/24 16:12:19.369
  E0513 16:12:19.572832      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:20.572973      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/13/24 16:12:21.384
  May 13 16:12:21.388: INFO: Initial restart count of pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 is 0
  May 13 16:12:21.393: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:12:21.574316      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:22.574597      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:23.408: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:12:23.575267      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:24.576524      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:25.410: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:12:25.576985      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:26.578274      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:27.417: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:12:27.578579      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:28.578925      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:29.425: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:12:29.581353      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:30.581513      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:31.428: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:12:31.582357      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:32.583124      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:33.436: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:12:33.583851      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:34.587526      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:35.443: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:12:35.588682      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:36.589910      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:37.450: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:12:37.589956      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:38.589984      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:39.457: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:12:39.590064      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:40.590316      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:41.461: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  May 13 16:12:41.461: INFO: Restart count of pod container-probe-6019/liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 is now 1 (20.073104671s elapsed)
  E0513 16:12:41.591603      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:42.591376      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:43.464: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:12:43.591743      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:44.593327      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:45.469: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:12:45.594023      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:46.594441      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:47.473: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:12:47.594765      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:48.594960      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:49.476: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:12:49.595826      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:50.596492      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:51.478: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:12:51.596504      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:52.597500      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:53.480: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:12:53.597576      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:54.597952      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:55.483: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:12:55.598362      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:56.598719      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:57.486: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:12:57.599205      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:12:58.599485      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:12:59.494: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:12:59.600547      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:00.600935      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:01.500: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  May 13 16:13:01.500: INFO: Restart count of pod container-probe-6019/liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 is now 2 (40.111771643s elapsed)
  E0513 16:13:01.601338      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:02.601990      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:03.502: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:03.603287      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:04.604399      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:05.506: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:05.604638      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:06.605000      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:07.513: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:07.605729      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:08.605844      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:09.516: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:09.606123      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:10.606442      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:11.519: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:11.607112      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:12.607177      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:13.525: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:13.608026      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:14.609074      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:15.528: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:15.609428      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:16.609762      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:17.531: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:17.609849      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:18.610599      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:19.535: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:19.610645      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:20.611149      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:21.537: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  May 13 16:13:21.537: INFO: Restart count of pod container-probe-6019/liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 is now 3 (1m0.149094786s elapsed)
  E0513 16:13:21.612322      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:22.612504      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:23.540: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:23.612789      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:24.612678      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:25.542: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:25.613496      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:26.614533      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:27.549: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:27.615447      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:28.615950      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:29.553: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:29.616011      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:30.616718      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:31.555: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:31.617325      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:32.618102      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:33.559: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:33.618887      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:34.619531      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:35.561: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:35.620067      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:36.620888      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:37.565: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:37.620829      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:38.621179      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:39.569: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:39.621453      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:40.621973      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:41.571: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  May 13 16:13:41.571: INFO: Restart count of pod container-probe-6019/liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 is now 4 (1m20.183050202s elapsed)
  E0513 16:13:41.621772      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:42.622746      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:43.575: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:43.622707      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:44.622797      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:45.578: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:45.623358      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:46.623566      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:47.584: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:47.624106      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:48.625144      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:49.586: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:49.624678      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:50.625424      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:51.588: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:51.626398      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:52.626984      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:53.592: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:53.627204      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:54.628094      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:55.594: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:55.628919      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:56.629235      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:57.597: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:57.629504      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:13:58.629688      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:13:59.599: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:13:59.630626      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:00.632048      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:01.601: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:01.632860      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:02.633090      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:03.603: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:03.633623      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:04.633982      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:05.610: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:05.635151      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:06.636174      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:07.616: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:07.637134      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:08.637772      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:09.619: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:09.637847      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:10.638008      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:11.627: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:11.638940      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:12.639259      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:13.633: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:13.640023      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:14.641073      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:15.637: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:15.641210      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:16.642172      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:17.641: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:17.642728      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:18.642883      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:19.643127      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:19.649: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:20.643380      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:21.644373      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:21.657: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:22.644584      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:23.644767      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:23.667: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:24.644990      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:25.646297      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:25.674: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:26.646324      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:27.647100      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:27.683: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:28.647436      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:29.647422      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:29.685: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:30.648488      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:31.649514      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:31.687: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:32.649873      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:33.650582      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:33.694: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:34.650539      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:35.650946      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:35.697: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:36.651089      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:37.651076      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:37.704: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:38.651699      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:39.651694      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:39.710: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:40.652546      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:41.652986      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:41.714: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  E0513 16:14:42.653215      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:43.653269      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:43.717: INFO: Get pod liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 in namespace container-probe-6019
  May 13 16:14:43.717: INFO: Restart count of pod container-probe-6019/liveness-e3675dcd-da46-4a47-afc2-2e7cfa604006 is now 5 (2m22.329191681s elapsed)
  STEP: deleting the pod @ 05/13/24 16:14:43.718
  May 13 16:14:43.730: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6019" for this suite. @ 05/13/24 16:14:43.734
• [144.384 seconds]
------------------------------
SS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:115
  STEP: Creating a kubernetes client @ 05/13/24 16:14:43.739
  May 13 16:14:43.739: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename var-expansion @ 05/13/24 16:14:43.739
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:14:43.749
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:14:43.751
  STEP: Creating a pod to test substitution in volume subpath @ 05/13/24 16:14:43.752
  E0513 16:14:44.653816      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:45.654667      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:46.655826      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:47.656502      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:14:47.771
  May 13 16:14:47.777: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod var-expansion-e388374e-2c0c-424a-98e7-e545200e483d container dapi-container: <nil>
  STEP: delete the pod @ 05/13/24 16:14:47.806
  May 13 16:14:47.821: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7971" for this suite. @ 05/13/24 16:14:47.823
• [4.087 seconds]
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2177
  STEP: Creating a kubernetes client @ 05/13/24 16:14:47.827
  May 13 16:14:47.827: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename services @ 05/13/24 16:14:47.828
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:14:47.837
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:14:47.839
  STEP: creating service in namespace services-8419 @ 05/13/24 16:14:47.841
  STEP: creating service affinity-clusterip in namespace services-8419 @ 05/13/24 16:14:47.841
  STEP: creating replication controller affinity-clusterip in namespace services-8419 @ 05/13/24 16:14:47.85
  I0513 16:14:47.861465      17 runners.go:197] Created replication controller with name: affinity-clusterip, namespace: services-8419, replica count: 3
  E0513 16:14:48.656887      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:49.657140      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:50.657446      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0513 16:14:50.911832      17 runners.go:197] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May 13 16:14:50.918: INFO: Creating new exec pod
  E0513 16:14:51.657556      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:52.657926      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:53.658008      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:53.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-8419 exec execpod-affinity725l4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  May 13 16:14:54.066: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  May 13 16:14:54.066: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 13 16:14:54.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-8419 exec execpod-affinity725l4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.124.167 80'
  May 13 16:14:54.163: INFO: stderr: "+ nc -v -t -w 2 10.43.124.167 80\nConnection to 10.43.124.167 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  May 13 16:14:54.163: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 13 16:14:54.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-8419 exec execpod-affinity725l4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.43.124.167:80/ ; done'
  May 13 16:14:54.345: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.124.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.124.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.124.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.124.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.124.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.124.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.124.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.124.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.124.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.124.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.124.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.124.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.124.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.124.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.124.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.124.167:80/\n"
  May 13 16:14:54.345: INFO: stdout: "\naffinity-clusterip-h2pzs\naffinity-clusterip-h2pzs\naffinity-clusterip-h2pzs\naffinity-clusterip-h2pzs\naffinity-clusterip-h2pzs\naffinity-clusterip-h2pzs\naffinity-clusterip-h2pzs\naffinity-clusterip-h2pzs\naffinity-clusterip-h2pzs\naffinity-clusterip-h2pzs\naffinity-clusterip-h2pzs\naffinity-clusterip-h2pzs\naffinity-clusterip-h2pzs\naffinity-clusterip-h2pzs\naffinity-clusterip-h2pzs\naffinity-clusterip-h2pzs"
  May 13 16:14:54.345: INFO: Received response from host: affinity-clusterip-h2pzs
  May 13 16:14:54.345: INFO: Received response from host: affinity-clusterip-h2pzs
  May 13 16:14:54.345: INFO: Received response from host: affinity-clusterip-h2pzs
  May 13 16:14:54.345: INFO: Received response from host: affinity-clusterip-h2pzs
  May 13 16:14:54.345: INFO: Received response from host: affinity-clusterip-h2pzs
  May 13 16:14:54.345: INFO: Received response from host: affinity-clusterip-h2pzs
  May 13 16:14:54.345: INFO: Received response from host: affinity-clusterip-h2pzs
  May 13 16:14:54.345: INFO: Received response from host: affinity-clusterip-h2pzs
  May 13 16:14:54.345: INFO: Received response from host: affinity-clusterip-h2pzs
  May 13 16:14:54.345: INFO: Received response from host: affinity-clusterip-h2pzs
  May 13 16:14:54.345: INFO: Received response from host: affinity-clusterip-h2pzs
  May 13 16:14:54.345: INFO: Received response from host: affinity-clusterip-h2pzs
  May 13 16:14:54.345: INFO: Received response from host: affinity-clusterip-h2pzs
  May 13 16:14:54.345: INFO: Received response from host: affinity-clusterip-h2pzs
  May 13 16:14:54.345: INFO: Received response from host: affinity-clusterip-h2pzs
  May 13 16:14:54.345: INFO: Received response from host: affinity-clusterip-h2pzs
  May 13 16:14:54.345: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-8419, will wait for the garbage collector to delete the pods @ 05/13/24 16:14:54.357
  May 13 16:14:54.421: INFO: Deleting ReplicationController affinity-clusterip took: 9.147066ms
  May 13 16:14:54.522: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.927513ms
  E0513 16:14:54.659063      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:55.661728      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:56.660683      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:14:57.471: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8419" for this suite. @ 05/13/24 16:14:57.473
• [9.650 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 05/13/24 16:14:57.478
  May 13 16:14:57.478: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename container-runtime @ 05/13/24 16:14:57.478
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:14:57.494
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:14:57.496
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 05/13/24 16:14:57.503
  E0513 16:14:57.662177      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:58.662853      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:14:59.675764      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:00.664161      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:01.664783      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:02.664467      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:03.665153      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:04.665517      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:05.665950      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:06.666606      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:07.667006      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:08.667576      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:09.668199      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:10.669583      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:11.669614      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:12.670964      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:13.671657      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 05/13/24 16:15:14.566
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 05/13/24 16:15:14.585
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 05/13/24 16:15:14.594
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 05/13/24 16:15:14.594
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 05/13/24 16:15:14.617
  E0513 16:15:14.671973      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:15.671990      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:16.672675      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 05/13/24 16:15:17.634
  E0513 16:15:17.673416      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 05/13/24 16:15:18.64
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 05/13/24 16:15:18.644
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 05/13/24 16:15:18.644
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 05/13/24 16:15:18.659
  E0513 16:15:18.674591      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 05/13/24 16:15:19.663
  E0513 16:15:19.674689      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:20.675378      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 05/13/24 16:15:21.675
  E0513 16:15:21.675467      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 05/13/24 16:15:21.679
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 05/13/24 16:15:21.679
  May 13 16:15:21.697: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-531" for this suite. @ 05/13/24 16:15:21.7
• [24.226 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 05/13/24 16:15:21.707
  May 13 16:15:21.707: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubectl-logs @ 05/13/24 16:15:21.708
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:15:21.719
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:15:21.721
  STEP: creating an pod @ 05/13/24 16:15:21.722
  May 13 16:15:21.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-logs-4172 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.47 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  May 13 16:15:21.771: INFO: stderr: ""
  May 13 16:15:21.771: INFO: stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 05/13/24 16:15:21.771
  May 13 16:15:21.771: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E0513 16:15:22.675727      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:23.676194      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:15:23.782: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 05/13/24 16:15:23.782
  May 13 16:15:23.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-logs-4172 logs logs-generator logs-generator'
  May 13 16:15:23.875: INFO: stderr: ""
  May 13 16:15:23.875: INFO: stdout: "I0513 16:15:22.422160       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/pdc 274\nI0513 16:15:22.621483       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/997 306\nI0513 16:15:22.822353       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/z67x 308\nI0513 16:15:23.021475       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/b5jf 203\nI0513 16:15:23.223301       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/t2sh 204\nI0513 16:15:23.421462       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/rc9 484\nI0513 16:15:23.622176       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/2n97 576\nI0513 16:15:23.821978       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/84d 416\n"
  STEP: limiting log lines @ 05/13/24 16:15:23.875
  May 13 16:15:23.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-logs-4172 logs logs-generator logs-generator --tail=1'
  May 13 16:15:23.941: INFO: stderr: ""
  May 13 16:15:23.941: INFO: stdout: "I0513 16:15:23.821978       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/84d 416\n"
  May 13 16:15:23.941: INFO: got output "I0513 16:15:23.821978       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/84d 416\n"
  STEP: limiting log bytes @ 05/13/24 16:15:23.941
  May 13 16:15:23.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-logs-4172 logs logs-generator logs-generator --limit-bytes=1'
  May 13 16:15:23.988: INFO: stderr: ""
  May 13 16:15:23.988: INFO: stdout: "I"
  May 13 16:15:23.988: INFO: got output "I"
  STEP: exposing timestamps @ 05/13/24 16:15:23.988
  May 13 16:15:23.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-logs-4172 logs logs-generator logs-generator --tail=1 --timestamps'
  May 13 16:15:24.042: INFO: stderr: ""
  May 13 16:15:24.042: INFO: stdout: "2024-05-13T16:15:24.022397461Z I0513 16:15:24.022277       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/dvg 236\n"
  May 13 16:15:24.042: INFO: got output "2024-05-13T16:15:24.022397461Z I0513 16:15:24.022277       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/dvg 236\n"
  STEP: restricting to a time range @ 05/13/24 16:15:24.042
  E0513 16:15:24.676176      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:25.676777      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:15:26.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-logs-4172 logs logs-generator logs-generator --since=1s'
  May 13 16:15:26.621: INFO: stderr: ""
  May 13 16:15:26.622: INFO: stdout: "I0513 16:15:25.621727       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/tbs5 247\nI0513 16:15:25.822216       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/m2t 595\nI0513 16:15:26.021633       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/zhl 251\nI0513 16:15:26.222297       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/kube-system/pods/k5q 419\nI0513 16:15:26.421471       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/dn2v 590\n"
  May 13 16:15:26.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-logs-4172 logs logs-generator logs-generator --since=24h'
  E0513 16:15:26.676875      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:15:26.677: INFO: stderr: ""
  May 13 16:15:26.677: INFO: stdout: "I0513 16:15:22.422160       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/pdc 274\nI0513 16:15:22.621483       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/997 306\nI0513 16:15:22.822353       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/z67x 308\nI0513 16:15:23.021475       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/b5jf 203\nI0513 16:15:23.223301       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/t2sh 204\nI0513 16:15:23.421462       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/rc9 484\nI0513 16:15:23.622176       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/2n97 576\nI0513 16:15:23.821978       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/84d 416\nI0513 16:15:24.022277       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/dvg 236\nI0513 16:15:24.221894       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/jn88 464\nI0513 16:15:24.422321       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/jvv 599\nI0513 16:15:24.621471       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/4t2 484\nI0513 16:15:24.821980       1 logs_generator.go:76] 12 GET /api/v1/namespaces/kube-system/pods/6z74 253\nI0513 16:15:25.021442       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/default/pods/txxr 424\nI0513 16:15:25.221835       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/mv4v 239\nI0513 16:15:25.422321       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/cqrb 564\nI0513 16:15:25.621727       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/tbs5 247\nI0513 16:15:25.822216       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/m2t 595\nI0513 16:15:26.021633       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/zhl 251\nI0513 16:15:26.222297       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/kube-system/pods/k5q 419\nI0513 16:15:26.421471       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/dn2v 590\nI0513 16:15:26.621913       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/jld 212\n"
  May 13 16:15:26.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-logs-4172 delete pod logs-generator'
  E0513 16:15:27.677378      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:15:28.034: INFO: stderr: ""
  May 13 16:15:28.034: INFO: stdout: "pod \"logs-generator\" deleted\n"
  May 13 16:15:28.034: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-4172" for this suite. @ 05/13/24 16:15:28.037
• [6.334 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:322
  STEP: Creating a kubernetes client @ 05/13/24 16:15:28.041
  May 13 16:15:28.041: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename gc @ 05/13/24 16:15:28.042
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:15:28.051
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:15:28.053
  STEP: create the rc @ 05/13/24 16:15:28.054
  W0513 16:15:28.058309      17 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0513 16:15:28.677648      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:29.677891      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:30.678110      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:31.679091      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:32.679642      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 05/13/24 16:15:33.06
  STEP: wait for all pods to be garbage collected @ 05/13/24 16:15:33.062
  E0513 16:15:33.680467      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:34.680674      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:35.680633      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:36.680720      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:37.680857      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/13/24 16:15:38.065
  May 13 16:15:38.120: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  May 13 16:15:38.123: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8800" for this suite. @ 05/13/24 16:15:38.125
• [10.088 seconds]
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 05/13/24 16:15:38.129
  May 13 16:15:38.129: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename proxy @ 05/13/24 16:15:38.13
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:15:38.142
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:15:38.144
  STEP: starting an echo server on multiple ports @ 05/13/24 16:15:38.154
  STEP: creating replication controller proxy-service-j5425 in namespace proxy-4429 @ 05/13/24 16:15:38.155
  I0513 16:15:38.171798      17 runners.go:197] Created replication controller with name: proxy-service-j5425, namespace: proxy-4429, replica count: 1
  E0513 16:15:38.681342      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0513 16:15:39.226729      17 runners.go:197] proxy-service-j5425 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May 13 16:15:39.232: INFO: setup took 1.086582546s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 05/13/24 16:15:39.233
  May 13 16:15:39.265: INFO: (0) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname2/proxy/: bar (200; 28.881034ms)
  May 13 16:15:39.265: INFO: (0) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:460/proxy/: tls baz (200; 29.284021ms)
  May 13 16:15:39.265: INFO: (0) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname2/proxy/: bar (200; 29.081166ms)
  May 13 16:15:39.265: INFO: (0) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname1/proxy/: tls baz (200; 29.042794ms)
  May 13 16:15:39.265: INFO: (0) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:162/proxy/: bar (200; 29.009643ms)
  May 13 16:15:39.278: INFO: (0) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:162/proxy/: bar (200; 43.659926ms)
  May 13 16:15:39.278: INFO: (0) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/tlsrewritem... (200; 41.412576ms)
  May 13 16:15:39.278: INFO: (0) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/rewriteme">test</a> (200; 41.521401ms)
  May 13 16:15:39.279: INFO: (0) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/rewriteme">test<... (200; 42.009725ms)
  May 13 16:15:39.279: INFO: (0) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/rewriteme">... (200; 41.928315ms)
  May 13 16:15:39.279: INFO: (0) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname1/proxy/: foo (200; 41.665492ms)
  May 13 16:15:39.279: INFO: (0) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname2/proxy/: tls qux (200; 42.128053ms)
  May 13 16:15:39.279: INFO: (0) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:462/proxy/: tls qux (200; 41.771508ms)
  May 13 16:15:39.279: INFO: (0) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:160/proxy/: foo (200; 41.603591ms)
  May 13 16:15:39.278: INFO: (0) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname1/proxy/: foo (200; 41.874133ms)
  May 13 16:15:39.279: INFO: (0) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:160/proxy/: foo (200; 42.070082ms)
  May 13 16:15:39.285: INFO: (1) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname1/proxy/: tls baz (200; 3.560853ms)
  May 13 16:15:39.285: INFO: (1) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:462/proxy/: tls qux (200; 3.558897ms)
  May 13 16:15:39.285: INFO: (1) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/rewriteme">... (200; 3.296683ms)
  May 13 16:15:39.285: INFO: (1) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname1/proxy/: foo (200; 3.255417ms)
  May 13 16:15:39.291: INFO: (1) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/rewriteme">test</a> (200; 8.327887ms)
  May 13 16:15:39.291: INFO: (1) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:162/proxy/: bar (200; 8.65454ms)
  May 13 16:15:39.292: INFO: (1) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/rewriteme">test<... (200; 9.682093ms)
  May 13 16:15:39.293: INFO: (1) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:160/proxy/: foo (200; 10.532681ms)
  May 13 16:15:39.293: INFO: (1) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:460/proxy/: tls baz (200; 10.583832ms)
  May 13 16:15:39.293: INFO: (1) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:162/proxy/: bar (200; 10.621917ms)
  May 13 16:15:39.293: INFO: (1) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:160/proxy/: foo (200; 11.091406ms)
  May 13 16:15:39.293: INFO: (1) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname2/proxy/: bar (200; 11.12695ms)
  May 13 16:15:39.293: INFO: (1) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname2/proxy/: bar (200; 11.23937ms)
  May 13 16:15:39.294: INFO: (1) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname1/proxy/: foo (200; 11.596087ms)
  May 13 16:15:39.294: INFO: (1) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname2/proxy/: tls qux (200; 11.797494ms)
  May 13 16:15:39.294: INFO: (1) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/tlsrewritem... (200; 11.7654ms)
  May 13 16:15:39.299: INFO: (2) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/rewriteme">test<... (200; 4.664141ms)
  May 13 16:15:39.299: INFO: (2) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/rewriteme">test</a> (200; 4.804142ms)
  May 13 16:15:39.299: INFO: (2) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/rewriteme">... (200; 4.866604ms)
  May 13 16:15:39.300: INFO: (2) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:462/proxy/: tls qux (200; 5.908729ms)
  May 13 16:15:39.301: INFO: (2) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:162/proxy/: bar (200; 5.983808ms)
  May 13 16:15:39.301: INFO: (2) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname2/proxy/: bar (200; 6.35248ms)
  May 13 16:15:39.303: INFO: (2) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:160/proxy/: foo (200; 8.269031ms)
  May 13 16:15:39.303: INFO: (2) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:162/proxy/: bar (200; 8.4228ms)
  May 13 16:15:39.303: INFO: (2) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname1/proxy/: foo (200; 8.734639ms)
  May 13 16:15:39.304: INFO: (2) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname2/proxy/: bar (200; 9.068026ms)
  May 13 16:15:39.304: INFO: (2) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname2/proxy/: tls qux (200; 9.396184ms)
  May 13 16:15:39.304: INFO: (2) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/tlsrewritem... (200; 9.377052ms)
  May 13 16:15:39.304: INFO: (2) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:460/proxy/: tls baz (200; 9.56032ms)
  May 13 16:15:39.305: INFO: (2) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname1/proxy/: foo (200; 10.284105ms)
  May 13 16:15:39.305: INFO: (2) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:160/proxy/: foo (200; 10.151049ms)
  May 13 16:15:39.305: INFO: (2) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname1/proxy/: tls baz (200; 10.252522ms)
  May 13 16:15:39.307: INFO: (3) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/rewriteme">test</a> (200; 2.157827ms)
  May 13 16:15:39.308: INFO: (3) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/rewriteme">test<... (200; 3.070788ms)
  May 13 16:15:39.308: INFO: (3) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:162/proxy/: bar (200; 3.229341ms)
  May 13 16:15:39.310: INFO: (3) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:462/proxy/: tls qux (200; 5.258816ms)
  May 13 16:15:39.311: INFO: (3) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/tlsrewritem... (200; 5.551183ms)
  May 13 16:15:39.311: INFO: (3) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname1/proxy/: foo (200; 4.858552ms)
  May 13 16:15:39.311: INFO: (3) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/rewriteme">... (200; 5.568216ms)
  May 13 16:15:39.311: INFO: (3) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname2/proxy/: tls qux (200; 4.837941ms)
  May 13 16:15:39.311: INFO: (3) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:460/proxy/: tls baz (200; 5.868365ms)
  May 13 16:15:39.313: INFO: (3) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:162/proxy/: bar (200; 7.086886ms)
  May 13 16:15:39.313: INFO: (3) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:160/proxy/: foo (200; 7.45749ms)
  May 13 16:15:39.313: INFO: (3) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname1/proxy/: foo (200; 8.213286ms)
  May 13 16:15:39.314: INFO: (3) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:160/proxy/: foo (200; 8.706208ms)
  May 13 16:15:39.315: INFO: (3) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname2/proxy/: bar (200; 8.849437ms)
  May 13 16:15:39.315: INFO: (3) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname2/proxy/: bar (200; 8.932301ms)
  May 13 16:15:39.315: INFO: (3) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname1/proxy/: tls baz (200; 9.086754ms)
  May 13 16:15:39.318: INFO: (4) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname1/proxy/: foo (200; 2.554292ms)
  May 13 16:15:39.318: INFO: (4) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:460/proxy/: tls baz (200; 3.265019ms)
  May 13 16:15:39.321: INFO: (4) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/rewriteme">... (200; 5.739355ms)
  May 13 16:15:39.323: INFO: (4) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/rewriteme">test<... (200; 7.633624ms)
  May 13 16:15:39.324: INFO: (4) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:160/proxy/: foo (200; 9.017137ms)
  May 13 16:15:39.327: INFO: (4) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/rewriteme">test</a> (200; 11.988798ms)
  May 13 16:15:39.327: INFO: (4) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname1/proxy/: foo (200; 12.089071ms)
  May 13 16:15:39.328: INFO: (4) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:162/proxy/: bar (200; 10.905447ms)
  May 13 16:15:39.328: INFO: (4) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:162/proxy/: bar (200; 12.052647ms)
  May 13 16:15:39.328: INFO: (4) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:462/proxy/: tls qux (200; 11.578509ms)
  May 13 16:15:39.328: INFO: (4) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname2/proxy/: bar (200; 11.158221ms)
  May 13 16:15:39.328: INFO: (4) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/tlsrewritem... (200; 11.771495ms)
  May 13 16:15:39.328: INFO: (4) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:160/proxy/: foo (200; 12.202751ms)
  May 13 16:15:39.328: INFO: (4) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname1/proxy/: tls baz (200; 11.124344ms)
  May 13 16:15:39.328: INFO: (4) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname2/proxy/: bar (200; 11.402659ms)
  May 13 16:15:39.328: INFO: (4) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname2/proxy/: tls qux (200; 12.936898ms)
  May 13 16:15:39.333: INFO: (5) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:162/proxy/: bar (200; 4.046882ms)
  May 13 16:15:39.335: INFO: (5) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/rewriteme">test<... (200; 5.366828ms)
  May 13 16:15:39.335: INFO: (5) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/rewriteme">... (200; 5.525921ms)
  May 13 16:15:39.335: INFO: (5) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:162/proxy/: bar (200; 5.784788ms)
  May 13 16:15:39.335: INFO: (5) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:160/proxy/: foo (200; 6.051743ms)
  May 13 16:15:39.336: INFO: (5) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/rewriteme">test</a> (200; 6.800194ms)
  May 13 16:15:39.336: INFO: (5) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/tlsrewritem... (200; 6.975407ms)
  May 13 16:15:39.337: INFO: (5) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:462/proxy/: tls qux (200; 7.267958ms)
  May 13 16:15:39.337: INFO: (5) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:160/proxy/: foo (200; 7.512535ms)
  May 13 16:15:39.337: INFO: (5) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:460/proxy/: tls baz (200; 7.86218ms)
  May 13 16:15:39.338: INFO: (5) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname2/proxy/: bar (200; 8.385216ms)
  May 13 16:15:39.338: INFO: (5) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname2/proxy/: bar (200; 8.520204ms)
  May 13 16:15:39.338: INFO: (5) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname2/proxy/: tls qux (200; 8.574261ms)
  May 13 16:15:39.338: INFO: (5) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname1/proxy/: foo (200; 8.642144ms)
  May 13 16:15:39.339: INFO: (5) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname1/proxy/: tls baz (200; 9.37693ms)
  May 13 16:15:39.339: INFO: (5) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname1/proxy/: foo (200; 9.432624ms)
  May 13 16:15:39.342: INFO: (6) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/rewriteme">test<... (200; 3.216061ms)
  May 13 16:15:39.344: INFO: (6) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/rewriteme">test</a> (200; 5.312258ms)
  May 13 16:15:39.345: INFO: (6) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:160/proxy/: foo (200; 5.457276ms)
  May 13 16:15:39.345: INFO: (6) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:160/proxy/: foo (200; 5.622272ms)
  May 13 16:15:39.346: INFO: (6) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:162/proxy/: bar (200; 6.465606ms)
  May 13 16:15:39.346: INFO: (6) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/tlsrewritem... (200; 7.038559ms)
  May 13 16:15:39.346: INFO: (6) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:462/proxy/: tls qux (200; 7.037789ms)
  May 13 16:15:39.346: INFO: (6) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:460/proxy/: tls baz (200; 7.192113ms)
  May 13 16:15:39.346: INFO: (6) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:162/proxy/: bar (200; 7.32604ms)
  May 13 16:15:39.347: INFO: (6) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname1/proxy/: foo (200; 7.276413ms)
  May 13 16:15:39.347: INFO: (6) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname1/proxy/: tls baz (200; 7.244368ms)
  May 13 16:15:39.348: INFO: (6) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/rewriteme">... (200; 8.540434ms)
  May 13 16:15:39.348: INFO: (6) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname1/proxy/: foo (200; 8.56815ms)
  May 13 16:15:39.348: INFO: (6) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname2/proxy/: bar (200; 8.590818ms)
  May 13 16:15:39.348: INFO: (6) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname2/proxy/: bar (200; 8.679693ms)
  May 13 16:15:39.349: INFO: (6) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname2/proxy/: tls qux (200; 9.145066ms)
  May 13 16:15:39.353: INFO: (7) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/rewriteme">test</a> (200; 3.900046ms)
  May 13 16:15:39.354: INFO: (7) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/rewriteme">test<... (200; 4.09723ms)
  May 13 16:15:39.354: INFO: (7) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:162/proxy/: bar (200; 3.398538ms)
  May 13 16:15:39.354: INFO: (7) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:460/proxy/: tls baz (200; 4.19727ms)
  May 13 16:15:39.354: INFO: (7) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname1/proxy/: foo (200; 4.129812ms)
  May 13 16:15:39.354: INFO: (7) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/rewriteme">... (200; 4.155536ms)
  May 13 16:15:39.354: INFO: (7) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:160/proxy/: foo (200; 4.207345ms)
  May 13 16:15:39.355: INFO: (7) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname2/proxy/: tls qux (200; 5.608973ms)
  May 13 16:15:39.358: INFO: (7) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:462/proxy/: tls qux (200; 8.123226ms)
  May 13 16:15:39.358: INFO: (7) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:162/proxy/: bar (200; 8.091431ms)
  May 13 16:15:39.358: INFO: (7) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:160/proxy/: foo (200; 8.110158ms)
  May 13 16:15:39.358: INFO: (7) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/tlsrewritem... (200; 8.096943ms)
  May 13 16:15:39.358: INFO: (7) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname2/proxy/: bar (200; 8.133438ms)
  May 13 16:15:39.358: INFO: (7) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname1/proxy/: foo (200; 8.149263ms)
  May 13 16:15:39.358: INFO: (7) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname1/proxy/: tls baz (200; 8.111044ms)
  May 13 16:15:39.358: INFO: (7) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname2/proxy/: bar (200; 7.3611ms)
  May 13 16:15:39.362: INFO: (8) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname2/proxy/: tls qux (200; 3.439585ms)
  May 13 16:15:39.362: INFO: (8) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:160/proxy/: foo (200; 3.896926ms)
  May 13 16:15:39.363: INFO: (8) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname1/proxy/: foo (200; 4.219978ms)
  May 13 16:15:39.363: INFO: (8) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/rewriteme">test<... (200; 4.421611ms)
  May 13 16:15:39.365: INFO: (8) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/rewriteme">... (200; 6.153372ms)
  May 13 16:15:39.365: INFO: (8) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/rewriteme">test</a> (200; 6.142837ms)
  May 13 16:15:39.367: INFO: (8) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname1/proxy/: foo (200; 8.425853ms)
  May 13 16:15:39.369: INFO: (8) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname2/proxy/: bar (200; 9.926264ms)
  May 13 16:15:39.369: INFO: (8) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:460/proxy/: tls baz (200; 11.026262ms)
  May 13 16:15:39.367: INFO: (8) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:160/proxy/: foo (200; 8.162739ms)
  May 13 16:15:39.370: INFO: (8) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname1/proxy/: tls baz (200; 11.467468ms)
  May 13 16:15:39.371: INFO: (8) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:162/proxy/: bar (200; 11.915812ms)
  May 13 16:15:39.371: INFO: (8) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:162/proxy/: bar (200; 12.223705ms)
  May 13 16:15:39.371: INFO: (8) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname2/proxy/: bar (200; 12.788641ms)
  May 13 16:15:39.371: INFO: (8) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/tlsrewritem... (200; 12.737085ms)
  May 13 16:15:39.372: INFO: (8) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:462/proxy/: tls qux (200; 13.518921ms)
  May 13 16:15:39.381: INFO: (9) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:160/proxy/: foo (200; 8.316129ms)
  May 13 16:15:39.381: INFO: (9) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname1/proxy/: foo (200; 8.291438ms)
  May 13 16:15:39.381: INFO: (9) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:162/proxy/: bar (200; 8.240714ms)
  May 13 16:15:39.381: INFO: (9) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:460/proxy/: tls baz (200; 8.403763ms)
  May 13 16:15:39.381: INFO: (9) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname1/proxy/: tls baz (200; 8.446208ms)
  May 13 16:15:39.381: INFO: (9) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/rewriteme">... (200; 8.447187ms)
  May 13 16:15:39.381: INFO: (9) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname2/proxy/: bar (200; 8.504847ms)
  May 13 16:15:39.381: INFO: (9) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:162/proxy/: bar (200; 8.467485ms)
  May 13 16:15:39.381: INFO: (9) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/rewriteme">test<... (200; 8.553651ms)
  May 13 16:15:39.381: INFO: (9) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/rewriteme">test</a> (200; 8.505761ms)
  May 13 16:15:39.381: INFO: (9) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/tlsrewritem... (200; 8.554842ms)
  May 13 16:15:39.381: INFO: (9) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:462/proxy/: tls qux (200; 8.587077ms)
  May 13 16:15:39.381: INFO: (9) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname2/proxy/: tls qux (200; 8.678603ms)
  May 13 16:15:39.381: INFO: (9) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:160/proxy/: foo (200; 8.754507ms)
  May 13 16:15:39.381: INFO: (9) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname1/proxy/: foo (200; 8.738017ms)
  May 13 16:15:39.381: INFO: (9) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname2/proxy/: bar (200; 8.915043ms)
  May 13 16:15:39.384: INFO: (10) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/rewriteme">test</a> (200; 2.342044ms)
  May 13 16:15:39.386: INFO: (10) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname1/proxy/: foo (200; 4.237779ms)
  May 13 16:15:39.386: INFO: (10) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/rewriteme">... (200; 4.383926ms)
  May 13 16:15:39.386: INFO: (10) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname2/proxy/: bar (200; 4.326084ms)
  May 13 16:15:39.386: INFO: (10) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:160/proxy/: foo (200; 4.768912ms)
  May 13 16:15:39.388: INFO: (10) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:160/proxy/: foo (200; 4.854941ms)
  May 13 16:15:39.390: INFO: (10) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:162/proxy/: bar (200; 7.299591ms)
  May 13 16:15:39.391: INFO: (10) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/rewriteme">test<... (200; 7.250038ms)
  May 13 16:15:39.391: INFO: (10) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:162/proxy/: bar (200; 7.48343ms)
  May 13 16:15:39.391: INFO: (10) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:462/proxy/: tls qux (200; 7.463965ms)
  May 13 16:15:39.391: INFO: (10) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:460/proxy/: tls baz (200; 7.462052ms)
  May 13 16:15:39.391: INFO: (10) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname1/proxy/: tls baz (200; 7.461522ms)
  May 13 16:15:39.391: INFO: (10) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/tlsrewritem... (200; 7.539321ms)
  May 13 16:15:39.392: INFO: (10) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname1/proxy/: foo (200; 8.667226ms)
  May 13 16:15:39.392: INFO: (10) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname2/proxy/: tls qux (200; 8.682661ms)
  May 13 16:15:39.392: INFO: (10) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname2/proxy/: bar (200; 8.732689ms)
  May 13 16:15:39.394: INFO: (11) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/rewriteme">test</a> (200; 2.124676ms)
  May 13 16:15:39.397: INFO: (11) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname2/proxy/: bar (200; 5.410798ms)
  May 13 16:15:39.397: INFO: (11) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:160/proxy/: foo (200; 5.350459ms)
  May 13 16:15:39.397: INFO: (11) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname1/proxy/: foo (200; 5.391612ms)
  May 13 16:15:39.398: INFO: (11) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:462/proxy/: tls qux (200; 6.076409ms)
  May 13 16:15:39.398: INFO: (11) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/tlsrewritem... (200; 6.134304ms)
  May 13 16:15:39.401: INFO: (11) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:162/proxy/: bar (200; 8.977601ms)
  May 13 16:15:39.402: INFO: (11) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:162/proxy/: bar (200; 9.555306ms)
  May 13 16:15:39.402: INFO: (11) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:160/proxy/: foo (200; 9.667183ms)
  May 13 16:15:39.402: INFO: (11) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname2/proxy/: bar (200; 9.614433ms)
  May 13 16:15:39.402: INFO: (11) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname1/proxy/: foo (200; 9.614823ms)
  May 13 16:15:39.402: INFO: (11) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/rewriteme">test<... (200; 9.553226ms)
  May 13 16:15:39.402: INFO: (11) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/rewriteme">... (200; 9.594111ms)
  May 13 16:15:39.402: INFO: (11) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname1/proxy/: tls baz (200; 10.002091ms)
  May 13 16:15:39.402: INFO: (11) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname2/proxy/: tls qux (200; 9.981039ms)
  May 13 16:15:39.402: INFO: (11) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:460/proxy/: tls baz (200; 9.948619ms)
  May 13 16:15:39.414: INFO: (12) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:160/proxy/: foo (200; 11.440517ms)
  May 13 16:15:39.454: INFO: (12) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/rewriteme">test</a> (200; 51.897581ms)
  May 13 16:15:39.454: INFO: (12) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:162/proxy/: bar (200; 51.754279ms)
  May 13 16:15:39.454: INFO: (12) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:162/proxy/: bar (200; 51.510036ms)
  May 13 16:15:39.454: INFO: (12) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:160/proxy/: foo (200; 51.866069ms)
  May 13 16:15:39.454: INFO: (12) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/tlsrewritem... (200; 51.737186ms)
  May 13 16:15:39.454: INFO: (12) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:462/proxy/: tls qux (200; 51.702842ms)
  May 13 16:15:39.456: INFO: (12) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/rewriteme">... (200; 52.676913ms)
  May 13 16:15:39.477: INFO: (12) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/rewriteme">test<... (200; 73.790055ms)
  May 13 16:15:39.477: INFO: (12) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname2/proxy/: bar (200; 74.207527ms)
  May 13 16:15:39.477: INFO: (12) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:460/proxy/: tls baz (200; 74.245913ms)
  May 13 16:15:39.477: INFO: (12) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname1/proxy/: foo (200; 74.572503ms)
  May 13 16:15:39.480: INFO: (12) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname2/proxy/: tls qux (200; 76.872616ms)
  May 13 16:15:39.490: INFO: (12) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname1/proxy/: tls baz (200; 87.13705ms)
  May 13 16:15:39.499: INFO: (12) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname1/proxy/: foo (200; 96.329655ms)
  May 13 16:15:39.514: INFO: (12) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname2/proxy/: bar (200; 111.717944ms)
  May 13 16:15:39.524: INFO: (13) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:460/proxy/: tls baz (200; 9.280037ms)
  May 13 16:15:39.524: INFO: (13) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname1/proxy/: tls baz (200; 9.405541ms)
  May 13 16:15:39.538: INFO: (13) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname1/proxy/: foo (200; 22.957499ms)
  May 13 16:15:39.538: INFO: (13) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:162/proxy/: bar (200; 23.205798ms)
  May 13 16:15:39.538: INFO: (13) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/rewriteme">test<... (200; 23.059067ms)
  May 13 16:15:39.538: INFO: (13) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname1/proxy/: foo (200; 22.939146ms)
  May 13 16:15:39.538: INFO: (13) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/rewriteme">... (200; 23.157166ms)
  May 13 16:15:39.538: INFO: (13) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/rewriteme">test</a> (200; 23.124246ms)
  May 13 16:15:39.538: INFO: (13) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/tlsrewritem... (200; 23.041637ms)
  May 13 16:15:39.538: INFO: (13) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname2/proxy/: bar (200; 23.656633ms)
  May 13 16:15:39.538: INFO: (13) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname2/proxy/: bar (200; 23.616205ms)
  May 13 16:15:39.538: INFO: (13) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:160/proxy/: foo (200; 23.160428ms)
  May 13 16:15:39.538: INFO: (13) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname2/proxy/: tls qux (200; 23.42259ms)
  May 13 16:15:39.539: INFO: (13) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:462/proxy/: tls qux (200; 23.921386ms)
  May 13 16:15:39.539: INFO: (13) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:162/proxy/: bar (200; 23.254321ms)
  May 13 16:15:39.539: INFO: (13) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:160/proxy/: foo (200; 23.423697ms)
  May 13 16:15:39.547: INFO: (14) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/rewriteme">test</a> (200; 8.6834ms)
  May 13 16:15:39.548: INFO: (14) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname1/proxy/: foo (200; 7.816531ms)
  May 13 16:15:39.548: INFO: (14) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:160/proxy/: foo (200; 7.975751ms)
  May 13 16:15:39.548: INFO: (14) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:160/proxy/: foo (200; 7.004527ms)
  May 13 16:15:39.548: INFO: (14) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:162/proxy/: bar (200; 6.338415ms)
  May 13 16:15:39.548: INFO: (14) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/tlsrewritem... (200; 5.568391ms)
  May 13 16:15:39.550: INFO: (14) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:462/proxy/: tls qux (200; 6.203082ms)
  May 13 16:15:39.550: INFO: (14) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname2/proxy/: bar (200; 5.391578ms)
  May 13 16:15:39.550: INFO: (14) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname2/proxy/: bar (200; 4.612469ms)
  May 13 16:15:39.550: INFO: (14) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname1/proxy/: tls baz (200; 4.606114ms)
  May 13 16:15:39.554: INFO: (14) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname1/proxy/: foo (200; 3.604286ms)
  May 13 16:15:39.554: INFO: (14) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:460/proxy/: tls baz (200; 2.551664ms)
  May 13 16:15:39.554: INFO: (14) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:162/proxy/: bar (200; 2.61448ms)
  May 13 16:15:39.557: INFO: (14) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/rewriteme">test<... (200; 4.314023ms)
  May 13 16:15:39.557: INFO: (14) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/rewriteme">... (200; 3.87936ms)
  May 13 16:15:39.559: INFO: (14) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname2/proxy/: tls qux (200; 5.853708ms)
  May 13 16:15:39.563: INFO: (15) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/rewriteme">test</a> (200; 3.771528ms)
  May 13 16:15:39.565: INFO: (15) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:162/proxy/: bar (200; 4.230991ms)
  May 13 16:15:39.565: INFO: (15) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:160/proxy/: foo (200; 5.188859ms)
  May 13 16:15:39.565: INFO: (15) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname2/proxy/: tls qux (200; 5.815656ms)
  May 13 16:15:39.565: INFO: (15) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:462/proxy/: tls qux (200; 2.28365ms)
  May 13 16:15:39.565: INFO: (15) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/tlsrewritem... (200; 4.002819ms)
  May 13 16:15:39.565: INFO: (15) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname1/proxy/: foo (200; 1.894542ms)
  May 13 16:15:39.567: INFO: (15) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname2/proxy/: bar (200; 2.485107ms)
  May 13 16:15:39.567: INFO: (15) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname1/proxy/: tls baz (200; 2.434731ms)
  May 13 16:15:39.570: INFO: (15) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:162/proxy/: bar (200; 4.956167ms)
  May 13 16:15:39.570: INFO: (15) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:460/proxy/: tls baz (200; 3.834557ms)
  May 13 16:15:39.570: INFO: (15) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/rewriteme">test<... (200; 2.985139ms)
  May 13 16:15:39.570: INFO: (15) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname2/proxy/: bar (200; 2.936384ms)
  May 13 16:15:39.573: INFO: (15) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/rewriteme">... (200; 5.841059ms)
  May 13 16:15:39.573: INFO: (15) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:160/proxy/: foo (200; 10.412683ms)
  May 13 16:15:39.575: INFO: (15) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname1/proxy/: foo (200; 4.28903ms)
  May 13 16:15:39.582: INFO: (16) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:462/proxy/: tls qux (200; 3.616024ms)
  May 13 16:15:39.584: INFO: (16) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/rewriteme">test<... (200; 8.212858ms)
  May 13 16:15:39.584: INFO: (16) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:162/proxy/: bar (200; 7.666697ms)
  May 13 16:15:39.584: INFO: (16) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:162/proxy/: bar (200; 7.01644ms)
  May 13 16:15:39.584: INFO: (16) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/tlsrewritem... (200; 6.451471ms)
  May 13 16:15:39.586: INFO: (16) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname1/proxy/: foo (200; 6.627047ms)
  May 13 16:15:39.586: INFO: (16) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:160/proxy/: foo (200; 6.592146ms)
  May 13 16:15:39.586: INFO: (16) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/rewriteme">... (200; 6.549865ms)
  May 13 16:15:39.586: INFO: (16) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:460/proxy/: tls baz (200; 6.601087ms)
  May 13 16:15:39.586: INFO: (16) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:160/proxy/: foo (200; 6.67254ms)
  May 13 16:15:39.586: INFO: (16) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/rewriteme">test</a> (200; 10.277281ms)
  May 13 16:15:39.588: INFO: (16) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname2/proxy/: bar (200; 8.352286ms)
  May 13 16:15:39.588: INFO: (16) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname2/proxy/: bar (200; 8.412978ms)
  May 13 16:15:39.588: INFO: (16) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname1/proxy/: tls baz (200; 8.534255ms)
  May 13 16:15:39.589: INFO: (16) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname1/proxy/: foo (200; 9.317557ms)
  May 13 16:15:39.589: INFO: (16) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname2/proxy/: tls qux (200; 9.333797ms)
  May 13 16:15:39.602: INFO: (17) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/rewriteme">test<... (200; 7.41391ms)
  May 13 16:15:39.602: INFO: (17) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:160/proxy/: foo (200; 5.82136ms)
  May 13 16:15:39.602: INFO: (17) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:162/proxy/: bar (200; 6.179853ms)
  May 13 16:15:39.602: INFO: (17) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:460/proxy/: tls baz (200; 6.156105ms)
  May 13 16:15:39.602: INFO: (17) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname2/proxy/: bar (200; 6.738081ms)
  May 13 16:15:39.602: INFO: (17) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname2/proxy/: bar (200; 6.389142ms)
  May 13 16:15:39.602: INFO: (17) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname1/proxy/: foo (200; 6.132242ms)
  May 13 16:15:39.602: INFO: (17) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname1/proxy/: tls baz (200; 6.349644ms)
  May 13 16:15:39.603: INFO: (17) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/rewriteme">... (200; 6.863944ms)
  May 13 16:15:39.604: INFO: (17) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname2/proxy/: tls qux (200; 8.284983ms)
  May 13 16:15:39.604: INFO: (17) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/rewriteme">test</a> (200; 8.266768ms)
  May 13 16:15:39.605: INFO: (17) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:160/proxy/: foo (200; 8.326467ms)
  May 13 16:15:39.605: INFO: (17) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname1/proxy/: foo (200; 8.674381ms)
  May 13 16:15:39.605: INFO: (17) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:462/proxy/: tls qux (200; 10.750147ms)
  May 13 16:15:39.605: INFO: (17) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:162/proxy/: bar (200; 8.891565ms)
  May 13 16:15:39.605: INFO: (17) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/tlsrewritem... (200; 8.803578ms)
  May 13 16:15:39.609: INFO: (18) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/tlsrewritem... (200; 3.316729ms)
  May 13 16:15:39.611: INFO: (18) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:162/proxy/: bar (200; 5.543239ms)
  May 13 16:15:39.613: INFO: (18) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/rewriteme">test<... (200; 7.224331ms)
  May 13 16:15:39.615: INFO: (18) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:160/proxy/: foo (200; 8.748619ms)
  May 13 16:15:39.615: INFO: (18) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:160/proxy/: foo (200; 8.826962ms)
  May 13 16:15:39.615: INFO: (18) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:462/proxy/: tls qux (200; 8.853221ms)
  May 13 16:15:39.615: INFO: (18) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:460/proxy/: tls baz (200; 8.969299ms)
  May 13 16:15:39.615: INFO: (18) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/rewriteme">... (200; 9.20585ms)
  May 13 16:15:39.615: INFO: (18) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/rewriteme">test</a> (200; 9.210831ms)
  May 13 16:15:39.617: INFO: (18) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname2/proxy/: bar (200; 10.977979ms)
  May 13 16:15:39.617: INFO: (18) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:162/proxy/: bar (200; 10.699069ms)
  May 13 16:15:39.618: INFO: (18) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname1/proxy/: foo (200; 11.716284ms)
  May 13 16:15:39.618: INFO: (18) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname2/proxy/: bar (200; 11.940883ms)
  May 13 16:15:39.618: INFO: (18) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname1/proxy/: tls baz (200; 12.3602ms)
  May 13 16:15:39.618: INFO: (18) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname1/proxy/: foo (200; 12.168593ms)
  May 13 16:15:39.618: INFO: (18) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname2/proxy/: tls qux (200; 12.258947ms)
  May 13 16:15:39.628: INFO: (19) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname1/proxy/: tls baz (200; 4.804512ms)
  May 13 16:15:39.629: INFO: (19) /api/v1/namespaces/proxy-4429/services/https:proxy-service-j5425:tlsportname2/proxy/: tls qux (200; 4.977677ms)
  May 13 16:15:39.629: INFO: (19) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname1/proxy/: foo (200; 5.00008ms)
  May 13 16:15:39.629: INFO: (19) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf/proxy/rewriteme">test</a> (200; 5.054242ms)
  May 13 16:15:39.629: INFO: (19) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:160/proxy/: foo (200; 8.149968ms)
  May 13 16:15:39.629: INFO: (19) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:162/proxy/: bar (200; 8.048566ms)
  May 13 16:15:39.629: INFO: (19) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname2/proxy/: bar (200; 6.802908ms)
  May 13 16:15:39.629: INFO: (19) /api/v1/namespaces/proxy-4429/services/http:proxy-service-j5425:portname2/proxy/: bar (200; 5.544161ms)
  May 13 16:15:39.629: INFO: (19) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:460/proxy/: tls baz (200; 7.365146ms)
  May 13 16:15:39.629: INFO: (19) /api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/http:proxy-service-j5425-mmsrf:1080/proxy/rewriteme">... (200; 5.411369ms)
  May 13 16:15:39.630: INFO: (19) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:1080/proxy/rewriteme">test<... (200; 6.138254ms)
  May 13 16:15:39.631: INFO: (19) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:160/proxy/: foo (200; 3.470662ms)
  May 13 16:15:39.631: INFO: (19) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/: <a href="/api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:443/proxy/tlsrewritem... (200; 7.325406ms)
  May 13 16:15:39.631: INFO: (19) /api/v1/namespaces/proxy-4429/pods/https:proxy-service-j5425-mmsrf:462/proxy/: tls qux (200; 7.735579ms)
  May 13 16:15:39.632: INFO: (19) /api/v1/namespaces/proxy-4429/pods/proxy-service-j5425-mmsrf:162/proxy/: bar (200; 8.005987ms)
  May 13 16:15:39.632: INFO: (19) /api/v1/namespaces/proxy-4429/services/proxy-service-j5425:portname1/proxy/: foo (200; 8.564527ms)
  STEP: deleting ReplicationController proxy-service-j5425 in namespace proxy-4429, will wait for the garbage collector to delete the pods @ 05/13/24 16:15:39.635
  E0513 16:15:39.682145      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:15:39.690: INFO: Deleting ReplicationController proxy-service-j5425 took: 3.0967ms
  May 13 16:15:39.790: INFO: Terminating ReplicationController proxy-service-j5425 pods took: 100.16214ms
  E0513 16:15:40.687480      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:41.688629      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:15:42.191: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-4429" for this suite. @ 05/13/24 16:15:42.198
• [4.077 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:155
  STEP: Creating a kubernetes client @ 05/13/24 16:15:42.209
  May 13 16:15:42.209: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename replicaset @ 05/13/24 16:15:42.211
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:15:42.229
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:15:42.231
  May 13 16:15:42.242: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0513 16:15:42.688674      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:43.689505      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:44.689765      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:45.690216      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:46.691382      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:15:47.247: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/13/24 16:15:47.248
  STEP: Scaling up "test-rs" replicaset @ 05/13/24 16:15:47.248
  May 13 16:15:47.256: INFO: Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 05/13/24 16:15:47.256
  May 13 16:15:47.264: INFO: observed ReplicaSet test-rs in namespace replicaset-2274 with ReadyReplicas 1, AvailableReplicas 1
  May 13 16:15:47.282: INFO: observed ReplicaSet test-rs in namespace replicaset-2274 with ReadyReplicas 1, AvailableReplicas 1
  May 13 16:15:47.297: INFO: observed ReplicaSet test-rs in namespace replicaset-2274 with ReadyReplicas 1, AvailableReplicas 1
  May 13 16:15:47.303: INFO: observed ReplicaSet test-rs in namespace replicaset-2274 with ReadyReplicas 1, AvailableReplicas 1
  E0513 16:15:47.691174      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:15:48.130: INFO: observed ReplicaSet test-rs in namespace replicaset-2274 with ReadyReplicas 2, AvailableReplicas 2
  May 13 16:15:48.220: INFO: observed Replicaset test-rs in namespace replicaset-2274 with ReadyReplicas 3 found true
  May 13 16:15:48.221: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-2274" for this suite. @ 05/13/24 16:15:48.224
• [6.021 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:86
  STEP: Creating a kubernetes client @ 05/13/24 16:15:48.234
  May 13 16:15:48.234: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename replication-controller @ 05/13/24 16:15:48.235
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:15:48.246
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:15:48.248
  May 13 16:15:48.250: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
  E0513 16:15:48.692002      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 05/13/24 16:15:49.257
  STEP: Checking rc "condition-test" has the desired failure condition set @ 05/13/24 16:15:49.261
  E0513 16:15:49.692136      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 05/13/24 16:15:50.28
  May 13 16:15:50.296: INFO: Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 05/13/24 16:15:50.296
  May 13 16:15:50.303: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-216" for this suite. @ 05/13/24 16:15:50.307
• [2.077 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:210
  STEP: Creating a kubernetes client @ 05/13/24 16:15:50.312
  May 13 16:15:50.312: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename emptydir @ 05/13/24 16:15:50.314
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:15:50.327
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:15:50.329
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 05/13/24 16:15:50.33
  E0513 16:15:50.693608      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:51.694444      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:52.695498      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:53.696215      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:15:54.351
  May 13 16:15:54.354: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-ccb1a86f-fac1-4a3a-bfeb-c915a3b66471 container test-container: <nil>
  STEP: delete the pod @ 05/13/24 16:15:54.361
  May 13 16:15:54.372: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1177" for this suite. @ 05/13/24 16:15:54.374
• [4.067 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 05/13/24 16:15:54.386
  May 13 16:15:54.386: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 16:15:54.387
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:15:54.397
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:15:54.399
  STEP: Creating projection with secret that has name projected-secret-test-map-ebd0f28a-0b32-493f-9c64-826f1b1501dd @ 05/13/24 16:15:54.4
  STEP: Creating a pod to test consume secrets @ 05/13/24 16:15:54.403
  E0513 16:15:54.697077      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:55.696984      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:56.697931      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:57.698147      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:15:58.415
  May 13 16:15:58.417: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-projected-secrets-16d2196d-d887-41c4-9f80-1fb10f4a45a3 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/13/24 16:15:58.42
  May 13 16:15:58.431: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-980" for this suite. @ 05/13/24 16:15:58.434
• [4.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 05/13/24 16:15:58.439
  May 13 16:15:58.439: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename pods @ 05/13/24 16:15:58.44
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:15:58.452
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:15:58.454
  May 13 16:15:58.455: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: creating the pod @ 05/13/24 16:15:58.456
  STEP: submitting the pod to kubernetes @ 05/13/24 16:15:58.456
  E0513 16:15:58.698532      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:15:59.698807      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:16:00.550: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-835" for this suite. @ 05/13/24 16:16:00.553
• [2.117 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3338
  STEP: Creating a kubernetes client @ 05/13/24 16:16:00.559
  May 13 16:16:00.559: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename services @ 05/13/24 16:16:00.56
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:16:00.582
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:16:00.584
  STEP: creating a Service @ 05/13/24 16:16:00.587
  STEP: watching for the Service to be added @ 05/13/24 16:16:00.594
  May 13 16:16:00.601: INFO: Found Service test-service-sw8df in namespace services-6088 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 31553}]
  May 13 16:16:00.601: INFO: Service test-service-sw8df created
  STEP: Getting /status @ 05/13/24 16:16:00.601
  May 13 16:16:00.604: INFO: Service test-service-sw8df has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 05/13/24 16:16:00.604
  STEP: watching for the Service to be patched @ 05/13/24 16:16:00.618
  May 13 16:16:00.624: INFO: observed Service test-service-sw8df in namespace services-6088 with annotations: map[] & LoadBalancer: {[]}
  May 13 16:16:00.624: INFO: Found Service test-service-sw8df in namespace services-6088 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  <nil> []}]}
  May 13 16:16:00.624: INFO: Service test-service-sw8df has service status patched
  STEP: updating the ServiceStatus @ 05/13/24 16:16:00.624
  May 13 16:16:00.637: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 05/13/24 16:16:00.637
  May 13 16:16:00.639: INFO: Observed Service test-service-sw8df in namespace services-6088 with annotations: map[] & Conditions: {[]}
  May 13 16:16:00.639: INFO: Observed event: &Service{ObjectMeta:{test-service-sw8df  services-6088  1845d7f5-a859-4718-b7f1-0a93fc27d8a6 38978 0 2024-05-13 16:16:00 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2024-05-13 16:16:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:allocateLoadBalancerNodePorts":{},"f:externalTrafficPolicy":{},"f:internalTrafficPolicy":{},"f:loadBalancerClass":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2024-05-13 16:16:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:31553,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.43.163.37,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.43.163.37],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:*example.com/internal-vip,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,IPMode:nil,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  May 13 16:16:00.639: INFO: Found Service test-service-sw8df in namespace services-6088 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  May 13 16:16:00.639: INFO: Service test-service-sw8df has service status updated
  STEP: patching the service @ 05/13/24 16:16:00.639
  STEP: watching for the Service to be patched @ 05/13/24 16:16:00.653
  May 13 16:16:00.656: INFO: observed Service test-service-sw8df in namespace services-6088 with labels: map[test-service-static:true]
  May 13 16:16:00.657: INFO: observed Service test-service-sw8df in namespace services-6088 with labels: map[test-service-static:true]
  May 13 16:16:00.657: INFO: observed Service test-service-sw8df in namespace services-6088 with labels: map[test-service-static:true]
  May 13 16:16:00.657: INFO: Found Service test-service-sw8df in namespace services-6088 with labels: map[test-service:patched test-service-static:true]
  May 13 16:16:00.657: INFO: Service test-service-sw8df patched
  STEP: deleting the service @ 05/13/24 16:16:00.657
  STEP: watching for the Service to be deleted @ 05/13/24 16:16:00.677
  May 13 16:16:00.678: INFO: Observed event: ADDED
  May 13 16:16:00.678: INFO: Observed event: MODIFIED
  May 13 16:16:00.678: INFO: Observed event: MODIFIED
  May 13 16:16:00.678: INFO: Observed event: MODIFIED
  May 13 16:16:00.678: INFO: Found Service test-service-sw8df in namespace services-6088 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  May 13 16:16:00.679: INFO: Service test-service-sw8df deleted
  May 13 16:16:00.679: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6088" for this suite. @ 05/13/24 16:16:00.681
• [0.125 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:69
  STEP: Creating a kubernetes client @ 05/13/24 16:16:00.694
  May 13 16:16:00.694: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename endpointslice @ 05/13/24 16:16:00.695
  E0513 16:16:00.699384      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:16:00.704
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:16:00.795
  May 13 16:16:00.819: INFO: Endpoints addresses: [172.16.100.4] , ports: [6443]
  May 13 16:16:00.819: INFO: EndpointSlices addresses: [172.16.100.4] , ports: [6443]
  May 13 16:16:00.820: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-4743" for this suite. @ 05/13/24 16:16:00.823
• [0.139 seconds]
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 05/13/24 16:16:00.838
  May 13 16:16:00.838: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename pods @ 05/13/24 16:16:00.839
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:16:00.851
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:16:00.858
  STEP: creating pod @ 05/13/24 16:16:00.86
  E0513 16:16:01.699988      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:02.700103      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:16:02.874: INFO: Pod pod-hostip-9d6a07fd-68f0-413c-8806-b8c753109248 has hostIP: 172.16.100.7
  May 13 16:16:02.875: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-606" for this suite. @ 05/13/24 16:16:02.877
• [2.048 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:237
  STEP: Creating a kubernetes client @ 05/13/24 16:16:02.881
  May 13 16:16:02.881: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename downward-api @ 05/13/24 16:16:02.882
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:16:02.892
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:16:02.894
  STEP: Creating a pod to test downward API volume plugin @ 05/13/24 16:16:02.895
  E0513 16:16:03.700239      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:04.700549      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:05.700567      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:06.700805      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:16:06.91
  May 13 16:16:06.913: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod downwardapi-volume-61e8d795-2bee-4b8f-a767-c01c39bb69ac container client-container: <nil>
  STEP: delete the pod @ 05/13/24 16:16:06.919
  May 13 16:16:06.935: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5774" for this suite. @ 05/13/24 16:16:06.94
• [4.066 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:514
  STEP: Creating a kubernetes client @ 05/13/24 16:16:06.948
  May 13 16:16:06.948: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename apf @ 05/13/24 16:16:06.949
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:16:06.961
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:16:06.963
  STEP: getting /apis @ 05/13/24 16:16:06.965
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 05/13/24 16:16:06.97
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 05/13/24 16:16:06.971
  STEP: creating @ 05/13/24 16:16:06.971
  STEP: getting @ 05/13/24 16:16:06.983
  STEP: listing @ 05/13/24 16:16:06.984
  STEP: watching @ 05/13/24 16:16:06.986
  May 13 16:16:06.986: INFO: starting watch
  STEP: patching @ 05/13/24 16:16:06.987
  STEP: updating @ 05/13/24 16:16:06.99
  May 13 16:16:06.993: INFO: waiting for watch events with expected annotations
  STEP: getting /status @ 05/13/24 16:16:06.993
  STEP: patching /status @ 05/13/24 16:16:06.994
  STEP: updating /status @ 05/13/24 16:16:06.997
  STEP: deleting @ 05/13/24 16:16:07.001
  STEP: deleting a collection @ 05/13/24 16:16:07.006
  May 13 16:16:07.012: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-6497" for this suite. @ 05/13/24 16:16:07.015
• [0.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:330
  STEP: Creating a kubernetes client @ 05/13/24 16:16:07.02
  May 13 16:16:07.020: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename resourcequota @ 05/13/24 16:16:07.021
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:16:07.031
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:16:07.033
  E0513 16:16:07.700827      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:08.701164      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:09.702172      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:10.702328      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:11.702647      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:12.703404      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:13.704411      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:14.704905      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:15.705387      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:16.705741      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:17.706894      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:18.707215      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:19.708199      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:20.708256      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:21.708555      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:22.708891      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:23.709899      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 05/13/24 16:16:24.042
  E0513 16:16:24.710573      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:25.711551      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:26.716516      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:27.716625      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:28.717290      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/13/24 16:16:29.044
  STEP: Ensuring resource quota status is calculated @ 05/13/24 16:16:29.047
  E0513 16:16:29.717273      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:30.717422      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 05/13/24 16:16:31.051
  STEP: Ensuring resource quota status captures configMap creation @ 05/13/24 16:16:31.065
  E0513 16:16:31.717808      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:32.717792      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 05/13/24 16:16:33.067
  STEP: Ensuring resource quota status released usage @ 05/13/24 16:16:33.071
  E0513 16:16:33.717866      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:34.718278      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:16:35.073: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3042" for this suite. @ 05/13/24 16:16:35.076
• [28.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 05/13/24 16:16:35.08
  May 13 16:16:35.080: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename sched-preemption @ 05/13/24 16:16:35.081
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:16:35.093
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:16:35.095
  May 13 16:16:35.103: INFO: Waiting up to 1m0s for all nodes to be ready
  E0513 16:16:35.718896      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:36.719108      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:37.719589      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:38.719721      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:39.720752      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:40.721633      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:41.721706      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:42.721833      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:43.721966      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:44.722308      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:45.722541      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:46.722861      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:47.723033      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:48.723335      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:49.724466      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:50.724415      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:51.724622      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:52.724964      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:53.725902      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:54.726086      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:55.726289      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:56.726659      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:57.726943      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:58.726952      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:16:59.727989      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:00.728750      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:01.729067      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:02.729449      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:03.729813      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:04.730597      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:05.730811      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:06.731433      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:07.732099      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:08.732595      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:09.733257      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:10.733877      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:11.734034      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:12.734284      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:13.734710      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:14.735417      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:15.736251      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:16.736444      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:17.737050      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:18.737436      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:19.737807      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:20.738793      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:21.739253      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:22.739639      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:23.741458      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:24.742424      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:25.742819      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:26.743227      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:27.743536      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:28.743579      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:29.744225      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:30.744384      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:31.744699      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:32.744937      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:33.744943      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:34.745423      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:17:35.106: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 05/13/24 16:17:35.108
  May 13 16:17:35.108: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename sched-preemption-path @ 05/13/24 16:17:35.108
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:17:35.118
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:17:35.121
  STEP: Finding an available node @ 05/13/24 16:17:35.122
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 05/13/24 16:17:35.122
  E0513 16:17:35.746223      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:36.747365      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 05/13/24 16:17:37.146
  May 13 16:17:37.165: INFO: found a healthy node: oneke-ip-172-16-100-7
  E0513 16:17:37.748128      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:38.748482      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:39.749106      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:40.749465      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:41.749876      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:42.750354      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:17:43.241: INFO: pods created so far: [1 1 1]
  May 13 16:17:43.241: INFO: length of pods created so far: 3
  E0513 16:17:43.751166      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:44.751405      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:17:45.248: INFO: pods created so far: [2 2 1]
  E0513 16:17:45.751621      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:46.752037      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:47.752117      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:48.752225      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:49.752617      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:50.753155      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:51.753426      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:17:52.297: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-8828" for this suite. @ 05/13/24 16:17:52.299
  May 13 16:17:52.304: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-7827" for this suite. @ 05/13/24 16:17:52.306
• [77.229 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 05/13/24 16:17:52.31
  May 13 16:17:52.310: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename daemonsets @ 05/13/24 16:17:52.311
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:17:52.32
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:17:52.322
  May 13 16:17:52.332: INFO: Create a RollingUpdate DaemonSet
  May 13 16:17:52.334: INFO: Check that daemon pods launch on every node of the cluster
  May 13 16:17:52.337: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:17:52.337: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 16:17:52.339: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 16:17:52.339: INFO: Node oneke-ip-172-16-100-5 is running 0 daemon pod, expected 1
  E0513 16:17:52.753542      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:17:53.337: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:17:53.337: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 16:17:53.338: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 16:17:53.338: INFO: Node oneke-ip-172-16-100-5 is running 0 daemon pod, expected 1
  E0513 16:17:53.754613      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:17:54.338: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:17:54.338: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 16:17:54.340: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May 13 16:17:54.340: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  May 13 16:17:54.340: INFO: Update the DaemonSet to trigger a rollout
  May 13 16:17:54.344: INFO: Updating DaemonSet daemon-set
  E0513 16:17:54.755303      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:17:55.755830      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:17:56.349: INFO: Roll back the DaemonSet before rollout is complete
  May 13 16:17:56.353: INFO: Updating DaemonSet daemon-set
  May 13 16:17:56.353: INFO: Make sure DaemonSet rollback is complete
  May 13 16:17:56.358: INFO: Wrong image for pod: daemon-set-hqgb6. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  May 13 16:17:56.358: INFO: Pod daemon-set-hqgb6 is not available
  May 13 16:17:56.360: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:17:56.361: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0513 16:17:56.755966      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:17:57.360: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:17:57.360: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0513 16:17:57.757473      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:17:58.367: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:17:58.367: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0513 16:17:58.758645      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:17:59.355: INFO: Pod daemon-set-dc6nh is not available
  May 13 16:17:59.357: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:17:59.357: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Deleting DaemonSet "daemon-set" @ 05/13/24 16:17:59.359
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4236, will wait for the garbage collector to delete the pods @ 05/13/24 16:17:59.36
  May 13 16:17:59.414: INFO: Deleting DaemonSet.extensions daemon-set took: 2.860731ms
  May 13 16:17:59.516: INFO: Terminating DaemonSet.extensions daemon-set pods took: 102.023356ms
  E0513 16:17:59.759225      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:00.759700      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:18:01.719: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 16:18:01.720: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  May 13 16:18:01.721: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"39951"},"items":null}

  May 13 16:18:01.722: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"39951"},"items":null}

  May 13 16:18:01.729: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4236" for this suite. @ 05/13/24 16:18:01.731
• [9.426 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 05/13/24 16:18:01.739
  May 13 16:18:01.739: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename cronjob @ 05/13/24 16:18:01.74
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:18:01.75
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:18:01.753
  STEP: Creating a cronjob @ 05/13/24 16:18:01.755
  STEP: Ensuring more than one job is running at a time @ 05/13/24 16:18:01.757
  E0513 16:18:01.760113      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:02.760316      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:03.761167      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:04.761455      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:05.763009      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:06.762662      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:07.763199      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:08.763672      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:09.764661      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:10.765128      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:11.766560      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:12.766766      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:13.766708      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:14.767811      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:15.768758      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:16.769189      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:17.770095      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:18.771017      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:19.771957      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:20.772074      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:21.772915      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:22.773350      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:23.773853      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:24.774438      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:25.775401      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:26.775602      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:27.775791      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:28.777120      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:29.777708      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:30.778408      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:31.779158      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:32.786129      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:33.787204      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:34.787447      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:35.787875      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:36.788167      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:37.789085      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:38.789937      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:39.790536      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:40.791028      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:41.792128      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:42.792108      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:43.793383      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:44.793816      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:45.794605      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:46.794999      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:47.795647      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:48.796041      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:49.805600      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:50.799909      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:51.800902      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:52.800783      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:53.801898      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:54.802196      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:55.803010      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:56.803807      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:57.804595      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:58.805080      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:18:59.805697      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:00.805741      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:01.805936      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:02.806575      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:03.808035      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:04.809209      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:05.810192      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:06.810453      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:07.811282      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:08.812037      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:09.817736      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:10.818202      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:11.819241      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:12.819566      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:13.820675      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:14.820914      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:15.821392      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:16.821399      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:17.823235      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:18.822790      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:19.823202      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:20.824296      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:21.824940      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:22.824968      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:23.825154      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:24.825352      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:25.826127      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:26.826549      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:27.827217      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:28.827565      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:29.829261      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:30.829850      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:31.830045      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:32.830011      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:33.830289      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:34.830691      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:35.831241      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:36.831657      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:37.832388      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:38.832416      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:39.833271      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:40.833375      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:41.833806      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:42.833645      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:43.833944      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:44.834154      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:45.834298      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:46.834746      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:47.835009      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:48.835894      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:49.836735      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:50.837742      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:51.837749      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:52.837836      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:53.838827      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:54.839898      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:55.840267      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:56.840907      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:57.841575      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:58.841630      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:19:59.842065      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:00.842593      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 05/13/24 16:20:01.759
  STEP: Removing cronjob @ 05/13/24 16:20:01.761
  May 13 16:20:01.764: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-8331" for this suite. @ 05/13/24 16:20:01.771
• [120.038 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:48
  STEP: Creating a kubernetes client @ 05/13/24 16:20:01.779
  May 13 16:20:01.779: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 16:20:01.781
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:20:01.806
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:20:01.81
  STEP: Creating configMap with name projected-configmap-test-volume-f28cba65-58da-433b-9b01-6475b198b27f @ 05/13/24 16:20:01.812
  STEP: Creating a pod to test consume configMaps @ 05/13/24 16:20:01.815
  E0513 16:20:01.844892      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:02.845004      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:03.845663      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:04.848115      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:20:05.827
  May 13 16:20:05.829: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-projected-configmaps-df1a7ee0-9490-401b-9572-d6a4ff52f191 container agnhost-container: <nil>
  STEP: delete the pod @ 05/13/24 16:20:05.837
  E0513 16:20:05.849023      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:20:05.878: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4315" for this suite. @ 05/13/24 16:20:05.881
• [4.110 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 05/13/24 16:20:05.892
  May 13 16:20:05.892: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename deployment @ 05/13/24 16:20:05.895
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:20:05.915
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:20:05.917
  May 13 16:20:05.945: INFO: Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/13/24 16:20:05.945
  E0513 16:20:06.849396      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:07.849673      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:20:07.974: INFO: Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 05/13/24 16:20:07.99
  E0513 16:20:08.850106      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:09.850144      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:20:10.011: INFO: Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5768",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b670a147-cf88-410c-94b1-703d278336c0",
      ResourceVersion: (string) (len=5) "40683",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851214007,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214007,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214009,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214008,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214008,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214009,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214008,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=76) "ReplicaSet \"test-cleanup-deployment-7bc75bbdf6\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  May 13 16:20:10.029: INFO: New ReplicaSet "test-cleanup-deployment-7bc75bbdf6" of Deployment "test-cleanup-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-cleanup-deployment-7bc75bbdf6",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5768",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2ba0c4a2-8b41-450f-b589-a07d9559701a",
      ResourceVersion: (string) (len=5) "40673",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851214008,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7bc75bbdf6"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "b670a147-cf88-410c-94b1-703d278336c0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214008,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 62 36 37 30 61 31  34 37 2d 63 66 38 38 2d  |\"b670a147-cf88-|
              00000120  34 31 30 63 2d 39 34 62  31 2d 37 30 33 64 32 37  |410c-94b1-703d27|
              00000130  38 33 33 36 63 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |8336c0\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214009,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "7bc75bbdf6"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "7bc75bbdf6"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 13 16:20:10.033: INFO: Pod "test-cleanup-deployment-7bc75bbdf6-gv929" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-cleanup-deployment-7bc75bbdf6-gv929",
      GenerateName: (string) (len=35) "test-cleanup-deployment-7bc75bbdf6-",
      Namespace: (string) (len=15) "deployment-5768",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c050f179-5c61-4993-9a71-4c890910c65f",
      ResourceVersion: (string) (len=5) "40672",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851214008,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7bc75bbdf6"
      },
      Annotations: (map[string]string) (len=4) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "c546bc89f02b29c3db69678d0e8779af607b988415738b8fc65de24bb96a38bb",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=13) "10.42.3.12/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=13) "10.42.3.12/32",
        (string) (len=33) "k8s.v1.cni.cncf.io/network-status": (string) (len=112) "[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.3.12\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-cleanup-deployment-7bc75bbdf6",
          UID: (types.UID) (len=36) "2ba0c4a2-8b41-450f-b589-a07d9559701a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=4) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214008,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214008,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 62  61 30 63 34 61 32 2d 38  |d\":\"2ba0c4a2-8|
              00000090  62 34 31 2d 34 35 30 66  2d 62 35 38 39 2d 61 30  |b41-450f-b589-a0|
              000000a0  37 64 39 35 35 39 37 30  31 61 5c 22 7d 22 3a 7b  |7d9559701a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "multus",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214008,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=75) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 6b 38 73 2e 76  31 2e 63 6e 69 2e 63 6e  |"f:k8s.v1.cni.cn|
              00000030  63 66 2e 69 6f 2f 6e 65  74 77 6f 72 6b 2d 73 74  |cf.io/network-st|
              00000040  61 74 75 73 22 3a 7b 7d  7d 7d 7d                 |atus":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214009,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=659) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 34 32 2e 33 2e 31 32  5c 22 7d 22 3a 7b 22 2e  |.42.3.12\"}":{".|
              00000270  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              00000280  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              00000290  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-66fp6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-66fp6",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214009,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214008,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214009,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214009,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214008,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.7",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.7"
        }
      },
      PodIP: (string) (len=10) "10.42.3.12",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.42.3.12"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851214008,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851214008,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253",
          ContainerID: (string) (len=77) "containerd://83882741b238b3feecdbeeecacc0024a72e18e0d2c56fa34ccd45e3a0c81beb9",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 16:20:10.045: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5768" for this suite. @ 05/13/24 16:20:10.047
• [4.159 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 05/13/24 16:20:10.052
  May 13 16:20:10.053: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename watch @ 05/13/24 16:20:10.053
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:20:10.063
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:20:10.065
  STEP: creating a new configmap @ 05/13/24 16:20:10.067
  STEP: modifying the configmap once @ 05/13/24 16:20:10.069
  STEP: modifying the configmap a second time @ 05/13/24 16:20:10.073
  STEP: deleting the configmap @ 05/13/24 16:20:10.077
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 05/13/24 16:20:10.079
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 05/13/24 16:20:10.08
  May 13 16:20:10.080: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-126  57536dab-f75c-4689-a29f-e231d3a061e8 40693 0 2024-05-13 16:20:10 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-05-13 16:20:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 13 16:20:10.081: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-126  57536dab-f75c-4689-a29f-e231d3a061e8 40694 0 2024-05-13 16:20:10 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-05-13 16:20:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 13 16:20:10.081: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-126" for this suite. @ 05/13/24 16:20:10.083
• [0.034 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 05/13/24 16:20:10.088
  May 13 16:20:10.088: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename watch @ 05/13/24 16:20:10.089
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:20:10.098
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:20:10.1
  STEP: creating a watch on configmaps with a certain label @ 05/13/24 16:20:10.102
  STEP: creating a new configmap @ 05/13/24 16:20:10.102
  STEP: modifying the configmap once @ 05/13/24 16:20:10.105
  STEP: changing the label value of the configmap @ 05/13/24 16:20:10.108
  STEP: Expecting to observe a delete notification for the watched object @ 05/13/24 16:20:10.111
  May 13 16:20:10.111: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9238  22c209c4-1b3d-4907-98e3-c1f10277a012 40699 0 2024-05-13 16:20:10 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-13 16:20:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  May 13 16:20:10.112: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9238  22c209c4-1b3d-4907-98e3-c1f10277a012 40700 0 2024-05-13 16:20:10 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-13 16:20:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 13 16:20:10.112: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9238  22c209c4-1b3d-4907-98e3-c1f10277a012 40701 0 2024-05-13 16:20:10 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-13 16:20:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 05/13/24 16:20:10.112
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 05/13/24 16:20:10.115
  E0513 16:20:10.852820      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:11.851369      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:12.851630      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:13.852295      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:14.852679      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:15.852978      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:16.853116      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:17.853980      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:18.854630      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:19.854847      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 05/13/24 16:20:20.116
  STEP: modifying the configmap a third time @ 05/13/24 16:20:20.121
  STEP: deleting the configmap @ 05/13/24 16:20:20.126
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 05/13/24 16:20:20.13
  May 13 16:20:20.131: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9238  22c209c4-1b3d-4907-98e3-c1f10277a012 40782 0 2024-05-13 16:20:10 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-13 16:20:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 13 16:20:20.132: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9238  22c209c4-1b3d-4907-98e3-c1f10277a012 40783 0 2024-05-13 16:20:10 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-13 16:20:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 13 16:20:20.133: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9238  22c209c4-1b3d-4907-98e3-c1f10277a012 40784 0 2024-05-13 16:20:10 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-13 16:20:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 13 16:20:20.134: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-9238" for this suite. @ 05/13/24 16:20:20.138
• [10.056 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 05/13/24 16:20:20.148
  May 13 16:20:20.148: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 05/13/24 16:20:20.149
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:20:20.209
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:20:20.214
  STEP: creating a target pod @ 05/13/24 16:20:20.216
  E0513 16:20:20.854856      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:21.855612      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 05/13/24 16:20:22.239
  E0513 16:20:22.856476      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:23.856779      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:24.856945      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:25.857422      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 05/13/24 16:20:26.263
  May 13 16:20:26.264: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-2665 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 16:20:26.264: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 16:20:26.266: INFO: ExecWithOptions: Clientset creation
  May 13 16:20:26.267: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/ephemeral-containers-test-2665/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  May 13 16:20:26.361: INFO: Exec stderr: ""
  May 13 16:20:26.367: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-2665" for this suite. @ 05/13/24 16:20:26.369
• [6.226 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:332
  STEP: Creating a kubernetes client @ 05/13/24 16:20:26.374
  May 13 16:20:26.374: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename webhook @ 05/13/24 16:20:26.375
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:20:26.383
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:20:26.385
  STEP: Setting up server cert @ 05/13/24 16:20:26.401
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/13/24 16:20:26.702
  STEP: Deploying the webhook pod @ 05/13/24 16:20:26.704
  STEP: Wait for the deployment to be ready @ 05/13/24 16:20:26.714
  May 13 16:20:26.719: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0513 16:20:26.857376      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:27.857462      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/13/24 16:20:28.724
  STEP: Verifying the service has paired with the endpoint @ 05/13/24 16:20:28.732
  E0513 16:20:28.858348      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:20:29.733: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  May 13 16:20:29.746: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 16:20:29.859161      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4095-crds.webhook.example.com via the AdmissionRegistration API @ 05/13/24 16:20:30.267
  STEP: Creating a custom resource that should be mutated by the webhook @ 05/13/24 16:20:30.278
  E0513 16:20:30.861197      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:31.860533      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:32.861466      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:20:32.862: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-863" for this suite. @ 05/13/24 16:20:32.865
  STEP: Destroying namespace "webhook-markers-8619" for this suite. @ 05/13/24 16:20:32.868
• [6.501 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:274
  STEP: Creating a kubernetes client @ 05/13/24 16:20:32.876
  May 13 16:20:32.876: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename namespaces @ 05/13/24 16:20:32.877
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:20:32.888
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:20:32.89
  STEP: creating a Namespace @ 05/13/24 16:20:32.891
  STEP: patching the Namespace @ 05/13/24 16:20:32.901
  STEP: get the Namespace and ensuring it has the label @ 05/13/24 16:20:32.906
  May 13 16:20:32.909: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1084" for this suite. @ 05/13/24 16:20:32.911
  STEP: Destroying namespace "nspatchtest-551e801b-3ae9-4755-9b7e-8673518cd919-673" for this suite. @ 05/13/24 16:20:32.914
• [0.043 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:611
  STEP: Creating a kubernetes client @ 05/13/24 16:20:32.922
  May 13 16:20:32.922: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename security-context-test @ 05/13/24 16:20:32.923
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:20:32.932
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:20:32.935
  E0513 16:20:33.861964      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:34.862587      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:35.862639      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:36.863215      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:20:36.964: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-7240" for this suite. @ 05/13/24 16:20:36.97
• [4.056 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 05/13/24 16:20:36.979
  May 13 16:20:36.979: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename init-container @ 05/13/24 16:20:36.981
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:20:36.999
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:20:37.001
  STEP: creating the pod @ 05/13/24 16:20:37.004
  May 13 16:20:37.004: INFO: PodSpec: initContainers in spec.initContainers
  E0513 16:20:37.863698      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:38.863808      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:39.865404      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:20:40.122: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-1417" for this suite. @ 05/13/24 16:20:40.125
• [3.150 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:276
  STEP: Creating a kubernetes client @ 05/13/24 16:20:40.13
  May 13 16:20:40.130: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/13/24 16:20:40.13
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:20:40.142
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:20:40.143
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 05/13/24 16:20:40.144
  May 13 16:20:40.144: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 16:20:40.866302      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:20:41.539: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 16:20:41.866864      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:42.866601      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:43.868468      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:44.868608      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:45.870710      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:46.870589      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:20:47.034: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3526" for this suite. @ 05/13/24 16:20:47.038
• [6.911 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:403
  STEP: Creating a kubernetes client @ 05/13/24 16:20:47.042
  May 13 16:20:47.042: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename webhook @ 05/13/24 16:20:47.043
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:20:47.053
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:20:47.054
  STEP: Setting up server cert @ 05/13/24 16:20:47.069
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/13/24 16:20:47.288
  STEP: Deploying the webhook pod @ 05/13/24 16:20:47.292
  STEP: Wait for the deployment to be ready @ 05/13/24 16:20:47.301
  May 13 16:20:47.326: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 16, 20, 47, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 16, 20, 47, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-7c55c7d74c\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 13, 16, 20, 47, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 16, 20, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
  E0513 16:20:47.871365      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:48.872179      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/13/24 16:20:49.333
  STEP: Verifying the service has paired with the endpoint @ 05/13/24 16:20:49.353
  E0513 16:20:49.872447      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:20:50.353: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 05/13/24 16:20:50.358
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/13/24 16:20:50.374
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 05/13/24 16:20:50.382
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/13/24 16:20:50.387
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 05/13/24 16:20:50.393
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/13/24 16:20:50.4
  May 13 16:20:50.450: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4234" for this suite. @ 05/13/24 16:20:50.453
  STEP: Destroying namespace "webhook-markers-2476" for this suite. @ 05/13/24 16:20:50.456
• [3.421 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:69
  STEP: Creating a kubernetes client @ 05/13/24 16:20:50.464
  May 13 16:20:50.465: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/13/24 16:20:50.467
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:20:50.478
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:20:50.482
  May 13 16:20:50.484: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 16:20:50.873451      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 05/13/24 16:20:51.786
  May 13 16:20:51.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-5463 --namespace=crd-publish-openapi-5463 create -f -'
  E0513 16:20:51.873299      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:52.874602      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:53.876364      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:20:53.878: INFO: stderr: ""
  May 13 16:20:53.878: INFO: stdout: "e2e-test-crd-publish-openapi-7855-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  May 13 16:20:53.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-5463 --namespace=crd-publish-openapi-5463 delete e2e-test-crd-publish-openapi-7855-crds test-foo'
  May 13 16:20:53.937: INFO: stderr: ""
  May 13 16:20:53.937: INFO: stdout: "e2e-test-crd-publish-openapi-7855-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  May 13 16:20:53.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-5463 --namespace=crd-publish-openapi-5463 apply -f -'
  May 13 16:20:53.986: INFO: stderr: ""
  May 13 16:20:53.986: INFO: stdout: "e2e-test-crd-publish-openapi-7855-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  May 13 16:20:53.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-5463 --namespace=crd-publish-openapi-5463 delete e2e-test-crd-publish-openapi-7855-crds test-foo'
  May 13 16:20:54.041: INFO: stderr: ""
  May 13 16:20:54.041: INFO: stdout: "e2e-test-crd-publish-openapi-7855-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 05/13/24 16:20:54.041
  May 13 16:20:54.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-5463 --namespace=crd-publish-openapi-5463 create -f -'
  May 13 16:20:54.086: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 05/13/24 16:20:54.086
  May 13 16:20:54.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-5463 --namespace=crd-publish-openapi-5463 create -f -'
  May 13 16:20:54.134: INFO: rc: 1
  May 13 16:20:54.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-5463 --namespace=crd-publish-openapi-5463 apply -f -'
  May 13 16:20:54.184: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 05/13/24 16:20:54.184
  May 13 16:20:54.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-5463 --namespace=crd-publish-openapi-5463 create -f -'
  May 13 16:20:54.231: INFO: rc: 1
  May 13 16:20:54.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-5463 --namespace=crd-publish-openapi-5463 apply -f -'
  May 13 16:20:54.279: INFO: rc: 1
  STEP: kubectl explain works to explain CR properties @ 05/13/24 16:20:54.279
  May 13 16:20:54.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-5463 explain e2e-test-crd-publish-openapi-7855-crds'
  May 13 16:20:54.329: INFO: stderr: ""
  May 13 16:20:54.329: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-7855-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 05/13/24 16:20:54.33
  May 13 16:20:54.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-5463 explain e2e-test-crd-publish-openapi-7855-crds.metadata'
  May 13 16:20:54.374: INFO: stderr: ""
  May 13 16:20:54.374: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-7855-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  May 13 16:20:54.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-5463 explain e2e-test-crd-publish-openapi-7855-crds.spec'
  May 13 16:20:54.426: INFO: stderr: ""
  May 13 16:20:54.426: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-7855-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  May 13 16:20:54.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-5463 explain e2e-test-crd-publish-openapi-7855-crds.spec.bars'
  May 13 16:20:54.505: INFO: stderr: ""
  May 13 16:20:54.505: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-7855-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 05/13/24 16:20:54.505
  May 13 16:20:54.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-5463 explain e2e-test-crd-publish-openapi-7855-crds.spec.bars2'
  May 13 16:20:54.621: INFO: rc: 1
  E0513 16:20:54.877222      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:55.891861      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:20:55.929: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5463" for this suite. @ 05/13/24 16:20:55.932
• [5.471 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:132
  STEP: Creating a kubernetes client @ 05/13/24 16:20:55.936
  May 13 16:20:55.936: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename downward-api @ 05/13/24 16:20:55.937
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:20:55.947
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:20:55.948
  STEP: Creating the pod @ 05/13/24 16:20:55.95
  E0513 16:20:56.893620      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:57.893729      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:20:58.514: INFO: Successfully updated pod "labelsupdatea37a9e25-8e0e-4894-9946-298e4731d2b2"
  E0513 16:20:58.894908      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:20:59.896135      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:00.896391      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:01.896997      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:21:02.539: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6353" for this suite. @ 05/13/24 16:21:02.553
• [6.624 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 05/13/24 16:21:02.563
  May 13 16:21:02.563: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename pod-network-test @ 05/13/24 16:21:02.564
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:21:02.577
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:21:02.579
  STEP: Performing setup for networking test in namespace pod-network-test-2234 @ 05/13/24 16:21:02.581
  STEP: creating a selector @ 05/13/24 16:21:02.581
  STEP: Creating the service pods in kubernetes @ 05/13/24 16:21:02.581
  May 13 16:21:02.581: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0513 16:21:02.896789      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:03.898252      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:04.898230      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:05.898325      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:06.898936      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:07.902955      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:08.901703      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:09.901862      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:10.902721      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:11.903415      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:12.903730      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:13.904963      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:14.905853      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:15.906614      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:16.906724      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:17.907670      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:18.909083      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:19.909969      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:20.910056      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:21.910276      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:22.911216      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:23.911341      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 05/13/24 16:21:24.674
  E0513 16:21:24.912096      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:25.914609      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:21:26.697: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  May 13 16:21:26.697: INFO: Breadth first check of 10.42.1.32 on host 172.16.100.5...
  May 13 16:21:26.702: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.3.17:9080/dial?request=hostname&protocol=http&host=10.42.1.32&port=8083&tries=1'] Namespace:pod-network-test-2234 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 16:21:26.703: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 16:21:26.704: INFO: ExecWithOptions: Clientset creation
  May 13 16:21:26.704: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-2234/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.3.17%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.42.1.32%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  May 13 16:21:26.770: INFO: Waiting for responses: map[]
  May 13 16:21:26.770: INFO: reached 10.42.1.32 after 0/1 tries
  May 13 16:21:26.770: INFO: Breadth first check of 10.42.3.16 on host 172.16.100.7...
  May 13 16:21:26.771: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.3.17:9080/dial?request=hostname&protocol=http&host=10.42.3.16&port=8083&tries=1'] Namespace:pod-network-test-2234 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 16:21:26.771: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 16:21:26.772: INFO: ExecWithOptions: Clientset creation
  May 13 16:21:26.772: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-2234/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.3.17%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.42.3.16%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  May 13 16:21:26.828: INFO: Waiting for responses: map[]
  May 13 16:21:26.828: INFO: reached 10.42.3.16 after 0/1 tries
  May 13 16:21:26.828: INFO: Going to retry 0 out of 2 pods....
  May 13 16:21:26.829: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-2234" for this suite. @ 05/13/24 16:21:26.831
• [24.273 seconds]
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:469
  STEP: Creating a kubernetes client @ 05/13/24 16:21:26.836
  May 13 16:21:26.837: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename sched-pred @ 05/13/24 16:21:26.837
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:21:26.848
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:21:26.849
  May 13 16:21:26.851: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  May 13 16:21:26.855: INFO: Waiting for terminating namespaces to be deleted...
  May 13 16:21:26.856: INFO: 
  Logging pods the apiserver thinks is on node oneke-ip-172-16-100-5 before test
  May 13 16:21:26.863: INFO: kube-proxy-oneke-ip-172-16-100-5 from kube-system started at 2024-05-13 15:01:47 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.864: INFO: 	Container kube-proxy ready: true, restart count 0
  May 13 16:21:26.864: INFO: rke2-canal-clmwk from kube-system started at 2024-05-13 15:01:49 +0000 UTC (2 container statuses recorded)
  May 13 16:21:26.864: INFO: 	Container calico-node ready: true, restart count 0
  May 13 16:21:26.864: INFO: 	Container kube-flannel ready: true, restart count 0
  May 13 16:21:26.864: INFO: rke2-multus-lqh56 from kube-system started at 2024-05-13 15:01:48 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.865: INFO: 	Container kube-rke2-multus ready: true, restart count 0
  May 13 16:21:26.865: INFO: rke2-multus-rke2-whereabouts-vdcd7 from kube-system started at 2024-05-13 16:02:22 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.865: INFO: 	Container rke2-whereabouts ready: true, restart count 0
  May 13 16:21:26.865: INFO: engine-image-ei-5cefaf2b-vfc6s from longhorn-system started at 2024-05-13 16:02:23 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.865: INFO: 	Container engine-image-ei-5cefaf2b ready: true, restart count 0
  May 13 16:21:26.865: INFO: instance-manager-55ef780465ba1d7a0e8ce28cb186ca26 from longhorn-system started at 2024-05-13 16:01:57 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.866: INFO: 	Container instance-manager ready: true, restart count 0
  May 13 16:21:26.866: INFO: longhorn-csi-plugin-tb722 from longhorn-system started at 2024-05-13 16:01:54 +0000 UTC (3 container statuses recorded)
  May 13 16:21:26.866: INFO: 	Container longhorn-csi-plugin ready: true, restart count 0
  May 13 16:21:26.866: INFO: 	Container longhorn-liveness-probe ready: true, restart count 0
  May 13 16:21:26.866: INFO: 	Container node-driver-registrar ready: true, restart count 0
  May 13 16:21:26.867: INFO: longhorn-manager-lh6mb from longhorn-system started at 2024-05-13 16:01:53 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.867: INFO: 	Container longhorn-manager ready: true, restart count 0
  May 13 16:21:26.867: INFO: one-metallb-speaker-8tc2q from metallb-system started at 2024-05-13 16:01:52 +0000 UTC (4 container statuses recorded)
  May 13 16:21:26.867: INFO: 	Container frr ready: true, restart count 0
  May 13 16:21:26.867: INFO: 	Container frr-metrics ready: true, restart count 0
  May 13 16:21:26.867: INFO: 	Container reloader ready: true, restart count 0
  May 13 16:21:26.868: INFO: 	Container speaker ready: true, restart count 0
  May 13 16:21:26.868: INFO: netserver-0 from pod-network-test-2234 started at 2024-05-13 16:21:02 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.868: INFO: 	Container webserver ready: true, restart count 0
  May 13 16:21:26.868: INFO: sonobuoy from sonobuoy started at 2024-05-13 15:21:42 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.868: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  May 13 16:21:26.868: INFO: sonobuoy-systemd-logs-daemon-set-6a4de22bea6049d2-97q5l from sonobuoy started at 2024-05-13 15:21:45 +0000 UTC (2 container statuses recorded)
  May 13 16:21:26.869: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 13 16:21:26.869: INFO: 	Container systemd-logs ready: true, restart count 0
  May 13 16:21:26.869: INFO: one-traefik-795c67dd65-zptl9 from traefik-system started at 2024-05-13 16:01:53 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.869: INFO: 	Container one-traefik ready: true, restart count 0
  May 13 16:21:26.869: INFO: 
  Logging pods the apiserver thinks is on node oneke-ip-172-16-100-7 before test
  May 13 16:21:26.883: INFO: kube-proxy-oneke-ip-172-16-100-7 from kube-system started at 2024-05-13 15:11:56 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container kube-proxy ready: true, restart count 0
  May 13 16:21:26.883: INFO: rke2-canal-2xv8f from kube-system started at 2024-05-13 15:11:57 +0000 UTC (2 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container calico-node ready: true, restart count 0
  May 13 16:21:26.883: INFO: 	Container kube-flannel ready: true, restart count 0
  May 13 16:21:26.883: INFO: rke2-coredns-rke2-coredns-5b7d84d764-x58ng from kube-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container coredns ready: true, restart count 0
  May 13 16:21:26.883: INFO: rke2-coredns-rke2-coredns-autoscaler-b49765765-9rbrr from kube-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container autoscaler ready: true, restart count 0
  May 13 16:21:26.883: INFO: rke2-metrics-server-655477f655-cnt8z from kube-system started at 2024-05-13 15:25:23 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container metrics-server ready: true, restart count 0
  May 13 16:21:26.883: INFO: rke2-multus-rke2-whereabouts-q2xbr from kube-system started at 2024-05-13 15:11:57 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container rke2-whereabouts ready: true, restart count 1
  May 13 16:21:26.883: INFO: rke2-multus-txzvb from kube-system started at 2024-05-13 15:11:57 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container kube-rke2-multus ready: true, restart count 2
  May 13 16:21:26.883: INFO: rke2-snapshot-controller-59cc9cd8f4-pk92s from kube-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container rke2-snapshot-controller ready: true, restart count 0
  May 13 16:21:26.883: INFO: rke2-snapshot-validation-webhook-54c5989b65-l9mj7 from kube-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container rke2-snapshot-validation-webhook ready: true, restart count 0
  May 13 16:21:26.883: INFO: csi-attacher-5468df46f9-mnkf6 from longhorn-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container csi-attacher ready: true, restart count 0
  May 13 16:21:26.883: INFO: csi-provisioner-76d7d4cb9-zl6gj from longhorn-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container csi-provisioner ready: true, restart count 0
  May 13 16:21:26.883: INFO: csi-resizer-7b5d5bd7cd-n9tjz from longhorn-system started at 2024-05-13 15:25:23 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container csi-resizer ready: true, restart count 0
  May 13 16:21:26.883: INFO: csi-snapshotter-6d8678cd76-dpskt from longhorn-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May 13 16:21:26.883: INFO: engine-image-ei-5cefaf2b-9j4sf from longhorn-system started at 2024-05-13 15:12:12 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container engine-image-ei-5cefaf2b ready: true, restart count 0
  May 13 16:21:26.883: INFO: instance-manager-1185f042d485c71dda675ea2338775ca from longhorn-system started at 2024-05-13 15:12:37 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container instance-manager ready: true, restart count 0
  May 13 16:21:26.883: INFO: longhorn-csi-plugin-wmfzz from longhorn-system started at 2024-05-13 15:12:12 +0000 UTC (3 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container longhorn-csi-plugin ready: true, restart count 0
  May 13 16:21:26.883: INFO: 	Container longhorn-liveness-probe ready: true, restart count 0
  May 13 16:21:26.883: INFO: 	Container node-driver-registrar ready: true, restart count 0
  May 13 16:21:26.883: INFO: longhorn-manager-42nnc from longhorn-system started at 2024-05-13 15:12:12 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container longhorn-manager ready: true, restart count 0
  May 13 16:21:26.883: INFO: one-metallb-controller-5dbfcc4788-79tmz from metallb-system started at 2024-05-13 15:25:23 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container controller ready: true, restart count 0
  May 13 16:21:26.883: INFO: one-metallb-speaker-mt7mb from metallb-system started at 2024-05-13 15:12:12 +0000 UTC (4 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container frr ready: true, restart count 0
  May 13 16:21:26.883: INFO: 	Container frr-metrics ready: true, restart count 0
  May 13 16:21:26.883: INFO: 	Container reloader ready: true, restart count 0
  May 13 16:21:26.883: INFO: 	Container speaker ready: true, restart count 0
  May 13 16:21:26.883: INFO: netserver-1 from pod-network-test-2234 started at 2024-05-13 16:21:02 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container webserver ready: true, restart count 0
  May 13 16:21:26.883: INFO: test-container-pod from pod-network-test-2234 started at 2024-05-13 16:21:24 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.883: INFO: 	Container webserver ready: true, restart count 0
  May 13 16:21:26.884: INFO: sonobuoy-systemd-logs-daemon-set-6a4de22bea6049d2-dx4h8 from sonobuoy started at 2024-05-13 15:21:45 +0000 UTC (2 container statuses recorded)
  May 13 16:21:26.884: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 13 16:21:26.884: INFO: 	Container systemd-logs ready: true, restart count 0
  May 13 16:21:26.884: INFO: one-traefik-795c67dd65-k9k5j from traefik-system started at 2024-05-13 15:12:14 +0000 UTC (1 container statuses recorded)
  May 13 16:21:26.884: INFO: 	Container one-traefik ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 05/13/24 16:21:26.884
  E0513 16:21:26.915081      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:27.915305      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 05/13/24 16:21:28.903
  STEP: Trying to apply a random label on the found node. @ 05/13/24 16:21:28.913
  E0513 16:21:28.916202      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the node has the label kubernetes.io/e2e-59375a35-8193-4573-a607-dab6f9a385c3 42 @ 05/13/24 16:21:28.927
  STEP: Trying to relaunch the pod, now with labels. @ 05/13/24 16:21:28.929
  E0513 16:21:29.917933      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:30.917401      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-59375a35-8193-4573-a607-dab6f9a385c3 off the node oneke-ip-172-16-100-7 @ 05/13/24 16:21:30.946
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-59375a35-8193-4573-a607-dab6f9a385c3 @ 05/13/24 16:21:30.963
  May 13 16:21:30.965: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-2893" for this suite. @ 05/13/24 16:21:30.969
• [4.137 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:176
  STEP: Creating a kubernetes client @ 05/13/24 16:21:30.974
  May 13 16:21:30.974: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename configmap @ 05/13/24 16:21:30.975
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:21:30.991
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:21:30.993
  STEP: Creating configMap with name configmap-test-upd-b407c767-bb6f-4e42-b26f-80d8acb8e408 @ 05/13/24 16:21:30.997
  STEP: Creating the pod @ 05/13/24 16:21:30.999
  E0513 16:21:31.918166      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:32.923897      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 05/13/24 16:21:33.007
  STEP: Waiting for pod with binary data @ 05/13/24 16:21:33.011
  May 13 16:21:33.014: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1127" for this suite. @ 05/13/24 16:21:33.017
• [2.047 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:100
  STEP: Creating a kubernetes client @ 05/13/24 16:21:33.022
  May 13 16:21:33.022: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename configmap @ 05/13/24 16:21:33.023
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:21:33.034
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:21:33.035
  STEP: Creating configMap with name configmap-test-volume-map-3c65c660-345e-4e21-8a09-db228368537d @ 05/13/24 16:21:33.037
  STEP: Creating a pod to test consume configMaps @ 05/13/24 16:21:33.039
  E0513 16:21:33.923809      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:34.923897      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:35.924160      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:36.924258      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:21:37.06
  May 13 16:21:37.064: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-configmaps-4179db6f-97a7-4d6a-b13c-ad1d36e23262 container agnhost-container: <nil>
  STEP: delete the pod @ 05/13/24 16:21:37.071
  May 13 16:21:37.099: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5088" for this suite. @ 05/13/24 16:21:37.108
• [4.091 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 05/13/24 16:21:37.114
  May 13 16:21:37.114: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 16:21:37.115
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:21:37.13
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:21:37.134
  STEP: Creating projection with secret that has name projected-secret-test-map-d577fd31-5d4a-404a-932b-6097eca96703 @ 05/13/24 16:21:37.139
  STEP: Creating a pod to test consume secrets @ 05/13/24 16:21:37.142
  E0513 16:21:37.924375      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:38.924633      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:39.924921      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:40.925374      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:21:41.166
  May 13 16:21:41.171: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-projected-secrets-044234db-88f2-4354-a2c7-581323ff031c container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/13/24 16:21:41.191
  May 13 16:21:41.210: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8119" for this suite. @ 05/13/24 16:21:41.214
• [4.103 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:622
  STEP: Creating a kubernetes client @ 05/13/24 16:21:41.218
  May 13 16:21:41.218: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename field-validation @ 05/13/24 16:21:41.219
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:21:41.279
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:21:41.282
  May 13 16:21:41.284: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 16:21:41.926111      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:42.926343      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0513 16:21:43.832705      17 warnings.go:70] unknown field "alpha"
  W0513 16:21:43.832739      17 warnings.go:70] unknown field "beta"
  W0513 16:21:43.832992      17 warnings.go:70] unknown field "delta"
  W0513 16:21:43.833015      17 warnings.go:70] unknown field "epsilon"
  W0513 16:21:43.833365      17 warnings.go:70] unknown field "gamma"
  E0513 16:21:43.942593      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:21:44.368: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8434" for this suite. @ 05/13/24 16:21:44.373
• [3.161 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:195
  STEP: Creating a kubernetes client @ 05/13/24 16:21:44.38
  May 13 16:21:44.380: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename downward-api @ 05/13/24 16:21:44.381
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:21:44.395
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:21:44.396
  STEP: Creating a pod to test downward API volume plugin @ 05/13/24 16:21:44.398
  E0513 16:21:44.943418      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:45.948604      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:46.944202      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:47.944581      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:21:48.419
  May 13 16:21:48.421: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod downwardapi-volume-00eac4c9-fc55-4a2e-99ea-3662b99e9314 container client-container: <nil>
  STEP: delete the pod @ 05/13/24 16:21:48.424
  May 13 16:21:48.433: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5979" for this suite. @ 05/13/24 16:21:48.436
• [4.059 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1863
  STEP: Creating a kubernetes client @ 05/13/24 16:21:48.44
  May 13 16:21:48.440: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubectl @ 05/13/24 16:21:48.441
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:21:48.45
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:21:48.452
  STEP: Starting the proxy @ 05/13/24 16:21:48.454
  May 13 16:21:48.454: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-8539 proxy --unix-socket=/tmp/kubectl-proxy-unix3002461173/test'
  STEP: retrieving proxy /api/ output @ 05/13/24 16:21:48.489
  May 13 16:21:48.489: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8539" for this suite. @ 05/13/24 16:21:48.492
• [0.055 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 05/13/24 16:21:48.497
  May 13 16:21:48.497: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename field-validation @ 05/13/24 16:21:48.497
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:21:48.507
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:21:48.508
  STEP: apply creating a deployment @ 05/13/24 16:21:48.51
  May 13 16:21:48.515: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7772" for this suite. @ 05/13/24 16:21:48.517
• [0.024 seconds]
------------------------------
SSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:147
  STEP: Creating a kubernetes client @ 05/13/24 16:21:48.521
  May 13 16:21:48.521: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubelet-test @ 05/13/24 16:21:48.522
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:21:48.533
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:21:48.537
  STEP: Waiting for pod completion @ 05/13/24 16:21:48.544
  E0513 16:21:48.945062      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:49.945270      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:50.946304      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:51.947159      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:21:52.582: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-1793" for this suite. @ 05/13/24 16:21:52.599
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:707
  STEP: Creating a kubernetes client @ 05/13/24 16:21:52.609
  May 13 16:21:52.609: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename sched-pred @ 05/13/24 16:21:52.61
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:21:52.621
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:21:52.623
  May 13 16:21:52.624: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  May 13 16:21:52.628: INFO: Waiting for terminating namespaces to be deleted...
  May 13 16:21:52.629: INFO: 
  Logging pods the apiserver thinks is on node oneke-ip-172-16-100-5 before test
  May 13 16:21:52.636: INFO: kube-proxy-oneke-ip-172-16-100-5 from kube-system started at 2024-05-13 15:01:47 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.636: INFO: 	Container kube-proxy ready: true, restart count 0
  May 13 16:21:52.636: INFO: rke2-canal-clmwk from kube-system started at 2024-05-13 15:01:49 +0000 UTC (2 container statuses recorded)
  May 13 16:21:52.636: INFO: 	Container calico-node ready: true, restart count 0
  May 13 16:21:52.636: INFO: 	Container kube-flannel ready: true, restart count 0
  May 13 16:21:52.637: INFO: rke2-multus-lqh56 from kube-system started at 2024-05-13 15:01:48 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.637: INFO: 	Container kube-rke2-multus ready: true, restart count 0
  May 13 16:21:52.637: INFO: rke2-multus-rke2-whereabouts-vdcd7 from kube-system started at 2024-05-13 16:02:22 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.637: INFO: 	Container rke2-whereabouts ready: true, restart count 0
  May 13 16:21:52.637: INFO: engine-image-ei-5cefaf2b-vfc6s from longhorn-system started at 2024-05-13 16:02:23 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.637: INFO: 	Container engine-image-ei-5cefaf2b ready: true, restart count 0
  May 13 16:21:52.637: INFO: instance-manager-55ef780465ba1d7a0e8ce28cb186ca26 from longhorn-system started at 2024-05-13 16:01:57 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.637: INFO: 	Container instance-manager ready: true, restart count 0
  May 13 16:21:52.637: INFO: longhorn-csi-plugin-tb722 from longhorn-system started at 2024-05-13 16:01:54 +0000 UTC (3 container statuses recorded)
  May 13 16:21:52.638: INFO: 	Container longhorn-csi-plugin ready: true, restart count 0
  May 13 16:21:52.638: INFO: 	Container longhorn-liveness-probe ready: true, restart count 0
  May 13 16:21:52.638: INFO: 	Container node-driver-registrar ready: true, restart count 0
  May 13 16:21:52.638: INFO: longhorn-manager-lh6mb from longhorn-system started at 2024-05-13 16:01:53 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.638: INFO: 	Container longhorn-manager ready: true, restart count 0
  May 13 16:21:52.638: INFO: one-metallb-speaker-8tc2q from metallb-system started at 2024-05-13 16:01:52 +0000 UTC (4 container statuses recorded)
  May 13 16:21:52.638: INFO: 	Container frr ready: true, restart count 0
  May 13 16:21:52.638: INFO: 	Container frr-metrics ready: true, restart count 0
  May 13 16:21:52.638: INFO: 	Container reloader ready: true, restart count 0
  May 13 16:21:52.638: INFO: 	Container speaker ready: true, restart count 0
  May 13 16:21:52.639: INFO: sonobuoy from sonobuoy started at 2024-05-13 15:21:42 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.639: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  May 13 16:21:52.639: INFO: sonobuoy-systemd-logs-daemon-set-6a4de22bea6049d2-97q5l from sonobuoy started at 2024-05-13 15:21:45 +0000 UTC (2 container statuses recorded)
  May 13 16:21:52.639: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 13 16:21:52.639: INFO: 	Container systemd-logs ready: true, restart count 0
  May 13 16:21:52.639: INFO: one-traefik-795c67dd65-zptl9 from traefik-system started at 2024-05-13 16:01:53 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.639: INFO: 	Container one-traefik ready: true, restart count 0
  May 13 16:21:52.639: INFO: 
  Logging pods the apiserver thinks is on node oneke-ip-172-16-100-7 before test
  May 13 16:21:52.648: INFO: kube-proxy-oneke-ip-172-16-100-7 from kube-system started at 2024-05-13 15:11:56 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.649: INFO: 	Container kube-proxy ready: true, restart count 0
  May 13 16:21:52.649: INFO: rke2-canal-2xv8f from kube-system started at 2024-05-13 15:11:57 +0000 UTC (2 container statuses recorded)
  May 13 16:21:52.649: INFO: 	Container calico-node ready: true, restart count 0
  May 13 16:21:52.649: INFO: 	Container kube-flannel ready: true, restart count 0
  May 13 16:21:52.649: INFO: rke2-coredns-rke2-coredns-5b7d84d764-x58ng from kube-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.649: INFO: 	Container coredns ready: true, restart count 0
  May 13 16:21:52.649: INFO: rke2-coredns-rke2-coredns-autoscaler-b49765765-9rbrr from kube-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.650: INFO: 	Container autoscaler ready: true, restart count 0
  May 13 16:21:52.650: INFO: rke2-metrics-server-655477f655-cnt8z from kube-system started at 2024-05-13 15:25:23 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.650: INFO: 	Container metrics-server ready: true, restart count 0
  May 13 16:21:52.650: INFO: rke2-multus-rke2-whereabouts-q2xbr from kube-system started at 2024-05-13 15:11:57 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.650: INFO: 	Container rke2-whereabouts ready: true, restart count 1
  May 13 16:21:52.650: INFO: rke2-multus-txzvb from kube-system started at 2024-05-13 15:11:57 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.650: INFO: 	Container kube-rke2-multus ready: true, restart count 2
  May 13 16:21:52.651: INFO: rke2-snapshot-controller-59cc9cd8f4-pk92s from kube-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.651: INFO: 	Container rke2-snapshot-controller ready: true, restart count 0
  May 13 16:21:52.651: INFO: rke2-snapshot-validation-webhook-54c5989b65-l9mj7 from kube-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.651: INFO: 	Container rke2-snapshot-validation-webhook ready: true, restart count 0
  May 13 16:21:52.651: INFO: agnhost-host-aliases524a93ca-6d0a-4753-b282-ed72f5611d81 from kubelet-test-1793 started at 2024-05-13 16:21:48 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.651: INFO: 	Container agnhost-container ready: false, restart count 0
  May 13 16:21:52.651: INFO: csi-attacher-5468df46f9-mnkf6 from longhorn-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.651: INFO: 	Container csi-attacher ready: true, restart count 0
  May 13 16:21:52.651: INFO: csi-provisioner-76d7d4cb9-zl6gj from longhorn-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.651: INFO: 	Container csi-provisioner ready: true, restart count 0
  May 13 16:21:52.652: INFO: csi-resizer-7b5d5bd7cd-n9tjz from longhorn-system started at 2024-05-13 15:25:23 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.652: INFO: 	Container csi-resizer ready: true, restart count 0
  May 13 16:21:52.652: INFO: csi-snapshotter-6d8678cd76-dpskt from longhorn-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.652: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May 13 16:21:52.652: INFO: engine-image-ei-5cefaf2b-9j4sf from longhorn-system started at 2024-05-13 15:12:12 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.652: INFO: 	Container engine-image-ei-5cefaf2b ready: true, restart count 0
  May 13 16:21:52.652: INFO: instance-manager-1185f042d485c71dda675ea2338775ca from longhorn-system started at 2024-05-13 15:12:37 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.652: INFO: 	Container instance-manager ready: true, restart count 0
  May 13 16:21:52.653: INFO: longhorn-csi-plugin-wmfzz from longhorn-system started at 2024-05-13 15:12:12 +0000 UTC (3 container statuses recorded)
  May 13 16:21:52.653: INFO: 	Container longhorn-csi-plugin ready: true, restart count 0
  May 13 16:21:52.653: INFO: 	Container longhorn-liveness-probe ready: true, restart count 0
  May 13 16:21:52.653: INFO: 	Container node-driver-registrar ready: true, restart count 0
  May 13 16:21:52.653: INFO: longhorn-manager-42nnc from longhorn-system started at 2024-05-13 15:12:12 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.653: INFO: 	Container longhorn-manager ready: true, restart count 0
  May 13 16:21:52.653: INFO: one-metallb-controller-5dbfcc4788-79tmz from metallb-system started at 2024-05-13 15:25:23 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.653: INFO: 	Container controller ready: true, restart count 0
  May 13 16:21:52.653: INFO: one-metallb-speaker-mt7mb from metallb-system started at 2024-05-13 15:12:12 +0000 UTC (4 container statuses recorded)
  May 13 16:21:52.653: INFO: 	Container frr ready: true, restart count 0
  May 13 16:21:52.653: INFO: 	Container frr-metrics ready: true, restart count 0
  May 13 16:21:52.653: INFO: 	Container reloader ready: true, restart count 0
  May 13 16:21:52.653: INFO: 	Container speaker ready: true, restart count 0
  May 13 16:21:52.653: INFO: sonobuoy-systemd-logs-daemon-set-6a4de22bea6049d2-dx4h8 from sonobuoy started at 2024-05-13 15:21:45 +0000 UTC (2 container statuses recorded)
  May 13 16:21:52.654: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 13 16:21:52.654: INFO: 	Container systemd-logs ready: true, restart count 0
  May 13 16:21:52.654: INFO: one-traefik-795c67dd65-k9k5j from traefik-system started at 2024-05-13 15:12:14 +0000 UTC (1 container statuses recorded)
  May 13 16:21:52.654: INFO: 	Container one-traefik ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 05/13/24 16:21:52.654
  E0513 16:21:52.947185      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:53.947269      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 05/13/24 16:21:54.67
  STEP: Trying to apply a random label on the found node. @ 05/13/24 16:21:54.685
  STEP: verifying the node has the label kubernetes.io/e2e-97e1c259-1032-450f-914c-d1eff4063ebb 95 @ 05/13/24 16:21:54.692
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 05/13/24 16:21:54.701
  E0513 16:21:54.948136      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:55.948489      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.16.100.7 on the node which pod4 resides and expect not scheduled @ 05/13/24 16:21:56.715
  E0513 16:21:56.949418      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:57.949949      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:58.950428      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:21:59.951688      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:00.952408      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:01.952499      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:02.952684      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:03.952938      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:04.953089      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:05.953186      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:06.954084      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:07.954091      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:08.955217      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:09.955394      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:10.955466      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:11.955881      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:12.956577      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:13.957300      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:14.957836      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:15.958368      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:16.959185      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:17.959581      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:18.960195      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:19.961386      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:20.961708      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:21.962975      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:22.963153      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:23.964151      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:24.964377      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:25.965376      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:26.966247      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:27.966835      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:28.966471      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:29.967464      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:30.968189      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:31.968717      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:32.969501      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:33.970216      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:34.971784      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:35.971968      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:36.973043      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:37.973158      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:38.973905      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:39.974127      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:40.974377      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:41.975357      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:42.976021      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:43.976043      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:44.976729      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:45.977520      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:46.978175      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:47.978299      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:48.979074      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:49.980046      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:50.980232      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:51.980631      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:52.982997      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:53.983288      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:54.984502      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:55.984998      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:56.985814      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:57.986885      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:58.986898      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:22:59.987429      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:00.988301      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:01.988735      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:02.988802      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:03.988949      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:04.989792      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:05.990036      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:06.990087      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:07.990188      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:08.990884      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:09.991096      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:10.991253      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:11.991615      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:12.991614      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:13.991779      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:14.992157      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:15.992219      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:16.992268      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:17.992418      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:18.992905      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:19.993527      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:20.993697      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:21.993922      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:22.994506      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:23.995054      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:24.995569      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:25.995658      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:26.996507      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:27.996290      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:28.996877      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:29.998052      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:30.998761      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:31.999449      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:32.999707      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:34.000479      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:35.002042      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:36.001822      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:37.002038      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:38.002090      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:39.002570      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:40.003449      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:41.003819      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:42.003996      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:43.004666      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:44.005235      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:45.005289      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:46.005510      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:47.006636      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:48.006732      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:49.007828      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:50.008738      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:51.009376      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:52.009833      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:53.009898      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:54.010555      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:55.011682      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:56.011784      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:57.012840      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:58.013130      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:23:59.013774      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:00.014361      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:01.015178      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:02.016123      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:03.016317      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:04.017068      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:05.017562      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:06.018708      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:07.018815      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:08.018867      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:09.019581      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:10.020174      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:11.022740      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:12.023003      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:13.023017      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:14.023971      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:15.024090      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:16.024214      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:17.024675      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:18.024796      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:19.025211      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:20.025932      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:21.026013      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:22.026096      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:23.026302      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:24.026540      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:25.026931      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:26.027066      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:27.027783      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:28.028402      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:29.028609      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:30.029946      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:31.030845      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:32.031546      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:33.031759      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:34.032991      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:35.033521      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:36.034944      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:37.035652      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:38.036200      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:39.036647      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:40.037505      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:41.037714      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:42.038079      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:43.038494      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:44.039821      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:45.040550      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:46.041452      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:47.041570      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:48.041726      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:49.042069      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:50.043894      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:51.043482      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:52.043528      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:53.043628      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:54.044384      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:55.044487      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:56.044711      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:57.044618      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:58.044758      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:24:59.045168      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:00.045306      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:01.045946      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:02.046713      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:03.046828      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:04.047059      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:05.047236      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:06.047751      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:07.049315      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:08.049370      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:09.050554      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:10.052043      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:11.051682      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:12.052440      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:13.052292      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:14.053163      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:15.053838      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:16.054586      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:17.055429      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:18.054873      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:19.055977      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:20.056677      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:21.057229      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:22.057595      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:23.057705      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:24.058095      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:25.059092      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:26.060321      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:27.060505      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:28.060342      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:29.061434      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:30.062220      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:31.062661      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:32.062733      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:33.063701      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:34.064267      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:35.065088      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:36.065973      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:37.066237      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:38.066685      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:39.067364      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:40.068178      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:41.069179      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:42.068799      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:43.068841      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:44.069617      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:45.070345      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:46.070705      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:47.071212      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:48.071168      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:49.072510      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:50.072435      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:51.072882      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:52.072985      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:53.073042      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:54.073653      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:55.073780      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:56.074130      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:57.074451      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:58.075223      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:25:59.076527      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:00.077712      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:01.077725      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:02.078368      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:03.079329      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:04.079986      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:05.080927      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:06.081369      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:07.081613      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:08.081754      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:09.082668      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:10.083535      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:11.083818      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:12.083944      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:13.083987      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:14.085098      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:15.086542      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:16.087010      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:17.087020      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:18.087927      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:19.088124      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:20.088221      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:21.088550      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:22.089141      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:23.090565      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:24.090968      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:25.091745      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:26.092770      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:27.093175      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:28.094444      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:29.094694      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:30.095135      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:31.095957      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:32.096486      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:33.097075      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:34.097177      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:35.098215      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:36.098764      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:37.099039      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:38.100355      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:39.100903      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:40.101343      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:41.101816      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:42.102814      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:43.102798      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:44.103498      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:45.104544      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:46.105391      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:47.105720      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:48.108474      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:49.106365      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:50.107400      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:51.107778      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:52.108323      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:53.108788      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:54.108683      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:55.109561      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:56.110319      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-97e1c259-1032-450f-914c-d1eff4063ebb off the node oneke-ip-172-16-100-7 @ 05/13/24 16:26:56.727
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-97e1c259-1032-450f-914c-d1eff4063ebb @ 05/13/24 16:26:56.741
  May 13 16:26:56.744: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-1409" for this suite. @ 05/13/24 16:26:56.748
• [304.141 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:1031
  STEP: Creating a kubernetes client @ 05/13/24 16:26:56.756
  May 13 16:26:56.756: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename statefulset @ 05/13/24 16:26:56.757
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:26:56.772
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:26:56.774
  STEP: Creating service test in namespace statefulset-4696 @ 05/13/24 16:26:56.776
  STEP: Creating statefulset ss in namespace statefulset-4696 @ 05/13/24 16:26:56.786
  May 13 16:26:56.791: INFO: Found 0 stateful pods, waiting for 1
  E0513 16:26:57.112386      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:58.112396      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:26:59.112571      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:00.112747      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:01.114035      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:02.114992      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:03.115211      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:04.116447      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:05.116419      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:06.116995      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:27:06.790: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 05/13/24 16:27:06.792
  STEP: Getting /status @ 05/13/24 16:27:06.796
  May 13 16:27:06.797: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 05/13/24 16:27:06.797
  May 13 16:27:06.803: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 05/13/24 16:27:06.804
  May 13 16:27:06.805: INFO: Observed &StatefulSet event: ADDED
  May 13 16:27:06.805: INFO: Found Statefulset ss in namespace statefulset-4696 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  May 13 16:27:06.805: INFO: Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 05/13/24 16:27:06.805
  May 13 16:27:06.805: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  May 13 16:27:06.809: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 05/13/24 16:27:06.81
  May 13 16:27:06.811: INFO: Observed &StatefulSet event: ADDED
  May 13 16:27:06.811: INFO: Observed Statefulset ss in namespace statefulset-4696 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  May 13 16:27:06.811: INFO: Observed &StatefulSet event: MODIFIED
  May 13 16:27:06.811: INFO: Deleting all statefulset in ns statefulset-4696
  May 13 16:27:06.812: INFO: Scaling statefulset ss to 0
  E0513 16:27:07.117184      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:08.117234      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:09.117319      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:10.117679      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:11.117703      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:12.118304      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:13.118167      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:14.119567      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:15.120255      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:16.120432      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:27:16.824: INFO: Waiting for statefulset status.replicas updated to 0
  May 13 16:27:16.831: INFO: Deleting statefulset ss
  May 13 16:27:16.846: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4696" for this suite. @ 05/13/24 16:27:16.85
• [20.099 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:161
  STEP: Creating a kubernetes client @ 05/13/24 16:27:16.856
  May 13 16:27:16.856: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename cronjob @ 05/13/24 16:27:16.857
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:27:16.868
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:27:16.87
  STEP: Creating a ReplaceConcurrent cronjob @ 05/13/24 16:27:16.871
  STEP: Ensuring a job is scheduled @ 05/13/24 16:27:16.874
  E0513 16:27:17.124458      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:18.124094      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:19.124978      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:20.125531      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:21.126776      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:22.126698      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:23.127834      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:24.128503      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:25.128292      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:26.128297      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:27.128350      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:28.128473      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:29.129218      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:30.130907      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:31.131452      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:32.132068      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:33.133159      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:34.134099      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:35.135098      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:36.135146      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:37.136450      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:38.136464      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:39.136828      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:40.136907      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:41.137534      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:42.137652      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:43.138017      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:44.138861      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:45.140133      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:46.140285      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:47.140605      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:48.140834      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:49.140995      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:50.141533      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:51.141837      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:52.142500      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:53.142943      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:54.144068      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:55.144449      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:56.145760      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:57.145720      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:58.146305      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:27:59.146212      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:00.146553      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 05/13/24 16:28:00.876
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 05/13/24 16:28:00.88
  STEP: Ensuring the job is replaced with a new one @ 05/13/24 16:28:00.881
  E0513 16:28:01.146641      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:02.147329      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:03.148221      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:04.148886      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:05.149994      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:06.150638      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:07.150669      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:08.151893      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:09.152294      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:10.153533      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:11.153411      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:12.153473      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:13.154166      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:14.154668      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:15.155452      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:16.155841      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:17.156544      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:18.157538      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:19.158844      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:20.159714      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:21.160318      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:22.160520      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:23.161188      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:24.162172      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:25.162243      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:26.162726      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:27.163907      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:28.164563      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:29.164932      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:30.165113      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:31.165444      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:32.165842      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:33.166174      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:34.167013      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:35.167615      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:36.168013      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:37.168233      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:38.168715      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:39.169178      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:40.169991      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:41.170202      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:42.170337      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:43.171365      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:44.171735      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:45.172254      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:46.172533      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:47.173084      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:48.174037      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:49.174847      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:50.175161      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:51.176501      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:52.177304      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:53.177000      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:54.178070      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:55.178568      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:56.178977      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:57.179244      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:58.179120      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:28:59.179846      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:00.180004      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 05/13/24 16:29:00.887
  May 13 16:29:00.896: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-2692" for this suite. @ 05/13/24 16:29:00.915
• [104.071 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 05/13/24 16:29:00.927
  May 13 16:29:00.927: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 16:29:00.932
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:29:00.945
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:29:00.947
  STEP: Creating projection with secret that has name projected-secret-test-aa0b9218-7eed-401d-a436-7cc6af252ee4 @ 05/13/24 16:29:00.949
  STEP: Creating a pod to test consume secrets @ 05/13/24 16:29:00.952
  E0513 16:29:01.181424      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:02.181517      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:03.182112      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:04.182235      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:29:04.971
  May 13 16:29:04.975: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-projected-secrets-1041ea31-e661-4a45-aed5-5a388fb59c40 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/13/24 16:29:04.992
  May 13 16:29:05.008: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3066" for this suite. @ 05/13/24 16:29:05.011
• [4.087 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:123
  STEP: Creating a kubernetes client @ 05/13/24 16:29:05.015
  May 13 16:29:05.015: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename podtemplate @ 05/13/24 16:29:05.015
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:29:05.025
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:29:05.026
  STEP: Create set of pod templates @ 05/13/24 16:29:05.028
  May 13 16:29:05.030: INFO: created test-podtemplate-1
  May 13 16:29:05.032: INFO: created test-podtemplate-2
  May 13 16:29:05.034: INFO: created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 05/13/24 16:29:05.034
  STEP: delete collection of pod templates @ 05/13/24 16:29:05.035
  May 13 16:29:05.035: INFO: requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 05/13/24 16:29:05.042
  May 13 16:29:05.042: INFO: requesting list of pod templates to confirm quantity
  May 13 16:29:05.043: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-415" for this suite. @ 05/13/24 16:29:05.045
• [0.034 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:209
  STEP: Creating a kubernetes client @ 05/13/24 16:29:05.049
  May 13 16:29:05.049: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 16:29:05.05
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:29:05.109
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:29:05.111
  STEP: Creating a pod to test downward API volume plugin @ 05/13/24 16:29:05.112
  E0513 16:29:05.182871      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:06.182979      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:07.184092      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:08.184504      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:29:09.136
  May 13 16:29:09.138: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod downwardapi-volume-e687d410-9caa-4aa4-9ff0-60cc28c01e74 container client-container: <nil>
  STEP: delete the pod @ 05/13/24 16:29:09.143
  May 13 16:29:09.155: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1411" for this suite. @ 05/13/24 16:29:09.159
• [4.115 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:646
  STEP: Creating a kubernetes client @ 05/13/24 16:29:09.166
  May 13 16:29:09.166: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename webhook @ 05/13/24 16:29:09.167
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:29:09.177
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:29:09.178
  E0513 16:29:09.184756      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Setting up server cert @ 05/13/24 16:29:09.193
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/13/24 16:29:09.454
  STEP: Deploying the webhook pod @ 05/13/24 16:29:09.462
  STEP: Wait for the deployment to be ready @ 05/13/24 16:29:09.474
  May 13 16:29:09.508: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 16, 29, 9, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 16, 29, 9, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-7c55c7d74c\""}}, CollisionCount:(*int32)(nil)}
  E0513 16:29:10.185651      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:11.186371      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/13/24 16:29:11.512
  STEP: Verifying the service has paired with the endpoint @ 05/13/24 16:29:11.519
  E0513 16:29:12.186684      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:29:12.519: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 05/13/24 16:29:12.573
  STEP: Creating a configMap that should be mutated @ 05/13/24 16:29:12.582
  STEP: Deleting the collection of validation webhooks @ 05/13/24 16:29:12.602
  STEP: Creating a configMap that should not be mutated @ 05/13/24 16:29:12.705
  May 13 16:29:12.752: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6011" for this suite. @ 05/13/24 16:29:12.756
  STEP: Destroying namespace "webhook-markers-7594" for this suite. @ 05/13/24 16:29:12.762
• [3.599 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:253
  STEP: Creating a kubernetes client @ 05/13/24 16:29:12.769
  May 13 16:29:12.769: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename limitrange @ 05/13/24 16:29:12.77
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:29:12.785
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:29:12.787
  STEP: Creating LimitRange "e2e-limitrange-4fl24" in namespace "limitrange-4720" @ 05/13/24 16:29:12.788
  STEP: Creating another limitRange in another namespace @ 05/13/24 16:29:12.791
  May 13 16:29:12.800: INFO: Namespace "e2e-limitrange-4fl24-579" created
  May 13 16:29:12.801: INFO: Creating LimitRange "e2e-limitrange-4fl24" in namespace "e2e-limitrange-4fl24-579"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-4fl24" @ 05/13/24 16:29:12.803
  May 13 16:29:12.805: INFO: Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-4fl24" in "limitrange-4720" namespace @ 05/13/24 16:29:12.805
  May 13 16:29:12.809: INFO: LimitRange "e2e-limitrange-4fl24" has been patched
  STEP: Delete LimitRange "e2e-limitrange-4fl24" by Collection with labelSelector: "e2e-limitrange-4fl24=patched" @ 05/13/24 16:29:12.81
  STEP: Confirm that the limitRange "e2e-limitrange-4fl24" has been deleted @ 05/13/24 16:29:12.812
  May 13 16:29:12.813: INFO: Requesting list of LimitRange to confirm quantity
  May 13 16:29:12.814: INFO: Found 0 LimitRange with label "e2e-limitrange-4fl24=patched"
  May 13 16:29:12.814: INFO: LimitRange "e2e-limitrange-4fl24" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-4fl24" @ 05/13/24 16:29:12.814
  May 13 16:29:12.815: INFO: Found 1 limitRange
  May 13 16:29:12.816: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-4720" for this suite. @ 05/13/24 16:29:12.818
  STEP: Destroying namespace "e2e-limitrange-4fl24-579" for this suite. @ 05/13/24 16:29:12.821
• [0.057 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:453
  STEP: Creating a kubernetes client @ 05/13/24 16:29:12.826
  May 13 16:29:12.826: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename resourcequota @ 05/13/24 16:29:12.827
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:29:12.837
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:29:12.838
  STEP: Counting existing ResourceQuota @ 05/13/24 16:29:12.84
  E0513 16:29:13.186858      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:14.187598      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:15.188483      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:16.188485      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:17.188535      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/13/24 16:29:17.845
  STEP: Ensuring resource quota status is calculated @ 05/13/24 16:29:17.856
  E0513 16:29:18.188703      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:19.188761      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicaSet @ 05/13/24 16:29:19.858
  STEP: Ensuring resource quota status captures replicaset creation @ 05/13/24 16:29:19.866
  E0513 16:29:20.189644      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:21.189751      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicaSet @ 05/13/24 16:29:21.876
  STEP: Ensuring resource quota status released usage @ 05/13/24 16:29:21.882
  E0513 16:29:22.190018      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:23.190721      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:29:23.890: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4616" for this suite. @ 05/13/24 16:29:23.893
• [11.070 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 05/13/24 16:29:23.897
  May 13 16:29:23.897: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename deployment @ 05/13/24 16:29:23.898
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:29:23.91
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:29:23.912
  May 13 16:29:23.918: INFO: Pod name rollover-pod: Found 0 pods out of 1
  E0513 16:29:24.190885      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:25.191789      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:26.191667      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:27.192195      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:28.192126      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:29:28.921: INFO: Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/13/24 16:29:28.922
  May 13 16:29:28.926: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E0513 16:29:29.192414      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:30.193539      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:29:30.929: INFO: Creating deployment "test-rollover-deployment"
  May 13 16:29:30.936: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
  E0513 16:29:31.193708      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:32.193959      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:29:32.942: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
  May 13 16:29:32.944: INFO: Ensure that both replica sets have 1 created replica
  May 13 16:29:32.947: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  May 13 16:29:32.953: INFO: Updating deployment test-rollover-deployment
  May 13 16:29:32.953: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E0513 16:29:33.194482      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:34.194641      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:29:34.958: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
  May 13 16:29:34.964: INFO: Make sure deployment "test-rollover-deployment" is complete
  May 13 16:29:34.968: INFO: all replica sets need to contain the pod-template-hash label
  May 13 16:29:34.968: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 16, 29, 30, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 16, 29, 30, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 16, 29, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 16, 29, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0513 16:29:35.195121      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:36.195678      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:29:36.988: INFO: all replica sets need to contain the pod-template-hash label
  May 13 16:29:36.991: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 16, 29, 30, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 16, 29, 30, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 16, 29, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 16, 29, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0513 16:29:37.196068      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:38.196011      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:29:38.972: INFO: all replica sets need to contain the pod-template-hash label
  May 13 16:29:38.972: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 16, 29, 30, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 16, 29, 30, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 16, 29, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 16, 29, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0513 16:29:39.196856      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:40.197417      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:29:40.985: INFO: all replica sets need to contain the pod-template-hash label
  May 13 16:29:40.987: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 16, 29, 30, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 16, 29, 30, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 16, 29, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 16, 29, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0513 16:29:41.197906      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:42.198683      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:29:42.973: INFO: all replica sets need to contain the pod-template-hash label
  May 13 16:29:42.973: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 16, 29, 30, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 16, 29, 30, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 16, 29, 33, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 16, 29, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0513 16:29:43.199461      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:44.199701      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:29:44.973: INFO: 
  May 13 16:29:44.973: INFO: Ensure that both old replica sets have no replicas
  May 13 16:29:44.978: INFO: Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6764",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1a770b03-aa43-4939-b1a0-50832a29bba0",
      ResourceVersion: (string) (len=5) "44403",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851214570,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214572,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214570,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214570,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214570,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-68774655d5\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  May 13 16:29:44.984: INFO: New ReplicaSet "test-rollover-deployment-68774655d5" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-68774655d5",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6764",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1824fd7b-2694-4152-8c10-ff601af3c932",
      ResourceVersion: (string) (len=5) "44393",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851214572,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "1a770b03-aa43-4939-b1a0-50832a29bba0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214572,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 31 61 37 37 30 62  30 33 2d 61 61 34 33 2d  |\"1a770b03-aa43-|
              00000120  34 39 33 39 2d 62 31 61  30 2d 35 30 38 33 32 61  |4939-b1a0-50832a|
              00000130  32 39 62 62 61 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |29bba0\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 13 16:29:44.986: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
  May 13 16:29:44.986: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6764",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "aa8c3a27-c38a-49f8-803a-b77ed1615b65",
      ResourceVersion: (string) (len=5) "44402",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851214563,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "1a770b03-aa43-4939-b1a0-50832a29bba0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214563,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  31 61 37 37 30 62 30 33  2d 61 61 34 33 2d 34 39  |1a770b03-aa43-49|
              000000c0  33 39 2d 62 31 61 30 2d  35 30 38 33 32 61 32 39  |39-b1a0-50832a29|
              000000d0  62 62 61 30 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |bba0\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 13 16:29:44.988: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-664fc6c874",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6764",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "119078b5-8cd0-4191-974f-99d2e0bf3aa9",
      ResourceVersion: (string) (len=5) "44324",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851214570,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "1a770b03-aa43-4939-b1a0-50832a29bba0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214572,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 31 61 37 37 30 62  30 33 2d 61 61 34 33 2d  |\"1a770b03-aa43-|
              00000120  34 39 33 39 2d 62 31 61  30 2d 35 30 38 33 32 61  |4939-b1a0-50832a|
              00000130  32 39 62 62 61 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |29bba0\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214572,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 13 16:29:44.993: INFO: Pod "test-rollover-deployment-68774655d5-db26k" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-68774655d5-db26k",
      GenerateName: (string) (len=36) "test-rollover-deployment-68774655d5-",
      Namespace: (string) (len=15) "deployment-6764",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "00f7d439-4e44-4f62-8911-d1adb2f9d72e",
      ResourceVersion: (string) (len=5) "44345",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851214572,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
      },
      Annotations: (map[string]string) (len=4) {
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=13) "10.42.1.41/32",
        (string) (len=33) "k8s.v1.cni.cncf.io/network-status": (string) (len=112) "[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.1.41\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "24e5afd1a5ac85a03b6cae3573ebe987b94dc35a0bd09e95960793e2aa10e6c6",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=13) "10.42.1.41/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-68774655d5",
          UID: (types.UID) (len=36) "1824fd7b-2694-4152-8c10-ff601af3c932",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=4) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214572,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 38  32 34 66 64 37 62 2d 32  |d\":\"1824fd7b-2|
              00000090  36 39 34 2d 34 31 35 32  2d 38 63 31 30 2d 66 66  |694-4152-8c10-ff|
              000000a0  36 30 31 61 66 33 63 39  33 32 5c 22 7d 22 3a 7b  |601af3c932\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214573,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214573,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=659) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 34 32 2e 31 2e 34 31  5c 22 7d 22 3a 7b 22 2e  |.42.1.41\"}":{".|
              00000270  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              00000280  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              00000290  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "multus",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214573,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=75) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 6b 38 73 2e 76  31 2e 63 6e 69 2e 63 6e  |"f:k8s.v1.cni.cn|
              00000030  63 66 2e 69 6f 2f 6e 65  74 77 6f 72 6b 2d 73 74  |cf.io/network-st|
              00000040  61 74 75 73 22 3a 7b 7d  7d 7d 7d                 |atus":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mh55f",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mh55f",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214573,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214573,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214573,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214573,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851214572,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.5",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.5"
        }
      },
      PodIP: (string) (len=10) "10.42.1.41",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.42.1.41"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851214573,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851214573,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253",
          ContainerID: (string) (len=77) "containerd://340c3e544029112cbd1b7eb845fb3ff4df2a56c086de777b34258241d067bd80",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 16:29:44.997: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6764" for this suite. @ 05/13/24 16:29:45
• [21.114 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:808
  STEP: Creating a kubernetes client @ 05/13/24 16:29:45.012
  May 13 16:29:45.013: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename resourcequota @ 05/13/24 16:29:45.013
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:29:45.023
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:29:45.025
  STEP: Creating a ResourceQuota with best effort scope @ 05/13/24 16:29:45.026
  STEP: Ensuring ResourceQuota status is calculated @ 05/13/24 16:29:45.03
  E0513 16:29:45.201394      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:46.200703      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not best effort scope @ 05/13/24 16:29:47.036
  STEP: Ensuring ResourceQuota status is calculated @ 05/13/24 16:29:47.046
  E0513 16:29:47.202057      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:48.202626      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a best-effort pod @ 05/13/24 16:29:49.048
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 05/13/24 16:29:49.056
  E0513 16:29:49.203568      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:50.204074      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 05/13/24 16:29:51.057
  E0513 16:29:51.204147      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:52.204286      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/13/24 16:29:53.06
  STEP: Ensuring resource quota status released the pod usage @ 05/13/24 16:29:53.07
  E0513 16:29:53.205134      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:54.206313      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a not best-effort pod @ 05/13/24 16:29:55.073
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 05/13/24 16:29:55.078
  E0513 16:29:55.206576      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:56.213049      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 05/13/24 16:29:57.083
  E0513 16:29:57.211994      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:29:58.212046      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/13/24 16:29:59.091
  STEP: Ensuring resource quota status released the pod usage @ 05/13/24 16:29:59.107
  E0513 16:29:59.212778      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:00.213448      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:30:01.108: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1337" for this suite. @ 05/13/24 16:30:01.111
• [16.105 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 05/13/24 16:30:01.12
  May 13 16:30:01.120: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename chunking @ 05/13/24 16:30:01.121
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:30:01.132
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:30:01.134
  STEP: creating a large number of resources @ 05/13/24 16:30:01.135
  E0513 16:30:01.214116      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:02.214528      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:03.215013      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:04.215502      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:05.216104      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:06.216307      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:07.217013      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:08.217074      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:09.218015      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:10.218622      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:11.219106      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:12.219319      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:13.220154      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:14.221228      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:15.221436      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:16.222044      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:17.222820      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:18.223613      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving those results in paged fashion several times @ 05/13/24 16:30:18.825
  May 13 16:30:18.880: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  May 13 16:30:18.924: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  May 13 16:30:18.974: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  May 13 16:30:19.028: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  May 13 16:30:19.080: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  May 13 16:30:19.125: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  May 13 16:30:19.178: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  E0513 16:30:19.224712      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:30:19.234: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  May 13 16:30:19.279: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  May 13 16:30:19.332: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  May 13 16:30:19.376: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  May 13 16:30:19.429: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  May 13 16:30:19.474: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  May 13 16:30:19.523: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  May 13 16:30:19.573: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  May 13 16:30:19.624: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  May 13 16:30:19.674: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  May 13 16:30:19.726: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  May 13 16:30:19.775: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  May 13 16:30:19.826: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  May 13 16:30:19.876: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  May 13 16:30:19.925: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  May 13 16:30:19.975: INFO: Retrieved 17/17 results with rv 45047 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNDcsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  May 13 16:30:20.030: INFO: Retrieved 9/17 results with rv 45047 and continue 
  May 13 16:30:20.081: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  May 13 16:30:20.125: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  May 13 16:30:20.176: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  E0513 16:30:20.225299      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:30:20.226: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  May 13 16:30:20.274: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  May 13 16:30:20.325: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  May 13 16:30:20.380: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  May 13 16:30:20.431: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  May 13 16:30:20.474: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  May 13 16:30:20.530: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  May 13 16:30:20.580: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  May 13 16:30:20.627: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  May 13 16:30:20.676: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  May 13 16:30:20.729: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  May 13 16:30:20.779: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  May 13 16:30:20.832: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  May 13 16:30:20.873: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  May 13 16:30:20.923: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  May 13 16:30:20.974: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  May 13 16:30:21.024: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  May 13 16:30:21.075: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  May 13 16:30:21.124: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  May 13 16:30:21.175: INFO: Retrieved 17/17 results with rv 45051 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTEsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  E0513 16:30:21.225502      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:30:21.225: INFO: Retrieved 9/17 results with rv 45051 and continue 
  May 13 16:30:21.275: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  May 13 16:30:21.326: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  May 13 16:30:21.376: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  May 13 16:30:21.426: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  May 13 16:30:21.475: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  May 13 16:30:21.524: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  May 13 16:30:21.574: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  May 13 16:30:21.625: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  May 13 16:30:21.681: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  May 13 16:30:21.733: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  May 13 16:30:21.784: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  May 13 16:30:21.828: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  May 13 16:30:21.877: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  May 13 16:30:21.925: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  May 13 16:30:21.975: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  May 13 16:30:22.026: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  May 13 16:30:22.074: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  May 13 16:30:22.125: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  May 13 16:30:22.175: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  May 13 16:30:22.225: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  E0513 16:30:22.226639      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:30:22.273: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  May 13 16:30:22.323: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  May 13 16:30:22.374: INFO: Retrieved 17/17 results with rv 45057 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUwNTcsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  May 13 16:30:22.431: INFO: Retrieved 9/17 results with rv 45057 and continue 
  STEP: retrieving those results all at once @ 05/13/24 16:30:22.432
  May 13 16:30:22.514: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-5446" for this suite. @ 05/13/24 16:30:22.528
• [21.463 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:119
  STEP: Creating a kubernetes client @ 05/13/24 16:30:22.596
  May 13 16:30:22.596: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename webhook @ 05/13/24 16:30:22.598
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:30:22.611
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:30:22.615
  STEP: Setting up server cert @ 05/13/24 16:30:22.632
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/13/24 16:30:22.953
  STEP: Deploying the webhook pod @ 05/13/24 16:30:22.956
  STEP: Wait for the deployment to be ready @ 05/13/24 16:30:22.963
  May 13 16:30:22.972: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0513 16:30:23.226725      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:24.226859      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/13/24 16:30:24.976
  STEP: Verifying the service has paired with the endpoint @ 05/13/24 16:30:24.984
  E0513 16:30:25.227012      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:30:25.984: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 05/13/24 16:30:25.987
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 05/13/24 16:30:25.988
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 05/13/24 16:30:25.988
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 05/13/24 16:30:25.988
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 05/13/24 16:30:25.988
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 05/13/24 16:30:25.988
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 05/13/24 16:30:25.989
  May 13 16:30:26.026: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4012" for this suite. @ 05/13/24 16:30:26.031
  STEP: Destroying namespace "webhook-markers-4047" for this suite. @ 05/13/24 16:30:26.035
• [3.444 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 05/13/24 16:30:26.041
  May 13 16:30:26.041: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename chunking @ 05/13/24 16:30:26.042
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:30:26.053
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:30:26.055
  STEP: creating a large number of resources @ 05/13/24 16:30:26.057
  E0513 16:30:26.227628      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:27.228246      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:28.229158      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:29.229338      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0513 16:30:29.558480      17 request.go:697] Waited for 1.011735864s due to client-side throttling, not priority and fairness, request: POST:https://10.43.0.1:443/api/v1/namespaces/chunking-9168/podtemplates
  E0513 16:30:30.230277      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:31.230668      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:32.232010      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:33.232033      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:34.233481      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:35.233570      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:36.234280      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:37.235547      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:38.235404      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:39.236269      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:40.236455      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:41.236940      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:42.237566      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:43.238209      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the first page @ 05/13/24 16:30:43.746
  May 13 16:30:43.797: INFO: Retrieved 40/40 results with rv 46020 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYwMjAsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page until the token expires @ 05/13/24 16:30:43.797
  E0513 16:30:44.239013      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:45.240301      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:46.240826      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:47.240429      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:48.240548      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:49.241898      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:50.242515      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:51.242818      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:52.243014      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:53.243025      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:54.243164      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:55.244121      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:56.245033      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:57.245296      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:58.245488      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:30:59.245580      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:00.245786      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:01.245925      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:02.246264      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:03.246249      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:31:03.801: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYwMjAsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0513 16:31:04.246758      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:05.247667      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:06.248041      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:07.248617      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:08.248713      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:09.248966      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:10.249062      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:11.249442      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:12.249561      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:13.249635      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:14.250225      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:15.250534      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:16.250821      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:17.252721      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:18.252799      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:19.253140      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:20.253943      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:21.254274      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:22.255031      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:23.254991      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:31:23.805: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYwMjAsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0513 16:31:24.255256      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:25.255764      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:26.256231      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:27.256539      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:28.256631      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:29.256744      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:30.256844      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:31.256931      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:32.257028      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:33.257134      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:34.258389      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:35.259307      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:36.259641      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:37.259641      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:38.259679      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:39.259939      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:40.260879      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:41.263084      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:42.263119      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:43.263159      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:31:43.808: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYwMjAsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0513 16:31:44.264160      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:45.264422      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:46.264857      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:47.265140      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:48.265585      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:49.266764      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:50.267281      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:51.267499      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:52.268153      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:53.268244      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:54.269367      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:55.269966      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:56.270431      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:57.271144      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:58.271155      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:31:59.271679      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:00.272284      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:01.273012      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:02.273179      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:03.273320      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:32:03.800: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYwMjAsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0513 16:32:04.273415      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:05.274640      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:06.274970      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:07.275103      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:08.275153      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:09.275279      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:10.275350      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:11.276276      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:12.277170      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:13.276853      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:14.277077      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:15.277121      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:16.277344      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:17.277628      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:18.277627      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:19.278064      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:20.278809      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:21.280095      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:22.280712      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:23.281069      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:32:23.807: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYwMjAsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0513 16:32:24.281338      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:25.282050      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:26.283154      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:27.283624      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:28.283689      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:29.283917      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:30.284030      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:31.284398      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:32.284738      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:33.284854      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:34.285330      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:35.285273      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:36.285368      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:37.285767      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:38.285938      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:39.286277      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:40.287291      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:41.288726      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:42.289120      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:43.289397      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:32:43.801: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYwMjAsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0513 16:32:44.290237      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:45.291057      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:46.291399      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:47.291702      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:48.292009      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:49.292398      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:50.292423      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:51.294163      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:52.294224      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:53.294565      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:54.294910      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:55.295109      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:56.295729      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:57.296750      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:58.296847      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:32:59.297115      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:00.297458      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:01.297905      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:02.298245      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:03.299003      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:33:03.809: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYwMjAsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0513 16:33:04.300221      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:05.300700      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:06.300832      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:07.301190      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:08.301697      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:09.301829      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:10.301939      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:11.302375      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:12.302813      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:13.303119      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:14.303392      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:15.304453      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:16.304912      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:17.304844      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:18.305494      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:19.305903      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:20.306077      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:21.306880      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:22.306994      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:23.307711      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:33:23.810: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYwMjAsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0513 16:33:24.308940      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:25.309005      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:26.309700      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:27.309752      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:28.310569      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:29.310650      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:30.311453      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:31.311660      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:32.311925      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:33.311923      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:34.312067      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:35.312166      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:36.312933      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:37.312888      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:38.313579      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:39.314012      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:40.314147      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:41.314246      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:42.314348      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:43.314483      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:33:43.799: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYwMjAsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0513 16:33:44.314792      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:45.314744      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:46.315056      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:47.315153      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:48.315249      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:49.315730      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:50.316658      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:51.317049      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:52.317891      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:53.317823      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:54.318881      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:55.319181      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:56.319630      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:57.320129      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:58.320284      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:33:59.320714      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:00.321539      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:01.321706      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:02.321804      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:03.321940      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:34:03.801: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYwMjAsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0513 16:34:04.322180      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:05.322339      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:06.326398      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:07.326900      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:08.327723      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:09.327943      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:10.328039      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:11.328437      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:12.328654      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:13.328771      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:14.328900      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:15.329963      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:16.330993      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:17.331822      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:18.331872      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:19.332192      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:20.334647      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:21.334560      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:22.336197      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:23.335482      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:34:23.804: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYwMjAsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0513 16:34:24.335866      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:25.336041      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:26.336313      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:27.337544      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:28.337574      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:29.337827      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:30.338245      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:31.338500      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:32.338773      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:33.338846      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:34.339099      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:35.339944      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:36.340484      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:37.340744      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:38.341520      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:39.344142      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:40.342936      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:41.343129      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:42.344171      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:43.344052      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:34:43.806: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYwMjAsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0513 16:34:44.344921      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:45.345497      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:46.345952      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:47.345947      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:48.346212      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:49.346297      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:50.347849      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:51.347847      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:52.348190      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:53.348582      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:54.349937      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:55.349991      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:56.351068      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:57.351107      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:58.351656      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:34:59.358556      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:00.358821      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:01.359617      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:02.360218      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:03.360307      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:35:03.808: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYwMjAsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0513 16:35:04.360652      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:05.361368      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:06.361708      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:07.361910      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:08.361803      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:09.362220      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:10.363499      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:11.363881      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:12.364463      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:13.364700      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:14.365744      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:15.366925      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:16.367213      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:17.368250      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:18.368463      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:19.369415      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:20.369573      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:21.369752      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:22.370035      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:23.370755      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:35:23.802: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYwMjAsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0513 16:35:24.371787      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:25.371821      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:26.372364      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:27.372806      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:28.373544      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:29.373890      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:30.375006      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:31.376274      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:32.376548      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:33.376496      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:34.377417      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:35.377727      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:36.378151      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:37.379021      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:38.379699      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:39.380226      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:40.380634      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:41.381214      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:42.381551      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:43.381866      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:35:43.809: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYwMjAsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0513 16:35:44.382964      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:45.383349      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:46.383627      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:47.384876      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:48.384046      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:49.384506      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:50.384632      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:51.385151      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:52.385910      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:53.386818      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:54.387063      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:55.387688      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:56.388128      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:57.389406      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:58.388613      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:35:59.388998      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:00.389575      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:01.389526      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:02.394637      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:03.394736      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:36:03.801: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYwMjAsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0513 16:36:04.394938      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:05.395314      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:06.395624      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:07.398575      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:08.399184      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:09.400359      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:10.400652      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:11.400953      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:12.401525      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:13.402650      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:14.403466      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:15.404077      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:16.404140      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:17.405238      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:18.405977      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:19.406845      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:20.406893      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:21.407942      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:22.411499      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:23.410990      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:36:23.800: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYwMjAsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0513 16:36:24.411234      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:25.412178      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:26.412337      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:27.412625      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:28.412801      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:29.414008      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:30.414789      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:31.415934      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:32.416674      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:33.417314      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:34.418087      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:35.418547      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:36.419174      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:37.419406      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:38.419523      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:39.420454      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:40.420698      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:41.420872      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:42.422630      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:43.421834      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:36:43.805: INFO: got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  May 13 16:36:43.806: INFO: Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 05/13/24 16:36:43.806
  STEP: retrieving all remaining pages @ 05/13/24 16:36:43.811
  May 13 16:36:43.817: INFO: Retrieved 40/40 results with rv 47581 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDc1ODEsInN0YXJ0IjoidGVtcGxhdGUtMDExOVx1MDAwMCJ9
  May 13 16:36:43.823: INFO: Retrieved 40/40 results with rv 47581 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDc1ODEsInN0YXJ0IjoidGVtcGxhdGUtMDE1OVx1MDAwMCJ9
  May 13 16:36:43.827: INFO: Retrieved 40/40 results with rv 47581 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDc1ODEsInN0YXJ0IjoidGVtcGxhdGUtMDE5OVx1MDAwMCJ9
  May 13 16:36:43.831: INFO: Retrieved 40/40 results with rv 47581 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDc1ODEsInN0YXJ0IjoidGVtcGxhdGUtMDIzOVx1MDAwMCJ9
  May 13 16:36:43.834: INFO: Retrieved 40/40 results with rv 47581 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDc1ODEsInN0YXJ0IjoidGVtcGxhdGUtMDI3OVx1MDAwMCJ9
  May 13 16:36:43.838: INFO: Retrieved 40/40 results with rv 47581 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDc1ODEsInN0YXJ0IjoidGVtcGxhdGUtMDMxOVx1MDAwMCJ9
  May 13 16:36:43.840: INFO: Retrieved 40/40 results with rv 47581 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDc1ODEsInN0YXJ0IjoidGVtcGxhdGUtMDM1OVx1MDAwMCJ9
  May 13 16:36:43.843: INFO: Retrieved 40/40 results with rv 47581 and continue 
  May 13 16:36:43.843: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-9168" for this suite. @ 05/13/24 16:36:43.846
• [377.809 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:153
  STEP: Creating a kubernetes client @ 05/13/24 16:36:43.853
  May 13 16:36:43.853: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/13/24 16:36:43.854
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:36:43.864
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:36:43.865
  STEP: create the container to handle the HTTPGet hook request. @ 05/13/24 16:36:43.868
  E0513 16:36:44.422154      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:45.422967      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/13/24 16:36:45.893
  E0513 16:36:46.422944      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:47.423275      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 05/13/24 16:36:47.921
  E0513 16:36:48.423952      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:49.424729      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:50.425083      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:51.425443      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 05/13/24 16:36:51.938
  May 13 16:36:51.946: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-3851" for this suite. @ 05/13/24 16:36:51.948
• [8.099 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:228
  STEP: Creating a kubernetes client @ 05/13/24 16:36:51.952
  May 13 16:36:51.952: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename var-expansion @ 05/13/24 16:36:51.953
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:36:51.962
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:36:51.964
  STEP: creating the pod with failed condition @ 05/13/24 16:36:51.965
  E0513 16:36:52.426289      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:53.426226      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:54.427359      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:55.428285      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:56.428347      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:57.432868      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:58.433571      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:36:59.434278      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:00.434444      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:01.435581      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:02.435385      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:03.436263      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:04.437427      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:05.438762      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:06.438629      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:07.440796      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:08.440803      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:09.441540      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:10.441572      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:11.442432      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:12.443650      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:13.443667      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:14.443933      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:15.444371      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:16.445087      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:17.445320      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:18.445434      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:19.446266      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:20.446909      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:21.447933      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:22.449034      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:23.449294      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:24.449999      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:25.450614      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:26.450707      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:27.450832      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:28.452078      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:29.452674      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:30.452925      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:31.454226      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:32.454635      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:33.455004      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:34.455827      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:35.456521      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:36.456699      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:37.456871      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:38.458431      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:39.460136      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:40.460121      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:41.460074      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:42.461313      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:43.462130      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:44.463278      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:45.463365      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:46.464265      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:47.464634      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:48.465136      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:49.467539      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:50.467784      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:51.468064      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:52.468834      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:53.469220      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:54.469903      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:55.470218      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:56.470772      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:57.470968      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:58.472240      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:37:59.474405      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:00.473459      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:01.475179      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:02.475286      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:03.477097      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:04.477997      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:05.478375      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:06.478570      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:07.478664      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:08.478957      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:09.479927      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:10.479909      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:11.482607      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:12.482679      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:13.482775      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:14.483778      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:15.484028      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:16.484868      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:17.485075      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:18.485301      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:19.487488      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:20.486579      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:21.486625      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:22.488049      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:23.488064      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:24.489141      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:25.490341      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:26.491180      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:27.491462      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:28.492544      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:29.494691      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:30.495046      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:31.494850      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:32.495895      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:33.495680      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:34.496518      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:35.497303      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:36.498060      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:37.498223      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:38.498652      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:39.499420      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:40.500479      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:41.501356      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:42.502166      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:43.502165      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:44.506629      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:45.506704      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:46.507693      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:47.508273      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:48.509534      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:49.510252      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:50.511601      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:51.511667      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pod @ 05/13/24 16:38:51.973
  May 13 16:38:52.482: INFO: Successfully updated pod "var-expansion-2125e1ff-fa2f-4c4c-bb25-66ff7c2aff72"
  STEP: waiting for pod running @ 05/13/24 16:38:52.482
  E0513 16:38:52.511719      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:53.512827      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 05/13/24 16:38:54.489
  May 13 16:38:54.489: INFO: Deleting pod "var-expansion-2125e1ff-fa2f-4c4c-bb25-66ff7c2aff72" in namespace "var-expansion-6218"
  May 13 16:38:54.500: INFO: Wait up to 5m0s for pod "var-expansion-2125e1ff-fa2f-4c4c-bb25-66ff7c2aff72" to be fully deleted
  E0513 16:38:54.513439      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:55.513584      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:56.514440      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:57.514683      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:58.515188      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:38:59.518607      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:00.520667      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:01.519358      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:02.519657      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:03.520245      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:04.522490      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:05.523027      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:06.523876      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:07.523937      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:08.524678      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:09.525480      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:10.525596      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:11.525721      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:12.526588      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:13.527282      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:14.527405      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:15.528233      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:16.528552      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:17.529329      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:18.529567      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:19.529548      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:20.530009      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:21.531227      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:22.531364      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:23.532433      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:24.542347      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:25.533261      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:26.533951      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:39:26.609: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6218" for this suite. @ 05/13/24 16:39:26.613
• [154.667 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:846
  STEP: Creating a kubernetes client @ 05/13/24 16:39:26.623
  May 13 16:39:26.623: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename services @ 05/13/24 16:39:26.624
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:39:26.636
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:39:26.638
  STEP: creating service multi-endpoint-test in namespace services-285 @ 05/13/24 16:39:26.639
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-285 to expose endpoints map[] @ 05/13/24 16:39:26.649
  May 13 16:39:26.656: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
  E0513 16:39:27.534804      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:39:27.666: INFO: successfully validated that service multi-endpoint-test in namespace services-285 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-285 @ 05/13/24 16:39:27.667
  E0513 16:39:28.534664      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:29.538581      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-285 to expose endpoints map[pod1:[100]] @ 05/13/24 16:39:29.698
  May 13 16:39:29.709: INFO: successfully validated that service multi-endpoint-test in namespace services-285 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-285 @ 05/13/24 16:39:29.71
  E0513 16:39:30.539277      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:31.538995      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-285 to expose endpoints map[pod1:[100] pod2:[101]] @ 05/13/24 16:39:31.729
  May 13 16:39:31.737: INFO: successfully validated that service multi-endpoint-test in namespace services-285 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 05/13/24 16:39:31.737
  May 13 16:39:31.737: INFO: Creating new exec pod
  E0513 16:39:32.539086      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:33.539545      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:34.540075      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:39:34.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-285 exec execpod6jvns -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  May 13 16:39:34.860: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  May 13 16:39:34.860: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 13 16:39:34.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-285 exec execpod6jvns -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.123.219 80'
  May 13 16:39:34.956: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.123.219 80\nConnection to 10.43.123.219 80 port [tcp/http] succeeded!\n"
  May 13 16:39:34.956: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 13 16:39:34.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-285 exec execpod6jvns -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  May 13 16:39:35.055: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  May 13 16:39:35.055: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 13 16:39:35.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-285 exec execpod6jvns -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.123.219 81'
  May 13 16:39:35.154: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.123.219 81\nConnection to 10.43.123.219 81 port [tcp/*] succeeded!\n"
  May 13 16:39:35.154: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-285 @ 05/13/24 16:39:35.154
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-285 to expose endpoints map[pod2:[101]] @ 05/13/24 16:39:35.171
  May 13 16:39:35.180: INFO: successfully validated that service multi-endpoint-test in namespace services-285 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-285 @ 05/13/24 16:39:35.18
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-285 to expose endpoints map[] @ 05/13/24 16:39:35.195
  May 13 16:39:35.202: INFO: successfully validated that service multi-endpoint-test in namespace services-285 exposes endpoints map[]
  May 13 16:39:35.231: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-285" for this suite. @ 05/13/24 16:39:35.237
• [8.619 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 05/13/24 16:39:35.242
  May 13 16:39:35.242: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename daemonsets @ 05/13/24 16:39:35.244
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:39:35.258
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:39:35.26
  STEP: Creating simple DaemonSet "daemon-set" @ 05/13/24 16:39:35.273
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/13/24 16:39:35.277
  May 13 16:39:35.280: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:39:35.280: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 16:39:35.284: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 16:39:35.284: INFO: Node oneke-ip-172-16-100-5 is running 0 daemon pod, expected 1
  E0513 16:39:35.540695      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:39:36.280: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:39:36.280: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 16:39:36.282: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May 13 16:39:36.282: INFO: Node oneke-ip-172-16-100-5 is running 0 daemon pod, expected 1
  E0513 16:39:36.541396      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:39:37.281: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:39:37.281: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 16:39:37.282: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May 13 16:39:37.282: INFO: Node oneke-ip-172-16-100-5 is running 0 daemon pod, expected 1
  E0513 16:39:37.542414      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:39:38.280: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:39:38.280: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 16:39:38.281: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May 13 16:39:38.281: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 05/13/24 16:39:38.283
  May 13 16:39:38.291: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:39:38.291: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 16:39:38.293: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May 13 16:39:38.293: INFO: Node oneke-ip-172-16-100-5 is running 0 daemon pod, expected 1
  E0513 16:39:38.543136      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:39:39.301: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:39:39.303: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 16:39:39.311: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May 13 16:39:39.311: INFO: Node oneke-ip-172-16-100-5 is running 0 daemon pod, expected 1
  E0513 16:39:39.543221      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:39:40.293: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:39:40.293: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 16:39:40.296: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May 13 16:39:40.296: INFO: Node oneke-ip-172-16-100-5 is running 0 daemon pod, expected 1
  E0513 16:39:40.544122      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:39:41.293: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:39:41.293: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 16:39:41.296: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May 13 16:39:41.296: INFO: Node oneke-ip-172-16-100-5 is running 0 daemon pod, expected 1
  E0513 16:39:41.544196      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:39:42.291: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:39:42.291: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 16:39:42.293: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May 13 16:39:42.293: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 05/13/24 16:39:42.294
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1126, will wait for the garbage collector to delete the pods @ 05/13/24 16:39:42.294
  May 13 16:39:42.349: INFO: Deleting DaemonSet.extensions daemon-set took: 3.843348ms
  May 13 16:39:42.452: INFO: Terminating DaemonSet.extensions daemon-set pods took: 102.87428ms
  E0513 16:39:42.545116      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:43.545552      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:44.545934      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:39:44.854: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 16:39:44.854: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  May 13 16:39:44.855: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"49030"},"items":null}

  May 13 16:39:44.856: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"49030"},"items":null}

  May 13 16:39:44.860: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1126" for this suite. @ 05/13/24 16:39:44.862
• [9.623 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:75
  STEP: Creating a kubernetes client @ 05/13/24 16:39:44.864
  May 13 16:39:44.864: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 16:39:44.866
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:39:44.875
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:39:44.877
  STEP: Creating configMap with name projected-configmap-test-volume-844e14fe-1366-4d2e-bb9f-c3473cbe03fb @ 05/13/24 16:39:44.878
  STEP: Creating a pod to test consume configMaps @ 05/13/24 16:39:44.882
  E0513 16:39:45.546265      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:46.546988      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:47.547375      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:48.548543      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:39:48.894
  May 13 16:39:48.897: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-projected-configmaps-29ab6f57-88bd-47af-94d0-d592931c24ba container agnhost-container: <nil>
  STEP: delete the pod @ 05/13/24 16:39:48.91
  May 13 16:39:48.921: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7746" for this suite. @ 05/13/24 16:39:48.924
• [4.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:324
  STEP: Creating a kubernetes client @ 05/13/24 16:39:48.929
  May 13 16:39:48.929: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename cronjob @ 05/13/24 16:39:48.93
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:39:48.94
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:39:48.942
  STEP: Creating a cronjob @ 05/13/24 16:39:48.943
  STEP: creating @ 05/13/24 16:39:48.943
  STEP: getting @ 05/13/24 16:39:48.946
  STEP: listing @ 05/13/24 16:39:48.947
  STEP: watching @ 05/13/24 16:39:48.948
  May 13 16:39:48.948: INFO: starting watch
  STEP: cluster-wide listing @ 05/13/24 16:39:48.949
  STEP: cluster-wide watching @ 05/13/24 16:39:48.95
  May 13 16:39:48.950: INFO: starting watch
  STEP: patching @ 05/13/24 16:39:48.951
  STEP: updating @ 05/13/24 16:39:48.954
  May 13 16:39:48.959: INFO: waiting for watch events with expected annotations
  May 13 16:39:48.960: INFO: saw patched and updated annotations
  STEP: patching /status @ 05/13/24 16:39:48.96
  STEP: updating /status @ 05/13/24 16:39:48.964
  STEP: get /status @ 05/13/24 16:39:48.967
  STEP: deleting @ 05/13/24 16:39:48.968
  STEP: deleting a collection @ 05/13/24 16:39:48.976
  May 13 16:39:48.980: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-8281" for this suite. @ 05/13/24 16:39:48.983
• [0.056 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:168
  STEP: Creating a kubernetes client @ 05/13/24 16:39:48.988
  May 13 16:39:48.988: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename container-probe @ 05/13/24 16:39:48.989
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:39:48.999
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:39:49.001
  STEP: Creating pod liveness-7bd05b2b-9c02-4f2a-a5d7-dd95e779cf81 in namespace container-probe-9578 @ 05/13/24 16:39:49.003
  E0513 16:39:49.549742      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:50.550634      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/13/24 16:39:51.02
  May 13 16:39:51.025: INFO: Initial restart count of pod liveness-7bd05b2b-9c02-4f2a-a5d7-dd95e779cf81 is 0
  May 13 16:39:51.031: INFO: Get pod liveness-7bd05b2b-9c02-4f2a-a5d7-dd95e779cf81 in namespace container-probe-9578
  E0513 16:39:51.550217      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:52.551382      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:39:53.033: INFO: Get pod liveness-7bd05b2b-9c02-4f2a-a5d7-dd95e779cf81 in namespace container-probe-9578
  E0513 16:39:53.551618      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:54.552222      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:39:55.036: INFO: Get pod liveness-7bd05b2b-9c02-4f2a-a5d7-dd95e779cf81 in namespace container-probe-9578
  E0513 16:39:55.554860      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:56.555895      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:39:57.043: INFO: Get pod liveness-7bd05b2b-9c02-4f2a-a5d7-dd95e779cf81 in namespace container-probe-9578
  E0513 16:39:57.556147      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:39:58.556999      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:39:59.046: INFO: Get pod liveness-7bd05b2b-9c02-4f2a-a5d7-dd95e779cf81 in namespace container-probe-9578
  E0513 16:39:59.556705      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:00.557088      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:40:01.047: INFO: Get pod liveness-7bd05b2b-9c02-4f2a-a5d7-dd95e779cf81 in namespace container-probe-9578
  E0513 16:40:01.557760      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:02.557893      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:40:03.050: INFO: Get pod liveness-7bd05b2b-9c02-4f2a-a5d7-dd95e779cf81 in namespace container-probe-9578
  E0513 16:40:03.558818      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:04.558951      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:40:05.057: INFO: Get pod liveness-7bd05b2b-9c02-4f2a-a5d7-dd95e779cf81 in namespace container-probe-9578
  E0513 16:40:05.559889      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:06.560257      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:40:07.063: INFO: Get pod liveness-7bd05b2b-9c02-4f2a-a5d7-dd95e779cf81 in namespace container-probe-9578
  E0513 16:40:07.561311      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:08.561296      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:40:09.065: INFO: Get pod liveness-7bd05b2b-9c02-4f2a-a5d7-dd95e779cf81 in namespace container-probe-9578
  E0513 16:40:09.561574      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:10.563760      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:40:11.069: INFO: Get pod liveness-7bd05b2b-9c02-4f2a-a5d7-dd95e779cf81 in namespace container-probe-9578
  May 13 16:40:11.069: INFO: Restart count of pod container-probe-9578/liveness-7bd05b2b-9c02-4f2a-a5d7-dd95e779cf81 is now 1 (20.044177636s elapsed)
  STEP: deleting the pod @ 05/13/24 16:40:11.07
  May 13 16:40:11.083: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9578" for this suite. @ 05/13/24 16:40:11.087
• [22.103 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 05/13/24 16:40:11.094
  May 13 16:40:11.094: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename watch @ 05/13/24 16:40:11.095
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:40:11.106
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:40:11.107
  STEP: creating a watch on configmaps @ 05/13/24 16:40:11.109
  STEP: creating a new configmap @ 05/13/24 16:40:11.11
  STEP: modifying the configmap once @ 05/13/24 16:40:11.113
  STEP: closing the watch once it receives two notifications @ 05/13/24 16:40:11.118
  May 13 16:40:11.118: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1538  6117b22a-e8c6-4e8a-afb5-b92e0a3a1c73 49260 0 2024-05-13 16:40:11 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-05-13 16:40:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  May 13 16:40:11.118: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1538  6117b22a-e8c6-4e8a-afb5-b92e0a3a1c73 49261 0 2024-05-13 16:40:11 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-05-13 16:40:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 05/13/24 16:40:11.118
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 05/13/24 16:40:11.121
  STEP: deleting the configmap @ 05/13/24 16:40:11.122
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 05/13/24 16:40:11.124
  May 13 16:40:11.124: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1538  6117b22a-e8c6-4e8a-afb5-b92e0a3a1c73 49262 0 2024-05-13 16:40:11 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-05-13 16:40:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 13 16:40:11.125: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1538  6117b22a-e8c6-4e8a-afb5-b92e0a3a1c73 49263 0 2024-05-13 16:40:11 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-05-13 16:40:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 13 16:40:11.125: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-1538" for this suite. @ 05/13/24 16:40:11.127
• [0.037 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:59
  STEP: Creating a kubernetes client @ 05/13/24 16:40:11.134
  May 13 16:40:11.134: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/13/24 16:40:11.134
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:40:11.147
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:40:11.148
  May 13 16:40:11.150: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 16:40:11.563714      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:40:12.175: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-6992" for this suite. @ 05/13/24 16:40:12.177
• [1.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1698
  STEP: Creating a kubernetes client @ 05/13/24 16:40:12.185
  May 13 16:40:12.185: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubectl @ 05/13/24 16:40:12.186
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:40:12.195
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:40:12.196
  STEP: creating Agnhost RC @ 05/13/24 16:40:12.198
  May 13 16:40:12.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3920 create -f -'
  May 13 16:40:12.310: INFO: stderr: ""
  May 13 16:40:12.310: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 05/13/24 16:40:12.31
  E0513 16:40:12.563926      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:40:13.313: INFO: Selector matched 1 pods for map[app:agnhost]
  May 13 16:40:13.313: INFO: Found 1 / 1
  May 13 16:40:13.313: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 05/13/24 16:40:13.313
  May 13 16:40:13.315: INFO: Selector matched 1 pods for map[app:agnhost]
  May 13 16:40:13.315: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  May 13 16:40:13.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3920 patch pod agnhost-primary-fkm6z -p {"metadata":{"annotations":{"x":"y"}}}'
  May 13 16:40:13.371: INFO: stderr: ""
  May 13 16:40:13.371: INFO: stdout: "pod/agnhost-primary-fkm6z patched\n"
  STEP: checking annotations @ 05/13/24 16:40:13.371
  May 13 16:40:13.372: INFO: Selector matched 1 pods for map[app:agnhost]
  May 13 16:40:13.372: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  May 13 16:40:13.372: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3920" for this suite. @ 05/13/24 16:40:13.375
• [1.192 seconds]
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 05/13/24 16:40:13.377
  May 13 16:40:13.378: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename subpath @ 05/13/24 16:40:13.379
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:40:13.39
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:40:13.392
  STEP: Setting up data @ 05/13/24 16:40:13.393
  STEP: Creating pod pod-subpath-test-downwardapi-ftf9 @ 05/13/24 16:40:13.401
  STEP: Creating a pod to test atomic-volume-subpath @ 05/13/24 16:40:13.401
  E0513 16:40:13.564932      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:14.571712      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:15.572594      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:16.572727      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:17.573129      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:18.573440      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:19.573927      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:20.574187      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:21.574639      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:22.576994      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:23.578716      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:24.579324      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:25.579399      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:26.580266      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:27.579874      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:28.580583      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:29.580783      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:30.580895      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:31.581861      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:32.582794      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:33.583451      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:34.585942      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:35.586368      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:36.586875      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:40:37.458
  May 13 16:40:37.460: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-subpath-test-downwardapi-ftf9 container test-container-subpath-downwardapi-ftf9: <nil>
  STEP: delete the pod @ 05/13/24 16:40:37.467
  STEP: Deleting pod pod-subpath-test-downwardapi-ftf9 @ 05/13/24 16:40:37.476
  May 13 16:40:37.476: INFO: Deleting pod "pod-subpath-test-downwardapi-ftf9" in namespace "subpath-1924"
  May 13 16:40:37.477: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-1924" for this suite. @ 05/13/24 16:40:37.48
• [24.108 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 05/13/24 16:40:37.486
  May 13 16:40:37.486: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename field-validation @ 05/13/24 16:40:37.487
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:40:37.498
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:40:37.5
  STEP: apply creating a deployment @ 05/13/24 16:40:37.501
  May 13 16:40:37.505: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8126" for this suite. @ 05/13/24 16:40:37.507
• [0.025 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingressclass.go:268
  STEP: Creating a kubernetes client @ 05/13/24 16:40:37.512
  May 13 16:40:37.512: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename ingressclass @ 05/13/24 16:40:37.513
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:40:37.523
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:40:37.524
  STEP: getting /apis @ 05/13/24 16:40:37.526
  STEP: getting /apis/networking.k8s.io @ 05/13/24 16:40:37.53
  STEP: getting /apis/networking.k8s.iov1 @ 05/13/24 16:40:37.531
  STEP: creating @ 05/13/24 16:40:37.531
  STEP: getting @ 05/13/24 16:40:37.537
  STEP: listing @ 05/13/24 16:40:37.539
  STEP: watching @ 05/13/24 16:40:37.54
  May 13 16:40:37.540: INFO: starting watch
  STEP: patching @ 05/13/24 16:40:37.54
  STEP: updating @ 05/13/24 16:40:37.543
  May 13 16:40:37.545: INFO: waiting for watch events with expected annotations
  May 13 16:40:37.545: INFO: saw patched and updated annotations
  STEP: deleting @ 05/13/24 16:40:37.545
  STEP: deleting a collection @ 05/13/24 16:40:37.549
  May 13 16:40:37.553: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-6736" for this suite. @ 05/13/24 16:40:37.555
• [0.047 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1538
  STEP: Creating a kubernetes client @ 05/13/24 16:40:37.559
  May 13 16:40:37.560: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubectl @ 05/13/24 16:40:37.56
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:40:37.57
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:40:37.572
  STEP: creating Agnhost RC @ 05/13/24 16:40:37.573
  May 13 16:40:37.573: INFO: namespace kubectl-3910
  May 13 16:40:37.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3910 create -f -'
  E0513 16:40:37.587411      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:40:37.669: INFO: stderr: ""
  May 13 16:40:37.669: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 05/13/24 16:40:37.669
  E0513 16:40:38.587950      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:40:38.675: INFO: Selector matched 1 pods for map[app:agnhost]
  May 13 16:40:38.675: INFO: Found 0 / 1
  E0513 16:40:39.588322      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:40:39.676: INFO: Selector matched 1 pods for map[app:agnhost]
  May 13 16:40:39.676: INFO: Found 1 / 1
  May 13 16:40:39.676: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  May 13 16:40:39.681: INFO: Selector matched 1 pods for map[app:agnhost]
  May 13 16:40:39.681: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  May 13 16:40:39.681: INFO: wait on agnhost-primary startup in kubectl-3910 
  May 13 16:40:39.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3910 logs agnhost-primary-xqkdg agnhost-primary'
  May 13 16:40:39.761: INFO: stderr: ""
  May 13 16:40:39.761: INFO: stdout: "Paused\n"
  STEP: exposing RC @ 05/13/24 16:40:39.761
  May 13 16:40:39.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3910 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  May 13 16:40:39.841: INFO: stderr: ""
  May 13 16:40:39.841: INFO: stdout: "service/rm2 exposed\n"
  May 13 16:40:39.843: INFO: Service rm2 in namespace kubectl-3910 found.
  E0513 16:40:40.589293      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:41.589293      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: exposing service @ 05/13/24 16:40:41.894
  May 13 16:40:41.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3910 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  May 13 16:40:41.969: INFO: stderr: ""
  May 13 16:40:41.969: INFO: stdout: "service/rm3 exposed\n"
  May 13 16:40:41.971: INFO: Service rm3 in namespace kubectl-3910 found.
  E0513 16:40:42.589864      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:43.591652      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:40:43.979: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3910" for this suite. @ 05/13/24 16:40:43.989
• [6.442 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 05/13/24 16:40:44.003
  May 13 16:40:44.003: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename dns @ 05/13/24 16:40:44.006
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:40:44.028
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:40:44.03
  STEP: Creating a test headless service @ 05/13/24 16:40:44.032
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4336.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4336.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4336.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4336.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4336.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4336.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4336.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4336.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4336.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4336.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 192.61.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.61.192_udp@PTR;check="$$(dig +tcp +noall +answer +search 192.61.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.61.192_tcp@PTR;sleep 1; done
   @ 05/13/24 16:40:44.052
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4336.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4336.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4336.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4336.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4336.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4336.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4336.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4336.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4336.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4336.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 192.61.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.61.192_udp@PTR;check="$$(dig +tcp +noall +answer +search 192.61.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.61.192_tcp@PTR;sleep 1; done
   @ 05/13/24 16:40:44.052
  STEP: creating a pod to probe DNS @ 05/13/24 16:40:44.054
  STEP: submitting the pod to kubernetes @ 05/13/24 16:40:44.054
  E0513 16:40:44.592044      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:45.592347      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/13/24 16:40:46.075
  STEP: looking for the results for each expected name from probers @ 05/13/24 16:40:46.083
  May 13 16:40:46.096: INFO: Unable to read wheezy_udp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:46.098: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:46.099: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:46.101: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:46.108: INFO: Unable to read jessie_udp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:46.109: INFO: Unable to read jessie_tcp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:46.111: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:46.112: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:46.118: INFO: Lookups using dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837 failed for: [wheezy_udp@dns-test-service.dns-4336.svc.cluster.local wheezy_tcp@dns-test-service.dns-4336.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local jessie_udp@dns-test-service.dns-4336.svc.cluster.local jessie_tcp@dns-test-service.dns-4336.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local]

  May 13 16:40:46.121: INFO: Pod client logs for webserver: 
  May 13 16:40:46.123: INFO: Pod client logs for querier: 
  May 13 16:40:46.126: INFO: Pod client logs for jessie-querier: 
  E0513 16:40:46.593250      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:47.593687      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:48.593655      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:49.593737      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:50.593827      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:40:51.087: INFO: Unable to read wheezy_udp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:51.089: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:51.091: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:51.093: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:51.103: INFO: Unable to read jessie_udp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:51.105: INFO: Unable to read jessie_tcp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:51.107: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:51.109: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:51.116: INFO: Lookups using dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837 failed for: [wheezy_udp@dns-test-service.dns-4336.svc.cluster.local wheezy_tcp@dns-test-service.dns-4336.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local jessie_udp@dns-test-service.dns-4336.svc.cluster.local jessie_tcp@dns-test-service.dns-4336.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local]

  May 13 16:40:51.120: INFO: Pod client logs for webserver: 
  May 13 16:40:51.124: INFO: Pod client logs for querier: 
  May 13 16:40:51.127: INFO: Pod client logs for jessie-querier: 
  E0513 16:40:51.594625      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:52.596101      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:53.596838      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:54.597278      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:55.597345      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:40:56.087: INFO: Unable to read wheezy_udp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:56.090: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:56.092: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:56.094: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:56.103: INFO: Unable to read jessie_udp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:56.105: INFO: Unable to read jessie_tcp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:56.107: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:56.109: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:40:56.117: INFO: Lookups using dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837 failed for: [wheezy_udp@dns-test-service.dns-4336.svc.cluster.local wheezy_tcp@dns-test-service.dns-4336.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local jessie_udp@dns-test-service.dns-4336.svc.cluster.local jessie_tcp@dns-test-service.dns-4336.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local]

  May 13 16:40:56.121: INFO: Pod client logs for webserver: 
  May 13 16:40:56.125: INFO: Pod client logs for querier: 
  May 13 16:40:56.128: INFO: Pod client logs for jessie-querier: 
  E0513 16:40:56.597830      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:57.598817      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:58.599642      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:40:59.599565      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:00.599794      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:41:01.092: INFO: Unable to read wheezy_udp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:01.100: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:01.108: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:01.118: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:01.138: INFO: Unable to read jessie_udp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:01.141: INFO: Unable to read jessie_tcp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:01.143: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:01.145: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:01.152: INFO: Lookups using dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837 failed for: [wheezy_udp@dns-test-service.dns-4336.svc.cluster.local wheezy_tcp@dns-test-service.dns-4336.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local jessie_udp@dns-test-service.dns-4336.svc.cluster.local jessie_tcp@dns-test-service.dns-4336.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local]

  May 13 16:41:01.156: INFO: Pod client logs for webserver: 
  May 13 16:41:01.159: INFO: Pod client logs for querier: 
  May 13 16:41:01.161: INFO: Pod client logs for jessie-querier: 
  E0513 16:41:01.600656      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:02.601661      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:03.603084      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:04.604359      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:05.604453      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:41:06.087: INFO: Unable to read wheezy_udp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:06.089: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:06.091: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:06.093: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:06.102: INFO: Unable to read jessie_udp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:06.104: INFO: Unable to read jessie_tcp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:06.106: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:06.108: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:06.115: INFO: Lookups using dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837 failed for: [wheezy_udp@dns-test-service.dns-4336.svc.cluster.local wheezy_tcp@dns-test-service.dns-4336.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local jessie_udp@dns-test-service.dns-4336.svc.cluster.local jessie_tcp@dns-test-service.dns-4336.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local]

  May 13 16:41:06.119: INFO: Pod client logs for webserver: 
  May 13 16:41:06.122: INFO: Pod client logs for querier: 
  May 13 16:41:06.124: INFO: Pod client logs for jessie-querier: 
  E0513 16:41:06.604795      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:07.606285      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:08.605963      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:09.606060      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:10.606247      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:41:11.091: INFO: Unable to read wheezy_udp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:11.094: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:11.096: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:11.099: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:11.109: INFO: Unable to read jessie_udp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:11.112: INFO: Unable to read jessie_tcp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:11.114: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:11.116: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:11.123: INFO: Lookups using dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837 failed for: [wheezy_udp@dns-test-service.dns-4336.svc.cluster.local wheezy_tcp@dns-test-service.dns-4336.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local jessie_udp@dns-test-service.dns-4336.svc.cluster.local jessie_tcp@dns-test-service.dns-4336.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local]

  May 13 16:41:11.126: INFO: Pod client logs for webserver: 
  May 13 16:41:11.129: INFO: Pod client logs for querier: 
  May 13 16:41:11.132: INFO: Pod client logs for jessie-querier: 
  E0513 16:41:11.609494      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:12.608159      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:13.608571      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:14.609174      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:15.609674      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:41:16.087: INFO: Unable to read wheezy_udp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:16.089: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:16.091: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:16.093: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local from pod dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837: the server could not find the requested resource (get pods dns-test-9586db65-0287-4330-8b14-bb1cba24d837)
  May 13 16:41:16.113: INFO: Lookups using dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837 failed for: [wheezy_udp@dns-test-service.dns-4336.svc.cluster.local wheezy_tcp@dns-test-service.dns-4336.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4336.svc.cluster.local]

  May 13 16:41:16.117: INFO: Pod client logs for webserver: 
  May 13 16:41:16.120: INFO: Pod client logs for querier: 
  May 13 16:41:16.123: INFO: Pod client logs for jessie-querier: 
  E0513 16:41:16.609936      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:17.610676      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:18.610852      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:19.610986      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:20.611279      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:41:21.107: INFO: DNS probes using dns-4336/dns-test-9586db65-0287-4330-8b14-bb1cba24d837 succeeded

  STEP: deleting the pod @ 05/13/24 16:41:21.107
  STEP: deleting the test service @ 05/13/24 16:41:21.125
  STEP: deleting the test headless service @ 05/13/24 16:41:21.152
  May 13 16:41:21.160: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-4336" for this suite. @ 05/13/24 16:41:21.167
• [37.168 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:238
  STEP: Creating a kubernetes client @ 05/13/24 16:41:21.174
  May 13 16:41:21.174: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename webhook @ 05/13/24 16:41:21.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:41:21.189
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:41:21.191
  STEP: Setting up server cert @ 05/13/24 16:41:21.207
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/13/24 16:41:21.541
  STEP: Deploying the webhook pod @ 05/13/24 16:41:21.547
  STEP: Wait for the deployment to be ready @ 05/13/24 16:41:21.556
  May 13 16:41:21.565: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0513 16:41:21.611942      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:22.612042      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/13/24 16:41:23.577
  STEP: Verifying the service has paired with the endpoint @ 05/13/24 16:41:23.588
  E0513 16:41:23.612942      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:41:24.590: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 05/13/24 16:41:24.595
  STEP: create a namespace for the webhook @ 05/13/24 16:41:24.608
  STEP: create a configmap should be unconditionally rejected by the webhook @ 05/13/24 16:41:24.623
  E0513 16:41:24.624661      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:41:24.665: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8414" for this suite. @ 05/13/24 16:41:24.671
  STEP: Destroying namespace "webhook-markers-9638" for this suite. @ 05/13/24 16:41:24.674
  STEP: Destroying namespace "fail-closed-namespace-3864" for this suite. @ 05/13/24 16:41:24.678
• [3.509 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/storageclass.go:53
  STEP: Creating a kubernetes client @ 05/13/24 16:41:24.685
  May 13 16:41:24.685: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename csi-storageclass @ 05/13/24 16:41:24.685
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:41:24.695
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:41:24.697
  STEP: Creating a StorageClass @ 05/13/24 16:41:24.698
  STEP: Get StorageClass "e2e-zll6s" @ 05/13/24 16:41:24.701
  STEP: Patching the StorageClass "e2e-zll6s" @ 05/13/24 16:41:24.703
  STEP: Delete StorageClass "e2e-zll6s" @ 05/13/24 16:41:24.707
  STEP: Confirm deletion of StorageClass "e2e-zll6s" @ 05/13/24 16:41:24.71
  STEP: Create a replacement StorageClass @ 05/13/24 16:41:24.711
  STEP: Updating StorageClass "e2e-v2-jrdf6" @ 05/13/24 16:41:24.714
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-jrdf6=updated" @ 05/13/24 16:41:24.717
  STEP: Deleting StorageClass "e2e-v2-jrdf6" via DeleteCollection @ 05/13/24 16:41:24.719
  STEP: Confirm deletion of StorageClass "e2e-v2-jrdf6" @ 05/13/24 16:41:24.722
  May 13 16:41:24.723: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-storageclass-134" for this suite. @ 05/13/24 16:41:24.726
• [0.045 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:321
  STEP: Creating a kubernetes client @ 05/13/24 16:41:24.73
  May 13 16:41:24.730: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename statefulset @ 05/13/24 16:41:24.731
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:41:24.74
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:41:24.742
  STEP: Creating service test in namespace statefulset-9282 @ 05/13/24 16:41:24.744
  STEP: Creating a new StatefulSet @ 05/13/24 16:41:24.747
  May 13 16:41:24.756: INFO: Found 0 stateful pods, waiting for 3
  E0513 16:41:25.625135      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:26.625389      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:27.626645      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:28.626589      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:29.627113      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:30.629331      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:31.627384      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:32.631006      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:33.631299      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:34.631270      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:41:34.756: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  May 13 16:41:34.757: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  May 13 16:41:34.757: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  May 13 16:41:34.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=statefulset-9282 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May 13 16:41:34.892: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May 13 16:41:34.892: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May 13 16:41:34.892: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0513 16:41:35.632414      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:36.632621      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:37.633005      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:38.633001      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:39.633497      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:40.633647      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:41.633783      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:42.634307      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:43.634884      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:44.635137      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 05/13/24 16:41:44.9
  May 13 16:41:44.918: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 05/13/24 16:41:44.918
  E0513 16:41:45.635415      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:46.636442      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:47.637799      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:48.639073      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:49.639389      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:50.640870      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:51.641196      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:52.641873      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:53.642023      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:54.642006      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 05/13/24 16:41:54.923
  May 13 16:41:54.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=statefulset-9282 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May 13 16:41:55.023: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May 13 16:41:55.023: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May 13 16:41:55.023: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0513 16:41:55.642678      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:56.642709      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:57.642959      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:58.643103      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:41:59.643216      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:00.643887      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:01.646600      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:02.646618      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:03.647758      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:04.648027      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:42:05.030: INFO: Waiting for StatefulSet statefulset-9282/ss2 to complete update
  E0513 16:42:05.648625      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:06.649488      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:07.649880      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:08.650916      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:09.651290      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:10.651321      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:11.652451      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:12.652821      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:13.653134      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:14.653444      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 05/13/24 16:42:15.041
  May 13 16:42:15.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=statefulset-9282 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May 13 16:42:15.174: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May 13 16:42:15.174: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May 13 16:42:15.174: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0513 16:42:15.653339      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:16.653489      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:17.653778      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:18.654356      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:19.654342      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:20.654865      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:21.655206      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:22.659182      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:23.657690      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:24.658286      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:42:25.218: INFO: Updating stateful set ss2
  E0513 16:42:25.658394      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:26.658919      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:27.659335      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:28.660057      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:29.660135      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:30.660233      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:31.660980      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:32.661056      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:33.661112      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:34.661253      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 05/13/24 16:42:35.231
  May 13 16:42:35.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=statefulset-9282 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May 13 16:42:35.353: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May 13 16:42:35.354: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May 13 16:42:35.354: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0513 16:42:35.661288      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:36.661971      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:37.662841      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:38.663780      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:39.664737      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:40.666065      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:41.671160      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:42.667400      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:43.667532      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:44.667803      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:42:45.388: INFO: Deleting all statefulset in ns statefulset-9282
  May 13 16:42:45.393: INFO: Scaling statefulset ss2 to 0
  E0513 16:42:45.667799      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:46.667913      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:47.668365      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:48.669711      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:49.669376      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:50.669575      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:51.669851      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:52.670360      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:53.671146      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:54.671299      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:42:55.411: INFO: Waiting for statefulset status.replicas updated to 0
  May 13 16:42:55.418: INFO: Deleting statefulset ss2
  May 13 16:42:55.447: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-9282" for this suite. @ 05/13/24 16:42:55.45
• [90.723 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 05/13/24 16:42:55.455
  May 13 16:42:55.455: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename field-validation @ 05/13/24 16:42:55.456
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:42:55.471
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:42:55.473
  May 13 16:42:55.475: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 16:42:55.671492      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:56.672440      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:57.672518      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0513 16:42:58.006335      17 warnings.go:70] unknown field "alpha"
  W0513 16:42:58.006716      17 warnings.go:70] unknown field "beta"
  W0513 16:42:58.006999      17 warnings.go:70] unknown field "delta"
  W0513 16:42:58.007198      17 warnings.go:70] unknown field "epsilon"
  W0513 16:42:58.007482      17 warnings.go:70] unknown field "gamma"
  May 13 16:42:58.566: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8177" for this suite. @ 05/13/24 16:42:58.569
• [3.117 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 05/13/24 16:42:58.572
  May 13 16:42:58.572: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename disruption @ 05/13/24 16:42:58.573
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:42:58.583
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:42:58.584
  STEP: creating the pdb @ 05/13/24 16:42:58.586
  STEP: Waiting for the pdb to be processed @ 05/13/24 16:42:58.589
  STEP: updating the pdb @ 05/13/24 16:42:58.591
  STEP: Waiting for the pdb to be processed @ 05/13/24 16:42:58.597
  STEP: patching the pdb @ 05/13/24 16:42:58.601
  STEP: Waiting for the pdb to be processed @ 05/13/24 16:42:58.606
  STEP: Waiting for the pdb to be deleted @ 05/13/24 16:42:58.612
  May 13 16:42:58.613: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9250" for this suite. @ 05/13/24 16:42:58.615
• [0.047 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:474
  STEP: Creating a kubernetes client @ 05/13/24 16:42:58.621
  May 13 16:42:58.621: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename field-validation @ 05/13/24 16:42:58.622
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:42:58.631
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:42:58.632
  May 13 16:42:58.634: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 16:42:58.673020      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:42:59.673595      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:00.674139      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0513 16:43:01.159563      17 warnings.go:70] unknown field "alpha"
  W0513 16:43:01.159581      17 warnings.go:70] unknown field "beta"
  W0513 16:43:01.159587      17 warnings.go:70] unknown field "delta"
  W0513 16:43:01.159592      17 warnings.go:70] unknown field "epsilon"
  W0513 16:43:01.159602      17 warnings.go:70] unknown field "gamma"
  E0513 16:43:01.675481      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:43:01.681: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7796" for this suite. @ 05/13/24 16:43:01.683
• [3.066 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:270
  STEP: Creating a kubernetes client @ 05/13/24 16:43:01.688
  May 13 16:43:01.688: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename apf @ 05/13/24 16:43:01.689
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:43:01.699
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:43:01.701
  STEP: getting /apis @ 05/13/24 16:43:01.702
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 05/13/24 16:43:01.705
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 05/13/24 16:43:01.706
  STEP: creating @ 05/13/24 16:43:01.706
  STEP: getting @ 05/13/24 16:43:01.718
  STEP: listing @ 05/13/24 16:43:01.721
  STEP: watching @ 05/13/24 16:43:01.722
  May 13 16:43:01.722: INFO: starting watch
  STEP: patching @ 05/13/24 16:43:01.723
  STEP: updating @ 05/13/24 16:43:01.725
  May 13 16:43:01.731: INFO: waiting for watch events with expected annotations
  STEP: getting /status @ 05/13/24 16:43:01.731
  STEP: patching /status @ 05/13/24 16:43:01.733
  STEP: updating /status @ 05/13/24 16:43:01.736
  STEP: deleting @ 05/13/24 16:43:01.757
  STEP: deleting a collection @ 05/13/24 16:43:01.762
  May 13 16:43:01.772: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-28" for this suite. @ 05/13/24 16:43:01.774
• [0.088 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:376
  STEP: Creating a kubernetes client @ 05/13/24 16:43:01.777
  May 13 16:43:01.777: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 16:43:01.778
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:43:01.787
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:43:01.789
  STEP: Creating configMap with name projected-configmap-test-volume-78880dbe-dde9-46bf-8f48-756c4053428a @ 05/13/24 16:43:01.791
  STEP: Creating a pod to test consume configMaps @ 05/13/24 16:43:01.794
  E0513 16:43:02.675896      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:03.676632      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:04.677002      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:05.677249      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:43:05.815
  May 13 16:43:05.820: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-projected-configmaps-f4705f84-7207-40f6-99a0-cbbeb5304437 container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 05/13/24 16:43:05.845
  May 13 16:43:05.859: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3146" for this suite. @ 05/13/24 16:43:05.862
• [4.089 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:175
  STEP: Creating a kubernetes client @ 05/13/24 16:43:05.867
  May 13 16:43:05.867: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 16:43:05.868
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:43:05.879
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:43:05.88
  STEP: Creating configMap with name cm-test-opt-del-0172a32f-87c6-4fd0-a545-8f0873f3d809 @ 05/13/24 16:43:05.884
  STEP: Creating configMap with name cm-test-opt-upd-789133c3-79ed-47e4-9b78-720c6ca73645 @ 05/13/24 16:43:05.887
  STEP: Creating the pod @ 05/13/24 16:43:05.889
  E0513 16:43:06.678166      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:07.678334      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-0172a32f-87c6-4fd0-a545-8f0873f3d809 @ 05/13/24 16:43:07.941
  STEP: Updating configmap cm-test-opt-upd-789133c3-79ed-47e4-9b78-720c6ca73645 @ 05/13/24 16:43:07.945
  STEP: Creating configMap with name cm-test-opt-create-34324e66-2dc6-4bec-828e-220e568d951c @ 05/13/24 16:43:07.949
  STEP: waiting to observe update in volume @ 05/13/24 16:43:07.952
  E0513 16:43:08.678701      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:09.679085      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:10.679274      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:11.679613      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:12.679836      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:13.680653      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:14.680259      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:15.680878      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:16.686440      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:17.684674      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:18.685208      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:19.685486      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:20.686097      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:21.687050      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:22.687562      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:23.688259      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:24.688931      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:25.689021      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:26.689361      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:27.689903      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:28.690615      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:29.690881      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:30.692276      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:31.693591      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:32.693077      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:33.694020      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:34.694139      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:35.694637      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:36.694806      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:37.695855      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:38.695613      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:39.695628      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:40.696734      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:41.697274      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:42.698321      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:43.698992      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:44.698851      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:45.699815      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:46.700156      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:47.700399      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:43:48.197: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8297" for this suite. @ 05/13/24 16:43:48.2
• [42.337 seconds]
------------------------------
SS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:751
  STEP: Creating a kubernetes client @ 05/13/24 16:43:48.204
  May 13 16:43:48.204: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename statefulset @ 05/13/24 16:43:48.205
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:43:48.222
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:43:48.224
  STEP: Creating service test in namespace statefulset-2655 @ 05/13/24 16:43:48.226
  STEP: Creating stateful set ss in namespace statefulset-2655 @ 05/13/24 16:43:48.233
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2655 @ 05/13/24 16:43:48.242
  May 13 16:43:48.246: INFO: Found 0 stateful pods, waiting for 1
  E0513 16:43:48.700497      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:49.701066      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:50.701100      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:51.702289      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:52.702272      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:53.702395      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:54.702625      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:55.703356      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:56.706943      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:57.705657      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:43:58.244: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 05/13/24 16:43:58.244
  May 13 16:43:58.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=statefulset-2655 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May 13 16:43:58.346: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May 13 16:43:58.346: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May 13 16:43:58.346: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May 13 16:43:58.348: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0513 16:43:58.706296      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:43:59.706181      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:00.706145      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:01.706279      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:02.706400      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:03.706535      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:04.706982      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:05.707466      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:06.707614      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:07.707787      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:08.349: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  May 13 16:44:08.349: INFO: Waiting for statefulset status.readyReplicas updated to 0
  May 13 16:44:08.368: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999979764s
  E0513 16:44:08.708087      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:09.377: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.985962237s
  E0513 16:44:09.708438      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:10.383: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.978305953s
  E0513 16:44:10.708637      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:11.387: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.970880904s
  E0513 16:44:11.708740      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:12.390: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.967625425s
  E0513 16:44:12.709515      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:13.392: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.965323404s
  E0513 16:44:13.710174      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:14.398: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.962375285s
  E0513 16:44:14.710744      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:15.404: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.956575062s
  E0513 16:44:15.711398      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:16.407: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.950800134s
  E0513 16:44:16.711555      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:17.411: INFO: Verifying statefulset ss doesn't scale past 3 for another 948.454854ms
  E0513 16:44:17.711917      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2655 @ 05/13/24 16:44:18.411
  May 13 16:44:18.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=statefulset-2655 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May 13 16:44:18.511: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May 13 16:44:18.511: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May 13 16:44:18.511: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May 13 16:44:18.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=statefulset-2655 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May 13 16:44:18.628: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  May 13 16:44:18.628: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May 13 16:44:18.628: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May 13 16:44:18.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=statefulset-2655 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0513 16:44:18.711994      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:18.724: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  May 13 16:44:18.724: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May 13 16:44:18.724: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May 13 16:44:18.726: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  May 13 16:44:18.726: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  May 13 16:44:18.726: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 05/13/24 16:44:18.726
  May 13 16:44:18.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=statefulset-2655 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May 13 16:44:18.825: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May 13 16:44:18.825: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May 13 16:44:18.825: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May 13 16:44:18.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=statefulset-2655 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May 13 16:44:18.925: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May 13 16:44:18.925: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May 13 16:44:18.925: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May 13 16:44:18.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=statefulset-2655 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May 13 16:44:19.023: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May 13 16:44:19.023: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May 13 16:44:19.023: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May 13 16:44:19.023: INFO: Waiting for statefulset status.readyReplicas updated to 0
  May 13 16:44:19.025: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 3
  E0513 16:44:19.712371      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:20.713459      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:21.713673      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:22.714288      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:23.714832      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:24.714733      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:25.714876      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:26.715070      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:27.715222      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:28.715403      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:29.027: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  May 13 16:44:29.027: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  May 13 16:44:29.027: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  May 13 16:44:29.037: INFO: POD   NODE                   PHASE    GRACE  CONDITIONS
  May 13 16:44:29.037: INFO: ss-0  oneke-ip-172-16-100-7  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 16:43:49 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 16:43:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-13 16:44:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-13 16:44:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 16:43:48 +0000 UTC  }]
  May 13 16:44:29.038: INFO: ss-1  oneke-ip-172-16-100-5  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 16:44:09 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 16:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-13 16:44:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-13 16:44:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 16:44:08 +0000 UTC  }]
  May 13 16:44:29.038: INFO: ss-2  oneke-ip-172-16-100-5  Running  30s    [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 16:44:09 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 16:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-13 16:44:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-13 16:44:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 16:44:08 +0000 UTC  }]
  May 13 16:44:29.038: INFO: 
  May 13 16:44:29.038: INFO: StatefulSet ss has not reached scale 0, at 3
  E0513 16:44:29.715733      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:30.041: INFO: POD   NODE                   PHASE      GRACE  CONDITIONS
  May 13 16:44:30.041: INFO: ss-0  oneke-ip-172-16-100-7  Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-05-13 16:44:29 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 16:43:48 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-13 16:44:19 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-13 16:44:19 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 16:43:48 +0000 UTC  }]
  May 13 16:44:30.041: INFO: 
  May 13 16:44:30.041: INFO: StatefulSet ss has not reached scale 0, at 1
  E0513 16:44:30.716799      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:31.045: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.992450625s
  E0513 16:44:31.717757      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:32.049: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.988881351s
  E0513 16:44:32.717786      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:33.050: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.986246748s
  E0513 16:44:33.718052      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:34.056: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.983798349s
  E0513 16:44:34.718362      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:35.060: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.97815317s
  E0513 16:44:35.718610      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:36.063: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.974181815s
  E0513 16:44:36.719221      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:37.066: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.970439511s
  E0513 16:44:37.718949      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:38.072: INFO: Verifying statefulset ss doesn't scale past 0 for another 967.782513ms
  E0513 16:44:38.719396      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2655 @ 05/13/24 16:44:39.075
  May 13 16:44:39.077: INFO: Scaling statefulset ss to 0
  May 13 16:44:39.081: INFO: Waiting for statefulset status.replicas updated to 0
  May 13 16:44:39.082: INFO: Deleting all statefulset in ns statefulset-2655
  May 13 16:44:39.083: INFO: Scaling statefulset ss to 0
  May 13 16:44:39.086: INFO: Waiting for statefulset status.replicas updated to 0
  May 13 16:44:39.087: INFO: Deleting statefulset ss
  May 13 16:44:39.094: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-2655" for this suite. @ 05/13/24 16:44:39.097
• [50.899 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:136
  STEP: Creating a kubernetes client @ 05/13/24 16:44:39.103
  May 13 16:44:39.103: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/13/24 16:44:39.104
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:44:39.115
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:44:39.117
  STEP: create the container to handle the HTTPGet hook request. @ 05/13/24 16:44:39.122
  E0513 16:44:39.719719      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:40.719834      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/13/24 16:44:41.132
  E0513 16:44:41.720564      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:42.721233      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 05/13/24 16:44:43.146
  STEP: delete the pod with lifecycle hook @ 05/13/24 16:44:43.158
  E0513 16:44:43.725658      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:44.722238      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:45.723072      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:46.723469      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:44:47.202: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-854" for this suite. @ 05/13/24 16:44:47.209
• [8.112 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:110
  STEP: Creating a kubernetes client @ 05/13/24 16:44:47.217
  May 13 16:44:47.217: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 16:44:47.217
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:44:47.229
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:44:47.231
  STEP: Creating configMap with name projected-configmap-test-volume-map-1db0730b-8723-4582-a923-09220199827b @ 05/13/24 16:44:47.232
  STEP: Creating a pod to test consume configMaps @ 05/13/24 16:44:47.235
  E0513 16:44:47.724332      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:48.724681      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:49.725986      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:50.726402      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:44:51.253
  May 13 16:44:51.255: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-projected-configmaps-02d1015f-61e0-441c-bb9e-50536cd76558 container agnhost-container: <nil>
  STEP: delete the pod @ 05/13/24 16:44:51.261
  May 13 16:44:51.273: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2259" for this suite. @ 05/13/24 16:44:51.276
• [4.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:902
  STEP: Creating a kubernetes client @ 05/13/24 16:44:51.285
  May 13 16:44:51.285: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename statefulset @ 05/13/24 16:44:51.286
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:44:51.295
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:44:51.297
  STEP: Creating service test in namespace statefulset-8937 @ 05/13/24 16:44:51.298
  STEP: Creating statefulset ss in namespace statefulset-8937 @ 05/13/24 16:44:51.31
  May 13 16:44:51.315: INFO: Found 0 stateful pods, waiting for 1
  E0513 16:44:51.726784      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:52.727541      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:53.727634      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:54.727727      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:55.728119      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:56.728204      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:57.728411      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:58.729379      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:44:59.729647      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:00.730306      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:45:01.323: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 05/13/24 16:45:01.327
  STEP: updating a scale subresource @ 05/13/24 16:45:01.329
  STEP: verifying the statefulset Spec.Replicas was modified @ 05/13/24 16:45:01.333
  STEP: Patch a scale subresource @ 05/13/24 16:45:01.338
  STEP: verifying the statefulset Spec.Replicas was modified @ 05/13/24 16:45:01.352
  May 13 16:45:01.359: INFO: Deleting all statefulset in ns statefulset-8937
  May 13 16:45:01.361: INFO: Scaling statefulset ss to 0
  E0513 16:45:01.731103      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:02.731066      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:03.730966      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:04.732006      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:05.733047      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:06.733515      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:07.733524      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:08.733535      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:09.733784      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:10.734979      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:45:11.375: INFO: Waiting for statefulset status.replicas updated to 0
  May 13 16:45:11.376: INFO: Deleting statefulset ss
  May 13 16:45:11.382: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8937" for this suite. @ 05/13/24 16:45:11.384
• [20.102 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 05/13/24 16:45:11.388
  May 13 16:45:11.388: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename container-runtime @ 05/13/24 16:45:11.389
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:45:11.399
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:45:11.401
  STEP: create the container @ 05/13/24 16:45:11.402
  W0513 16:45:11.409182      17 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 05/13/24 16:45:11.411
  E0513 16:45:11.735087      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:12.735208      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:13.735752      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/13/24 16:45:14.426
  STEP: the container should be terminated @ 05/13/24 16:45:14.433
  STEP: the termination message should be set @ 05/13/24 16:45:14.434
  May 13 16:45:14.434: INFO: Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 05/13/24 16:45:14.435
  May 13 16:45:14.452: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-1214" for this suite. @ 05/13/24 16:45:14.456
• [3.083 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:350
  STEP: Creating a kubernetes client @ 05/13/24 16:45:14.472
  May 13 16:45:14.472: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename field-validation @ 05/13/24 16:45:14.473
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:45:14.488
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:45:14.493
  May 13 16:45:14.495: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  W0513 16:45:14.495897      17 field_validation.go:423] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc0011264d0 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  E0513 16:45:14.736173      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:15.737024      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:16.737503      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0513 16:45:17.063142      17 warnings.go:70] unknown field "alpha"
  W0513 16:45:17.063265      17 warnings.go:70] unknown field "beta"
  W0513 16:45:17.063346      17 warnings.go:70] unknown field "delta"
  W0513 16:45:17.068037      17 warnings.go:70] unknown field "epsilon"
  W0513 16:45:17.068838      17 warnings.go:70] unknown field "gamma"
  May 13 16:45:17.633: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-4562" for this suite. @ 05/13/24 16:45:17.635
• [3.166 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:132
  STEP: Creating a kubernetes client @ 05/13/24 16:45:17.638
  May 13 16:45:17.638: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 16:45:17.639
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:45:17.651
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:45:17.652
  STEP: Creating the pod @ 05/13/24 16:45:17.654
  E0513 16:45:17.738219      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:18.738402      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:19.739636      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:45:20.198: INFO: Successfully updated pod "labelsupdatee84c9d35-7c69-405b-945c-3c3e78f6783a"
  E0513 16:45:20.739829      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:21.740125      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:22.740231      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:23.741243      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:45:24.231: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7420" for this suite. @ 05/13/24 16:45:24.236
• [6.602 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 05/13/24 16:45:24.241
  May 13 16:45:24.241: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename secrets @ 05/13/24 16:45:24.242
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:45:24.256
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:45:24.257
  STEP: Creating secret with name secret-test-77ab702d-c5df-4780-8453-895c452440fb @ 05/13/24 16:45:24.271
  STEP: Creating a pod to test consume secrets @ 05/13/24 16:45:24.275
  E0513 16:45:24.741806      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:25.742258      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:26.743987      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:27.744104      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:45:28.287
  May 13 16:45:28.288: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-secrets-54798840-a137-4b1b-9fee-bbf97f811a56 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/13/24 16:45:28.291
  May 13 16:45:28.301: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7279" for this suite. @ 05/13/24 16:45:28.303
  STEP: Destroying namespace "secret-namespace-5890" for this suite. @ 05/13/24 16:45:28.307
• [4.070 seconds]
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:489
  STEP: Creating a kubernetes client @ 05/13/24 16:45:28.311
  May 13 16:45:28.311: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename deployment @ 05/13/24 16:45:28.312
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:45:28.325
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:45:28.328
  STEP: creating a Deployment @ 05/13/24 16:45:28.331
  May 13 16:45:28.331: INFO: Creating simple deployment test-deployment-8c628
  May 13 16:45:28.337: INFO: new replicaset for deployment "test-deployment-8c628" is yet to be created
  E0513 16:45:28.744366      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:29.744534      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Getting /status @ 05/13/24 16:45:30.341
  May 13 16:45:30.342: INFO: Deployment test-deployment-8c628 has Conditions: [{Available True 2024-05-13 16:45:29 +0000 UTC 2024-05-13 16:45:29 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2024-05-13 16:45:29 +0000 UTC 2024-05-13 16:45:28 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-8c628-5d576bd769" has successfully progressed.}]
  STEP: updating Deployment Status @ 05/13/24 16:45:30.342
  May 13 16:45:30.346: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 16, 45, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 16, 45, 29, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 16, 45, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 16, 45, 28, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-8c628-5d576bd769\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 05/13/24 16:45:30.346
  May 13 16:45:30.347: INFO: Observed &Deployment event: ADDED
  May 13 16:45:30.347: INFO: Observed Deployment test-deployment-8c628 in namespace deployment-3637 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-13 16:45:28 +0000 UTC 2024-05-13 16:45:28 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-8c628-5d576bd769"}
  May 13 16:45:30.348: INFO: Observed &Deployment event: MODIFIED
  May 13 16:45:30.348: INFO: Observed Deployment test-deployment-8c628 in namespace deployment-3637 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-13 16:45:28 +0000 UTC 2024-05-13 16:45:28 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-8c628-5d576bd769"}
  May 13 16:45:30.348: INFO: Observed Deployment test-deployment-8c628 in namespace deployment-3637 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-05-13 16:45:28 +0000 UTC 2024-05-13 16:45:28 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  May 13 16:45:30.348: INFO: Observed &Deployment event: MODIFIED
  May 13 16:45:30.348: INFO: Observed Deployment test-deployment-8c628 in namespace deployment-3637 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-05-13 16:45:28 +0000 UTC 2024-05-13 16:45:28 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  May 13 16:45:30.348: INFO: Observed Deployment test-deployment-8c628 in namespace deployment-3637 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-13 16:45:28 +0000 UTC 2024-05-13 16:45:28 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-8c628-5d576bd769" is progressing.}
  May 13 16:45:30.349: INFO: Observed &Deployment event: MODIFIED
  May 13 16:45:30.349: INFO: Observed Deployment test-deployment-8c628 in namespace deployment-3637 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-05-13 16:45:29 +0000 UTC 2024-05-13 16:45:29 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  May 13 16:45:30.349: INFO: Observed Deployment test-deployment-8c628 in namespace deployment-3637 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-13 16:45:29 +0000 UTC 2024-05-13 16:45:28 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-8c628-5d576bd769" has successfully progressed.}
  May 13 16:45:30.349: INFO: Observed &Deployment event: MODIFIED
  May 13 16:45:30.349: INFO: Observed Deployment test-deployment-8c628 in namespace deployment-3637 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-05-13 16:45:29 +0000 UTC 2024-05-13 16:45:29 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  May 13 16:45:30.349: INFO: Observed Deployment test-deployment-8c628 in namespace deployment-3637 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-13 16:45:29 +0000 UTC 2024-05-13 16:45:28 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-8c628-5d576bd769" has successfully progressed.}
  May 13 16:45:30.349: INFO: Found Deployment test-deployment-8c628 in namespace deployment-3637 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  May 13 16:45:30.350: INFO: Deployment test-deployment-8c628 has an updated status
  STEP: patching the Statefulset Status @ 05/13/24 16:45:30.35
  May 13 16:45:30.350: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  May 13 16:45:30.354: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 05/13/24 16:45:30.354
  May 13 16:45:30.356: INFO: Observed &Deployment event: ADDED
  May 13 16:45:30.356: INFO: Observed deployment test-deployment-8c628 in namespace deployment-3637 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-13 16:45:28 +0000 UTC 2024-05-13 16:45:28 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-8c628-5d576bd769"}
  May 13 16:45:30.356: INFO: Observed &Deployment event: MODIFIED
  May 13 16:45:30.358: INFO: Observed deployment test-deployment-8c628 in namespace deployment-3637 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-13 16:45:28 +0000 UTC 2024-05-13 16:45:28 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-8c628-5d576bd769"}
  May 13 16:45:30.358: INFO: Observed deployment test-deployment-8c628 in namespace deployment-3637 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-05-13 16:45:28 +0000 UTC 2024-05-13 16:45:28 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  May 13 16:45:30.359: INFO: Observed &Deployment event: MODIFIED
  May 13 16:45:30.359: INFO: Observed deployment test-deployment-8c628 in namespace deployment-3637 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-05-13 16:45:28 +0000 UTC 2024-05-13 16:45:28 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  May 13 16:45:30.359: INFO: Observed deployment test-deployment-8c628 in namespace deployment-3637 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-13 16:45:28 +0000 UTC 2024-05-13 16:45:28 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-8c628-5d576bd769" is progressing.}
  May 13 16:45:30.359: INFO: Observed &Deployment event: MODIFIED
  May 13 16:45:30.359: INFO: Observed deployment test-deployment-8c628 in namespace deployment-3637 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-05-13 16:45:29 +0000 UTC 2024-05-13 16:45:29 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  May 13 16:45:30.360: INFO: Observed deployment test-deployment-8c628 in namespace deployment-3637 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-13 16:45:29 +0000 UTC 2024-05-13 16:45:28 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-8c628-5d576bd769" has successfully progressed.}
  May 13 16:45:30.360: INFO: Observed &Deployment event: MODIFIED
  May 13 16:45:30.360: INFO: Observed deployment test-deployment-8c628 in namespace deployment-3637 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-05-13 16:45:29 +0000 UTC 2024-05-13 16:45:29 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  May 13 16:45:30.360: INFO: Observed deployment test-deployment-8c628 in namespace deployment-3637 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-13 16:45:29 +0000 UTC 2024-05-13 16:45:28 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-8c628-5d576bd769" has successfully progressed.}
  May 13 16:45:30.361: INFO: Observed deployment test-deployment-8c628 in namespace deployment-3637 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  May 13 16:45:30.361: INFO: Observed &Deployment event: MODIFIED
  May 13 16:45:30.361: INFO: Found deployment test-deployment-8c628 in namespace deployment-3637 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  May 13 16:45:30.361: INFO: Deployment test-deployment-8c628 has a patched status
  May 13 16:45:30.363: INFO: Deployment "test-deployment-8c628":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-8c628",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3637",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1cf9b6bc-7e7f-4628-8945-488033aa6954",
      ResourceVersion: (string) (len=5) "52112",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851215528,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215528,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215530,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215530,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=3) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215530,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215530,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215530,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215530,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=74) "ReplicaSet \"test-deployment-8c628-5d576bd769\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  May 13 16:45:30.372: INFO: New ReplicaSet "test-deployment-8c628-5d576bd769" of Deployment "test-deployment-8c628":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-8c628-5d576bd769",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3637",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1a2204f8-b8e1-4584-9699-c3329c407c84",
      ResourceVersion: (string) (len=5) "52093",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851215528,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-8c628",
          UID: (types.UID) (len=36) "1cf9b6bc-7e7f-4628-8945-488033aa6954",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215528,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 31 63 66  |k:{\"uid\":\"1cf|
              00000120  39 62 36 62 63 2d 37 65  37 66 2d 34 36 32 38 2d  |9b6bc-7e7f-4628-|
              00000130  38 39 34 35 2d 34 38 38  30 33 33 61 61 36 39 35  |8945-488033aa695|
              00000140  34 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |4\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 13 16:45:30.385: INFO: Pod "test-deployment-8c628-5d576bd769-twzhd" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=38) "test-deployment-8c628-5d576bd769-twzhd",
      GenerateName: (string) (len=33) "test-deployment-8c628-5d576bd769-",
      Namespace: (string) (len=15) "deployment-3637",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "28745d15-b770-46d8-a1dd-f1e124138b69",
      ResourceVersion: (string) (len=5) "52092",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851215528,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
      },
      Annotations: (map[string]string) (len=4) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "f2250541fe3cefdbb8a9535d326bf0edc0e434859a5d8f913d41f0e761b70ee1",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=13) "10.42.3.56/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=13) "10.42.3.56/32",
        (string) (len=33) "k8s.v1.cni.cncf.io/network-status": (string) (len=112) "[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.3.56\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=32) "test-deployment-8c628-5d576bd769",
          UID: (types.UID) (len=36) "1a2204f8-b8e1-4584-9699-c3329c407c84",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=4) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215528,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215528,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 31 61 32 32 30 34 66  38 2d 62 38 65 31 2d 34  |"1a2204f8-b8e1-4|
              000000a0  35 38 34 2d 39 36 39 39  2d 63 33 33 32 39 63 34  |584-9699-c3329c4|
              000000b0  30 37 63 38 34 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |07c84\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "multus",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215528,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=75) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 6b 38 73 2e 76  31 2e 63 6e 69 2e 63 6e  |"f:k8s.v1.cni.cn|
              00000030  63 66 2e 69 6f 2f 6e 65  74 77 6f 72 6b 2d 73 74  |cf.io/network-st|
              00000040  61 74 75 73 22 3a 7b 7d  7d 7d 7d                 |atus":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=659) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 34 32 2e 33 2e 35 36  5c 22 7d 22 3a 7b 22 2e  |.42.3.56\"}":{".|
              00000270  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              00000280  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              00000290  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-92dhz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-92dhz",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215528,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215528,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.7",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.7"
        }
      },
      PodIP: (string) (len=10) "10.42.3.56",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.42.3.56"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851215528,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851215529,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://a4e6903942888f67323f1744d4e83593e840a22932b2d6f1f573e1aca8bb7d98",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 16:45:30.394: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3637" for this suite. @ 05/13/24 16:45:30.396
• [2.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:391
  STEP: Creating a kubernetes client @ 05/13/24 16:45:30.401
  May 13 16:45:30.401: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/13/24 16:45:30.402
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:45:30.422
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:45:30.427
  STEP: set up a multi version CRD @ 05/13/24 16:45:30.428
  May 13 16:45:30.428: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 16:45:30.745629      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:31.746247      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:32.747917      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:33.748560      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: rename a version @ 05/13/24 16:45:33.879
  STEP: check the new version name is served @ 05/13/24 16:45:33.889
  E0513 16:45:34.748844      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 05/13/24 16:45:34.829
  STEP: check the other version is not changed @ 05/13/24 16:45:35.562
  E0513 16:45:35.749700      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:36.750404      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:37.751639      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:45:38.265: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-6563" for this suite. @ 05/13/24 16:45:38.268
• [7.870 seconds]
------------------------------
SS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 05/13/24 16:45:38.272
  May 13 16:45:38.272: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename container-runtime @ 05/13/24 16:45:38.272
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:45:38.283
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:45:38.285
  STEP: create the container @ 05/13/24 16:45:38.287
  W0513 16:45:38.291111      17 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 05/13/24 16:45:38.292
  E0513 16:45:38.752315      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:39.753066      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:40.754225      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/13/24 16:45:41.308
  STEP: the container should be terminated @ 05/13/24 16:45:41.316
  STEP: the termination message should be set @ 05/13/24 16:45:41.317
  May 13 16:45:41.317: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 05/13/24 16:45:41.317
  May 13 16:45:41.340: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-9836" for this suite. @ 05/13/24 16:45:41.343
• [3.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:251
  STEP: Creating a kubernetes client @ 05/13/24 16:45:41.348
  May 13 16:45:41.348: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename downward-api @ 05/13/24 16:45:41.349
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:45:41.361
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:45:41.363
  STEP: Creating a pod to test downward API volume plugin @ 05/13/24 16:45:41.368
  E0513 16:45:41.754742      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:42.755724      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:43.756265      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:44.757083      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:45:45.39
  May 13 16:45:45.391: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod downwardapi-volume-afb660ab-47df-417f-80da-a159a473324d container client-container: <nil>
  STEP: delete the pod @ 05/13/24 16:45:45.395
  May 13 16:45:45.404: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3079" for this suite. @ 05/13/24 16:45:45.406
• [4.061 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:531
  STEP: Creating a kubernetes client @ 05/13/24 16:45:45.411
  May 13 16:45:45.411: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename svcaccounts @ 05/13/24 16:45:45.411
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:45:45.422
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:45:45.424
  May 13 16:45:45.431: INFO: created pod
  E0513 16:45:45.757338      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:46.758250      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:47.758762      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:48.758993      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:45:49.443
  E0513 16:45:49.759574      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:50.759906      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:51.761131      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:52.760611      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:53.760962      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:54.761147      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:55.762238      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:56.762970      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:57.763668      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:58.763633      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:45:59.764538      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:00.765140      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:01.765273      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:02.766209      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:03.766219      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:04.766923      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:05.767896      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:06.768242      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:07.768857      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:08.768991      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:09.769388      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:10.770423      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:11.770839      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:12.771006      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:13.771062      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:14.771866      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:15.772066      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:16.776542      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:17.774036      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:18.774166      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:46:19.444: INFO: polling logs
  May 13 16:46:19.448: INFO: Pod logs: 
  I0513 16:45:46.148405       1 log.go:245] OK: Got token
  I0513 16:45:46.148487       1 log.go:245] validating with in-cluster discovery
  I0513 16:45:46.148894       1 log.go:245] OK: got issuer https://kubernetes.default.svc.cluster.local
  I0513 16:45:46.148957       1 log.go:245] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-304:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0001a5ae0), NotBefore:(*jwt.NumericDate)(0xc0001a5bc8), IssuedAt:(*jwt.NumericDate)(0xc0001a5af0), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-304", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"ba9ca2bb-1a74-43f4-ba53-4121853d1b52"}}}
  I0513 16:45:46.155743       1 log.go:245] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
  I0513 16:45:46.158287       1 log.go:245] OK: Validated signature on JWT
  I0513 16:45:46.158390       1 log.go:245] OK: Got valid claims from token!
  I0513 16:45:46.158462       1 log.go:245] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-304:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0002b77d0), NotBefore:(*jwt.NumericDate)(0xc0002b77f8), IssuedAt:(*jwt.NumericDate)(0xc0002b77d8), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-304", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"ba9ca2bb-1a74-43f4-ba53-4121853d1b52"}}}

  May 13 16:46:19.449: INFO: completed pod
  May 13 16:46:19.452: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-304" for this suite. @ 05/13/24 16:46:19.455
• [34.049 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 05/13/24 16:46:19.46
  May 13 16:46:19.460: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename deployment @ 05/13/24 16:46:19.461
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:46:19.481
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:46:19.489
  May 13 16:46:19.494: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
  May 13 16:46:19.511: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/13/24 16:46:19.511
  E0513 16:46:19.774561      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:20.774882      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:46:21.523: INFO: Creating deployment "test-rolling-update-deployment"
  May 13 16:46:21.525: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  May 13 16:46:21.530: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  E0513 16:46:21.775745      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:22.775945      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:46:23.534: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
  May 13 16:46:23.535: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  May 13 16:46:23.538: INFO: Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9624",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fa0aff83-a2f3-48fd-acc1-7e05a6b5b9ec",
      ResourceVersion: (string) (len=5) "52532",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851215581,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215581,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215581,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215581,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215581,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=83) "ReplicaSet \"test-rolling-update-deployment-7ddb77f68b\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  May 13 16:46:23.563: INFO: New ReplicaSet "test-rolling-update-deployment-7ddb77f68b" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rolling-update-deployment-7ddb77f68b",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9624",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "61dd53c9-8276-4e33-b8bb-87127240a9bf",
      ResourceVersion: (string) (len=5) "52522",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851215581,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "fa0aff83-a2f3-48fd-acc1-7e05a6b5b9ec",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215581,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 66 61 30 61 66 66  38 33 2d 61 32 66 33 2d  |\"fa0aff83-a2f3-|
              00000120  34 38 66 64 2d 61 63 63  31 2d 37 65 30 35 61 36  |48fd-acc1-7e05a6|
              00000130  62 35 62 39 65 63 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |b5b9ec\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 13 16:46:23.564: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
  May 13 16:46:23.564: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9624",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "20d9594a-c93e-4a08-8271-6dca6d248f1e",
      ResourceVersion: (string) (len=5) "52531",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851215579,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "fa0aff83-a2f3-48fd-acc1-7e05a6b5b9ec",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215579,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 66 61 30 61 66 66 38  |"uid\":\"fa0aff8|
              000000b0  33 2d 61 32 66 33 2d 34  38 66 64 2d 61 63 63 31  |3-a2f3-48fd-acc1|
              000000c0  2d 37 65 30 35 61 36 62  35 62 39 65 63 5c 22 7d  |-7e05a6b5b9ec\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 13 16:46:23.567: INFO: Pod "test-rolling-update-deployment-7ddb77f68b-ndjmp" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=47) "test-rolling-update-deployment-7ddb77f68b-ndjmp",
      GenerateName: (string) (len=42) "test-rolling-update-deployment-7ddb77f68b-",
      Namespace: (string) (len=15) "deployment-9624",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0c0f13e1-ba90-4ae2-885c-b70253ccc791",
      ResourceVersion: (string) (len=5) "52521",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851215581,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
      },
      Annotations: (map[string]string) (len=4) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "8e3cf5ff93930f36467b303a2312cfd033c251b0ec62dab10948d918e407f426",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=13) "10.42.1.63/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=13) "10.42.1.63/32",
        (string) (len=33) "k8s.v1.cni.cncf.io/network-status": (string) (len=112) "[{\n    \"name\": \"k8s-pod-network\",\n    \"ips\": [\n        \"10.42.1.63\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=41) "test-rolling-update-deployment-7ddb77f68b",
          UID: (types.UID) (len=36) "61dd53c9-8276-4e33-b8bb-87127240a9bf",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=4) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215581,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215581,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 31  64 64 35 33 63 39 2d 38  |d\":\"61dd53c9-8|
              00000090  32 37 36 2d 34 65 33 33  2d 62 38 62 62 2d 38 37  |276-4e33-b8bb-87|
              000000a0  31 32 37 32 34 30 61 39  62 66 5c 22 7d 22 3a 7b  |127240a9bf\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "multus",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215581,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=75) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 6b 38 73 2e 76  31 2e 63 6e 69 2e 63 6e  |"f:k8s.v1.cni.cn|
              00000030  63 66 2e 69 6f 2f 6e 65  74 77 6f 72 6b 2d 73 74  |cf.io/network-st|
              00000040  61 74 75 73 22 3a 7b 7d  7d 7d 7d                 |atus":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=659) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 34 32 2e 31 2e 36 33  5c 22 7d 22 3a 7b 22 2e  |.42.1.63\"}":{".|
              00000270  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              00000280  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              00000290  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-h86p4",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-h86p4",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=21) "oneke-ip-172-16-100-5",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215581,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851215581,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.16.100.5",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.16.100.5"
        }
      },
      PodIP: (string) (len=10) "10.42.1.63",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.42.1.63"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851215581,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851215582,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253",
          ContainerID: (string) (len=77) "containerd://d29ce19d84f446255b12e3ef32fe1bbcd3c80c00ee61efe2e2509fbff1d7b6fe",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 13 16:46:23.577: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9624" for this suite. @ 05/13/24 16:46:23.579
• [4.123 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:263
  STEP: Creating a kubernetes client @ 05/13/24 16:46:23.585
  May 13 16:46:23.585: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename downward-api @ 05/13/24 16:46:23.585
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:46:23.595
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:46:23.597
  STEP: Creating a pod to test downward API volume plugin @ 05/13/24 16:46:23.599
  E0513 16:46:23.776964      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:24.777062      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:25.777594      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:26.777977      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:46:27.619
  May 13 16:46:27.627: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod downwardapi-volume-773a28d2-c8cb-4dea-b3ac-8fe58a9e925b container client-container: <nil>
  STEP: delete the pod @ 05/13/24 16:46:27.64
  May 13 16:46:27.656: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8045" for this suite. @ 05/13/24 16:46:27.661
• [4.080 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 05/13/24 16:46:27.667
  May 13 16:46:27.667: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename dns @ 05/13/24 16:46:27.668
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:46:27.681
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:46:27.682
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 05/13/24 16:46:27.684
  May 13 16:46:27.692: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-2780  771275b9-2bd1-4631-b262-1aa2792cba22 52587 0 2024-05-13 16:46:27 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2024-05-13 16:46:27 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zfzcn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.47,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zfzcn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  E0513 16:46:27.778638      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:28.778604      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 05/13/24 16:46:29.713
  May 13 16:46:29.713: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-2780 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 16:46:29.713: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 16:46:29.716: INFO: ExecWithOptions: Clientset creation
  May 13 16:46:29.717: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/dns-2780/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0513 16:46:29.778775      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS server is configured on pod... @ 05/13/24 16:46:29.797
  May 13 16:46:29.797: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-2780 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 16:46:29.797: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 16:46:29.797: INFO: ExecWithOptions: Clientset creation
  May 13 16:46:29.797: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/dns-2780/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  May 13 16:46:29.856: INFO: Deleting pod test-dns-nameservers...
  May 13 16:46:29.864: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2780" for this suite. @ 05/13/24 16:46:29.873
• [2.211 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:155
  STEP: Creating a kubernetes client @ 05/13/24 16:46:29.878
  May 13 16:46:29.879: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename secrets @ 05/13/24 16:46:29.879
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:46:29.889
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:46:29.891
  STEP: creating a secret @ 05/13/24 16:46:29.892
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 05/13/24 16:46:29.896
  STEP: patching the secret @ 05/13/24 16:46:29.906
  STEP: deleting the secret using a LabelSelector @ 05/13/24 16:46:29.911
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 05/13/24 16:46:29.915
  May 13 16:46:29.924: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9183" for this suite. @ 05/13/24 16:46:29.926
• [0.052 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:164
  STEP: Creating a kubernetes client @ 05/13/24 16:46:29.931
  May 13 16:46:29.931: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename downward-api @ 05/13/24 16:46:29.932
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:46:29.945
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:46:29.946
  STEP: Creating the pod @ 05/13/24 16:46:29.951
  E0513 16:46:30.778989      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:31.779803      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:46:32.512: INFO: Successfully updated pod "annotationupdate4e35b74b-0dd9-4183-bf73-aedf71eee89e"
  E0513 16:46:32.780131      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:33.780068      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:34.781503      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:35.781532      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:46:36.545: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-704" for this suite. @ 05/13/24 16:46:36.56
• [6.641 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1084
  STEP: Creating a kubernetes client @ 05/13/24 16:46:36.572
  May 13 16:46:36.572: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubectl @ 05/13/24 16:46:36.573
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:46:36.585
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:46:36.586
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/13/24 16:46:36.588
  May 13 16:46:36.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3693 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  May 13 16:46:36.641: INFO: stderr: ""
  May 13 16:46:36.641: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 05/13/24 16:46:36.641
  May 13 16:46:36.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3693 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.36.1-1"}]}} --dry-run=server'
  May 13 16:46:36.693: INFO: stderr: ""
  May 13 16:46:36.693: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/13/24 16:46:36.693
  May 13 16:46:36.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3693 delete pods e2e-test-httpd-pod'
  E0513 16:46:36.782352      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:37.782489      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:46:38.590: INFO: stderr: ""
  May 13 16:46:38.590: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  May 13 16:46:38.590: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3693" for this suite. @ 05/13/24 16:46:38.594
• [2.026 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 05/13/24 16:46:38.598
  May 13 16:46:38.598: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename dns @ 05/13/24 16:46:38.599
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:46:38.611
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:46:38.612
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 05/13/24 16:46:38.614
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 05/13/24 16:46:38.614
  STEP: creating a pod to probe DNS @ 05/13/24 16:46:38.614
  STEP: submitting the pod to kubernetes @ 05/13/24 16:46:38.614
  E0513 16:46:38.782692      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:39.782813      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/13/24 16:46:40.626
  STEP: looking for the results for each expected name from probers @ 05/13/24 16:46:40.632
  May 13 16:46:40.657: INFO: DNS probes using dns-9424/dns-test-0a132db7-6af7-41c0-a979-1d419e61fb85 succeeded

  STEP: deleting the pod @ 05/13/24 16:46:40.657
  May 13 16:46:40.668: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-9424" for this suite. @ 05/13/24 16:46:40.67
• [2.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 05/13/24 16:46:40.676
  May 13 16:46:40.676: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename pods @ 05/13/24 16:46:40.676
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:46:40.687
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:46:40.689
  E0513 16:46:40.783788      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:41.783462      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:42.784466      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:43.785302      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:44.785327      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:45.785914      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:46:46.741
  May 13 16:46:46.743: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod client-envvars-1a353fb2-912b-40eb-b7a9-eaf52a5c67b6 container env3cont: <nil>
  STEP: delete the pod @ 05/13/24 16:46:46.747
  May 13 16:46:46.758: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4676" for this suite. @ 05/13/24 16:46:46.761
• [6.091 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 05/13/24 16:46:46.767
  May 13 16:46:46.767: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename subpath @ 05/13/24 16:46:46.768
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:46:46.782
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:46:46.783
  STEP: Setting up data @ 05/13/24 16:46:46.785
  E0513 16:46:46.785945      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating pod pod-subpath-test-projected-llwb @ 05/13/24 16:46:46.79
  STEP: Creating a pod to test atomic-volume-subpath @ 05/13/24 16:46:46.79
  E0513 16:46:47.786595      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:48.787174      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:49.788040      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:50.788445      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:51.789358      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:52.789487      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:53.789862      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:54.790420      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:55.790940      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:56.790758      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:57.791778      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:58.792054      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:46:59.792845      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:00.792793      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:01.793253      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:02.793684      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:03.794674      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:04.795807      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:05.795575      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:06.796828      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:07.797030      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:08.797350      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:09.797571      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:10.798006      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:47:10.849
  May 13 16:47:10.850: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-subpath-test-projected-llwb container test-container-subpath-projected-llwb: <nil>
  STEP: delete the pod @ 05/13/24 16:47:10.856
  STEP: Deleting pod pod-subpath-test-projected-llwb @ 05/13/24 16:47:10.866
  May 13 16:47:10.866: INFO: Deleting pod "pod-subpath-test-projected-llwb" in namespace "subpath-8956"
  May 13 16:47:10.867: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-8956" for this suite. @ 05/13/24 16:47:10.869
• [24.105 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:380
  STEP: Creating a kubernetes client @ 05/13/24 16:47:10.873
  May 13 16:47:10.873: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename gc @ 05/13/24 16:47:10.874
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:47:10.884
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:47:10.887
  STEP: create the rc @ 05/13/24 16:47:10.89
  W0513 16:47:10.893806      17 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0513 16:47:11.798601      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:12.802549      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:13.802639      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:14.802718      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 05/13/24 16:47:14.898
  STEP: wait for the rc to be deleted @ 05/13/24 16:47:14.924
  E0513 16:47:15.803304      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:16.806137      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:17.805425      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:18.805850      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:19.806628      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 05/13/24 16:47:19.94
  E0513 16:47:20.806872      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:21.807002      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:22.807449      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:23.807625      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:24.807916      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:25.808174      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:26.809357      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:27.810776      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:28.811543      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:29.811667      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:30.811735      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:31.812261      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:32.812362      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:33.813525      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:34.814275      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:35.814747      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:36.816177      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:37.816917      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:38.817113      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:39.818040      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:40.818056      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:41.818424      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:42.818508      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:43.819005      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:44.818833      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:45.819818      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:46.819979      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:47.820741      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:48.822009      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:49.822564      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/13/24 16:47:49.958
  May 13 16:47:50.028: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  May 13 16:47:50.029: INFO: Deleting pod "simpletest.rc-47hms" in namespace "gc-1343"
  May 13 16:47:50.040: INFO: Deleting pod "simpletest.rc-4jcxz" in namespace "gc-1343"
  May 13 16:47:50.050: INFO: Deleting pod "simpletest.rc-4vb26" in namespace "gc-1343"
  May 13 16:47:50.062: INFO: Deleting pod "simpletest.rc-5cbsq" in namespace "gc-1343"
  May 13 16:47:50.068: INFO: Deleting pod "simpletest.rc-5lxk5" in namespace "gc-1343"
  May 13 16:47:50.079: INFO: Deleting pod "simpletest.rc-5wj4q" in namespace "gc-1343"
  May 13 16:47:50.088: INFO: Deleting pod "simpletest.rc-64pj6" in namespace "gc-1343"
  May 13 16:47:50.098: INFO: Deleting pod "simpletest.rc-6cn6l" in namespace "gc-1343"
  May 13 16:47:50.103: INFO: Deleting pod "simpletest.rc-6l2b4" in namespace "gc-1343"
  May 13 16:47:50.113: INFO: Deleting pod "simpletest.rc-6n6dq" in namespace "gc-1343"
  May 13 16:47:50.123: INFO: Deleting pod "simpletest.rc-6w9r8" in namespace "gc-1343"
  May 13 16:47:50.133: INFO: Deleting pod "simpletest.rc-74d47" in namespace "gc-1343"
  May 13 16:47:50.142: INFO: Deleting pod "simpletest.rc-79xqr" in namespace "gc-1343"
  May 13 16:47:50.156: INFO: Deleting pod "simpletest.rc-7c56l" in namespace "gc-1343"
  May 13 16:47:50.166: INFO: Deleting pod "simpletest.rc-7fjbf" in namespace "gc-1343"
  May 13 16:47:50.182: INFO: Deleting pod "simpletest.rc-7h5s7" in namespace "gc-1343"
  May 13 16:47:50.194: INFO: Deleting pod "simpletest.rc-7zvkl" in namespace "gc-1343"
  May 13 16:47:50.201: INFO: Deleting pod "simpletest.rc-84ffj" in namespace "gc-1343"
  May 13 16:47:50.219: INFO: Deleting pod "simpletest.rc-8hw42" in namespace "gc-1343"
  May 13 16:47:50.228: INFO: Deleting pod "simpletest.rc-8qznb" in namespace "gc-1343"
  May 13 16:47:50.234: INFO: Deleting pod "simpletest.rc-8sfp7" in namespace "gc-1343"
  May 13 16:47:50.244: INFO: Deleting pod "simpletest.rc-8wbk5" in namespace "gc-1343"
  May 13 16:47:50.258: INFO: Deleting pod "simpletest.rc-92j6w" in namespace "gc-1343"
  May 13 16:47:50.266: INFO: Deleting pod "simpletest.rc-99xx9" in namespace "gc-1343"
  May 13 16:47:50.276: INFO: Deleting pod "simpletest.rc-9ms6n" in namespace "gc-1343"
  May 13 16:47:50.287: INFO: Deleting pod "simpletest.rc-9s68p" in namespace "gc-1343"
  May 13 16:47:50.294: INFO: Deleting pod "simpletest.rc-bfgbj" in namespace "gc-1343"
  May 13 16:47:50.304: INFO: Deleting pod "simpletest.rc-bmmnr" in namespace "gc-1343"
  May 13 16:47:50.309: INFO: Deleting pod "simpletest.rc-clhf4" in namespace "gc-1343"
  May 13 16:47:50.320: INFO: Deleting pod "simpletest.rc-d6xt6" in namespace "gc-1343"
  May 13 16:47:50.329: INFO: Deleting pod "simpletest.rc-d82v8" in namespace "gc-1343"
  May 13 16:47:50.339: INFO: Deleting pod "simpletest.rc-d89qc" in namespace "gc-1343"
  May 13 16:47:50.348: INFO: Deleting pod "simpletest.rc-dns2v" in namespace "gc-1343"
  May 13 16:47:50.363: INFO: Deleting pod "simpletest.rc-dqmj9" in namespace "gc-1343"
  May 13 16:47:50.380: INFO: Deleting pod "simpletest.rc-dvcc2" in namespace "gc-1343"
  May 13 16:47:50.392: INFO: Deleting pod "simpletest.rc-f9bps" in namespace "gc-1343"
  May 13 16:47:50.402: INFO: Deleting pod "simpletest.rc-g464g" in namespace "gc-1343"
  May 13 16:47:50.409: INFO: Deleting pod "simpletest.rc-gccb6" in namespace "gc-1343"
  May 13 16:47:50.419: INFO: Deleting pod "simpletest.rc-gfvq6" in namespace "gc-1343"
  May 13 16:47:50.430: INFO: Deleting pod "simpletest.rc-gmmzg" in namespace "gc-1343"
  May 13 16:47:50.455: INFO: Deleting pod "simpletest.rc-gn5t9" in namespace "gc-1343"
  May 13 16:47:50.546: INFO: Deleting pod "simpletest.rc-gv94h" in namespace "gc-1343"
  May 13 16:47:50.590: INFO: Deleting pod "simpletest.rc-gx42q" in namespace "gc-1343"
  May 13 16:47:50.605: INFO: Deleting pod "simpletest.rc-h2kgp" in namespace "gc-1343"
  May 13 16:47:50.612: INFO: Deleting pod "simpletest.rc-h6ftv" in namespace "gc-1343"
  May 13 16:47:50.621: INFO: Deleting pod "simpletest.rc-hzp2h" in namespace "gc-1343"
  May 13 16:47:50.629: INFO: Deleting pod "simpletest.rc-j9nrv" in namespace "gc-1343"
  May 13 16:47:50.640: INFO: Deleting pod "simpletest.rc-jgxvm" in namespace "gc-1343"
  May 13 16:47:50.648: INFO: Deleting pod "simpletest.rc-jjf6k" in namespace "gc-1343"
  May 13 16:47:50.655: INFO: Deleting pod "simpletest.rc-jztgm" in namespace "gc-1343"
  May 13 16:47:50.664: INFO: Deleting pod "simpletest.rc-k2qg7" in namespace "gc-1343"
  May 13 16:47:50.670: INFO: Deleting pod "simpletest.rc-kj86l" in namespace "gc-1343"
  May 13 16:47:50.683: INFO: Deleting pod "simpletest.rc-km2kj" in namespace "gc-1343"
  May 13 16:47:50.693: INFO: Deleting pod "simpletest.rc-kn6jx" in namespace "gc-1343"
  May 13 16:47:50.700: INFO: Deleting pod "simpletest.rc-ktblz" in namespace "gc-1343"
  May 13 16:47:50.708: INFO: Deleting pod "simpletest.rc-l9ndn" in namespace "gc-1343"
  May 13 16:47:50.717: INFO: Deleting pod "simpletest.rc-llsjz" in namespace "gc-1343"
  May 13 16:47:50.725: INFO: Deleting pod "simpletest.rc-msttb" in namespace "gc-1343"
  May 13 16:47:50.733: INFO: Deleting pod "simpletest.rc-mv5z5" in namespace "gc-1343"
  May 13 16:47:50.743: INFO: Deleting pod "simpletest.rc-nm46v" in namespace "gc-1343"
  May 13 16:47:50.750: INFO: Deleting pod "simpletest.rc-nnsql" in namespace "gc-1343"
  May 13 16:47:50.758: INFO: Deleting pod "simpletest.rc-nrzkw" in namespace "gc-1343"
  May 13 16:47:50.765: INFO: Deleting pod "simpletest.rc-ntrbv" in namespace "gc-1343"
  May 13 16:47:50.802: INFO: Deleting pod "simpletest.rc-nvxn4" in namespace "gc-1343"
  E0513 16:47:50.823586      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:47:50.851: INFO: Deleting pod "simpletest.rc-p9rj5" in namespace "gc-1343"
  May 13 16:47:50.901: INFO: Deleting pod "simpletest.rc-pf8mb" in namespace "gc-1343"
  May 13 16:47:50.953: INFO: Deleting pod "simpletest.rc-pgthh" in namespace "gc-1343"
  May 13 16:47:51.004: INFO: Deleting pod "simpletest.rc-pkhnl" in namespace "gc-1343"
  May 13 16:47:51.048: INFO: Deleting pod "simpletest.rc-pwbfn" in namespace "gc-1343"
  May 13 16:47:51.100: INFO: Deleting pod "simpletest.rc-q84bm" in namespace "gc-1343"
  May 13 16:47:51.153: INFO: Deleting pod "simpletest.rc-qmjnb" in namespace "gc-1343"
  May 13 16:47:51.199: INFO: Deleting pod "simpletest.rc-rhqzb" in namespace "gc-1343"
  May 13 16:47:51.258: INFO: Deleting pod "simpletest.rc-rr8gf" in namespace "gc-1343"
  May 13 16:47:51.303: INFO: Deleting pod "simpletest.rc-rv4h6" in namespace "gc-1343"
  May 13 16:47:51.349: INFO: Deleting pod "simpletest.rc-rzkc9" in namespace "gc-1343"
  May 13 16:47:51.400: INFO: Deleting pod "simpletest.rc-srnpg" in namespace "gc-1343"
  May 13 16:47:51.466: INFO: Deleting pod "simpletest.rc-srwrp" in namespace "gc-1343"
  May 13 16:47:51.509: INFO: Deleting pod "simpletest.rc-sv4xz" in namespace "gc-1343"
  May 13 16:47:51.550: INFO: Deleting pod "simpletest.rc-sv9c8" in namespace "gc-1343"
  May 13 16:47:51.600: INFO: Deleting pod "simpletest.rc-t8kfg" in namespace "gc-1343"
  May 13 16:47:51.652: INFO: Deleting pod "simpletest.rc-tf9hj" in namespace "gc-1343"
  May 13 16:47:51.702: INFO: Deleting pod "simpletest.rc-v2l6t" in namespace "gc-1343"
  May 13 16:47:51.750: INFO: Deleting pod "simpletest.rc-v72qq" in namespace "gc-1343"
  May 13 16:47:51.800: INFO: Deleting pod "simpletest.rc-vbwjc" in namespace "gc-1343"
  E0513 16:47:51.823999      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:47:51.851: INFO: Deleting pod "simpletest.rc-vk8gt" in namespace "gc-1343"
  May 13 16:47:51.902: INFO: Deleting pod "simpletest.rc-vp85d" in namespace "gc-1343"
  May 13 16:47:51.949: INFO: Deleting pod "simpletest.rc-wmbkx" in namespace "gc-1343"
  May 13 16:47:52.000: INFO: Deleting pod "simpletest.rc-wrz8w" in namespace "gc-1343"
  May 13 16:47:52.054: INFO: Deleting pod "simpletest.rc-ws8bt" in namespace "gc-1343"
  May 13 16:47:52.100: INFO: Deleting pod "simpletest.rc-x2fwp" in namespace "gc-1343"
  May 13 16:47:52.149: INFO: Deleting pod "simpletest.rc-x8pfv" in namespace "gc-1343"
  May 13 16:47:52.202: INFO: Deleting pod "simpletest.rc-x8zvl" in namespace "gc-1343"
  May 13 16:47:52.252: INFO: Deleting pod "simpletest.rc-xhfmb" in namespace "gc-1343"
  May 13 16:47:52.317: INFO: Deleting pod "simpletest.rc-xwh64" in namespace "gc-1343"
  May 13 16:47:52.349: INFO: Deleting pod "simpletest.rc-z6sf4" in namespace "gc-1343"
  May 13 16:47:52.401: INFO: Deleting pod "simpletest.rc-z76nf" in namespace "gc-1343"
  May 13 16:47:52.448: INFO: Deleting pod "simpletest.rc-zbb46" in namespace "gc-1343"
  May 13 16:47:52.500: INFO: Deleting pod "simpletest.rc-zq27b" in namespace "gc-1343"
  May 13 16:47:52.549: INFO: Deleting pod "simpletest.rc-zrznc" in namespace "gc-1343"
  May 13 16:47:52.601: INFO: Deleting pod "simpletest.rc-ztvs8" in namespace "gc-1343"
  May 13 16:47:52.649: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1343" for this suite. @ 05/13/24 16:47:52.695
• [41.874 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:170
  STEP: Creating a kubernetes client @ 05/13/24 16:47:52.748
  May 13 16:47:52.748: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename security-context @ 05/13/24 16:47:52.749
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:47:52.759
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:47:52.761
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 05/13/24 16:47:52.764
  E0513 16:47:52.824592      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:53.824683      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:54.825321      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:55.825726      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:56.826429      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:57.826610      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:58.827676      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:47:59.828397      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:00.829447      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:01.830513      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:48:02.79
  May 13 16:48:02.791: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod security-context-cf08ca06-de2f-4361-a27f-028810081b7f container test-container: <nil>
  STEP: delete the pod @ 05/13/24 16:48:02.794
  May 13 16:48:02.804: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-3206" for this suite. @ 05/13/24 16:48:02.806
• [10.062 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 05/13/24 16:48:02.81
  May 13 16:48:02.810: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename sched-preemption @ 05/13/24 16:48:02.811
  E0513 16:48:02.838902      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:48:02.84
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:48:02.842
  May 13 16:48:02.852: INFO: Waiting up to 1m0s for all nodes to be ready
  E0513 16:48:03.839496      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:04.841019      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:05.840415      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:06.840669      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:07.841411      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:08.842111      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:09.842320      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:10.843009      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:11.843937      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:12.844150      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:13.844401      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:14.844698      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:15.844693      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:16.844810      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:17.845548      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:18.845960      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:19.846244      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:20.846540      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:21.846890      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:22.847557      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:23.847638      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:24.848794      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:25.849604      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:26.849709      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:27.850866      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:28.851940      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:29.851915      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:30.852011      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:31.852799      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:32.852814      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:33.853697      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:34.854603      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:35.855215      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:36.855987      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:37.856062      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:38.859527      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:39.860418      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:40.860476      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:41.861507      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:42.862176      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:43.863456      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:44.863473      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:45.864386      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:46.864602      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:47.865647      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:48.865656      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:49.866410      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:50.867342      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:51.867983      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:52.868554      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:53.869399      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:54.871879      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:55.871927      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:56.872477      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:57.872875      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:58.874003      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:48:59.874819      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:00.878283      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:01.877193      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:49:02.854: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 05/13/24 16:49:02.855
  May 13 16:49:02.872: INFO: Created pod: pod0-0-sched-preemption-low-priority
  E0513 16:49:02.877996      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:49:02.882: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  May 13 16:49:02.904: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  May 13 16:49:02.916: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 05/13/24 16:49:02.918
  E0513 16:49:03.878138      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:04.878366      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 05/13/24 16:49:04.926
  E0513 16:49:05.878777      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:06.878988      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:07.879238      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:08.879391      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:09.880465      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:10.880825      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:49:10.993: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-1868" for this suite. @ 05/13/24 16:49:10.995
• [68.189 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 05/13/24 16:49:11.001
  May 13 16:49:11.001: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename pod-network-test @ 05/13/24 16:49:11.002
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:49:11.012
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:49:11.013
  STEP: Performing setup for networking test in namespace pod-network-test-8979 @ 05/13/24 16:49:11.015
  STEP: creating a selector @ 05/13/24 16:49:11.015
  STEP: Creating the service pods in kubernetes @ 05/13/24 16:49:11.015
  May 13 16:49:11.015: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0513 16:49:11.880932      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:12.881090      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:13.881511      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:14.882218      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:15.883143      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:16.884096      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:17.884888      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:18.884884      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:19.884894      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:20.885646      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:21.886674      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:22.888358      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 05/13/24 16:49:23.095
  E0513 16:49:23.887853      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:24.889079      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:49:25.147: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  May 13 16:49:25.147: INFO: Going to poll 10.42.1.124 on port 8081 at least 0 times, with a maximum of 34 tries before failing
  May 13 16:49:25.152: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.42.1.124 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8979 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 16:49:25.153: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 16:49:25.155: INFO: ExecWithOptions: Clientset creation
  May 13 16:49:25.156: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-8979/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.42.1.124+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0513 16:49:25.889308      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:49:26.236: INFO: Found all 1 expected endpoints: [netserver-0]
  May 13 16:49:26.236: INFO: Going to poll 10.42.3.112 on port 8081 at least 0 times, with a maximum of 34 tries before failing
  May 13 16:49:26.243: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.42.3.112 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8979 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 16:49:26.244: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 16:49:26.247: INFO: ExecWithOptions: Clientset creation
  May 13 16:49:26.249: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-8979/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.42.3.112+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0513 16:49:26.889972      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:49:27.320: INFO: Found all 1 expected endpoints: [netserver-1]
  May 13 16:49:27.321: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-8979" for this suite. @ 05/13/24 16:49:27.323
• [16.326 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:695
  STEP: Creating a kubernetes client @ 05/13/24 16:49:27.328
  May 13 16:49:27.328: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename resourcequota @ 05/13/24 16:49:27.329
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:49:27.34
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:49:27.341
  STEP: Creating a ResourceQuota with terminating scope @ 05/13/24 16:49:27.343
  STEP: Ensuring ResourceQuota status is calculated @ 05/13/24 16:49:27.346
  E0513 16:49:27.890136      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:28.890030      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 05/13/24 16:49:29.349
  STEP: Ensuring ResourceQuota status is calculated @ 05/13/24 16:49:29.357
  E0513 16:49:29.890910      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:30.891261      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 05/13/24 16:49:31.36
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 05/13/24 16:49:31.367
  E0513 16:49:31.891605      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:32.891680      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 05/13/24 16:49:33.369
  E0513 16:49:33.892091      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:34.892676      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/13/24 16:49:35.372
  STEP: Ensuring resource quota status released the pod usage @ 05/13/24 16:49:35.38
  E0513 16:49:35.892508      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:36.893566      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 05/13/24 16:49:37.382
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 05/13/24 16:49:37.391
  E0513 16:49:37.894505      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:38.894757      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 05/13/24 16:49:39.394
  E0513 16:49:39.897045      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:40.897338      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/13/24 16:49:41.395
  STEP: Ensuring resource quota status released the pod usage @ 05/13/24 16:49:41.408
  E0513 16:49:41.898791      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:42.900738      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:49:43.411: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2951" for this suite. @ 05/13/24 16:49:43.414
• [16.090 seconds]
------------------------------
SS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 05/13/24 16:49:43.42
  May 13 16:49:43.420: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename container-runtime @ 05/13/24 16:49:43.421
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:49:43.431
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:49:43.433
  STEP: create the container @ 05/13/24 16:49:43.434
  W0513 16:49:43.441938      17 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 05/13/24 16:49:43.442
  E0513 16:49:43.901590      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:44.902084      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:45.902598      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/13/24 16:49:46.459
  STEP: the container should be terminated @ 05/13/24 16:49:46.46
  STEP: the termination message should be set @ 05/13/24 16:49:46.46
  May 13 16:49:46.460: INFO: Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 05/13/24 16:49:46.46
  May 13 16:49:46.469: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-3597" for this suite. @ 05/13/24 16:49:46.472
• [3.056 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:86
  STEP: Creating a kubernetes client @ 05/13/24 16:49:46.476
  May 13 16:49:46.477: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename downward-api @ 05/13/24 16:49:46.477
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:49:46.488
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:49:46.49
  STEP: Creating a pod to test downward API volume plugin @ 05/13/24 16:49:46.491
  E0513 16:49:46.903552      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:47.906761      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:48.906598      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:49.909185      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:49:50.516
  May 13 16:49:50.524: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod downwardapi-volume-bcf474e8-7d41-41f1-9b4f-1098fd4916c7 container client-container: <nil>
  STEP: delete the pod @ 05/13/24 16:49:50.552
  May 13 16:49:50.564: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3217" for this suite. @ 05/13/24 16:49:50.567
• [4.096 seconds]
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:334
  STEP: Creating a kubernetes client @ 05/13/24 16:49:50.574
  May 13 16:49:50.574: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename sched-pred @ 05/13/24 16:49:50.574
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:49:50.584
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:49:50.586
  May 13 16:49:50.587: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  May 13 16:49:50.590: INFO: Waiting for terminating namespaces to be deleted...
  May 13 16:49:50.592: INFO: 
  Logging pods the apiserver thinks is on node oneke-ip-172-16-100-5 before test
  May 13 16:49:50.599: INFO: kube-proxy-oneke-ip-172-16-100-5 from kube-system started at 2024-05-13 15:01:47 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.599: INFO: 	Container kube-proxy ready: true, restart count 0
  May 13 16:49:50.599: INFO: rke2-canal-clmwk from kube-system started at 2024-05-13 15:01:49 +0000 UTC (2 container statuses recorded)
  May 13 16:49:50.599: INFO: 	Container calico-node ready: true, restart count 0
  May 13 16:49:50.599: INFO: 	Container kube-flannel ready: true, restart count 0
  May 13 16:49:50.599: INFO: rke2-multus-lqh56 from kube-system started at 2024-05-13 15:01:48 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.599: INFO: 	Container kube-rke2-multus ready: true, restart count 0
  May 13 16:49:50.599: INFO: rke2-multus-rke2-whereabouts-vdcd7 from kube-system started at 2024-05-13 16:02:22 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.599: INFO: 	Container rke2-whereabouts ready: true, restart count 0
  May 13 16:49:50.599: INFO: engine-image-ei-5cefaf2b-vfc6s from longhorn-system started at 2024-05-13 16:02:23 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.599: INFO: 	Container engine-image-ei-5cefaf2b ready: true, restart count 0
  May 13 16:49:50.599: INFO: instance-manager-55ef780465ba1d7a0e8ce28cb186ca26 from longhorn-system started at 2024-05-13 16:01:57 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.599: INFO: 	Container instance-manager ready: true, restart count 0
  May 13 16:49:50.599: INFO: longhorn-csi-plugin-tb722 from longhorn-system started at 2024-05-13 16:01:54 +0000 UTC (3 container statuses recorded)
  May 13 16:49:50.599: INFO: 	Container longhorn-csi-plugin ready: true, restart count 0
  May 13 16:49:50.599: INFO: 	Container longhorn-liveness-probe ready: true, restart count 0
  May 13 16:49:50.599: INFO: 	Container node-driver-registrar ready: true, restart count 0
  May 13 16:49:50.599: INFO: longhorn-manager-lh6mb from longhorn-system started at 2024-05-13 16:01:53 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.599: INFO: 	Container longhorn-manager ready: true, restart count 0
  May 13 16:49:50.599: INFO: one-metallb-speaker-8tc2q from metallb-system started at 2024-05-13 16:01:52 +0000 UTC (4 container statuses recorded)
  May 13 16:49:50.599: INFO: 	Container frr ready: true, restart count 0
  May 13 16:49:50.599: INFO: 	Container frr-metrics ready: true, restart count 0
  May 13 16:49:50.599: INFO: 	Container reloader ready: true, restart count 0
  May 13 16:49:50.599: INFO: 	Container speaker ready: true, restart count 0
  May 13 16:49:50.599: INFO: sonobuoy from sonobuoy started at 2024-05-13 15:21:42 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.599: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  May 13 16:49:50.599: INFO: sonobuoy-systemd-logs-daemon-set-6a4de22bea6049d2-97q5l from sonobuoy started at 2024-05-13 15:21:45 +0000 UTC (2 container statuses recorded)
  May 13 16:49:50.599: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 13 16:49:50.599: INFO: 	Container systemd-logs ready: true, restart count 0
  May 13 16:49:50.599: INFO: one-traefik-795c67dd65-zptl9 from traefik-system started at 2024-05-13 16:01:53 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.599: INFO: 	Container one-traefik ready: true, restart count 0
  May 13 16:49:50.599: INFO: 
  Logging pods the apiserver thinks is on node oneke-ip-172-16-100-7 before test
  May 13 16:49:50.607: INFO: kube-proxy-oneke-ip-172-16-100-7 from kube-system started at 2024-05-13 15:11:56 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container kube-proxy ready: true, restart count 0
  May 13 16:49:50.607: INFO: rke2-canal-2xv8f from kube-system started at 2024-05-13 15:11:57 +0000 UTC (2 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container calico-node ready: true, restart count 0
  May 13 16:49:50.607: INFO: 	Container kube-flannel ready: true, restart count 0
  May 13 16:49:50.607: INFO: rke2-coredns-rke2-coredns-5b7d84d764-x58ng from kube-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container coredns ready: true, restart count 0
  May 13 16:49:50.607: INFO: rke2-coredns-rke2-coredns-autoscaler-b49765765-9rbrr from kube-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container autoscaler ready: true, restart count 0
  May 13 16:49:50.607: INFO: rke2-metrics-server-655477f655-cnt8z from kube-system started at 2024-05-13 15:25:23 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container metrics-server ready: true, restart count 0
  May 13 16:49:50.607: INFO: rke2-multus-rke2-whereabouts-q2xbr from kube-system started at 2024-05-13 15:11:57 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container rke2-whereabouts ready: true, restart count 1
  May 13 16:49:50.607: INFO: rke2-multus-txzvb from kube-system started at 2024-05-13 15:11:57 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container kube-rke2-multus ready: true, restart count 2
  May 13 16:49:50.607: INFO: rke2-snapshot-controller-59cc9cd8f4-pk92s from kube-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container rke2-snapshot-controller ready: true, restart count 0
  May 13 16:49:50.607: INFO: rke2-snapshot-validation-webhook-54c5989b65-l9mj7 from kube-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container rke2-snapshot-validation-webhook ready: true, restart count 0
  May 13 16:49:50.607: INFO: csi-attacher-5468df46f9-mnkf6 from longhorn-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container csi-attacher ready: true, restart count 0
  May 13 16:49:50.607: INFO: csi-provisioner-76d7d4cb9-zl6gj from longhorn-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container csi-provisioner ready: true, restart count 0
  May 13 16:49:50.607: INFO: csi-resizer-7b5d5bd7cd-n9tjz from longhorn-system started at 2024-05-13 15:25:23 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container csi-resizer ready: true, restart count 0
  May 13 16:49:50.607: INFO: csi-snapshotter-6d8678cd76-dpskt from longhorn-system started at 2024-05-13 15:25:24 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container csi-snapshotter ready: true, restart count 0
  May 13 16:49:50.607: INFO: engine-image-ei-5cefaf2b-9j4sf from longhorn-system started at 2024-05-13 15:12:12 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container engine-image-ei-5cefaf2b ready: true, restart count 0
  May 13 16:49:50.607: INFO: instance-manager-1185f042d485c71dda675ea2338775ca from longhorn-system started at 2024-05-13 15:12:37 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container instance-manager ready: true, restart count 0
  May 13 16:49:50.607: INFO: longhorn-csi-plugin-wmfzz from longhorn-system started at 2024-05-13 15:12:12 +0000 UTC (3 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container longhorn-csi-plugin ready: true, restart count 0
  May 13 16:49:50.607: INFO: 	Container longhorn-liveness-probe ready: true, restart count 0
  May 13 16:49:50.607: INFO: 	Container node-driver-registrar ready: true, restart count 0
  May 13 16:49:50.607: INFO: longhorn-manager-42nnc from longhorn-system started at 2024-05-13 15:12:12 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container longhorn-manager ready: true, restart count 0
  May 13 16:49:50.607: INFO: one-metallb-controller-5dbfcc4788-79tmz from metallb-system started at 2024-05-13 15:25:23 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container controller ready: true, restart count 0
  May 13 16:49:50.607: INFO: one-metallb-speaker-mt7mb from metallb-system started at 2024-05-13 15:12:12 +0000 UTC (4 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container frr ready: true, restart count 0
  May 13 16:49:50.607: INFO: 	Container frr-metrics ready: true, restart count 0
  May 13 16:49:50.607: INFO: 	Container reloader ready: true, restart count 0
  May 13 16:49:50.607: INFO: 	Container speaker ready: true, restart count 0
  May 13 16:49:50.607: INFO: sonobuoy-systemd-logs-daemon-set-6a4de22bea6049d2-dx4h8 from sonobuoy started at 2024-05-13 15:21:45 +0000 UTC (2 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 13 16:49:50.607: INFO: 	Container systemd-logs ready: true, restart count 0
  May 13 16:49:50.607: INFO: one-traefik-795c67dd65-k9k5j from traefik-system started at 2024-05-13 15:12:14 +0000 UTC (1 container statuses recorded)
  May 13 16:49:50.607: INFO: 	Container one-traefik ready: true, restart count 0
  STEP: verifying the node has the label node oneke-ip-172-16-100-5 @ 05/13/24 16:49:50.628
  STEP: verifying the node has the label node oneke-ip-172-16-100-7 @ 05/13/24 16:49:50.642
  May 13 16:49:50.656: INFO: Pod kube-proxy-oneke-ip-172-16-100-5 requesting resource cpu=250m on Node oneke-ip-172-16-100-5
  May 13 16:49:50.656: INFO: Pod kube-proxy-oneke-ip-172-16-100-7 requesting resource cpu=250m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod rke2-canal-2xv8f requesting resource cpu=250m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod rke2-canal-clmwk requesting resource cpu=250m on Node oneke-ip-172-16-100-5
  May 13 16:49:50.656: INFO: Pod rke2-coredns-rke2-coredns-5b7d84d764-x58ng requesting resource cpu=100m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod rke2-coredns-rke2-coredns-autoscaler-b49765765-9rbrr requesting resource cpu=25m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod rke2-metrics-server-655477f655-cnt8z requesting resource cpu=100m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod rke2-multus-lqh56 requesting resource cpu=250m on Node oneke-ip-172-16-100-5
  May 13 16:49:50.656: INFO: Pod rke2-multus-rke2-whereabouts-q2xbr requesting resource cpu=100m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod rke2-multus-rke2-whereabouts-vdcd7 requesting resource cpu=100m on Node oneke-ip-172-16-100-5
  May 13 16:49:50.656: INFO: Pod rke2-multus-txzvb requesting resource cpu=250m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod rke2-snapshot-controller-59cc9cd8f4-pk92s requesting resource cpu=0m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod rke2-snapshot-validation-webhook-54c5989b65-l9mj7 requesting resource cpu=0m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod csi-attacher-5468df46f9-mnkf6 requesting resource cpu=0m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod csi-provisioner-76d7d4cb9-zl6gj requesting resource cpu=0m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod csi-resizer-7b5d5bd7cd-n9tjz requesting resource cpu=0m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod csi-snapshotter-6d8678cd76-dpskt requesting resource cpu=0m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod engine-image-ei-5cefaf2b-9j4sf requesting resource cpu=0m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod engine-image-ei-5cefaf2b-vfc6s requesting resource cpu=0m on Node oneke-ip-172-16-100-5
  May 13 16:49:50.656: INFO: Pod instance-manager-1185f042d485c71dda675ea2338775ca requesting resource cpu=240m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod instance-manager-55ef780465ba1d7a0e8ce28cb186ca26 requesting resource cpu=240m on Node oneke-ip-172-16-100-5
  May 13 16:49:50.656: INFO: Pod longhorn-csi-plugin-tb722 requesting resource cpu=0m on Node oneke-ip-172-16-100-5
  May 13 16:49:50.656: INFO: Pod longhorn-csi-plugin-wmfzz requesting resource cpu=0m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod longhorn-manager-42nnc requesting resource cpu=0m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod longhorn-manager-lh6mb requesting resource cpu=0m on Node oneke-ip-172-16-100-5
  May 13 16:49:50.656: INFO: Pod one-metallb-controller-5dbfcc4788-79tmz requesting resource cpu=0m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod one-metallb-speaker-8tc2q requesting resource cpu=0m on Node oneke-ip-172-16-100-5
  May 13 16:49:50.656: INFO: Pod one-metallb-speaker-mt7mb requesting resource cpu=0m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod sonobuoy requesting resource cpu=0m on Node oneke-ip-172-16-100-5
  May 13 16:49:50.656: INFO: Pod sonobuoy-systemd-logs-daemon-set-6a4de22bea6049d2-97q5l requesting resource cpu=0m on Node oneke-ip-172-16-100-5
  May 13 16:49:50.656: INFO: Pod sonobuoy-systemd-logs-daemon-set-6a4de22bea6049d2-dx4h8 requesting resource cpu=0m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod one-traefik-795c67dd65-k9k5j requesting resource cpu=0m on Node oneke-ip-172-16-100-7
  May 13 16:49:50.656: INFO: Pod one-traefik-795c67dd65-zptl9 requesting resource cpu=0m on Node oneke-ip-172-16-100-5
  STEP: Starting Pods to consume most of the cluster CPU. @ 05/13/24 16:49:50.656
  May 13 16:49:50.656: INFO: Creating a pod which consumes cpu=637m on Node oneke-ip-172-16-100-5
  May 13 16:49:50.661: INFO: Creating a pod which consumes cpu=479m on Node oneke-ip-172-16-100-7
  E0513 16:49:50.909878      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:51.911113      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 05/13/24 16:49:52.675
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-4e3b0ee2-6f30-44bc-bcb6-e55f397ae5ed.17cf1a61dc950a3c], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2276/filler-pod-4e3b0ee2-6f30-44bc-bcb6-e55f397ae5ed to oneke-ip-172-16-100-5] @ 05/13/24 16:49:52.68
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-4e3b0ee2-6f30-44bc-bcb6-e55f397ae5ed.17cf1a620969b876], Reason = [AddedInterface], Message = [Add eth0 [10.42.1.127/32] from k8s-pod-network] @ 05/13/24 16:49:52.681
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-4e3b0ee2-6f30-44bc-bcb6-e55f397ae5ed.17cf1a62115f0b13], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 05/13/24 16:49:52.682
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-4e3b0ee2-6f30-44bc-bcb6-e55f397ae5ed.17cf1a6211f46448], Reason = [Created], Message = [Created container filler-pod-4e3b0ee2-6f30-44bc-bcb6-e55f397ae5ed] @ 05/13/24 16:49:52.683
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-4e3b0ee2-6f30-44bc-bcb6-e55f397ae5ed.17cf1a62175b6525], Reason = [Started], Message = [Started container filler-pod-4e3b0ee2-6f30-44bc-bcb6-e55f397ae5ed] @ 05/13/24 16:49:52.684
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-7c69bdf6-79f8-4033-9c80-ea262f1e3692.17cf1a61dcfce7ff], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2276/filler-pod-7c69bdf6-79f8-4033-9c80-ea262f1e3692 to oneke-ip-172-16-100-7] @ 05/13/24 16:49:52.685
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-7c69bdf6-79f8-4033-9c80-ea262f1e3692.17cf1a6209f81a5c], Reason = [AddedInterface], Message = [Add eth0 [10.42.3.114/32] from k8s-pod-network] @ 05/13/24 16:49:52.686
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-7c69bdf6-79f8-4033-9c80-ea262f1e3692.17cf1a62119f1253], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 05/13/24 16:49:52.687
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-7c69bdf6-79f8-4033-9c80-ea262f1e3692.17cf1a6212398ea7], Reason = [Created], Message = [Created container filler-pod-7c69bdf6-79f8-4033-9c80-ea262f1e3692] @ 05/13/24 16:49:52.688
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-7c69bdf6-79f8-4033-9c80-ea262f1e3692.17cf1a6217cf175c], Reason = [Started], Message = [Started container filler-pod-7c69bdf6-79f8-4033-9c80-ea262f1e3692] @ 05/13/24 16:49:52.691
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.17cf1a62552be615], Reason = [FailedScheduling], Message = [0/4 nodes are available: 1 node(s) had untolerated taint {CriticalAddonsOnly: true}, 1 node(s) had untolerated taint {node.longhorn.io/create-default-disk: true}, 2 Insufficient cpu. preemption: 0/4 nodes are available: 2 No preemption victims found for incoming pod, 2 Preemption is not helpful for scheduling.] @ 05/13/24 16:49:52.698
  E0513 16:49:52.910915      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label node off the node oneke-ip-172-16-100-5 @ 05/13/24 16:49:53.694
  STEP: verifying the node doesn't have the label node @ 05/13/24 16:49:53.71
  STEP: removing the label node off the node oneke-ip-172-16-100-7 @ 05/13/24 16:49:53.712
  STEP: verifying the node doesn't have the label node @ 05/13/24 16:49:53.728
  May 13 16:49:53.730: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-2276" for this suite. @ 05/13/24 16:49:53.734
• [3.165 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:349
  STEP: Creating a kubernetes client @ 05/13/24 16:49:53.739
  May 13 16:49:53.739: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename security-context-test @ 05/13/24 16:49:53.74
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:49:53.755
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:49:53.756
  E0513 16:49:53.911866      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:54.912007      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:55.912648      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:56.912773      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:49:57.782: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-7236" for this suite. @ 05/13/24 16:49:57.79
• [4.064 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:51
  STEP: Creating a kubernetes client @ 05/13/24 16:49:57.805
  May 13 16:49:57.805: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubelet-test @ 05/13/24 16:49:57.806
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:49:57.814
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:49:57.816
  E0513 16:49:57.913075      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:49:58.913160      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:49:59.832: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-8122" for this suite. @ 05/13/24 16:49:59.837
• [2.038 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:170
  STEP: Creating a kubernetes client @ 05/13/24 16:49:59.843
  May 13 16:49:59.843: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename emptydir @ 05/13/24 16:49:59.844
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:49:59.853
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:49:59.855
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 05/13/24 16:49:59.856
  E0513 16:49:59.913655      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:00.914012      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:01.914903      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:02.915756      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:50:03.871
  May 13 16:50:03.872: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-1e4ba930-114f-4fcb-8894-871e38c7bb05 container test-container: <nil>
  STEP: delete the pod @ 05/13/24 16:50:03.879
  May 13 16:50:03.888: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6862" for this suite. @ 05/13/24 16:50:03.891
• [4.052 seconds]
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1416
  STEP: Creating a kubernetes client @ 05/13/24 16:50:03.896
  May 13 16:50:03.896: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename services @ 05/13/24 16:50:03.897
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:50:03.909
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:50:03.911
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-5193 @ 05/13/24 16:50:03.912
  E0513 16:50:03.915377      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: changing the ExternalName service to type=ClusterIP @ 05/13/24 16:50:03.915
  STEP: creating replication controller externalname-service in namespace services-5193 @ 05/13/24 16:50:03.93
  I0513 16:50:03.942640      17 runners.go:197] Created replication controller with name: externalname-service, namespace: services-5193, replica count: 2
  E0513 16:50:04.915451      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:05.916083      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:06.916359      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0513 16:50:06.994908      17 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May 13 16:50:06.994: INFO: Creating new exec pod
  E0513 16:50:07.917145      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:08.917808      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:09.917976      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:50:10.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-5193 exec execpod96g9z -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  May 13 16:50:10.175: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  May 13 16:50:10.175: INFO: stdout: "externalname-service-w8tnp"
  May 13 16:50:10.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-5193 exec execpod96g9z -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.243.236 80'
  May 13 16:50:10.312: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.243.236 80\nConnection to 10.43.243.236 80 port [tcp/http] succeeded!\n"
  May 13 16:50:10.312: INFO: stdout: "externalname-service-w8tnp"
  May 13 16:50:10.312: INFO: Cleaning up the ExternalName to ClusterIP test service
  May 13 16:50:10.330: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5193" for this suite. @ 05/13/24 16:50:10.335
• [6.445 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:107
  STEP: Creating a kubernetes client @ 05/13/24 16:50:10.341
  May 13 16:50:10.341: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename container-probe @ 05/13/24 16:50:10.342
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:50:10.352
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:50:10.356
  E0513 16:50:10.918782      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:11.919131      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:12.921588      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:13.921030      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:14.923559      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:15.922660      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:16.923418      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:17.924540      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:18.925569      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:19.926807      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:20.927034      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:21.927509      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:22.927984      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:23.928011      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:24.929260      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:25.929175      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:26.930597      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:27.930752      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:28.931676      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:29.932191      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:30.933529      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:31.933539      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:32.933703      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:33.934184      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:34.934532      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:35.934748      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:36.936117      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:37.937046      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:38.936944      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:39.937012      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:40.938343      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:41.938288      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:42.939003      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:43.939437      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:44.939809      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:45.941003      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:46.941252      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:47.941991      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:48.941998      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:49.942556      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:50.943678      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:51.944179      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:52.945236      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:53.946574      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:54.947753      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:55.948869      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:56.950091      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:57.950656      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:58.950788      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:50:59.951025      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:00.951984      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:01.953079      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:02.953062      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:03.953817      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:04.954603      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:05.955392      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:06.955664      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:07.956908      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:08.957117      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:09.958885      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:51:10.364: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9704" for this suite. @ 05/13/24 16:51:10.369
• [60.034 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 05/13/24 16:51:10.38
  May 13 16:51:10.380: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename pods @ 05/13/24 16:51:10.383
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:51:10.404
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:51:10.406
  STEP: Create a pod @ 05/13/24 16:51:10.408
  E0513 16:51:10.958174      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:11.958582      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 05/13/24 16:51:12.425
  May 13 16:51:12.444: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
  May 13 16:51:12.444: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3057" for this suite. @ 05/13/24 16:51:12.447
• [2.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:400
  STEP: Creating a kubernetes client @ 05/13/24 16:51:12.456
  May 13 16:51:12.456: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename namespaces @ 05/13/24 16:51:12.457
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:51:12.468
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:51:12.469
  STEP: Creating namespace "e2e-ns-9qcp5" @ 05/13/24 16:51:12.47
  May 13 16:51:12.488: INFO: Namespace "e2e-ns-9qcp5-6695" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-9qcp5-6695" @ 05/13/24 16:51:12.488
  May 13 16:51:12.492: INFO: Namespace "e2e-ns-9qcp5-6695" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-9qcp5-6695" @ 05/13/24 16:51:12.492
  May 13 16:51:12.498: INFO: Namespace "e2e-ns-9qcp5-6695" has []v1.FinalizerName{"kubernetes"}
  May 13 16:51:12.498: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-4318" for this suite. @ 05/13/24 16:51:12.501
  STEP: Destroying namespace "e2e-ns-9qcp5-6695" for this suite. @ 05/13/24 16:51:12.506
• [0.055 seconds]
------------------------------
SS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 05/13/24 16:51:12.511
  May 13 16:51:12.511: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename secrets @ 05/13/24 16:51:12.512
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:51:12.522
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:51:12.523
  STEP: Creating secret with name secret-test-099c80ad-6dc9-4cd6-8864-1ce101d01dc2 @ 05/13/24 16:51:12.525
  STEP: Creating a pod to test consume secrets @ 05/13/24 16:51:12.528
  E0513 16:51:12.959016      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:13.959143      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:14.960002      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:15.960259      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:51:16.556
  May 13 16:51:16.558: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-secrets-0fc7f2db-d475-4273-87f6-255159b4bd50 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/13/24 16:51:16.563
  May 13 16:51:16.572: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-313" for this suite. @ 05/13/24 16:51:16.573
• [4.066 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:669
  STEP: Creating a kubernetes client @ 05/13/24 16:51:16.58
  May 13 16:51:16.580: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename pv @ 05/13/24 16:51:16.58
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:51:16.59
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:51:16.592
  STEP: Creating initial PV and PVC @ 05/13/24 16:51:16.639
  May 13 16:51:16.639: INFO: Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-8703" @ 05/13/24 16:51:16.648
  STEP: Listing PVCs in namespace "pv-8703" @ 05/13/24 16:51:16.651
  STEP: Reading "pvc-xvcqg" Status @ 05/13/24 16:51:16.654
  STEP: Reading "pv-8703-rwck2" Status @ 05/13/24 16:51:16.657
  STEP: Patching "pvc-xvcqg" Status @ 05/13/24 16:51:16.66
  STEP: Patching "pv-8703-rwck2" Status @ 05/13/24 16:51:16.665
  STEP: Updating "pvc-xvcqg" Status @ 05/13/24 16:51:16.68
  STEP: Updating "pv-8703-rwck2" Status @ 05/13/24 16:51:16.702
  May 13 16:51:16.707: INFO: AfterEach: deleting 1 PVCs and 1 PVs...
  May 13 16:51:16.707: INFO: Deleting PersistentVolumeClaim "pvc-xvcqg"
  May 13 16:51:16.714: INFO: Deleting PersistentVolume "pv-8703-rwck2"
  May 13 16:51:16.717: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-8703" for this suite. @ 05/13/24 16:51:16.72
• [0.147 seconds]
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:399
  STEP: Creating a kubernetes client @ 05/13/24 16:51:16.726
  May 13 16:51:16.726: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubectl @ 05/13/24 16:51:16.727
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:51:16.74
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:51:16.743
  STEP: creating all guestbook components @ 05/13/24 16:51:16.747
  May 13 16:51:16.747: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  May 13 16:51:16.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5115 create -f -'
  May 13 16:51:16.871: INFO: stderr: ""
  May 13 16:51:16.871: INFO: stdout: "service/agnhost-replica created\n"
  May 13 16:51:16.871: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  May 13 16:51:16.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5115 create -f -'
  E0513 16:51:16.961081      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:51:16.979: INFO: stderr: ""
  May 13 16:51:16.979: INFO: stdout: "service/agnhost-primary created\n"
  May 13 16:51:16.979: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  May 13 16:51:16.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5115 create -f -'
  May 13 16:51:17.075: INFO: stderr: ""
  May 13 16:51:17.075: INFO: stdout: "service/frontend created\n"
  May 13 16:51:17.075: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  May 13 16:51:17.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5115 create -f -'
  May 13 16:51:17.155: INFO: stderr: ""
  May 13 16:51:17.155: INFO: stdout: "deployment.apps/frontend created\n"
  May 13 16:51:17.155: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  May 13 16:51:17.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5115 create -f -'
  May 13 16:51:17.274: INFO: stderr: ""
  May 13 16:51:17.274: INFO: stdout: "deployment.apps/agnhost-primary created\n"
  May 13 16:51:17.274: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  May 13 16:51:17.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5115 create -f -'
  May 13 16:51:17.369: INFO: stderr: ""
  May 13 16:51:17.369: INFO: stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 05/13/24 16:51:17.369
  May 13 16:51:17.369: INFO: Waiting for all frontend pods to be Running.
  E0513 16:51:17.961716      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:18.961826      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:19.962719      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:20.962993      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:21.965555      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:51:22.420: INFO: Waiting for frontend to serve content.
  May 13 16:51:22.428: INFO: Trying to add a new entry to the guestbook.
  May 13 16:51:22.437: INFO: Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 05/13/24 16:51:22.441
  May 13 16:51:22.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5115 delete --grace-period=0 --force -f -'
  May 13 16:51:22.528: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May 13 16:51:22.528: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 05/13/24 16:51:22.528
  May 13 16:51:22.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5115 delete --grace-period=0 --force -f -'
  May 13 16:51:22.600: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May 13 16:51:22.600: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 05/13/24 16:51:22.6
  May 13 16:51:22.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5115 delete --grace-period=0 --force -f -'
  May 13 16:51:22.660: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May 13 16:51:22.660: INFO: stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 05/13/24 16:51:22.66
  May 13 16:51:22.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5115 delete --grace-period=0 --force -f -'
  May 13 16:51:22.708: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May 13 16:51:22.708: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 05/13/24 16:51:22.708
  May 13 16:51:22.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5115 delete --grace-period=0 --force -f -'
  May 13 16:51:22.783: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May 13 16:51:22.786: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 05/13/24 16:51:22.786
  May 13 16:51:22.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-5115 delete --grace-period=0 --force -f -'
  May 13 16:51:22.868: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May 13 16:51:22.868: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  May 13 16:51:22.868: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5115" for this suite. @ 05/13/24 16:51:22.871
• [6.149 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:889
  STEP: Creating a kubernetes client @ 05/13/24 16:51:22.876
  May 13 16:51:22.876: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename resourcequota @ 05/13/24 16:51:22.877
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:51:22.886
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:51:22.889
  STEP: Creating a ResourceQuota @ 05/13/24 16:51:22.89
  STEP: Getting a ResourceQuota @ 05/13/24 16:51:22.893
  STEP: Updating a ResourceQuota @ 05/13/24 16:51:22.895
  STEP: Verifying a ResourceQuota was modified @ 05/13/24 16:51:22.9
  STEP: Deleting a ResourceQuota @ 05/13/24 16:51:22.903
  STEP: Verifying the deleted ResourceQuota @ 05/13/24 16:51:22.905
  May 13 16:51:22.907: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7777" for this suite. @ 05/13/24 16:51:22.909
• [0.037 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:371
  STEP: Creating a kubernetes client @ 05/13/24 16:51:22.915
  May 13 16:51:22.915: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename webhook @ 05/13/24 16:51:22.916
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:51:22.932
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:51:22.933
  STEP: Setting up server cert @ 05/13/24 16:51:22.949
  E0513 16:51:22.966040      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/13/24 16:51:23.243
  STEP: Deploying the webhook pod @ 05/13/24 16:51:23.25
  STEP: Wait for the deployment to be ready @ 05/13/24 16:51:23.261
  May 13 16:51:23.267: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0513 16:51:23.966841      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:24.967541      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/13/24 16:51:25.272
  STEP: Verifying the service has paired with the endpoint @ 05/13/24 16:51:25.28
  E0513 16:51:25.967609      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:51:26.281: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 05/13/24 16:51:26.295
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/13/24 16:51:26.296
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 05/13/24 16:51:26.325
  E0513 16:51:26.968410      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 05/13/24 16:51:27.331
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/13/24 16:51:27.331
  E0513 16:51:27.968882      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 05/13/24 16:51:28.347
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/13/24 16:51:28.347
  E0513 16:51:28.968830      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:29.970077      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:30.971176      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:31.971235      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:32.971600      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 05/13/24 16:51:33.371
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/13/24 16:51:33.371
  E0513 16:51:33.972893      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:34.973284      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:35.974037      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:36.974111      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:37.974957      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:51:38.436: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-950" for this suite. @ 05/13/24 16:51:38.439
  STEP: Destroying namespace "webhook-markers-1161" for this suite. @ 05/13/24 16:51:38.444
• [15.533 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:163
  STEP: Creating a kubernetes client @ 05/13/24 16:51:38.45
  May 13 16:51:38.450: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename resourcequota @ 05/13/24 16:51:38.451
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:51:38.464
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:51:38.467
  STEP: Discovering how many secrets are in namespace by default @ 05/13/24 16:51:38.468
  E0513 16:51:38.975626      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:39.976777      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:40.976993      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:41.978230      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:42.979007      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 05/13/24 16:51:43.47
  E0513 16:51:43.978664      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:44.979899      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:45.979969      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:46.979988      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:47.980141      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/13/24 16:51:48.473
  STEP: Ensuring resource quota status is calculated @ 05/13/24 16:51:48.478
  E0513 16:51:48.980450      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:49.980957      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 05/13/24 16:51:50.483
  STEP: Ensuring resource quota status captures secret creation @ 05/13/24 16:51:50.498
  E0513 16:51:50.981175      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:51.981519      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 05/13/24 16:51:52.501
  STEP: Ensuring resource quota status released usage @ 05/13/24 16:51:52.505
  E0513 16:51:52.982611      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:53.982949      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:51:54.526: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1758" for this suite. @ 05/13/24 16:51:54.533
• [16.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:142
  STEP: Creating a kubernetes client @ 05/13/24 16:51:54.55
  May 13 16:51:54.550: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename crd-webhook @ 05/13/24 16:51:54.567
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:51:54.582
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:51:54.584
  STEP: Setting up server cert @ 05/13/24 16:51:54.589
  E0513 16:51:54.983444      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 05/13/24 16:51:55.035
  STEP: Deploying the custom resource conversion webhook pod @ 05/13/24 16:51:55.04
  STEP: Wait for the deployment to be ready @ 05/13/24 16:51:55.049
  May 13 16:51:55.052: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
  E0513 16:51:55.983888      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:56.984268      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/13/24 16:51:57.074
  STEP: Verifying the service has paired with the endpoint @ 05/13/24 16:51:57.1
  E0513 16:51:57.984500      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:51:58.101: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  May 13 16:51:58.105: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 16:51:58.984611      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:51:59.985943      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 05/13/24 16:52:00.658
  STEP: v2 custom resource should be converted @ 05/13/24 16:52:00.661
  E0513 16:52:00.986347      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:01.216: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-3399" for this suite. @ 05/13/24 16:52:01.223
• [6.683 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:285
  STEP: Creating a kubernetes client @ 05/13/24 16:52:01.233
  May 13 16:52:01.233: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename webhook @ 05/13/24 16:52:01.234
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:52:01.244
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:52:01.247
  STEP: Setting up server cert @ 05/13/24 16:52:01.269
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/13/24 16:52:01.76
  STEP: Deploying the webhook pod @ 05/13/24 16:52:01.764
  STEP: Wait for the deployment to be ready @ 05/13/24 16:52:01.777
  May 13 16:52:01.810: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 13, 16, 52, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 16, 52, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 13, 16, 52, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 13, 16, 52, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0513 16:52:01.986451      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:02.986598      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/13/24 16:52:03.811
  STEP: Verifying the service has paired with the endpoint @ 05/13/24 16:52:03.828
  E0513 16:52:03.987228      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:04.829: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  May 13 16:52:04.844: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 16:52:04.988359      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3767-crds.webhook.example.com via the AdmissionRegistration API @ 05/13/24 16:52:05.373
  STEP: Creating a custom resource that should be mutated by the webhook @ 05/13/24 16:52:05.388
  E0513 16:52:05.989174      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:06.989673      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:07.979: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7183" for this suite. @ 05/13/24 16:52:07.981
  STEP: Destroying namespace "webhook-markers-3074" for this suite. @ 05/13/24 16:52:07.984
• [6.757 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:103
  STEP: Creating a kubernetes client @ 05/13/24 16:52:07.991
  May 13 16:52:07.991: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename resourcequota @ 05/13/24 16:52:07.991
  E0513 16:52:07.992338      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:52:08.002
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:52:08.003
  STEP: Counting existing ResourceQuota @ 05/13/24 16:52:08.005
  E0513 16:52:08.993266      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:09.994360      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:10.995303      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:11.996363      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:12.999095      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/13/24 16:52:13.008
  STEP: Ensuring resource quota status is calculated @ 05/13/24 16:52:13.023
  E0513 16:52:13.999541      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:15.000475      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 05/13/24 16:52:15.029
  STEP: Creating a NodePort Service @ 05/13/24 16:52:15.047
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 05/13/24 16:52:15.06
  STEP: Ensuring resource quota status captures service creation @ 05/13/24 16:52:15.071
  E0513 16:52:16.000291      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:17.000911      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 05/13/24 16:52:17.079
  STEP: Ensuring resource quota status released usage @ 05/13/24 16:52:17.108
  E0513 16:52:18.000808      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:19.001731      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:19.115: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4968" for this suite. @ 05/13/24 16:52:19.128
• [11.145 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:527
  STEP: Creating a kubernetes client @ 05/13/24 16:52:19.137
  May 13 16:52:19.137: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename container-probe @ 05/13/24 16:52:19.138
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:52:19.152
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:52:19.154
  STEP: Creating pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797 @ 05/13/24 16:52:19.156
  E0513 16:52:20.002716      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:21.002802      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/13/24 16:52:21.166
  May 13 16:52:21.168: INFO: Initial restart count of pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 is 0
  May 13 16:52:21.169: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:52:22.002899      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:23.003037      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:23.172: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:52:24.004110      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:25.004859      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:25.179: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:52:26.005574      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:27.005928      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:27.182: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:52:28.005684      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:29.006656      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:29.184: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:52:30.007460      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:31.007569      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:31.187: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:52:32.007758      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:33.008095      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:33.192: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:52:34.009320      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:35.010234      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:35.196: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:52:36.012267      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:37.012532      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:37.205: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:52:38.012190      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:39.012307      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:39.217: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:52:40.013066      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:41.013212      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:41.226: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:52:42.013325      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:43.013386      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:43.229: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:52:44.014741      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:45.015773      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:45.237: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:52:46.016533      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:47.016546      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:47.248: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:52:48.016760      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:49.016889      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:49.255: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:52:50.017955      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:51.018217      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:51.264: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:52:52.019155      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:53.020080      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:53.267: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:52:54.020635      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:55.020744      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:55.270: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:52:56.021700      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:57.022694      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:57.276: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:52:58.023021      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:52:59.023046      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:52:59.279: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:00.024291      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:01.025598      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:01.283: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:02.025944      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:03.026738      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:03.288: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:04.027406      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:05.027967      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:05.291: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:06.028657      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:07.029318      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:07.300: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:08.029171      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:09.029777      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:09.303: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:10.030674      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:11.030550      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:11.311: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:12.030606      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:13.030629      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:13.314: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:14.030986      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:15.031402      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:15.316: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:16.031666      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:17.032376      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:17.326: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:18.032759      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:19.032863      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:19.333: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:20.033094      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:21.034070      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:21.340: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:22.042146      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:23.042095      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:23.344: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:24.043367      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:25.044418      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:25.346: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:26.045257      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:27.045422      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:27.348: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:28.046415      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:29.047476      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:29.353: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:30.048361      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:31.049499      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:31.359: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:32.049610      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:33.049636      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:33.364: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:34.050399      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:35.051316      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:35.367: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:36.051775      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:37.052129      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:37.373: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:38.052452      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:39.052783      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:39.377: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:40.054542      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:41.054580      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:41.385: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:42.054899      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:43.055346      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:43.388: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:44.056206      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:45.056880      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:45.396: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:46.057157      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:47.058434      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:47.400: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:48.058381      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:49.058651      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:49.404: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:50.059019      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:51.059870      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:51.406: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:52.060447      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:53.060959      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:53.409: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:54.061585      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:55.061658      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:55.415: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:56.062804      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:57.063841      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:57.418: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:53:58.063902      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:53:59.064018      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:53:59.420: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:00.064962      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:01.065213      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:01.422: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:02.066054      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:03.067128      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:03.424: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:04.068177      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:05.069037      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:05.432: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:06.069508      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:07.069425      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:07.434: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:08.070035      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:09.070746      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:09.437: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:10.071037      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:11.071838      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:11.458: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:12.072673      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:13.073467      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:13.461: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:14.073611      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:15.074589      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:15.469: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:16.075209      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:17.075351      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:17.471: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:18.075260      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:19.077200      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:19.481: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:20.077177      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:21.078876      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:21.487: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:22.078719      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:23.079082      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:23.488: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:24.080186      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:25.080705      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:25.496: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:26.080933      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:27.080961      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:27.500: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:28.081933      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:29.082333      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:29.506: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:30.083314      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:31.083587      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:31.522: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:32.083523      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:33.083909      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:33.524: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:34.084837      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:35.085440      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:35.527: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:36.086894      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:37.086742      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:37.529: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:38.086924      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:39.087488      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:39.532: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:40.087635      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:41.088308      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:41.534: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:42.088797      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:43.089290      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:43.540: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:44.090098      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:45.090658      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:45.544: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:46.090725      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:47.090907      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:47.552: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:48.091849      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:49.092239      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:49.555: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:50.092400      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:51.093674      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:51.559: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:52.093936      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:53.094527      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:53.566: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:54.096206      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:55.097169      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:55.570: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:56.097446      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:57.098191      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:57.575: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:54:58.098722      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:54:59.098898      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:54:59.579: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:00.098996      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:01.099549      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:01.582: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:02.100505      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:03.101253      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:03.585: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:04.102353      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:05.102125      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:05.588: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:06.102259      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:07.103026      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:07.590: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:08.103100      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:09.104071      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:09.593: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:10.104128      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:11.104592      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:11.597: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:12.105688      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:13.106281      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:13.606: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:14.106929      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:15.107164      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:15.610: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:16.107566      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:17.108057      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:17.615: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:18.109154      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:19.110194      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:19.617: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:20.110593      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:21.111863      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:21.624: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:22.112133      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:23.112868      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:23.626: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:24.113828      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:25.114771      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:25.630: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:26.114676      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:27.115342      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:27.632: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:28.115500      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:29.116482      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:29.639: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:30.117482      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:31.118180      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:31.645: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:32.119505      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:33.119862      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:33.650: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:34.120331      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:35.120205      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:35.653: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:36.120602      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:37.121407      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:37.655: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:38.121512      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:39.122285      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:39.657: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:40.122947      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:41.123278      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:41.659: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:42.123399      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:43.123608      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:43.662: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:44.124019      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:45.124722      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:45.664: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:46.125165      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:47.125513      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:47.670: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:48.125887      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:49.126186      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:49.673: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:50.126885      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:51.128842      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:51.676: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:52.127384      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:53.127866      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:53.678: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:54.129172      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:55.129343      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:55.680: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:56.130159      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:57.131196      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:57.686: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:55:58.132595      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:55:59.132744      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:55:59.691: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:56:00.133947      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:01.134418      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:56:01.694: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:56:02.134990      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:03.135718      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:56:03.696: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:56:04.136755      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:05.137082      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:56:05.699: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:56:06.137789      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:07.138588      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:56:07.704: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:56:08.138858      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:09.139348      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:56:09.708: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:56:10.140066      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:11.140195      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:56:11.713: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:56:12.141201      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:13.142253      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:56:13.722: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:56:14.143014      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:15.143581      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:56:15.731: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:56:16.143903      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:17.144916      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:56:17.735: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:56:18.145804      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:19.146049      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:56:19.737: INFO: Get pod test-grpc-a621e947-e17d-4286-b2af-05e27ee6fe42 in namespace container-probe-4797
  E0513 16:56:20.146737      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:21.147177      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 05/13/24 16:56:21.738
  May 13 16:56:21.750: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4797" for this suite. @ 05/13/24 16:56:21.756
• [242.627 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:655
  STEP: Creating a kubernetes client @ 05/13/24 16:56:21.767
  May 13 16:56:21.767: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename job @ 05/13/24 16:56:21.767
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:56:21.778
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:56:21.779
  STEP: Creating a job @ 05/13/24 16:56:21.78
  STEP: Ensuring active pods == parallelism @ 05/13/24 16:56:21.783
  E0513 16:56:22.147210      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:23.147907      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 05/13/24 16:56:23.786
  E0513 16:56:24.148661      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:56:24.298: INFO: Successfully updated pod "adopt-release-crmqs"
  STEP: Checking that the Job readopts the Pod @ 05/13/24 16:56:24.298
  E0513 16:56:25.148846      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:26.149438      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 05/13/24 16:56:26.319
  May 13 16:56:26.831: INFO: Successfully updated pod "adopt-release-crmqs"
  STEP: Checking that the Job releases the Pod @ 05/13/24 16:56:26.831
  E0513 16:56:27.149511      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:28.150344      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:56:28.840: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4442" for this suite. @ 05/13/24 16:56:28.854
• [7.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:55
  STEP: Creating a kubernetes client @ 05/13/24 16:56:28.867
  May 13 16:56:28.867: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename downward-api @ 05/13/24 16:56:28.869
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:56:28.886
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:56:28.887
  STEP: Creating a pod to test downward API volume plugin @ 05/13/24 16:56:28.889
  E0513 16:56:29.150702      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:30.150879      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:31.151582      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:32.151706      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:56:32.911
  May 13 16:56:32.919: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod downwardapi-volume-4a41771e-f685-4c72-ae2c-42147e0fcf5a container client-container: <nil>
  STEP: delete the pod @ 05/13/24 16:56:32.949
  May 13 16:56:32.960: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6719" for this suite. @ 05/13/24 16:56:32.963
• [4.101 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:141
  STEP: Creating a kubernetes client @ 05/13/24 16:56:32.968
  May 13 16:56:32.968: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename secrets @ 05/13/24 16:56:32.968
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:56:32.981
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:56:32.983
  STEP: Creating projection with secret that has name secret-emptykey-test-51907f00-194e-4aa2-8884-7dc2ec296df4 @ 05/13/24 16:56:32.984
  May 13 16:56:32.986: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6727" for this suite. @ 05/13/24 16:56:32.988
• [0.025 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 05/13/24 16:56:32.993
  May 13 16:56:32.993: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename secrets @ 05/13/24 16:56:32.994
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:56:33.006
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:56:33.007
  STEP: Creating secret with name secret-test-map-130f31ce-78ac-48cd-be34-b53980393ec4 @ 05/13/24 16:56:33.008
  STEP: Creating a pod to test consume secrets @ 05/13/24 16:56:33.011
  E0513 16:56:33.151683      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:34.152711      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:35.155102      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:36.155983      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:56:37.038
  May 13 16:56:37.046: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-secrets-f5f14223-7839-4ea9-b453-0e5419e78e66 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/13/24 16:56:37.074
  May 13 16:56:37.086: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9294" for this suite. @ 05/13/24 16:56:37.089
• [4.101 seconds]
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 05/13/24 16:56:37.094
  May 13 16:56:37.094: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename secrets @ 05/13/24 16:56:37.095
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:56:37.104
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:56:37.106
  STEP: Creating secret with name secret-test-44614e4c-4ce9-4ffd-b380-eb7f448eff2d @ 05/13/24 16:56:37.108
  STEP: Creating a pod to test consume secrets @ 05/13/24 16:56:37.112
  E0513 16:56:37.157010      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:38.157111      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:39.157783      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:40.157920      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:56:41.13
  May 13 16:56:41.137: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-secrets-39591a21-2af8-4afa-bde5-6c9464ec65ca container secret-volume-test: <nil>
  STEP: delete the pod @ 05/13/24 16:56:41.154
  E0513 16:56:41.159038      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:56:41.171: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4108" for this suite. @ 05/13/24 16:56:41.175
• [4.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:95
  STEP: Creating a kubernetes client @ 05/13/24 16:56:41.181
  May 13 16:56:41.181: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename replication-controller @ 05/13/24 16:56:41.182
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:56:41.192
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:56:41.195
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 05/13/24 16:56:41.196
  E0513 16:56:42.159023      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:43.159171      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 05/13/24 16:56:43.206
  STEP: Then the orphan pod is adopted @ 05/13/24 16:56:43.209
  E0513 16:56:44.159966      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:56:44.214: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-4695" for this suite. @ 05/13/24 16:56:44.217
• [3.038 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 05/13/24 16:56:44.222
  May 13 16:56:44.222: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename containers @ 05/13/24 16:56:44.223
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:56:44.235
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:56:44.236
  STEP: Creating a pod to test override all @ 05/13/24 16:56:44.238
  E0513 16:56:45.160821      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:46.160874      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:47.164384      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:48.163023      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:56:48.261
  May 13 16:56:48.262: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod client-containers-ad19b107-f682-492d-b799-7362fd6f4564 container agnhost-container: <nil>
  STEP: delete the pod @ 05/13/24 16:56:48.265
  May 13 16:56:48.275: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-7293" for this suite. @ 05/13/24 16:56:48.278
• [4.059 seconds]
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:424
  STEP: Creating a kubernetes client @ 05/13/24 16:56:48.282
  May 13 16:56:48.282: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename configmap @ 05/13/24 16:56:48.285
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:56:48.295
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:56:48.296
  STEP: Creating configMap with name configmap-test-volume-c710f4b3-7d3b-4047-b7b7-8da987fc90e3 @ 05/13/24 16:56:48.298
  STEP: Creating a pod to test consume configMaps @ 05/13/24 16:56:48.301
  E0513 16:56:49.162789      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:50.163660      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:51.164322      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:52.164754      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:56:52.317
  May 13 16:56:52.319: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-configmaps-a595de54-dd6f-401d-baa3-90b7bfa69728 container configmap-volume-test: <nil>
  STEP: delete the pod @ 05/13/24 16:56:52.322
  May 13 16:56:52.331: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-12" for this suite. @ 05/13/24 16:56:52.333
• [4.055 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 05/13/24 16:56:52.337
  May 13 16:56:52.337: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename proxy @ 05/13/24 16:56:52.338
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:56:52.349
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:56:52.35
  May 13 16:56:52.352: INFO: Creating pod...
  E0513 16:56:53.164914      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:54.165623      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:56:54.362: INFO: Creating service...
  May 13 16:56:54.375: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-3386/pods/agnhost/proxy?method=DELETE
  May 13 16:56:54.385: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  May 13 16:56:54.385: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-3386/pods/agnhost/proxy?method=OPTIONS
  May 13 16:56:54.387: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  May 13 16:56:54.387: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-3386/pods/agnhost/proxy?method=PATCH
  May 13 16:56:54.392: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  May 13 16:56:54.392: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-3386/pods/agnhost/proxy?method=POST
  May 13 16:56:54.395: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  May 13 16:56:54.395: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-3386/pods/agnhost/proxy?method=PUT
  May 13 16:56:54.397: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  May 13 16:56:54.397: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-3386/services/e2e-proxy-test-service/proxy?method=DELETE
  May 13 16:56:54.400: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  May 13 16:56:54.400: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-3386/services/e2e-proxy-test-service/proxy?method=OPTIONS
  May 13 16:56:54.402: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  May 13 16:56:54.403: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-3386/services/e2e-proxy-test-service/proxy?method=PATCH
  May 13 16:56:54.405: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  May 13 16:56:54.405: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-3386/services/e2e-proxy-test-service/proxy?method=POST
  May 13 16:56:54.407: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  May 13 16:56:54.407: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-3386/services/e2e-proxy-test-service/proxy?method=PUT
  May 13 16:56:54.409: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  May 13 16:56:54.409: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-3386/pods/agnhost/proxy?method=GET
  May 13 16:56:54.412: INFO: http.Client request:GET StatusCode:301
  May 13 16:56:54.412: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-3386/services/e2e-proxy-test-service/proxy?method=GET
  May 13 16:56:54.414: INFO: http.Client request:GET StatusCode:301
  May 13 16:56:54.414: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-3386/pods/agnhost/proxy?method=HEAD
  May 13 16:56:54.416: INFO: http.Client request:HEAD StatusCode:301
  May 13 16:56:54.416: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-3386/services/e2e-proxy-test-service/proxy?method=HEAD
  May 13 16:56:54.418: INFO: http.Client request:HEAD StatusCode:301
  May 13 16:56:54.418: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-3386" for this suite. @ 05/13/24 16:56:54.421
• [2.094 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:269
  STEP: Creating a kubernetes client @ 05/13/24 16:56:54.435
  May 13 16:56:54.435: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename downward-api @ 05/13/24 16:56:54.439
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:56:54.452
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:56:54.476
  STEP: Creating a pod to test downward api env vars @ 05/13/24 16:56:54.478
  E0513 16:56:55.166668      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:56.166947      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:57.168266      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:56:58.168549      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:56:58.496
  May 13 16:56:58.497: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod downward-api-ac859d02-a22b-42fa-ba65-195f21434af5 container dapi-container: <nil>
  STEP: delete the pod @ 05/13/24 16:56:58.501
  May 13 16:56:58.510: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9344" for this suite. @ 05/13/24 16:56:58.513
• [4.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 05/13/24 16:56:58.518
  May 13 16:56:58.518: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename disruption @ 05/13/24 16:56:58.519
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:56:58.53
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:56:58.531
  STEP: Waiting for the pdb to be processed @ 05/13/24 16:56:58.536
  E0513 16:56:59.168429      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:00.168599      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 05/13/24 16:57:00.537
  STEP: Waiting for all pods to be running @ 05/13/24 16:57:00.547
  May 13 16:57:00.549: INFO: running pods: 0 < 1
  E0513 16:57:01.168588      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:02.168860      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 05/13/24 16:57:02.551
  STEP: Waiting for the pdb to be processed @ 05/13/24 16:57:02.565
  STEP: Patching PodDisruptionBudget status @ 05/13/24 16:57:02.568
  STEP: Waiting for the pdb to be processed @ 05/13/24 16:57:02.572
  May 13 16:57:02.574: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-3179" for this suite. @ 05/13/24 16:57:02.576
• [4.062 seconds]
------------------------------
SS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 05/13/24 16:57:02.58
  May 13 16:57:02.580: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename containers @ 05/13/24 16:57:02.581
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:57:02.593
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:57:02.594
  STEP: Creating a pod to test override command @ 05/13/24 16:57:02.595
  E0513 16:57:03.169124      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:04.169983      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:05.171163      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:06.171087      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:57:06.605
  May 13 16:57:06.606: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod client-containers-c0e2bafa-8e75-4dcd-a79c-6496dc5ec1cd container agnhost-container: <nil>
  STEP: delete the pod @ 05/13/24 16:57:06.61
  May 13 16:57:06.623: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-568" for this suite. @ 05/13/24 16:57:06.627
• [4.050 seconds]
------------------------------
SS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 05/13/24 16:57:06.63
  May 13 16:57:06.630: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename secrets @ 05/13/24 16:57:06.631
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:57:06.645
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:57:06.646
  STEP: Creating secret with name secret-test-map-0a2db335-9930-4612-b3ec-0c7ce44bc9a8 @ 05/13/24 16:57:06.648
  STEP: Creating a pod to test consume secrets @ 05/13/24 16:57:06.651
  E0513 16:57:07.171110      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:08.171232      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:09.174718      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:10.175406      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:57:10.674
  May 13 16:57:10.675: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-secrets-cc76b7a9-1df2-4ec9-a166-ef6d8cebaa84 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/13/24 16:57:10.679
  May 13 16:57:10.691: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8299" for this suite. @ 05/13/24 16:57:10.693
• [4.066 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:332
  STEP: Creating a kubernetes client @ 05/13/24 16:57:10.697
  May 13 16:57:10.697: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename statefulset @ 05/13/24 16:57:10.698
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:57:10.708
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:57:10.71
  STEP: Creating service test in namespace statefulset-8674 @ 05/13/24 16:57:10.711
  STEP: Creating a new StatefulSet @ 05/13/24 16:57:10.717
  May 13 16:57:10.724: INFO: Found 0 stateful pods, waiting for 3
  E0513 16:57:11.175318      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:12.175617      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:13.175866      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:14.176096      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:15.176808      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:16.176640      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:17.176797      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:18.176901      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:19.177407      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:20.177475      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:57:20.730: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  May 13 16:57:20.731: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  May 13 16:57:20.732: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 05/13/24 16:57:20.741
  May 13 16:57:20.759: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 05/13/24 16:57:20.759
  E0513 16:57:21.178601      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:22.179103      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:23.179215      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:24.180286      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:25.181017      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:26.181581      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:27.181709      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:28.182740      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:29.182844      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:30.182899      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 05/13/24 16:57:30.772
  STEP: Performing a canary update @ 05/13/24 16:57:30.773
  May 13 16:57:30.799: INFO: Updating stateful set ss2
  May 13 16:57:30.820: INFO: Waiting for Pod statefulset-8674/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0513 16:57:31.183227      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:32.184277      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:33.184457      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:34.185638      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:35.185435      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:36.186296      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:37.187056      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:38.187666      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:39.187792      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:40.188135      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 05/13/24 16:57:40.815
  May 13 16:57:40.880: INFO: Found 2 stateful pods, waiting for 3
  E0513 16:57:41.188912      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:42.189815      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:43.189961      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:44.190655      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:45.191814      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:46.192513      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:47.193500      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:48.194534      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:49.194615      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:50.194787      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:57:50.876: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  May 13 16:57:50.877: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  May 13 16:57:50.877: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 05/13/24 16:57:50.879
  May 13 16:57:50.896: INFO: Updating stateful set ss2
  May 13 16:57:50.910: INFO: Waiting for Pod statefulset-8674/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0513 16:57:51.195319      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:52.195486      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:53.195485      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:54.195757      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:55.196024      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:56.196860      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:57.197064      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:58.197300      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:57:59.197364      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:00.198095      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:58:00.916: INFO: Updating stateful set ss2
  May 13 16:58:00.936: INFO: Waiting for StatefulSet statefulset-8674/ss2 to complete update
  May 13 16:58:00.936: INFO: Waiting for Pod statefulset-8674/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0513 16:58:01.198792      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:02.198830      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:03.199050      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:04.199499      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:05.200275      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:06.201233      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:07.200867      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:08.200933      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:09.201788      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:10.202380      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:58:10.920: INFO: Deleting all statefulset in ns statefulset-8674
  May 13 16:58:10.921: INFO: Scaling statefulset ss2 to 0
  E0513 16:58:11.202657      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:12.202970      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:13.203334      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:14.203675      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:15.204665      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:16.205260      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:17.206279      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:18.207024      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:19.208071      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:20.209475      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:58:20.933: INFO: Waiting for statefulset status.replicas updated to 0
  May 13 16:58:20.937: INFO: Deleting statefulset ss2
  May 13 16:58:20.959: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8674" for this suite. @ 05/13/24 16:58:20.968
• [70.277 seconds]
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:810
  STEP: Creating a kubernetes client @ 05/13/24 16:58:20.975
  May 13 16:58:20.975: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename svcaccounts @ 05/13/24 16:58:20.976
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:58:20.987
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:58:20.988
  STEP: Creating ServiceAccount "e2e-sa-zb7nb"  @ 05/13/24 16:58:20.989
  May 13 16:58:20.994: INFO: AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-zb7nb"  @ 05/13/24 16:58:20.994
  May 13 16:58:20.998: INFO: AutomountServiceAccountToken: true
  May 13 16:58:20.998: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7136" for this suite. @ 05/13/24 16:58:21.001
• [0.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:273
  STEP: Creating a kubernetes client @ 05/13/24 16:58:21.007
  May 13 16:58:21.007: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename webhook @ 05/13/24 16:58:21.008
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:58:21.017
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:58:21.019
  STEP: Setting up server cert @ 05/13/24 16:58:21.034
  E0513 16:58:21.209729      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/13/24 16:58:21.225
  STEP: Deploying the webhook pod @ 05/13/24 16:58:21.227
  STEP: Wait for the deployment to be ready @ 05/13/24 16:58:21.234
  May 13 16:58:21.243: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0513 16:58:22.209871      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:23.210020      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/13/24 16:58:23.248
  STEP: Verifying the service has paired with the endpoint @ 05/13/24 16:58:23.262
  E0513 16:58:24.210964      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:58:24.263: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 05/13/24 16:58:24.266
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 05/13/24 16:58:24.28
  STEP: Creating a dummy validating-webhook-configuration object @ 05/13/24 16:58:24.293
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 05/13/24 16:58:24.299
  STEP: Creating a dummy mutating-webhook-configuration object @ 05/13/24 16:58:24.302
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 05/13/24 16:58:24.308
  May 13 16:58:24.354: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3596" for this suite. @ 05/13/24 16:58:24.358
  STEP: Destroying namespace "webhook-markers-8072" for this suite. @ 05/13/24 16:58:24.363
• [3.362 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 05/13/24 16:58:24.374
  May 13 16:58:24.374: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename prestop @ 05/13/24 16:58:24.375
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:58:24.388
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:58:24.389
  STEP: Creating server pod server in namespace prestop-3449 @ 05/13/24 16:58:24.39
  STEP: Waiting for pods to come up. @ 05/13/24 16:58:24.397
  E0513 16:58:25.211108      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:26.211196      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating tester pod tester in namespace prestop-3449 @ 05/13/24 16:58:26.407
  E0513 16:58:27.211615      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:28.211610      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pre-stop pod @ 05/13/24 16:58:28.418
  E0513 16:58:29.212048      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:30.212139      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:31.212826      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:32.213460      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:33.213560      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:58:33.429: INFO: Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 05/13/24 16:58:33.43
  May 13 16:58:33.439: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-3449" for this suite. @ 05/13/24 16:58:33.445
• [9.075 seconds]
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:90
  STEP: Creating a kubernetes client @ 05/13/24 16:58:33.449
  May 13 16:58:33.449: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename configmap @ 05/13/24 16:58:33.45
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:58:33.462
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:58:33.464
  STEP: Creating configMap with name configmap-test-volume-map-5624a2c2-231a-4d98-a7c6-e91a8cf53308 @ 05/13/24 16:58:33.466
  STEP: Creating a pod to test consume configMaps @ 05/13/24 16:58:33.469
  E0513 16:58:34.213704      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:35.214787      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:36.215275      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:37.214798      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:58:37.492
  May 13 16:58:37.494: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-configmaps-fa6e016d-987b-4332-8755-c045419c568e container agnhost-container: <nil>
  STEP: delete the pod @ 05/13/24 16:58:37.498
  May 13 16:58:37.510: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9255" for this suite. @ 05/13/24 16:58:37.513
• [4.070 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 05/13/24 16:58:37.52
  May 13 16:58:37.520: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename daemonsets @ 05/13/24 16:58:37.52
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:58:37.53
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:58:37.531
  May 13 16:58:37.541: INFO: Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/13/24 16:58:37.545
  May 13 16:58:37.548: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:58:37.548: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 16:58:37.549: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 16:58:37.549: INFO: Node oneke-ip-172-16-100-5 is running 0 daemon pod, expected 1
  E0513 16:58:38.215689      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:58:38.553: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:58:38.553: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 16:58:38.555: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May 13 16:58:38.555: INFO: Node oneke-ip-172-16-100-7 is running 0 daemon pod, expected 1
  E0513 16:58:39.216595      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:58:39.548: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:58:39.548: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 16:58:39.550: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May 13 16:58:39.550: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Update daemon pods image. @ 05/13/24 16:58:39.554
  STEP: Check that daemon pods images are updated. @ 05/13/24 16:58:39.562
  May 13 16:58:39.569: INFO: Wrong image for pod: daemon-set-kfpkx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  May 13 16:58:39.573: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:58:39.573: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0513 16:58:40.218946      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:58:40.565: INFO: Wrong image for pod: daemon-set-kfpkx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  May 13 16:58:40.568: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:58:40.568: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0513 16:58:41.216914      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:58:41.564: INFO: Pod daemon-set-974zx is not available
  May 13 16:58:41.564: INFO: Wrong image for pod: daemon-set-kfpkx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  May 13 16:58:41.566: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:58:41.566: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0513 16:58:42.217599      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:58:42.570: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:58:42.570: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0513 16:58:43.217507      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:58:43.566: INFO: Pod daemon-set-c5nr9 is not available
  May 13 16:58:43.574: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:58:43.574: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Check that daemon pods are still running on every node of the cluster. @ 05/13/24 16:58:43.574
  May 13 16:58:43.579: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:58:43.579: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 16:58:43.586: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May 13 16:58:43.586: INFO: Node oneke-ip-172-16-100-7 is running 0 daemon pod, expected 1
  E0513 16:58:44.217861      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:58:44.581: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-4 with taints [{Key:CriticalAddonsOnly Value:true Effect:NoExecute TimeAdded:<nil>}], skip checking this node
  May 13 16:58:44.581: INFO: DaemonSet pods can't tolerate node oneke-ip-172-16-100-6 with taints [{Key:node.longhorn.io/create-default-disk Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 13 16:58:44.585: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May 13 16:58:44.585: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 05/13/24 16:58:44.596
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8914, will wait for the garbage collector to delete the pods @ 05/13/24 16:58:44.596
  May 13 16:58:44.662: INFO: Deleting DaemonSet.extensions daemon-set took: 14.264408ms
  May 13 16:58:44.764: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.926105ms
  E0513 16:58:45.218642      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:46.219428      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:47.220143      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:58:47.667: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 13 16:58:47.667: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  May 13 16:58:47.668: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"60631"},"items":null}

  May 13 16:58:47.669: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"60631"},"items":null}

  May 13 16:58:47.674: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-8914" for this suite. @ 05/13/24 16:58:47.676
• [10.160 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 05/13/24 16:58:47.681
  May 13 16:58:47.681: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 16:58:47.682
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:58:47.693
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:58:47.696
  STEP: Creating projection with secret that has name projected-secret-test-9dc63da5-b0b3-4de7-a3d3-c1ac3ae610f7 @ 05/13/24 16:58:47.698
  STEP: Creating a pod to test consume secrets @ 05/13/24 16:58:47.702
  E0513 16:58:48.220770      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:49.221468      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:50.222087      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:51.222711      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:58:51.715
  May 13 16:58:51.716: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-projected-secrets-c22b7715-41d8-4e01-9521-10e46731610d container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/13/24 16:58:51.724
  May 13 16:58:51.734: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9300" for this suite. @ 05/13/24 16:58:51.736
• [4.058 seconds]
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 05/13/24 16:58:51.739
  May 13 16:58:51.739: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename pod-network-test @ 05/13/24 16:58:51.74
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:58:51.751
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:58:51.752
  STEP: Performing setup for networking test in namespace pod-network-test-6445 @ 05/13/24 16:58:51.753
  STEP: creating a selector @ 05/13/24 16:58:51.754
  STEP: Creating the service pods in kubernetes @ 05/13/24 16:58:51.754
  May 13 16:58:51.754: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0513 16:58:52.222612      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:53.223741      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:54.224862      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:55.224944      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:56.226020      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:57.226979      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:58.227717      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:58:59.227865      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:00.228839      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:01.229139      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:02.230058      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:03.230528      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 05/13/24 16:59:03.831
  E0513 16:59:04.231609      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:05.231826      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:59:05.869: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  May 13 16:59:05.870: INFO: Going to poll 10.42.1.155 on port 8083 at least 0 times, with a maximum of 34 tries before failing
  May 13 16:59:05.873: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.1.155:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6445 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 16:59:05.873: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 16:59:05.875: INFO: ExecWithOptions: Clientset creation
  May 13 16:59:05.875: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-6445/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.42.1.155%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  May 13 16:59:05.975: INFO: Found all 1 expected endpoints: [netserver-0]
  May 13 16:59:05.975: INFO: Going to poll 10.42.3.138 on port 8083 at least 0 times, with a maximum of 34 tries before failing
  May 13 16:59:05.977: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.3.138:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6445 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 16:59:05.977: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 16:59:05.978: INFO: ExecWithOptions: Clientset creation
  May 13 16:59:05.978: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-6445/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.42.3.138%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  May 13 16:59:06.031: INFO: Found all 1 expected endpoints: [netserver-1]
  May 13 16:59:06.031: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-6445" for this suite. @ 05/13/24 16:59:06.035
• [14.300 seconds]
------------------------------
SS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 05/13/24 16:59:06.039
  May 13 16:59:06.039: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename hostport @ 05/13/24 16:59:06.04
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:59:06.052
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:59:06.053
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 05/13/24 16:59:06.058
  E0513 16:59:06.232295      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:07.233239      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.16.100.7 on the node which pod1 resides and expect scheduled @ 05/13/24 16:59:08.071
  E0513 16:59:08.233859      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:09.234118      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:10.234112      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:11.234265      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.16.100.7 but use UDP protocol on the node which pod2 resides @ 05/13/24 16:59:12.086
  E0513 16:59:12.234358      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:13.234439      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:14.235184      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:15.236105      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 05/13/24 16:59:16.145
  May 13 16:59:16.145: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.16.100.7 http://127.0.0.1:54323/hostname] Namespace:hostport-1076 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 16:59:16.145: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 16:59:16.145: INFO: ExecWithOptions: Clientset creation
  May 13 16:59:16.146: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/hostport-1076/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.16.100.7+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.16.100.7, port: 54323 @ 05/13/24 16:59:16.199
  May 13 16:59:16.200: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.16.100.7:54323/hostname] Namespace:hostport-1076 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 16:59:16.200: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 16:59:16.200: INFO: ExecWithOptions: Clientset creation
  May 13 16:59:16.200: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/hostport-1076/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.16.100.7%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E0513 16:59:16.237057      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.16.100.7, port: 54323 UDP @ 05/13/24 16:59:16.265
  May 13 16:59:16.265: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.16.100.7 54323] Namespace:hostport-1076 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 16:59:16.265: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 16:59:16.266: INFO: ExecWithOptions: Clientset creation
  May 13 16:59:16.266: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/hostport-1076/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.16.100.7+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E0513 16:59:17.237630      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:18.237963      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:19.238092      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:20.238500      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:21.239767      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:59:21.322: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-1076" for this suite. @ 05/13/24 16:59:21.326
• [15.293 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:236
  STEP: Creating a kubernetes client @ 05/13/24 16:59:21.334
  May 13 16:59:21.334: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/13/24 16:59:21.335
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:59:21.35
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:59:21.355
  May 13 16:59:21.357: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 16:59:22.248139      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 05/13/24 16:59:22.813
  May 13 16:59:22.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-6981 --namespace=crd-publish-openapi-6981 create -f -'
  E0513 16:59:23.241033      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:24.241825      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:59:24.896: INFO: stderr: ""
  May 13 16:59:24.896: INFO: stdout: "e2e-test-crd-publish-openapi-6208-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  May 13 16:59:24.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-6981 --namespace=crd-publish-openapi-6981 delete e2e-test-crd-publish-openapi-6208-crds test-cr'
  May 13 16:59:24.969: INFO: stderr: ""
  May 13 16:59:24.969: INFO: stdout: "e2e-test-crd-publish-openapi-6208-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  May 13 16:59:24.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-6981 --namespace=crd-publish-openapi-6981 apply -f -'
  May 13 16:59:25.017: INFO: stderr: ""
  May 13 16:59:25.017: INFO: stdout: "e2e-test-crd-publish-openapi-6208-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  May 13 16:59:25.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-6981 --namespace=crd-publish-openapi-6981 delete e2e-test-crd-publish-openapi-6208-crds test-cr'
  May 13 16:59:25.064: INFO: stderr: ""
  May 13 16:59:25.064: INFO: stdout: "e2e-test-crd-publish-openapi-6208-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 05/13/24 16:59:25.064
  May 13 16:59:25.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-6981 explain e2e-test-crd-publish-openapi-6208-crds'
  May 13 16:59:25.108: INFO: stderr: ""
  May 13 16:59:25.108: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-6208-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0513 16:59:25.242636      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:26.243651      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:59:26.546: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-6981" for this suite. @ 05/13/24 16:59:26.553
• [5.228 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:139
  STEP: Creating a kubernetes client @ 05/13/24 16:59:26.565
  May 13 16:59:26.565: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename configmap @ 05/13/24 16:59:26.568
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:59:26.589
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:59:26.59
  STEP: Creating configMap that has name configmap-test-emptyKey-9913e124-1a2f-44d2-88bf-7cb1815e1121 @ 05/13/24 16:59:26.591
  May 13 16:59:26.592: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2102" for this suite. @ 05/13/24 16:59:26.594
• [0.036 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:80
  STEP: Creating a kubernetes client @ 05/13/24 16:59:26.601
  May 13 16:59:26.601: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename svcaccounts @ 05/13/24 16:59:26.601
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:59:26.611
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:59:26.613
  E0513 16:59:27.244591      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:28.244672      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 05/13/24 16:59:28.626
  May 13 16:59:28.626: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2504 pod-service-account-f885d357-e928-4e8c-9ee6-b92ed03c0494 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 05/13/24 16:59:28.726
  May 13 16:59:28.727: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2504 pod-service-account-f885d357-e928-4e8c-9ee6-b92ed03c0494 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 05/13/24 16:59:28.829
  May 13 16:59:28.829: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2504 pod-service-account-f885d357-e928-4e8c-9ee6-b92ed03c0494 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  May 13 16:59:28.926: INFO: Got root ca configmap in namespace "svcaccounts-2504"
  May 13 16:59:28.927: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2504" for this suite. @ 05/13/24 16:59:28.929
• [2.332 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:144
  STEP: Creating a kubernetes client @ 05/13/24 16:59:28.933
  May 13 16:59:28.933: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename replicaset @ 05/13/24 16:59:28.935
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:59:28.95
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:59:28.956
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 05/13/24 16:59:28.957
  May 13 16:59:28.963: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0513 16:59:29.245401      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:30.245961      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:31.246545      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:32.246669      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:33.247051      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:59:33.975: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/13/24 16:59:33.975
  STEP: getting scale subresource @ 05/13/24 16:59:33.976
  STEP: updating a scale subresource @ 05/13/24 16:59:33.98
  STEP: verifying the replicaset Spec.Replicas was modified @ 05/13/24 16:59:33.995
  STEP: Patch a scale subresource @ 05/13/24 16:59:34.008
  May 13 16:59:34.018: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-512" for this suite. @ 05/13/24 16:59:34.031
• [5.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:95
  STEP: Creating a kubernetes client @ 05/13/24 16:59:34.047
  May 13 16:59:34.047: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename var-expansion @ 05/13/24 16:59:34.049
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:59:34.062
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:59:34.064
  STEP: Creating a pod to test substitution in container's args @ 05/13/24 16:59:34.065
  E0513 16:59:34.247822      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:35.248071      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:36.248197      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:37.249304      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:59:38.088
  May 13 16:59:38.089: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod var-expansion-2cd36bcf-79d4-40e2-9b6b-6f29537723ec container dapi-container: <nil>
  STEP: delete the pod @ 05/13/24 16:59:38.093
  May 13 16:59:38.105: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3087" for this suite. @ 05/13/24 16:59:38.107
• [4.065 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:57
  STEP: Creating a kubernetes client @ 05/13/24 16:59:38.113
  May 13 16:59:38.113: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename runtimeclass @ 05/13/24 16:59:38.114
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:59:38.126
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:59:38.127
  May 13 16:59:38.132: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-6191" for this suite. @ 05/13/24 16:59:38.134
• [0.025 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:627
  STEP: Creating a kubernetes client @ 05/13/24 16:59:38.143
  May 13 16:59:38.144: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename job @ 05/13/24 16:59:38.144
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:59:38.155
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:59:38.156
  STEP: Creating a job @ 05/13/24 16:59:38.158
  STEP: Ensuring active pods == parallelism @ 05/13/24 16:59:38.161
  E0513 16:59:38.250024      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:39.250143      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete a job @ 05/13/24 16:59:40.165
  STEP: deleting Job.batch foo in namespace job-1563, will wait for the garbage collector to delete the pods @ 05/13/24 16:59:40.165
  May 13 16:59:40.226: INFO: Deleting Job.batch foo took: 7.224393ms
  E0513 16:59:40.250427      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:59:40.327: INFO: Terminating Job.batch foo pods took: 101.154236ms
  E0513 16:59:41.250678      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:42.251346      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 05/13/24 16:59:42.728
  May 13 16:59:42.729: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1563" for this suite. @ 05/13/24 16:59:42.732
• [4.593 seconds]
------------------------------
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:169
  STEP: Creating a kubernetes client @ 05/13/24 16:59:42.738
  May 13 16:59:42.738: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/13/24 16:59:42.739
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:59:42.751
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:59:42.752
  STEP: create the container to handle the HTTPGet hook request. @ 05/13/24 16:59:42.756
  E0513 16:59:43.252173      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:44.253124      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/13/24 16:59:44.776
  E0513 16:59:45.254065      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:46.255232      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 05/13/24 16:59:46.795
  STEP: delete the pod with lifecycle hook @ 05/13/24 16:59:46.801
  E0513 16:59:47.255137      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:48.254875      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:59:48.814: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-6173" for this suite. @ 05/13/24 16:59:48.817
• [6.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1764
  STEP: Creating a kubernetes client @ 05/13/24 16:59:48.822
  May 13 16:59:48.822: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubectl @ 05/13/24 16:59:48.823
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:59:48.834
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:59:48.835
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/13/24 16:59:48.836
  May 13 16:59:48.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-9679 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  May 13 16:59:48.892: INFO: stderr: ""
  May 13 16:59:48.892: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 05/13/24 16:59:48.892
  May 13 16:59:48.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-9679 delete pods e2e-test-httpd-pod'
  E0513 16:59:49.255158      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:50.255586      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:59:50.788: INFO: stderr: ""
  May 13 16:59:50.788: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  May 13 16:59:50.788: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9679" for this suite. @ 05/13/24 16:59:50.791
• [1.973 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:140
  STEP: Creating a kubernetes client @ 05/13/24 16:59:50.797
  May 13 16:59:50.797: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename emptydir @ 05/13/24 16:59:50.797
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:59:50.81
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:59:50.812
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 05/13/24 16:59:50.813
  E0513 16:59:51.256002      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:52.257429      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:53.257564      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:54.258096      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 16:59:54.83
  May 13 16:59:54.832: INFO: Trying to get logs from node oneke-ip-172-16-100-7 pod pod-e05c245c-1db1-4038-8121-11f153923908 container test-container: <nil>
  STEP: delete the pod @ 05/13/24 16:59:54.835
  May 13 16:59:54.847: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2747" for this suite. @ 05/13/24 16:59:54.849
• [4.055 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:54
  STEP: Creating a kubernetes client @ 05/13/24 16:59:54.852
  May 13 16:59:54.852: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename podtemplate @ 05/13/24 16:59:54.853
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:59:54.864
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:59:54.865
  May 13 16:59:54.878: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-9337" for this suite. @ 05/13/24 16:59:54.881
• [0.032 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1053
  STEP: Creating a kubernetes client @ 05/13/24 16:59:54.886
  May 13 16:59:54.887: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubectl @ 05/13/24 16:59:54.888
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:59:54.898
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:59:54.9
  STEP: create deployment with httpd image @ 05/13/24 16:59:54.902
  May 13 16:59:54.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-2581 create -f -'
  May 13 16:59:54.979: INFO: stderr: ""
  May 13 16:59:54.980: INFO: stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 05/13/24 16:59:54.98
  May 13 16:59:54.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-2581 diff -f -'
  May 13 16:59:55.194: INFO: rc: 1
  May 13 16:59:55.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-2581 delete -f -'
  May 13 16:59:55.245: INFO: stderr: ""
  May 13 16:59:55.245: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  May 13 16:59:55.245: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2581" for this suite. @ 05/13/24 16:59:55.25
• [0.371 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
  E0513 16:59:55.259947      17 retrywatcher.go:129] "Watch failed" err="context canceled"
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:177
  STEP: Creating a kubernetes client @ 05/13/24 16:59:55.26
  May 13 16:59:55.260: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename crd-webhook @ 05/13/24 16:59:55.261
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 16:59:55.271
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 16:59:55.273
  STEP: Setting up server cert @ 05/13/24 16:59:55.275
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 05/13/24 16:59:56.027
  STEP: Deploying the custom resource conversion webhook pod @ 05/13/24 16:59:56.032
  STEP: Wait for the deployment to be ready @ 05/13/24 16:59:56.04
  May 13 16:59:56.048: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0513 16:59:56.262121      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 16:59:57.261958      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/13/24 16:59:58.072
  STEP: Verifying the service has paired with the endpoint @ 05/13/24 16:59:58.085
  E0513 16:59:58.263165      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 16:59:59.086: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  May 13 16:59:59.091: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 16:59:59.263440      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:00.264031      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:01.264475      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 05/13/24 17:00:01.639
  STEP: Create a v2 custom resource @ 05/13/24 17:00:01.65
  STEP: List CRs in v1 @ 05/13/24 17:00:01.669
  STEP: List CRs in v2 @ 05/13/24 17:00:01.678
  May 13 17:00:02.245: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-205" for this suite. @ 05/13/24 17:00:02.247
• [6.991 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:194
  STEP: Creating a kubernetes client @ 05/13/24 17:00:02.253
  May 13 17:00:02.253: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/13/24 17:00:02.254
  E0513 17:00:02.264566      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:00:02.267
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:00:02.268
  May 13 17:00:02.270: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  E0513 17:00:03.264972      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 05/13/24 17:00:03.753
  May 13 17:00:03.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-4256 --namespace=crd-publish-openapi-4256 create -f -'
  E0513 17:00:04.265382      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:05.266204      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:00:05.832: INFO: stderr: ""
  May 13 17:00:05.832: INFO: stdout: "e2e-test-crd-publish-openapi-6017-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  May 13 17:00:05.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-4256 --namespace=crd-publish-openapi-4256 delete e2e-test-crd-publish-openapi-6017-crds test-cr'
  May 13 17:00:05.882: INFO: stderr: ""
  May 13 17:00:05.882: INFO: stdout: "e2e-test-crd-publish-openapi-6017-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  May 13 17:00:05.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-4256 --namespace=crd-publish-openapi-4256 apply -f -'
  May 13 17:00:05.945: INFO: stderr: ""
  May 13 17:00:05.945: INFO: stdout: "e2e-test-crd-publish-openapi-6017-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  May 13 17:00:05.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-4256 --namespace=crd-publish-openapi-4256 delete e2e-test-crd-publish-openapi-6017-crds test-cr'
  May 13 17:00:05.995: INFO: stderr: ""
  May 13 17:00:05.995: INFO: stdout: "e2e-test-crd-publish-openapi-6017-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 05/13/24 17:00:05.995
  May 13 17:00:05.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=crd-publish-openapi-4256 explain e2e-test-crd-publish-openapi-6017-crds'
  May 13 17:00:06.042: INFO: stderr: ""
  May 13 17:00:06.042: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-6017-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0513 17:00:06.267455      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:07.268475      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:00:07.476: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4256" for this suite. @ 05/13/24 17:00:07.481
• [5.234 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:1015
  STEP: Creating a kubernetes client @ 05/13/24 17:00:07.487
  May 13 17:00:07.487: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename resourcequota @ 05/13/24 17:00:07.488
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:00:07.502
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:00:07.503
  STEP: Creating resourceQuota "e2e-rq-status-fqpxs" @ 05/13/24 17:00:07.505
  May 13 17:00:07.510: INFO: Resource quota "e2e-rq-status-fqpxs" reports spec: hard cpu limit of 500m
  May 13 17:00:07.510: INFO: Resource quota "e2e-rq-status-fqpxs" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-fqpxs" /status @ 05/13/24 17:00:07.51
  STEP: Confirm /status for "e2e-rq-status-fqpxs" resourceQuota via watch @ 05/13/24 17:00:07.514
  May 13 17:00:07.514: INFO: observed resourceQuota "e2e-rq-status-fqpxs" in namespace "resourcequota-9340" with hard status: v1.ResourceList(nil)
  May 13 17:00:07.515: INFO: Found resourceQuota "e2e-rq-status-fqpxs" in namespace "resourcequota-9340" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  May 13 17:00:07.515: INFO: ResourceQuota "e2e-rq-status-fqpxs" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 05/13/24 17:00:07.516
  May 13 17:00:07.520: INFO: Resource quota "e2e-rq-status-fqpxs" reports spec: hard cpu limit of 1
  May 13 17:00:07.520: INFO: Resource quota "e2e-rq-status-fqpxs" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-fqpxs" /status @ 05/13/24 17:00:07.521
  STEP: Confirm /status for "e2e-rq-status-fqpxs" resourceQuota via watch @ 05/13/24 17:00:07.523
  May 13 17:00:07.524: INFO: observed resourceQuota "e2e-rq-status-fqpxs" in namespace "resourcequota-9340" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  May 13 17:00:07.524: INFO: Found resourceQuota "e2e-rq-status-fqpxs" in namespace "resourcequota-9340" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  May 13 17:00:07.524: INFO: ResourceQuota "e2e-rq-status-fqpxs" /status was patched
  STEP: Get "e2e-rq-status-fqpxs" /status @ 05/13/24 17:00:07.524
  May 13 17:00:07.526: INFO: Resourcequota "e2e-rq-status-fqpxs" reports status: hard cpu of 1
  May 13 17:00:07.526: INFO: Resourcequota "e2e-rq-status-fqpxs" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-fqpxs" /status before checking Spec is unchanged @ 05/13/24 17:00:07.527
  May 13 17:00:07.529: INFO: Resourcequota "e2e-rq-status-fqpxs" reports status: hard cpu of 2
  May 13 17:00:07.529: INFO: Resourcequota "e2e-rq-status-fqpxs" reports status: hard memory of 2Gi
  May 13 17:00:07.530: INFO: Found resourceQuota "e2e-rq-status-fqpxs" in namespace "resourcequota-9340" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  May 13 17:00:07.531: INFO: ResourceQuota "e2e-rq-status-fqpxs" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fqpxs", GenerateName:"", Namespace:"resourcequota-9340", SelfLink:"", UID:"e854489e-9328-43e8-b3c2-176b3a1375a6", ResourceVersion:"61704", Generation:0, CreationTimestamp:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fqpxs"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0055a97a0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0055a97d0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0055a9830), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0513 17:00:08.268611      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:09.269197      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:10.269396      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:11.269985      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:12.270513      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:00:12.548: INFO: ResourceQuota "e2e-rq-status-fqpxs" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fqpxs", GenerateName:"", Namespace:"resourcequota-9340", SelfLink:"", UID:"e854489e-9328-43e8-b3c2-176b3a1375a6", ResourceVersion:"61704", Generation:0, CreationTimestamp:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fqpxs"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0055a9c80), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0055a9ce0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0055a9d10), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0513 17:00:13.270430      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:14.271857      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:15.271834      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:16.271924      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:17.272147      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:00:17.533: INFO: ResourceQuota "e2e-rq-status-fqpxs" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fqpxs", GenerateName:"", Namespace:"resourcequota-9340", SelfLink:"", UID:"e854489e-9328-43e8-b3c2-176b3a1375a6", ResourceVersion:"61704", Generation:0, CreationTimestamp:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fqpxs"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00541e8a0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00541e8e8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00541e918), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0513 17:00:18.272943      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:19.272960      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:20.272951      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:21.273418      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:22.273387      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:00:22.537: INFO: ResourceQuota "e2e-rq-status-fqpxs" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fqpxs", GenerateName:"", Namespace:"resourcequota-9340", SelfLink:"", UID:"e854489e-9328-43e8-b3c2-176b3a1375a6", ResourceVersion:"61704", Generation:0, CreationTimestamp:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fqpxs"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00541ecd8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00541ed08), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00541ed68), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0513 17:00:23.273588      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:24.274256      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:25.275227      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:26.275754      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:27.276514      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:00:27.533: INFO: ResourceQuota "e2e-rq-status-fqpxs" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fqpxs", GenerateName:"", Namespace:"resourcequota-9340", SelfLink:"", UID:"e854489e-9328-43e8-b3c2-176b3a1375a6", ResourceVersion:"61704", Generation:0, CreationTimestamp:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fqpxs"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000a46540), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000a46588), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000a465b8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0513 17:00:28.276203      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:29.277472      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:30.277447      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:31.278304      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:32.279035      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:00:32.536: INFO: ResourceQuota "e2e-rq-status-fqpxs" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fqpxs", GenerateName:"", Namespace:"resourcequota-9340", SelfLink:"", UID:"e854489e-9328-43e8-b3c2-176b3a1375a6", ResourceVersion:"61704", Generation:0, CreationTimestamp:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fqpxs"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000a469d8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000a46a38), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000a46a68), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0513 17:00:33.279129      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:34.279668      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:35.279768      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:36.280044      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:37.280323      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:00:37.533: INFO: ResourceQuota "e2e-rq-status-fqpxs" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fqpxs", GenerateName:"", Namespace:"resourcequota-9340", SelfLink:"", UID:"e854489e-9328-43e8-b3c2-176b3a1375a6", ResourceVersion:"61704", Generation:0, CreationTimestamp:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fqpxs"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000a46d98), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000a46e10), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000a46e70), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0513 17:00:38.280278      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:39.280800      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:40.281400      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:41.281541      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:42.281705      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:00:42.536: INFO: ResourceQuota "e2e-rq-status-fqpxs" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fqpxs", GenerateName:"", Namespace:"resourcequota-9340", SelfLink:"", UID:"e854489e-9328-43e8-b3c2-176b3a1375a6", ResourceVersion:"61704", Generation:0, CreationTimestamp:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fqpxs"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00541f398), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00541f410), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00541f440), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0513 17:00:43.281900      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:44.282549      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:45.283156      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:46.283371      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:47.283466      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:00:47.532: INFO: ResourceQuota "e2e-rq-status-fqpxs" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fqpxs", GenerateName:"", Namespace:"resourcequota-9340", SelfLink:"", UID:"e854489e-9328-43e8-b3c2-176b3a1375a6", ResourceVersion:"61704", Generation:0, CreationTimestamp:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fqpxs"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00541f770), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00541f7a0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00541f7d0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0513 17:00:48.283681      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:49.284300      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:50.285145      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:51.285371      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:52.285732      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:00:52.532: INFO: ResourceQuota "e2e-rq-status-fqpxs" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fqpxs", GenerateName:"", Namespace:"resourcequota-9340", SelfLink:"", UID:"e854489e-9328-43e8-b3c2-176b3a1375a6", ResourceVersion:"61704", Generation:0, CreationTimestamp:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fqpxs"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000a47668), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000a476b0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000a476e0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0513 17:00:53.285989      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:54.286454      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:55.287279      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:56.287414      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:57.287641      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:00:57.536: INFO: ResourceQuota "e2e-rq-status-fqpxs" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fqpxs", GenerateName:"", Namespace:"resourcequota-9340", SelfLink:"", UID:"e854489e-9328-43e8-b3c2-176b3a1375a6", ResourceVersion:"61704", Generation:0, CreationTimestamp:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fqpxs"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00541fc50), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00541fc98), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00541fcc8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0513 17:00:58.288396      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:00:59.288861      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:00.288959      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:01.290165      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:02.290930      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:01:02.537: INFO: ResourceQuota "e2e-rq-status-fqpxs" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fqpxs", GenerateName:"", Namespace:"resourcequota-9340", SelfLink:"", UID:"e854489e-9328-43e8-b3c2-176b3a1375a6", ResourceVersion:"61704", Generation:0, CreationTimestamp:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fqpxs"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000a47c98), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000a47d70), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000a47db8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0513 17:01:03.291599      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:04.291969      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:05.292066      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:06.292516      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:07.292617      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:01:07.532: INFO: ResourceQuota "e2e-rq-status-fqpxs" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fqpxs", GenerateName:"", Namespace:"resourcequota-9340", SelfLink:"", UID:"e854489e-9328-43e8-b3c2-176b3a1375a6", ResourceVersion:"61704", Generation:0, CreationTimestamp:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fqpxs"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0029de210), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0029de2a0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0029de360), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0513 17:01:08.292685      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:09.292785      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:10.292909      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:11.293381      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:12.293359      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:01:12.536: INFO: ResourceQuota "e2e-rq-status-fqpxs" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fqpxs", GenerateName:"", Namespace:"resourcequota-9340", SelfLink:"", UID:"e854489e-9328-43e8-b3c2-176b3a1375a6", ResourceVersion:"61704", Generation:0, CreationTimestamp:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fqpxs"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0029de870), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0029de8d0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0029de918), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0513 17:01:13.293582      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:14.294699      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:15.295459      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:16.295693      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:17.296018      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:01:17.532: INFO: ResourceQuota "e2e-rq-status-fqpxs" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fqpxs", GenerateName:"", Namespace:"resourcequota-9340", SelfLink:"", UID:"e854489e-9328-43e8-b3c2-176b3a1375a6", ResourceVersion:"61704", Generation:0, CreationTimestamp:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fqpxs"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0029dee40), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0029deea0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0029deee8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0513 17:01:18.296231      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:19.296495      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:20.297004      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:21.298932      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:22.299464      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:01:22.536: INFO: ResourceQuota "e2e-rq-status-fqpxs" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fqpxs", GenerateName:"", Namespace:"resourcequota-9340", SelfLink:"", UID:"e854489e-9328-43e8-b3c2-176b3a1375a6", ResourceVersion:"61704", Generation:0, CreationTimestamp:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fqpxs"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0029df290), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0029df2f0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0029df338), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0513 17:01:23.299947      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:24.301011      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:25.300312      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:26.301214      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:27.301824      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:01:27.533: INFO: ResourceQuota "e2e-rq-status-fqpxs" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fqpxs", GenerateName:"", Namespace:"resourcequota-9340", SelfLink:"", UID:"e854489e-9328-43e8-b3c2-176b3a1375a6", ResourceVersion:"61704", Generation:0, CreationTimestamp:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fqpxs"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0029df7a0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0029df7e8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0029df878), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0513 17:01:28.301997      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:29.302684      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:30.302750      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:31.303229      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:32.303533      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:01:32.536: INFO: ResourceQuota "e2e-rq-status-fqpxs" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fqpxs", GenerateName:"", Namespace:"resourcequota-9340", SelfLink:"", UID:"e854489e-9328-43e8-b3c2-176b3a1375a6", ResourceVersion:"61704", Generation:0, CreationTimestamp:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fqpxs"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0029dfe90), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0029dff20), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0029dff80), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0513 17:01:33.303783      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:34.303748      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:35.304831      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:36.305899      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:37.306644      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:01:37.532: INFO: ResourceQuota "e2e-rq-status-fqpxs" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fqpxs", GenerateName:"", Namespace:"resourcequota-9340", SelfLink:"", UID:"e854489e-9328-43e8-b3c2-176b3a1375a6", ResourceVersion:"61704", Generation:0, CreationTimestamp:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fqpxs"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0005f1890), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0005f18f0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 13, 17, 0, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0005f1950), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0513 17:01:38.306601      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:39.306920      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:40.306913      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:41.307532      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:42.307623      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:01:42.536: INFO: ResourceQuota "e2e-rq-status-fqpxs" Spec was unchanged and /status reset
  May 13 17:01:42.537: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9340" for this suite. @ 05/13/24 17:01:42.546
• [95.066 seconds]
------------------------------
SSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 05/13/24 17:01:42.557
  May 13 17:01:42.557: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename certificates @ 05/13/24 17:01:42.561
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:01:42.578
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:01:42.581
  STEP: getting /apis @ 05/13/24 17:01:43.17
  STEP: getting /apis/certificates.k8s.io @ 05/13/24 17:01:43.174
  STEP: getting /apis/certificates.k8s.io/v1 @ 05/13/24 17:01:43.174
  STEP: creating @ 05/13/24 17:01:43.175
  STEP: getting @ 05/13/24 17:01:43.188
  STEP: listing @ 05/13/24 17:01:43.189
  STEP: watching @ 05/13/24 17:01:43.192
  May 13 17:01:43.192: INFO: starting watch
  STEP: patching @ 05/13/24 17:01:43.192
  STEP: updating @ 05/13/24 17:01:43.195
  May 13 17:01:43.198: INFO: waiting for watch events with expected annotations
  May 13 17:01:43.199: INFO: saw patched and updated annotations
  STEP: getting /approval @ 05/13/24 17:01:43.199
  STEP: patching /approval @ 05/13/24 17:01:43.2
  STEP: updating /approval @ 05/13/24 17:01:43.203
  STEP: getting /status @ 05/13/24 17:01:43.207
  STEP: patching /status @ 05/13/24 17:01:43.208
  STEP: updating /status @ 05/13/24 17:01:43.213
  STEP: deleting @ 05/13/24 17:01:43.217
  STEP: deleting a collection @ 05/13/24 17:01:43.222
  May 13 17:01:43.228: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-614" for this suite. @ 05/13/24 17:01:43.231
• [0.680 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 05/13/24 17:01:43.235
  May 13 17:01:43.235: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename events @ 05/13/24 17:01:43.236
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:01:43.246
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:01:43.247
  STEP: Create set of events @ 05/13/24 17:01:43.249
  STEP: get a list of Events with a label in the current namespace @ 05/13/24 17:01:43.256
  STEP: delete a list of events @ 05/13/24 17:01:43.257
  May 13 17:01:43.257: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 05/13/24 17:01:43.261
  May 13 17:01:43.262: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-137" for this suite. @ 05/13/24 17:01:43.264
• [0.032 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1493
  STEP: Creating a kubernetes client @ 05/13/24 17:01:43.269
  May 13 17:01:43.269: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename services @ 05/13/24 17:01:43.27
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:01:43.281
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:01:43.282
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-8395 @ 05/13/24 17:01:43.283
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 05/13/24 17:01:43.29
  STEP: creating service externalsvc in namespace services-8395 @ 05/13/24 17:01:43.29
  STEP: creating replication controller externalsvc in namespace services-8395 @ 05/13/24 17:01:43.301
  I0513 17:01:43.306406      17 runners.go:197] Created replication controller with name: externalsvc, namespace: services-8395, replica count: 2
  E0513 17:01:43.308135      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:44.308689      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:45.309806      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:46.310293      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0513 17:01:46.358280      17 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 05/13/24 17:01:46.366
  May 13 17:01:46.390: INFO: Creating new exec pod
  E0513 17:01:47.310554      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:48.311366      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:01:48.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=services-8395 exec execpodxwvmh -- /bin/sh -x -c nslookup clusterip-service.services-8395.svc.cluster.local'
  May 13 17:01:48.632: INFO: stderr: "+ nslookup clusterip-service.services-8395.svc.cluster.local\n"
  May 13 17:01:48.632: INFO: stdout: "Server:\t\t10.43.0.10\nAddress:\t10.43.0.10#53\n\nclusterip-service.services-8395.svc.cluster.local\tcanonical name = externalsvc.services-8395.svc.cluster.local.\nName:\texternalsvc.services-8395.svc.cluster.local\nAddress: 10.43.141.148\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-8395, will wait for the garbage collector to delete the pods @ 05/13/24 17:01:48.632
  May 13 17:01:48.687: INFO: Deleting ReplicationController externalsvc took: 3.110432ms
  May 13 17:01:48.788: INFO: Terminating ReplicationController externalsvc pods took: 100.661553ms
  E0513 17:01:49.312267      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:50.313236      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:51.314128      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:01:51.520: INFO: Cleaning up the ClusterIP to ExternalName test service
  May 13 17:01:51.531: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8395" for this suite. @ 05/13/24 17:01:51.535
• [8.278 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1798
  STEP: Creating a kubernetes client @ 05/13/24 17:01:51.547
  May 13 17:01:51.547: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubectl @ 05/13/24 17:01:51.548
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:01:51.561
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:01:51.567
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/13/24 17:01:51.569
  May 13 17:01:51.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3067 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  May 13 17:01:51.624: INFO: stderr: ""
  May 13 17:01:51.624: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 05/13/24 17:01:51.624
  E0513 17:01:52.315132      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:53.315937      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:54.316143      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:55.317103      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:56.317647      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 05/13/24 17:01:56.675
  May 13 17:01:56.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3067 get pod e2e-test-httpd-pod -o json'
  May 13 17:01:56.782: INFO: stderr: ""
  May 13 17:01:56.782: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"ba094c9671648afc03d09ceaf09bb2411c3a2d953279cc131b72948db02d2429\",\n            \"cni.projectcalico.org/podIP\": \"10.42.1.162/32\",\n            \"cni.projectcalico.org/podIPs\": \"10.42.1.162/32\",\n            \"k8s.v1.cni.cncf.io/network-status\": \"[{\\n    \\\"name\\\": \\\"k8s-pod-network\\\",\\n    \\\"ips\\\": [\\n        \\\"10.42.1.162\\\"\\n    ],\\n    \\\"default\\\": true,\\n    \\\"dns\\\": {}\\n}]\"\n        },\n        \"creationTimestamp\": \"2024-05-13T17:01:51Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-3067\",\n        \"resourceVersion\": \"62283\",\n        \"uid\": \"e8dd6e8f-a8f0-4332-8530-ce93e6dd4744\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-xfn59\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"oneke-ip-172-16-100-5\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-xfn59\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-13T17:01:53Z\",\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-13T17:01:51Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-13T17:01:53Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-13T17:01:53Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-13T17:01:51Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://867a55debf474d2b66a16814c5cbfc0eb6e7fe50544ba93e09f36ab7722e965a\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2024-05-13T17:01:52Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.16.100.5\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"172.16.100.5\"\n            }\n        ],\n        \"phase\": \"Running\",\n        \"podIP\": \"10.42.1.162\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.42.1.162\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2024-05-13T17:01:51Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 05/13/24 17:01:56.782
  May 13 17:01:56.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3067 replace -f -'
  May 13 17:01:56.876: INFO: stderr: ""
  May 13 17:01:56.876: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.36.1-1 @ 05/13/24 17:01:56.876
  May 13 17:01:56.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3236183377 --namespace=kubectl-3067 delete pods e2e-test-httpd-pod'
  E0513 17:01:57.318145      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:01:58.230: INFO: stderr: ""
  May 13 17:01:58.230: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  May 13 17:01:58.230: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3067" for this suite. @ 05/13/24 17:01:58.233
• [6.691 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:134
  STEP: Creating a kubernetes client @ 05/13/24 17:01:58.239
  May 13 17:01:58.239: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename container-probe @ 05/13/24 17:01:58.24
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:01:58.251
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:01:58.253
  STEP: Creating pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164 @ 05/13/24 17:01:58.254
  E0513 17:01:58.319731      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:01:59.320152      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/13/24 17:02:00.27
  May 13 17:02:00.272: INFO: Initial restart count of pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 is 0
  May 13 17:02:00.273: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:00.320348      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:01.320387      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:02.276: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:02.321343      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:03.321685      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:04.279: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:04.322703      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:05.323548      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:06.281: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:06.323907      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:07.324116      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:08.284: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:08.324305      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:09.324462      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:10.287: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:10.324735      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:11.324848      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:12.292: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:12.325021      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:13.325519      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:14.295: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:14.326083      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:15.327100      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:16.297: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:16.327246      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:17.327477      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:18.299: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:18.328171      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:19.328662      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:20.303: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:20.329451      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:21.329912      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:22.305: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:22.330689      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:23.331343      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:24.311: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:24.332213      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:25.333339      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:26.317: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:26.333847      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:27.333692      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:28.321: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:28.334552      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:29.335094      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:30.324: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:30.335634      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:31.335963      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:32.327: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:32.335975      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:33.336107      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:34.333: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:34.336878      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:35.336863      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:36.337222      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:36.337: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:37.337668      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:38.338441      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:38.339: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:39.339376      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:40.339276      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:40.342: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:41.340606      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:42.340558      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:42.346: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:43.341323      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:44.341526      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:44.348: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:45.342256      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:46.342825      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:46.350: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:47.343548      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:48.344193      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:48.353: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  E0513 17:02:49.345318      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:50.346769      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:02:50.360: INFO: Get pod busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 in namespace container-probe-5164
  May 13 17:02:50.361: INFO: Restart count of pod container-probe-5164/busybox-ca0abf47-8443-4ca6-8a86-9edbecd82a04 is now 1 (50.089228955s elapsed)
  STEP: deleting the pod @ 05/13/24 17:02:50.362
  May 13 17:02:50.382: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-5164" for this suite. @ 05/13/24 17:02:50.388
• [52.155 seconds]
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:106
  STEP: Creating a kubernetes client @ 05/13/24 17:02:50.394
  May 13 17:02:50.394: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename runtimeclass @ 05/13/24 17:02:50.395
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:02:50.408
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:02:50.41
  May 13 17:02:50.427: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-7765" for this suite. @ 05/13/24 17:02:50.431
• [0.048 seconds]
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 05/13/24 17:02:50.442
  May 13 17:02:50.442: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename discovery @ 05/13/24 17:02:50.443
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:02:50.452
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:02:50.454
  STEP: Setting up server cert @ 05/13/24 17:02:50.456
  May 13 17:02:50.973: INFO: Checking APIGroup: apiregistration.k8s.io
  May 13 17:02:50.973: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  May 13 17:02:50.973: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
  May 13 17:02:50.973: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  May 13 17:02:50.973: INFO: Checking APIGroup: apps
  May 13 17:02:50.974: INFO: PreferredVersion.GroupVersion: apps/v1
  May 13 17:02:50.974: INFO: Versions found [{apps/v1 v1}]
  May 13 17:02:50.974: INFO: apps/v1 matches apps/v1
  May 13 17:02:50.974: INFO: Checking APIGroup: events.k8s.io
  May 13 17:02:50.974: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
  May 13 17:02:50.974: INFO: Versions found [{events.k8s.io/v1 v1}]
  May 13 17:02:50.974: INFO: events.k8s.io/v1 matches events.k8s.io/v1
  May 13 17:02:50.974: INFO: Checking APIGroup: authentication.k8s.io
  May 13 17:02:50.975: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
  May 13 17:02:50.975: INFO: Versions found [{authentication.k8s.io/v1 v1}]
  May 13 17:02:50.975: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
  May 13 17:02:50.975: INFO: Checking APIGroup: authorization.k8s.io
  May 13 17:02:50.975: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
  May 13 17:02:50.975: INFO: Versions found [{authorization.k8s.io/v1 v1}]
  May 13 17:02:50.975: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
  May 13 17:02:50.975: INFO: Checking APIGroup: autoscaling
  May 13 17:02:50.975: INFO: PreferredVersion.GroupVersion: autoscaling/v2
  May 13 17:02:50.975: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  May 13 17:02:50.975: INFO: autoscaling/v2 matches autoscaling/v2
  May 13 17:02:50.975: INFO: Checking APIGroup: batch
  May 13 17:02:50.976: INFO: PreferredVersion.GroupVersion: batch/v1
  May 13 17:02:50.976: INFO: Versions found [{batch/v1 v1}]
  May 13 17:02:50.976: INFO: batch/v1 matches batch/v1
  May 13 17:02:50.976: INFO: Checking APIGroup: certificates.k8s.io
  May 13 17:02:50.976: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
  May 13 17:02:50.976: INFO: Versions found [{certificates.k8s.io/v1 v1}]
  May 13 17:02:50.976: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
  May 13 17:02:50.976: INFO: Checking APIGroup: networking.k8s.io
  May 13 17:02:50.976: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
  May 13 17:02:50.976: INFO: Versions found [{networking.k8s.io/v1 v1}]
  May 13 17:02:50.976: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
  May 13 17:02:50.976: INFO: Checking APIGroup: policy
  May 13 17:02:50.977: INFO: PreferredVersion.GroupVersion: policy/v1
  May 13 17:02:50.977: INFO: Versions found [{policy/v1 v1}]
  May 13 17:02:50.977: INFO: policy/v1 matches policy/v1
  May 13 17:02:50.977: INFO: Checking APIGroup: rbac.authorization.k8s.io
  May 13 17:02:50.977: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  May 13 17:02:50.977: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
  May 13 17:02:50.977: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  May 13 17:02:50.977: INFO: Checking APIGroup: storage.k8s.io
  May 13 17:02:50.977: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
  May 13 17:02:50.977: INFO: Versions found [{storage.k8s.io/v1 v1}]
  May 13 17:02:50.977: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
  May 13 17:02:50.977: INFO: Checking APIGroup: admissionregistration.k8s.io
  May 13 17:02:50.978: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  May 13 17:02:50.978: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
  May 13 17:02:50.978: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  May 13 17:02:50.978: INFO: Checking APIGroup: apiextensions.k8s.io
  May 13 17:02:50.978: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  May 13 17:02:50.978: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
  May 13 17:02:50.978: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  May 13 17:02:50.978: INFO: Checking APIGroup: scheduling.k8s.io
  May 13 17:02:50.978: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  May 13 17:02:50.978: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
  May 13 17:02:50.978: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  May 13 17:02:50.978: INFO: Checking APIGroup: coordination.k8s.io
  May 13 17:02:50.979: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
  May 13 17:02:50.979: INFO: Versions found [{coordination.k8s.io/v1 v1}]
  May 13 17:02:50.979: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
  May 13 17:02:50.979: INFO: Checking APIGroup: node.k8s.io
  May 13 17:02:50.980: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
  May 13 17:02:50.980: INFO: Versions found [{node.k8s.io/v1 v1}]
  May 13 17:02:50.980: INFO: node.k8s.io/v1 matches node.k8s.io/v1
  May 13 17:02:50.980: INFO: Checking APIGroup: discovery.k8s.io
  May 13 17:02:50.981: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
  May 13 17:02:50.981: INFO: Versions found [{discovery.k8s.io/v1 v1}]
  May 13 17:02:50.981: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
  May 13 17:02:50.981: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
  May 13 17:02:50.981: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  May 13 17:02:50.982: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1 v1} {flowcontrol.apiserver.k8s.io/v1beta3 v1beta3}]
  May 13 17:02:50.982: INFO: flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  May 13 17:02:50.982: INFO: Checking APIGroup: crd.projectcalico.org
  May 13 17:02:50.982: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
  May 13 17:02:50.983: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
  May 13 17:02:50.983: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
  May 13 17:02:50.983: INFO: Checking APIGroup: helm.cattle.io
  May 13 17:02:50.983: INFO: PreferredVersion.GroupVersion: helm.cattle.io/v1
  May 13 17:02:50.983: INFO: Versions found [{helm.cattle.io/v1 v1}]
  May 13 17:02:50.984: INFO: helm.cattle.io/v1 matches helm.cattle.io/v1
  May 13 17:02:50.984: INFO: Checking APIGroup: k3s.cattle.io
  May 13 17:02:50.984: INFO: PreferredVersion.GroupVersion: k3s.cattle.io/v1
  May 13 17:02:50.984: INFO: Versions found [{k3s.cattle.io/v1 v1}]
  May 13 17:02:50.985: INFO: k3s.cattle.io/v1 matches k3s.cattle.io/v1
  May 13 17:02:50.985: INFO: Checking APIGroup: k8s.cni.cncf.io
  May 13 17:02:50.985: INFO: PreferredVersion.GroupVersion: k8s.cni.cncf.io/v1
  May 13 17:02:50.985: INFO: Versions found [{k8s.cni.cncf.io/v1 v1}]
  May 13 17:02:50.985: INFO: k8s.cni.cncf.io/v1 matches k8s.cni.cncf.io/v1
  May 13 17:02:50.986: INFO: Checking APIGroup: snapshot.storage.k8s.io
  May 13 17:02:50.986: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
  May 13 17:02:50.986: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1} {snapshot.storage.k8s.io/v1beta1 v1beta1}]
  May 13 17:02:50.986: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
  May 13 17:02:50.987: INFO: Checking APIGroup: traefik.io
  May 13 17:02:50.987: INFO: PreferredVersion.GroupVersion: traefik.io/v1alpha1
  May 13 17:02:50.987: INFO: Versions found [{traefik.io/v1alpha1 v1alpha1}]
  May 13 17:02:50.987: INFO: traefik.io/v1alpha1 matches traefik.io/v1alpha1
  May 13 17:02:50.988: INFO: Checking APIGroup: whereabouts.cni.cncf.io
  May 13 17:02:50.988: INFO: PreferredVersion.GroupVersion: whereabouts.cni.cncf.io/v1alpha1
  May 13 17:02:50.988: INFO: Versions found [{whereabouts.cni.cncf.io/v1alpha1 v1alpha1}]
  May 13 17:02:50.988: INFO: whereabouts.cni.cncf.io/v1alpha1 matches whereabouts.cni.cncf.io/v1alpha1
  May 13 17:02:50.988: INFO: Checking APIGroup: longhorn.io
  May 13 17:02:50.989: INFO: PreferredVersion.GroupVersion: longhorn.io/v1beta2
  May 13 17:02:50.989: INFO: Versions found [{longhorn.io/v1beta2 v1beta2} {longhorn.io/v1beta1 v1beta1}]
  May 13 17:02:50.989: INFO: longhorn.io/v1beta2 matches longhorn.io/v1beta2
  May 13 17:02:50.989: INFO: Checking APIGroup: metallb.io
  May 13 17:02:50.990: INFO: PreferredVersion.GroupVersion: metallb.io/v1beta2
  May 13 17:02:50.990: INFO: Versions found [{metallb.io/v1beta2 v1beta2} {metallb.io/v1beta1 v1beta1}]
  May 13 17:02:50.990: INFO: metallb.io/v1beta2 matches metallb.io/v1beta2
  May 13 17:02:50.991: INFO: Checking APIGroup: metrics.k8s.io
  May 13 17:02:50.991: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
  May 13 17:02:50.991: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
  May 13 17:02:50.992: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
  May 13 17:02:50.992: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-7479" for this suite. @ 05/13/24 17:02:50.994
• [0.556 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 05/13/24 17:02:50.999
  May 13 17:02:50.999: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename pods @ 05/13/24 17:02:51
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:02:51.009
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:02:51.011
  STEP: creating the pod @ 05/13/24 17:02:51.012
  STEP: submitting the pod to kubernetes @ 05/13/24 17:02:51.013
  STEP: verifying QOS class is set on the pod @ 05/13/24 17:02:51.019
  May 13 17:02:51.025: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9818" for this suite. @ 05/13/24 17:02:51.034
• [0.039 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 05/13/24 17:02:51.038
  May 13 17:02:51.038: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename subpath @ 05/13/24 17:02:51.038
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:02:51.048
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:02:51.049
  STEP: Setting up data @ 05/13/24 17:02:51.051
  STEP: Creating pod pod-subpath-test-configmap-cw5m @ 05/13/24 17:02:51.056
  STEP: Creating a pod to test atomic-volume-subpath @ 05/13/24 17:02:51.056
  E0513 17:02:51.347498      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:52.347197      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:53.347731      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:54.348695      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:55.348732      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:56.349305      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:57.350568      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:58.350252      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:02:59.350719      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:00.351290      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:01.351893      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:02.353733      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:03.353070      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:04.354187      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:05.354807      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:06.355247      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:07.355805      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:08.355953      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:09.356944      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:10.356816      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:11.358061      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:12.357903      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:13.358652      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:14.358803      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/13/24 17:03:15.136
  May 13 17:03:15.143: INFO: Trying to get logs from node oneke-ip-172-16-100-5 pod pod-subpath-test-configmap-cw5m container test-container-subpath-configmap-cw5m: <nil>
  STEP: delete the pod @ 05/13/24 17:03:15.163
  STEP: Deleting pod pod-subpath-test-configmap-cw5m @ 05/13/24 17:03:15.178
  May 13 17:03:15.178: INFO: Deleting pod "pod-subpath-test-configmap-cw5m" in namespace "subpath-1942"
  May 13 17:03:15.179: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-1942" for this suite. @ 05/13/24 17:03:15.182
• [24.147 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 05/13/24 17:03:15.187
  May 13 17:03:15.187: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename events @ 05/13/24 17:03:15.187
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:03:15.198
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:03:15.2
  STEP: creating a test event @ 05/13/24 17:03:15.201
  STEP: listing events in all namespaces @ 05/13/24 17:03:15.203
  STEP: listing events in test namespace @ 05/13/24 17:03:15.207
  STEP: listing events with field selection filtering on source @ 05/13/24 17:03:15.208
  STEP: listing events with field selection filtering on reportingController @ 05/13/24 17:03:15.209
  STEP: getting the test event @ 05/13/24 17:03:15.21
  STEP: patching the test event @ 05/13/24 17:03:15.211
  STEP: getting the test event @ 05/13/24 17:03:15.213
  STEP: updating the test event @ 05/13/24 17:03:15.214
  STEP: getting the test event @ 05/13/24 17:03:15.217
  STEP: deleting the test event @ 05/13/24 17:03:15.218
  STEP: listing events in all namespaces @ 05/13/24 17:03:15.22
  STEP: listing events in test namespace @ 05/13/24 17:03:15.224
  May 13 17:03:15.225: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-4148" for this suite. @ 05/13/24 17:03:15.227
• [0.045 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:125
  STEP: Creating a kubernetes client @ 05/13/24 17:03:15.232
  May 13 17:03:15.232: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 17:03:15.233
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:03:15.244
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:03:15.246
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-3f418ad3-2c0a-4184-a142-6d2a1cb1dd53 @ 05/13/24 17:03:15.25
  STEP: Creating the pod @ 05/13/24 17:03:15.253
  E0513 17:03:15.359294      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:16.360372      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-3f418ad3-2c0a-4184-a142-6d2a1cb1dd53 @ 05/13/24 17:03:17.31
  STEP: waiting to observe update in volume @ 05/13/24 17:03:17.315
  E0513 17:03:17.360421      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:18.360525      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:03:19.325: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9440" for this suite. @ 05/13/24 17:03:19.328
• [4.099 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csistoragecapacity.go:50
  STEP: Creating a kubernetes client @ 05/13/24 17:03:19.333
  May 13 17:03:19.333: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename csistoragecapacity @ 05/13/24 17:03:19.334
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:03:19.344
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:03:19.346
  STEP: getting /apis @ 05/13/24 17:03:19.347
  STEP: getting /apis/storage.k8s.io @ 05/13/24 17:03:19.351
  STEP: getting /apis/storage.k8s.io/v1 @ 05/13/24 17:03:19.351
  STEP: creating @ 05/13/24 17:03:19.352
  STEP: watching @ 05/13/24 17:03:19.36
  May 13 17:03:19.360: INFO: starting watch
  E0513 17:03:19.360739      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting @ 05/13/24 17:03:19.365
  STEP: listing in namespace @ 05/13/24 17:03:19.366
  STEP: listing across namespaces @ 05/13/24 17:03:19.367
  STEP: patching @ 05/13/24 17:03:19.368
  STEP: updating @ 05/13/24 17:03:19.37
  May 13 17:03:19.373: INFO: waiting for watch events with expected annotations in namespace
  May 13 17:03:19.373: INFO: waiting for watch events with expected annotations across namespace
  STEP: deleting @ 05/13/24 17:03:19.373
  STEP: deleting a collection @ 05/13/24 17:03:19.378
  May 13 17:03:19.384: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-9799" for this suite. @ 05/13/24 17:03:19.386
• [0.058 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 05/13/24 17:03:19.396
  May 13 17:03:19.396: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename pods @ 05/13/24 17:03:19.397
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:03:19.408
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:03:19.409
  STEP: creating a Pod with a static label @ 05/13/24 17:03:19.417
  STEP: watching for Pod to be ready @ 05/13/24 17:03:19.421
  May 13 17:03:19.423: INFO: observed Pod pod-test in namespace pods-2790 in phase Pending with labels: map[test-pod-static:true] & conditions []
  May 13 17:03:19.430: INFO: observed Pod pod-test in namespace pods-2790 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:19 +0000 UTC  }]
  May 13 17:03:19.435: INFO: observed Pod pod-test in namespace pods-2790 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:19 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:19 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:19 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:19 +0000 UTC  }]
  May 13 17:03:19.828: INFO: observed Pod pod-test in namespace pods-2790 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:19 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:19 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:19 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:19 +0000 UTC  }]
  May 13 17:03:19.876: INFO: observed Pod pod-test in namespace pods-2790 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:19 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:19 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:19 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:19 +0000 UTC  }]
  E0513 17:03:20.361148      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:03:20.615: INFO: Found Pod pod-test in namespace pods-2790 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:20 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-13 17:03:19 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 05/13/24 17:03:20.618
  STEP: getting the Pod and ensuring that it's patched @ 05/13/24 17:03:20.625
  STEP: replacing the Pod's status Ready condition to False @ 05/13/24 17:03:20.627
  STEP: check the Pod again to ensure its Ready conditions are False @ 05/13/24 17:03:20.636
  STEP: deleting the Pod via a Collection with a LabelSelector @ 05/13/24 17:03:20.636
  STEP: watching for the Pod to be deleted @ 05/13/24 17:03:20.639
  May 13 17:03:20.642: INFO: observed event type MODIFIED
  E0513 17:03:21.361344      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:22.362610      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:03:22.620: INFO: observed event type MODIFIED
  May 13 17:03:22.898: INFO: observed event type MODIFIED
  May 13 17:03:22.961: INFO: observed event type MODIFIED
  E0513 17:03:23.363181      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:03:23.631: INFO: observed event type MODIFIED
  May 13 17:03:23.642: INFO: observed event type MODIFIED
  May 13 17:03:23.646: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2790" for this suite. @ 05/13/24 17:03:23.648
• [4.255 seconds]
------------------------------
SSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:183
  STEP: Creating a kubernetes client @ 05/13/24 17:03:23.652
  May 13 17:03:23.652: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename kubelet-test @ 05/13/24 17:03:23.652
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:03:23.662
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:03:23.664
  E0513 17:03:24.363997      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:25.364610      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:03:25.685: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-5932" for this suite. @ 05/13/24 17:03:25.688
• [2.044 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:155
  STEP: Creating a kubernetes client @ 05/13/24 17:03:25.713
  May 13 17:03:25.713: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename var-expansion @ 05/13/24 17:03:25.714
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:03:25.725
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:03:25.726
  E0513 17:03:26.364513      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:27.365925      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:03:27.742: INFO: Deleting pod "var-expansion-6b91a346-5ea6-44fb-9e41-6653a8d8900b" in namespace "var-expansion-2940"
  May 13 17:03:27.753: INFO: Wait up to 5m0s for pod "var-expansion-6b91a346-5ea6-44fb-9e41-6653a8d8900b" to be fully deleted
  E0513 17:03:28.365589      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:29.366886      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:03:29.757: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-2940" for this suite. @ 05/13/24 17:03:29.76
• [4.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:241
  STEP: Creating a kubernetes client @ 05/13/24 17:03:29.766
  May 13 17:03:29.766: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename configmap @ 05/13/24 17:03:29.767
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:03:29.775
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:03:29.777
  STEP: Creating configMap with name cm-test-opt-del-632c126e-0ff1-4752-b372-fa635be7862c @ 05/13/24 17:03:29.78
  STEP: Creating configMap with name cm-test-opt-upd-22bb7923-743d-4402-9ce8-09c087f1f09d @ 05/13/24 17:03:29.783
  STEP: Creating the pod @ 05/13/24 17:03:29.784
  E0513 17:03:30.366853      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:31.367088      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-632c126e-0ff1-4752-b372-fa635be7862c @ 05/13/24 17:03:31.834
  STEP: Updating configmap cm-test-opt-upd-22bb7923-743d-4402-9ce8-09c087f1f09d @ 05/13/24 17:03:31.838
  STEP: Creating configMap with name cm-test-opt-create-f38799ff-d94f-45f7-830b-1922427e606e @ 05/13/24 17:03:31.843
  STEP: waiting to observe update in volume @ 05/13/24 17:03:31.846
  E0513 17:03:32.369887      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:33.370299      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:34.370366      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:35.371509      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:03:35.881: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3147" for this suite. @ 05/13/24 17:03:35.884
• [6.125 seconds]
------------------------------
S
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:177
  STEP: Creating a kubernetes client @ 05/13/24 17:03:35.892
  May 13 17:03:35.892: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename replicaset @ 05/13/24 17:03:35.893
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:03:35.912
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:03:35.915
  STEP: Create a Replicaset @ 05/13/24 17:03:35.92
  STEP: Verify that the required pods have come up. @ 05/13/24 17:03:35.924
  May 13 17:03:35.927: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0513 17:03:36.371675      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:37.372014      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:38.371980      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:39.372575      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:40.372533      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:03:40.945: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/13/24 17:03:40.946
  STEP: Getting /status @ 05/13/24 17:03:40.946
  May 13 17:03:40.952: INFO: Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 05/13/24 17:03:40.953
  May 13 17:03:40.965: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 05/13/24 17:03:40.965
  May 13 17:03:40.967: INFO: Observed &ReplicaSet event: ADDED
  May 13 17:03:40.967: INFO: Observed &ReplicaSet event: MODIFIED
  May 13 17:03:40.967: INFO: Observed &ReplicaSet event: MODIFIED
  May 13 17:03:40.976: INFO: Observed &ReplicaSet event: MODIFIED
  May 13 17:03:40.976: INFO: Found replicaset test-rs in namespace replicaset-9909 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  May 13 17:03:40.976: INFO: Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 05/13/24 17:03:40.978
  May 13 17:03:40.978: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  May 13 17:03:40.990: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 05/13/24 17:03:40.99
  May 13 17:03:40.992: INFO: Observed &ReplicaSet event: ADDED
  May 13 17:03:40.992: INFO: Observed &ReplicaSet event: MODIFIED
  May 13 17:03:40.993: INFO: Observed &ReplicaSet event: MODIFIED
  May 13 17:03:40.993: INFO: Observed &ReplicaSet event: MODIFIED
  May 13 17:03:40.994: INFO: Observed replicaset test-rs in namespace replicaset-9909 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  May 13 17:03:40.994: INFO: Observed &ReplicaSet event: MODIFIED
  May 13 17:03:40.994: INFO: Found replicaset test-rs in namespace replicaset-9909 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  May 13 17:03:40.994: INFO: Replicaset test-rs has a patched status
  May 13 17:03:40.995: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-9909" for this suite. @ 05/13/24 17:03:40.999
• [5.118 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 05/13/24 17:03:41.01
  May 13 17:03:41.010: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 05/13/24 17:03:41.012
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:03:41.024
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:03:41.03
  STEP: Setting up the test @ 05/13/24 17:03:41.032
  STEP: Creating hostNetwork=false pod @ 05/13/24 17:03:41.032
  E0513 17:03:41.374635      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:42.375351      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating hostNetwork=true pod @ 05/13/24 17:03:43.049
  E0513 17:03:43.375083      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:44.376319      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Running the test @ 05/13/24 17:03:45.076
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 05/13/24 17:03:45.077
  May 13 17:03:45.077: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2934 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 17:03:45.078: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 17:03:45.080: INFO: ExecWithOptions: Clientset creation
  May 13 17:03:45.081: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2934/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  May 13 17:03:45.169: INFO: Exec stderr: ""
  May 13 17:03:45.169: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2934 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 17:03:45.169: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 17:03:45.170: INFO: ExecWithOptions: Clientset creation
  May 13 17:03:45.170: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2934/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  May 13 17:03:45.219: INFO: Exec stderr: ""
  May 13 17:03:45.219: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2934 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 17:03:45.219: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 17:03:45.220: INFO: ExecWithOptions: Clientset creation
  May 13 17:03:45.220: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2934/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  May 13 17:03:45.269: INFO: Exec stderr: ""
  May 13 17:03:45.269: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2934 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 17:03:45.269: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 17:03:45.270: INFO: ExecWithOptions: Clientset creation
  May 13 17:03:45.270: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2934/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  May 13 17:03:45.319: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 05/13/24 17:03:45.319
  May 13 17:03:45.319: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2934 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 17:03:45.319: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 17:03:45.320: INFO: ExecWithOptions: Clientset creation
  May 13 17:03:45.320: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2934/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  May 13 17:03:45.366: INFO: Exec stderr: ""
  May 13 17:03:45.366: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2934 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 17:03:45.366: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 17:03:45.367: INFO: ExecWithOptions: Clientset creation
  May 13 17:03:45.367: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2934/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  E0513 17:03:45.376862      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:03:45.424: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 05/13/24 17:03:45.424
  May 13 17:03:45.424: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2934 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 17:03:45.424: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 17:03:45.425: INFO: ExecWithOptions: Clientset creation
  May 13 17:03:45.425: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2934/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  May 13 17:03:45.478: INFO: Exec stderr: ""
  May 13 17:03:45.478: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2934 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 17:03:45.478: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 17:03:45.478: INFO: ExecWithOptions: Clientset creation
  May 13 17:03:45.478: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2934/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  May 13 17:03:45.523: INFO: Exec stderr: ""
  May 13 17:03:45.523: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2934 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 17:03:45.524: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 17:03:45.524: INFO: ExecWithOptions: Clientset creation
  May 13 17:03:45.524: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2934/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  May 13 17:03:45.571: INFO: Exec stderr: ""
  May 13 17:03:45.571: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2934 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 13 17:03:45.571: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  May 13 17:03:45.572: INFO: ExecWithOptions: Clientset creation
  May 13 17:03:45.572: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2934/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  May 13 17:03:45.623: INFO: Exec stderr: ""
  May 13 17:03:45.623: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-2934" for this suite. @ 05/13/24 17:03:45.626
• [4.619 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:164
  STEP: Creating a kubernetes client @ 05/13/24 17:03:45.631
  May 13 17:03:45.631: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename projected @ 05/13/24 17:03:45.632
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:03:45.642
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:03:45.643
  STEP: Creating the pod @ 05/13/24 17:03:45.645
  E0513 17:03:46.377400      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:47.378698      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:03:48.190: INFO: Successfully updated pod "annotationupdate208e1b94-6266-4d2d-a437-02b0465898fc"
  E0513 17:03:48.378492      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:49.379528      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:50.380101      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:51.379877      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:03:52.213: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-918" for this suite. @ 05/13/24 17:03:52.219
• [6.591 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 05/13/24 17:03:52.226
  May 13 17:03:52.227: INFO: >>> kubeConfig: /tmp/kubeconfig-3236183377
  STEP: Building a namespace api object, basename sched-preemption @ 05/13/24 17:03:52.235
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/13/24 17:03:52.247
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/13/24 17:03:52.249
  May 13 17:03:52.264: INFO: Waiting up to 1m0s for all nodes to be ready
  E0513 17:03:52.380568      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:53.380823      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:54.381004      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:55.381235      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:56.382170      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:57.383098      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:58.383540      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:03:59.383921      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:00.384563      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:01.384761      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:02.385088      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:03.385236      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:04.385815      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:05.387222      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:06.387642      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:07.387840      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:08.387899      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:09.388247      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:10.406965      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:11.408336      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:12.410819      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:13.410801      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:14.411332      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:15.412073      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:16.412027      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:17.412309      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:18.412671      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:19.413870      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:20.414805      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:21.415132      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:22.415926      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:23.415957      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:24.416992      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:25.417421      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:26.417539      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:27.417837      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:28.418073      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:29.418502      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:30.419598      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:31.419181      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:32.419691      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:33.419675      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:34.420294      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:35.421174      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:36.421356      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:37.422422      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:38.422915      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:39.423202      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:40.424489      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:41.425452      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:42.426147      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:43.426202      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:44.427073      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:45.428099      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:46.428226      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:47.429446      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:48.429129      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:49.429363      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:50.429732      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:51.429799      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:04:52.275: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 05/13/24 17:04:52.279
  May 13 17:04:52.298: INFO: Created pod: pod0-0-sched-preemption-low-priority
  May 13 17:04:52.308: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  May 13 17:04:52.323: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  May 13 17:04:52.330: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 05/13/24 17:04:52.33
  E0513 17:04:52.430572      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:53.430659      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 05/13/24 17:04:54.37
  E0513 17:04:54.431003      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:55.433546      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:56.434084      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:57.435218      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:58.435958      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:04:59.435903      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0513 17:05:00.439430      17 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 13 17:05:00.457: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-2833" for this suite. @ 05/13/24 17:05:00.46
• [68.239 seconds]
------------------------------
SSSSSS
------------------------------
[SynchronizedAfterSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:88
  May 13 17:05:00.466: INFO: Running AfterSuite actions on node 1
  May 13 17:05:00.467: INFO: Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.001 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
k8s.io/kubernetes/test/e2e/e2e_test.go:161
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
k8s.io/kubernetes/test/e2e/framework/test_context.go:621
[ReportAfterSuite] PASSED [0.037 seconds]
------------------------------

Ran 388 of 7407 Specs in 6185.376 seconds
SUCCESS! -- 388 Passed | 0 Failed | 0 Pending | 7019 Skipped
PASS

Ginkgo ran 1 suite in 1h43m6.578953028s
Test Suite Passed
